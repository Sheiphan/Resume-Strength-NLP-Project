{"Job Description":{"0":"Our Mission\nTo restore cell health and resilience through cellular rejuvenation programming to reverse disease, injury, and the disabilities that can occur throughout life.\nFor more information, see our website at altoslabs.com.\nDiversity at Altos\nWe believe that diverse perspectives are foundational to scientific innovation and inquiry. \nWe are building a company where exceptional scientists and industry leaders from around the world work side by side to advance a shared mission. \nOur intentional focus is on Belonging, so that all employees know that they are valued for their unique perspectives. \nAt Altos, we are all accountable for sustaining a diverse and inclusive environment.\nResponsibilities\nDevelop new statistical and machine learning-based methods for querying biological data to produce insights about cell health and rejuvenation.\nTrain and optimize machine learning models on large, complex datasets.\nPartner with experimental biologists across Altos to help design experiments and interpret their results.\nBring computational thinking to bear on Altos\u2019 mission and challenges, ranging from modeling biological phenomena to supporting the research process and culture at Altos through computation and AI.\nExcitement about the Altos mission of investigating cellular rejuvenation programming to restore cell health and resilience.\nQualifications\nPhD in Computational Biology or related fields.\nExperience with machine learning and deep learning models applied to biological data.\nStrong understanding of machine learning concepts, including model training, generalization and optimization.\nStrong programming skills in R and Python.\nExperience with deep learning libraries such as TensorFlow or PyTorch.\nWorking knowledge of cellular and molecular biology.\nTrack record of analysis of -omics data (RNA expression, chromatin accessibility, DNA methylation, etc.).\nBonus: Experience in cell health and rejuvenation related research area.\nBonus: Proven track record in open-source software development, e.g., demonstrated by high-impact github repository.\nBonus: Proven track record of high-caliber scientific work, e.g., demonstrated through publications in peer-reviewed scientific journals.\nThe job ranges for this position are: Scientist I \u00a351,850 to \u00a370,150; Scientist II \u00a361,000 to \u00a391,800; Senior Scientist \u00a368,000 to \u00a3130,980\n  #LI-LY1\n What We Want You To Know\nWe are a culture of collaboration and scientific freedom, and we believe in the values of diversity, inclusion and belonging to inspire innovation.\nAltos Labs provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. \nThis policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. \nAltos currently requires all employees to be fully vaccinated against COVID-19, subject to legally required exemptions (e.g., due to a medical condition or sincerely-held religious belief).\nThank you for your interest in Altos Labs where we strive for a culture of scientific freedom, learning, and belonging.\nNote: Altos Labs will not ask you to download a messaging app for an interview or outlay your own money to get started as an employee. If this sounds like your interaction with people claiming to be with Altos, it is not legitimate and has nothing to do with Altos. Learn more about a common job scam at https:\/\/www.linkedin.com\/pulse\/how-spot-avoid-online-job-scams-biron-clark\/","1":"Company Description\nREFID276761\nAt NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking for a Senior Big Data Software Engineer to join our ciValue Technology team in Israel.\nThe ciValue division of NIQ is a leading provider of AI-powered customer analytics, personalization, and brand collaboration platform. Serving dozens of retailers and brands across the world using cutting-edge big-data, real-time analytics, and data-science automation. Our solution is disrupting existing data & media monetization model by enabling retailers to remain in control of their revenue.\nJob Description\nWe believe that building a great product and teams starts with amazing, diverse-minded, and bright people who make an impact, generate creative & innovative ideas, and take on new perspectives.\u202f \nThe Big Data Software Engineer is responsible for building new data solutions for our rapidly expanding customer base and working with the top data ingestion technologies in an open, collaborative, and innovative environment. \nResponsibilities\nBe responsible for Data flow stages from definition to architecture, including Data acquisition, Data set acceptance criteria and Data Science integration. \nArchitecture designing and customizing technological solutions for large-scale data processing. \nDevelop and deploy real-time and batch data processing infrastructures and pipelines. \nTake responsibility to explore technologies to scale up the Data ecosystem to handle rapid Big Data growth. \nWork closely with the Data Science team to embed ML \/ AI algorithms into the product.\nWork with cloud, DevOps, application, and client teams to make sure your solution is solving significant business problems in a robust, scalable manner. \nUse cutting-edge technologies: Python, Airflow, Java, Kubernetes, Spark, Scala, and Kafka.\nQualifications\n4+ years of backend engineering work experience in production environments (Data environments, Big Data processing, Database techniques). \nExperience in Big Data \u2013 Spark \/ Kafka \/ Flink. \nProven experience with Python and Java\/Scala.\nExperience in the design and development of scalable Big Data solutions.\nExperience working with SQL & NO-SQL Databases \u2013 PostgreSQL, DataLake, Columnar DB.\nExperience in Kubernetes, containers & Helm is a plus.\nAbility to learn new technologies and work in a dynamic fast-paced environment.\nResult-driven, pragmatic, and innovative. \nExperience with Cloud technology is an advantage.\nExcellent English communication skills spoken and written. \nBachelor's or Master\u2019s degree in Computer Science, Computer Engineering, or a related field.\nAdditional Information\n#LI-SG\nAbout NIQ\nNIQ, the world\u2019s leading consumer intelligence company, reveals new pathways to growth for retailers and consumer goods manufacturers. With operations in more than 100 countries, NIQ delivers the most complete and clear understanding of consumer buying behavior through an advanced business intelligence platform with integrated predictive analytics. NIQ delivers the Full View. \nNIQ was founded in 1923 and is an Advent International portfolio company. For more information, visit NIQ.com \nWant to keep up with the latest updates on our business and #LifeAtNIQ? Follow us on: LinkedIn | Instagram | Twitter | Facebook\nOur commitment to Diversity, Equity, and Inclusion\nNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us.\nWe are proud to be an Equal Opportunity\/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide.\nLearn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https:\/\/nielseniq.com\/global\/en\/news-center\/diversity-inclusion\/\nNIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process.","2":"What if\u2026 you could join an organization that creates, resources, and builds life sciences companies that invent breakthrough technologies in order to transform health care and sustainability?\nMetaphore Biotechnologies is an early-stage biotechnology company with an ambitious and exciting mission: to reimagine drug discovery and vaccine design. The company is developing a first-in-class platform for the intelligent design of molecular mimicry. Our platform integrates massively parallel assays with machine-learning-guided protein engineering to navigate the combinatorial space of molecular interactions and design protein-protein interfaces with exquisite precision.\nMetaphore Biotechnologies is a product of Flagship Pioneering's venture creation engine, which has also given rise to companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune\u2019s \u201cChange the World\u201d list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies.\nPosition Summary:\nMetaphore Biotechnologies is seeking an enthusiastic Senior Scientist to join our Computational Biology team and accelerate the design of protein-protein interfaces.  In this role, you will collaborate closely with members of the Computational Biology and Protein Engineering teams to advance our use of next-generation sequencing-based mutational assays to characterize and engineer molecular interactions.  Your scientific-rigor and creativity will advance our platform, unlocking the potential of molecular mimicry for therapeutic development.  The ideal candidate will bring experience in mutational screening, bioinformatic pipelines design and analysis, and experience implementing robust data standards.  This individual will have the opportunity to join a dynamic interdisciplinary team working at the interface of computational biology, protein engineering, functional genomics and machine learning.\nThe candidate will also have an extraordinary opportunity to be part of the Flagship ecosystem of companies, providing unique networking benefits through regular meetups, collaboration, and an environment of development and discussion around new ideas shaping the fields of computational biology and ML\/AI.\nKey Responsibilities:\nProvide scientific and technical expertise in the analysis and interpretation of NGS-based mutational screens.\nContribute to the continuous development of scientifically rigorous next-generation sequencing (NGS) pipelines.\nDevelop and implement computational frameworks to derive biological insights from data, such as mapping key residues for molecular interactions and estimating interaction kinetics.\nCollaborate on experimental design to establish and maintain high data quality standards and confidence in results.\nLeverage internal and external datasets to aid in interpretation and further develop our ML-guided protein engineering platform.\nCollaborate with computational and experimental scientists and engineers to execute on company goals.\nCommunicate insights and conclusions to scientific colleagues and the leadership team.\nQualifications:\nPhD or equivalent, plus 3+ years of experience in computational biology, bioinformatics, or a related field.\nExperience developing robust quantitative NGS-based pipelines in a cloud platform.  Familiarity with AWS, docker and snakemake is a plus.\nExperience with screening or highly parallel protein engineering workflows is highly desired.\nPrior experience in automated noise thresholding is a plus.\nVery strong programming skills in python and knowledge of software development best practices.\nExcellent communication skills and capable of clearly conveying technical information.\nExperience collaborating with wet lab scientists to jointly execute on goals.\nStrong organization and problem-solving skills.\nExperience with machine learning of biomolecules is a plus.\nFlagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.\nRecruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, \u201cFSP\u201d) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering\u2019s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.","3":"Company Description\nDynatrace exists to make the world\u2019s software work perfectly. Our unified software intelligence platform combines broad and deep observability and continuous runtime application security with the most advanced AIOps to provide answers and intelligent automation from data at an enormous scale. This enables innovators to modernize and automate cloud operations, deliver software faster and more securely, and ensure flawless digital experiences. That is why the world\u2019s largest organizations trust Dynatrace\u00ae to accelerate digital transformation.\u202f \nWe're an equal opportunity employer and embrace all applicants. Dynatrace wants YOU\u2014your diverse background, talents, values, ideas, and expertise. These qualities are what make our global team stronger and more seasoned. We're fueled by the diversity of our talented employees.\u202f \nJob Description\nDeveloping the Dynatrace Software Intelligence Solution in Java (Apache Spark, Apache Kafka, Lucene, Kubernetes, Git, Jenkins, Eclipse\/IntelliJ)\nBackend\u202fspecialization (big data, cluster technologies, horizontal scale, storage, analytics) \nIndependent design and implementation of the Dynatrace Platform\nCollaborate with local and international development teams\nQualifications\nTechnical study related to Software Engineering\nA minimum of 5 years experience in Java development, including architectural design\nExcited to learn new technologies\nTeamplayer with proactive approach\nAdditional Information\nA one-product software company creating real value for the largest enterprises and millions of end customers globally, striving for a world where software works perfectly. \nWorking with the latest technologies and at the forefront of innovation in tech on scale; but also, in other areas like marketing, design, or research. \nWorking models that offer you the flexibility you need, ranging from full remote options to hybrid ones combining home and in-office work. \nA team that thinks outside the box, welcomes unconventional ideas, and pushes boundaries.  \nAn environment that fosters innovation, enables creative collaboration, and allows you to grow. \nA globally unique and tailor-made career development program recognizing your potential, promoting your strengths, and supporting you in achieving your career goals.  \nA truly international mindset with Dynatracers from different countries & cultures all over the world, and English as the corporate language that connects us all\u202f \nA culture that is being shaped by the diverse personalities, expertise, and backgrounds of our global team.\u202f\u202f\u202f \nA relocation team that is eager to help you start your journey to a new country, always there to support and by your side.\u202f If you need to relocate for a position you are applying for, we offer you a relocation allowance and support with your visa, work permit, accommodation, language courses, as well as a dedicated buddy program.\u202f \nCompensation and rewards\nAttractive compensation packages and stock purchase options with numerous benefits and advantages. \nDue to legal reasons we are obliged to disclose the minimum salary for this position, which is \u20ac 56,000 gross per year based on full-time employment (38.5 h\/week). We offer a higher salary in line with qualifications and experience.","4":"Definitive Logic has a unique opportunity for a Business Intelligence (BI) Solution Developer to join our tightly knit team supporting the implementation and deployment of a Cloud software solution. We are an\u202faward-winning\u202fcompany that cares about its customers and its employees, and we are a recognized consulting leader in Corporate Performance Management services. \u202fWe offer great benefits, a casual work environment, volunteer hours to help the community, and training. \u202fIf you want to work with a great team that provides growth and training opportunities, we want to talk with you.  We are only looking for people who want to join our team as regular, full-time employees. \u202fWe want to continue building our corporate knowledge and invest in making our employees the best in the business.\nRoles and Responsibilities include but not limited the following:\nApply standard industry practices and methodologies to develop, deploy, and maintain BI interfaces, those include query tools, data visualization and interactive dashboards, ad hoc reporting, and data warehousing tools\nBackground development data solutions and can operate in a fast paced, highly collaborative environment\nAssist in the development of dashboards and other data visualizations\nAssist in all conversion, design, and training activities throughout program planning and execution\nRequired Qualifications\nBachelor's degree or higher in Computer Science, Engineering, Information Systems, Mathematics, Business, Accounting or related degree\nExperience consulting or delivering solutions to federal clients\nMinimum of 8 years of work experience in a technical field with at least 2 years of hands-on experience with BI platforms to include Tableau, Microsoft Power BI, Qlik, etc\nThe ability to obtain a DoD Secret Security Clearance\nDesired Qualifications\nGeneral knowledge of federal financial management processes and requirements\nSQL experience with Oracle databases or SQL Server, or other industry standard DB platforms\nTableau development experience\nExperience working with Redshift, AWS or other Cloud Platforms\nActive DoD Secret Clearance\nAbout Definitive Logic Definitive Logic (DL) is a management and technology consulting firm known for delivering outcomes and ROI for agencies\u2019 most complex business challenges.\u202f DL delivers performance-based and outcome-driven technology consulting solutions that directly support the strategic intent of our Defense, Homeland Security, Emergency Management, Federal Civilian and Commercial clients. We\u2019re the preferred technology integration partner for Federal agencies to apply the best of data science, app dev, DevSecOps, cyber and cloud solutions to improve decision support, empower front-line employees and enhance back-office operations. We serve as trusted advisors providing objective, fact-based, vendor & technology-neutral consulting services.  Definitive Logic is ultimately a team of problem solvers \u2014 thought leaders, domain experts, coders, data enthusiasts, and technophiles.\u202f Our exciting projects and learning and sharing culture have consistently resulted in validation as a Great Place to Work: 2023 Washington Post Top Workplaces\u202f(8-time winner) | 2023 Virginia Best Places to Work\u202f(10 years running, #1 midsize in 2019). \nDefinitive Logic is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity\/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class.\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable, or limited in your ability, to use or access our Careers page: https:\/\/www.definitivelogic.com\/careers\/open-opportunities\/ as a result of your disability. You can request a reasonable accommodation by sending an e-mail to Recruiting@DefinitiveLogic.com or via phone: 703-955-4186. In order to quickly respond to your request, please use the words \"Accommodation Request\" as your e-mail subject line.\nDL BenefitsHealthDentalVisionLife\/AD&D: Company paid STD\/LTD:Company paidSupplemental Plans: TriCare Supplement, Pet Insurance through Nationwide, Legal Resources and hospital\/accidental indemnity plans and Wellness initiatives. Compensation Benefits:Competitive Base SalaryAnnual performance based bonus401(k) & Roth option: You are fully (100%) vested on day 1 and DL matches up to 5%Spot Bonuses Referral Bonuses Additional Benefits:Flexible Time Off (FTO): Under our FTO plan, there is no cap in the amount of leave you choose to take, with proper coordination and prior approval.Volunteer Hours: DL allocates up to 8 hours for you to use every year to volunteer for a 501c3 organization of your choice and DL will donate to that charity based on how many hours you volunteer.Cell Phone Reimbursement: $80\/monthLocation Specific Metro\/Parking Tuition Reimbursement Training & Certifications","5":"Company Description\nExperian is the world\u2019s leading global information services company. During life\u2019s big moments \u2014 from buying a home or a car to sending a child to college to growing a business by connecting with new customers \u2014 we empower consumers and our clients to manage their data with confidence. We help individuals to take financial control and access financial services, businesses to make smarter decisions and thrive, lenders to lend more responsibly, and organizations to prevent identity fraud and crime.\nWe have 17,800 people operating across 44 countries, and every day we\u2019re investing in new technologies, talented people and innovation to help all our clients maximize every opportunity. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index.\nLearn more at www.experianplc.com or visit our global content hub at our global news blog for the latest news and insights from the Group\nExperian is the world\u2019s leading global information services company. During life\u2019s big moments \u2014 from buying a home or a car to sending a child to college to growing a business by connecting with new customers \u2014 we empower consumers and our clients to manage their data with confidence. We help individuals to take financial control and access financial services, businesses to make smarter decisions and thrive, lenders to lend more responsibly, and organizations to prevent identity fraud and crime.\nWe have 17,800 people operating across 44 countries, and every day we\u2019re investing in new technologies, talented people and innovation to help all our clients maximize every opportunity. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index.\nLearn more at www.experianplc.com or visit our global content hub at our global news blog for the latest news and insights from the Group\nJob Description\nAs a key aide to both the IT Infrastructure and Development teams, we are looking for an individual, who can lead a team of Big Data Platform Engineers supporting data management platforms globally. This is an exciting opportunity to come and work in a company that develops many solutions involving data platforms at their core. The candidate will be responsible for managing data platform environments and engineers to maintain, optimize, develop, and integrate working solutions for our big data, relational and No SQL data management technologies. To support the product development process in line with the product roadmap for product maintenance and enhancement such that the quality of software deliverables maintains excellent customer relationships and increases the customer base. \n\nThe ideal candidate will have a strong track record of leadership and influence. This individual will be driving the data platforms support for the company\u2019s web, online, and batch systems which are critical for delivering business results. Candidate must have demonstrated not only an ability to lead and motivate a team of direct reports, but also can drive change across a broader organization. Candidate will be responsible for team mentoring, training, forecasting and goal setting for the staff. \n \nAn overall experience of big data platforms, databases is required. Candidate should have a mastery of a wide range of Big Data, database architectures for 24\/7 transactional and batch systems. An ideal candidate would also have prior experience in administering cloud data management systems preferably, but an added plus would be experience in embracing cloud native principles (12-factor concepts etc.) such as AWS EMR platforms. A major plus is experience in data warehouse designing, master data management, unstructured data and metadata management.  \n If you have the skills and \u201ccan do\u201d attitude, we would love to talk to you! \n What you\u2019ll be doing  \nResponsible for implementation and ongoing administration of Data Platforms in hybrid environments On-premises\/Co-Lo\/Cloud \nHands-on Technical leader working with your team, including participating in on call rotation with your team \nProvide technical leadership to build high-quality performant big data platform solutions that scale well conforming to internal and industry enterprise standards \nManage engineering teams and drive new initiatives in a fast-paced environment, embrace cloud native principles (12-factor concepts, and similar), automation, CI\/CD, including a coding skillset. \u202f \nBring a DevOps mindset to enable big data and batch\/real-time analytical solutions that leverage emerging technologies \nEnsure team members follow software development life cycle \u201cSDLC\u201d (branch\/release strategies, peer review and merge practices, CI and CD pipelines) practices so that solutions meet specified requirements (e.g., business requirements, company enterprise standards, quality, availability and performance expectations) \nManage coding practices such as SQL, Python, Scala etc. across data management platforms \nManage internal and external dependencies, collaborate with stakeholders and product managers, operations, customer research teams to deliver business objectivities \nMaintain and improve existing codebases and contribute technically to the overall engineering processes followed in Connected Technologies \nReview, design and vet architecture, system design to solve complex distributed system problems with scale and security \nCollaborate with Senior Management, Product Managers, Tech Leads etc. and help build backlogs for product \nIdentify and encourage adoption of new technologies, tools, processes for the organization as needed \nUnblock Engineers and ensure project milestones are met \nRecruit top talent and scale team\/s, conduct performance reviews for software engineers \nEstablish and monitor objectives for all employees by providing regular feedback, coaching, training and development that fosters both personal and organizational growth \nDevelop a team-oriented, supportive culture with a strong focus on creating a working environment that fosters creativity and open communication, as well as one that demands discipline and results \nBuild a first-class Engineering team that will scale as the company and business grows, identifying and filling any organizational gaps \nContinually strengthen and simplify the engineering ecosystem \nQualifications\nTypically requires a bachelor's degree (in Computer Science or related field) or equivalent. \n5+ years of proven experience in data management platform engineering, including leading high-performance teams \n10+ years of experience with software backend systems, architectures, infrastructure, especially cross-platform, cloud native Hadoop systems. \nStrong Data management platforms design and development experience for very large enterprises \nExpert Level in designing and implementing large scale data platform systems catering to consumer products with Hadoop distribution both hybrid and cloud native platforms \nExpert level in managing coding practices such as SQL, Python, Scala etc. across data management platforms \nExpert level in AWS systems such as ECS, EMR, RDS etc. leveraging terraform for data platform automation. \nProven experience designing and scaling relational databases \nExpert level in non-relational databases such as HBase, Redis, DynamoDB etc. \nExpert level working in a data-driven culture to improve the efficiency of continuous deliver, scalability, stability, and security of software \nExpert level in agile framework (Scrum, Kanban etc.), facilitation, and consensus-building skills to mediate priority conflicts in an effective and collaborative manner \nContinuously build and test code using tools like Jenkins \nExpert level in building highly scalable distributed data platforms and processes in Cloud environment IaaS\/PaaS. \nExpert level in recruiting and managing technical teams, including performance management \nExpert level in working with Engineering teams, product management, and Architecture teams to define product strategy \nDemonstrated success influencing senior level stakeholders on strategic direction based on recommendations backed by in-depth analysis \nBring a strong perspective that inspires change and motivates engineers to develop simple solutions to hard problems \nAbility to adapt to multi-lingual and multicultural environment, additional language skills are a bonus. \nExperience working with geographically distributed teams \nHigh energy, confidence, and ambition--someone who can consistently perform at the highest level  \nAdditional Information\nExperian Careers - Creating a better tomorrow together\nFind out what its like to work for Experian by clicking here","6":"Company Description\nBosch Global Software Technologies Private Limited (BGSW) is a 100% owned subsidiary of Robert Bosch GmbH. We are one of the world\u2019s leading global suppliers of technology and services, offering end-to-end Engineering, IT, and Business Solutions.\nWith a global footprint and presence in US, Europe, Japan, China, and the Asia Pacific region, we are at the forefront of designing, developing, and executing IoT ecosystems through our all-encompassing capability within the 3 aspects of IoT \u2013 Sensors, Software, and Services.\nWe have always focused on improving the quality of the life of people, providing newer revenue-generating opportunities, and improving operational efficiencies for enterprises through an array of solutions. With our unique ability to offer end-to-end solutions that connect Sensors, Software, and Services, we enable businesses to move from the traditional to digital or improve businesses by introducing a digital element in their products and processes.\nJob Description\n\u00b7        Passionate about data and how it can make a difference?\n\u00b7        Interested in learning how to create a strategy and execute the same?\n\u00b7        Want to be part of a vibrant global Power BI community with some of the most passionate people?\n\u00b7        Committed to making a difference with a role with vast opportunities to grow and excel?\nIf your answer to all above questions is \u201cYes\u201d, then the role is for you! We are looking for passionate and dynamic associate who want to be part of this exciting journey.\nWhat you\u2019ll do?\nYou will work as part of our global DevOps teams to provide data solutions for our internal customers across the globe. In collaboration with our product owners and business experts you will create and improve Power BI Reports and meaningful Premium Data Sets. You will be able to explore the full world of our business data platform to generate insights and derive actions. You will be responsible to drive continuous improvement engagements and be part of a problem-solving culture\nTake responsibility: You will work with our internal customers and international team of developers to design and implement Power BI Reports and Power BI Premium Datasets.\nHelp shape the future: As an employee of the global cross-functional Business Intelligence team (xBI), you will work on the future steering of Bosch.\nUse freedom and creativity: We live agile values so that you can contribute your ideas and experiences for the benefit of the team and the company.\nThink entrepreneurially: As part of the leading in-house provider for data and analytics-based solutions within Bosch, you will experience the start-up spirit with us and make your contribution through entrepreneurial thinking and acting.\nLive Cooperation: You will work in an interdisciplinary and international team supported by internal and external service providers as well as in direct exchange with our internal customers.\nPersonality: Team player, committed, responsible and flexible\nQualifications\nEducation: Graduate \/ Postgraduate in Engineering (preferably Computer Science) \/ MBA \/ MCA  \nExperience: 5+ years of experience working as a Power BI developer (rare exceptions for highly skilled developers). Professional experience in the field of BI and Data Warehouse. Working knowledge of Microsoft BI and Azure stack. Prolific experience with data analytics and data warehousing environments. Experience in translating business requirements into set of analytical tasks.\nWay of working: Agile, analytical, proactive, result, solution-oriented and high code\/solution quality.\nAdditional Information\nKnow-How:\n\u00b7        Collection and analysis of complex requirements and creation of solution concepts\n\u00b7        Ability to tackle complex problems independently or by collaborating with other team members\n\u00b7        Conception and implementation of data analysis, data strategies and visualizations\n\u00b7        Working knowledge on how to extract data from SQL, transform data through SQL backend, Power Query, DAX.\n\u00b7        Familiarity with BI concepts such as ETL design, analytics, and reporting\n\u00b7        Excellent troubleshooting and analytical skills\n\u00b7        Experience in DAX queries, Power BI, Building Analysis Services tabular models (SSAS)\n\u00b7        Solid understanding of data warehousing concepts including the common schema architectures, dimensions, facts, aggregate facts, and data marts. Data Vault knowledge and Azure certificates will be beneficial.\n\u00b7        Certification in Power BI will be an added advantage\n\u00b7        Good understanding of Agile and leveraging Agile to deliver consistent business results\nEnthusiasm: Passion for data, data solutions and its integration, developing interdisciplinary approaches and products for customers and presenting complex issues in a simple manner\nLanguages: Fluent in English, written and spoken to collaborate with developers and communicate with customers.","7":"Company Description\nOcorian is a global leader in corporate and fiduciary services, fund administration and capital markets. Wherever our clients hold financial interests, or however they are structured, we provide compliant, tailored solutions that are individual to their needs.\nWe manage over 17,000 structures for 8000+ clients with a global footprint operating from 18 locations. Our scale offers all our people great opportunities to develop their knowledge and skills and to progress their careers.\nJob Description\nPurpose of the job\nTo assist in the development of business intelligence and management information solutions for Ocorian taking information from the financial, HR, corporate administration systems, and Cloud-based solutions to create a reporting base for the business, the single source of truth\nDelivery of key dashboards and reporting requirements from the BI\/MI solutions with appropriate robust security models\nAssist with data cleansing and data loading exercises, which may extend to jurisdictional and regulatory filing requirements\nDocumentation of solutions, handover to BAU Teams, and supporting solutions\nPrior experience of creating\/supporting ETL, data warehouses and Tabular data models. Ocorian utilises Microsoft SQL Server technologies, including SSIS, SSAS, SSRS and Power BI and the successful candidate should have delivered projects using aspects of this technology stack in recent times\nThe individual will be expected to work across all levels of the Business to liaise with key stakeholders to ensure the design, development and documentation meets the requirements of the Business. The role will work extensively with IT functions and the role may be matrix-managed when required with tasks assigned by the BAU BI Team\nMain Rresponsibilities\nDesign and implement data warehouse solutions and Tabular data models\nDevelop dashboards and reporting to meet business reporting needs\nDeliver approved projects within timeframe\nProvide regular updates to management\nMake recommendations for potential improvement or changes\nPromote the use of core systems for data capture aligned to standards and initiatives\nQualifications\nTechnical Skills\nSQL Server 2016 onwards\nSQL Server BI stack \u2013 SSAS \/ SSIS \/ SSRS\nMicrosoft Power BI\nExperience of data cleansing tools and methodologies\nBusinesss Skills\nDemonstrated ability to apply IT in solving business problems\nGood written, oral, and interpersonal communication skills\nAbility to present ideas in business-friendly and user-friendly language\nHighly self-motivated, proactive and attentive to detail\nAbility to effectively prioritise and execute tasks in a high-pressure environment\nExtensive experience working in a team-oriented, collaborative multi-jurisdictional environment\nExperience of working in project teams with mixed skillsets and levels of technical knowledge\nEnergy and enthusiasm to support the future growth and success of the business\nAdditional Information\nAll staff are expected to embody our core values that underpin everything that we do and that reflect the skills and behaviours we all need to be successful.  These are:\nWe are AMBITIOUS - We think and act globally, seizing every opportunity to support our clients and staff - wherever in the world they may be.\nWe are AGILE - Our independence from any financial institution gives us the flexibility and freedom to keep things simple, efficient and effective.\nWe are COLLABORATIVE - We take the time to understand our clients' needs so that we can deliver personalised solutions every time.","8":"Company Description\nExperian unlocks the power of data to create opportunities for consumers, businesses and society. We gather, analyze and process data in ways others can\u2019t. We help individuals take financial control and access financial services, businesses make smarter decision and thrive, lenders lend more responsibly, and organizations prevent identity fraud and crime. For more than 125 years, we\u2019ve helped consumers and clients prosper, and economies and communities flourish \u2013 and we\u2019re not done. Our 17,800 people in 45 countries believe the possibilities for you, and our world, are growing. We\u2019re investing in new technologies, talented people and innovation so we can help create a better tomorrow.\nJob Description\nExperian India is looking for a Data Analyst to join Credit Bureau development team. The candidate would possess a strong analytical mind, be a technical and creative thinker, have a strong aptitude for problem solving, and have zero tolerance for inefficiencies in software development & deliveries. The ideal candidate will have excellent written, oral and interpersonal communication skills, along with the fervent desire to continuously learn about different products and technologies.                                                                                                                                                   \nYou will be working on Big Data application. You will be a member of a team collaborating and working together towards common goals. The team is responsible for the design, development and support of the application.\nWhat you\u2019ll be doing\nUtilize your software engineering skills including Java, Spark, Python, Scala to Analyze disparate, complex systems and collaboratively design new products and services\nIntegrate new data sources and tools\nImplement scalable and reliable distributed data replication strategies\nAbility to mentor and provide direction in architecture and design to onsite\/offshore developers\nCollaborate with other teams to design and develop and deploy data tools that support both operations and product use cases\nPerform analysis of large data sets using components from the Hadoop ecosystem\nOwn product features from the development, testing through to production deployment\nEvaluate big data technologies and prototype solutions to improve our data processing architecture \u2022 Automate everythin\nQualifications\nWhat you\u2019ll need to bring to the party\nBS degree in computer science, computer engineering or equivalent\n5 \u2013 6 years of experience delivering enterprise software solutions \u2022 Proficient in Spark, Scala, Python, AWS Cloud technologies\n3+ years of experience across multiple Hadoop \/ Spark technologies such as Hadoop, MapReduce, HDFS, HBase, Hive, Flume, Sqoop, Kafka, Scala\nFlair for data, schema, data model, how to bring efficiency in big data related life cycle\nMust be able to quickly understand technical and business requirements and can translate them into technical implementations\nExperience with Agile Development methodologies\nExperience with data ingestion and transformation\nSolid understanding of secure application development methodologies\nExperienced in developing microservices using spring framework is a plus\nExperience in with Airflow and Python will be preferred\nUnderstanding of automated QA needs related to Big data\nStrong object-oriented design and analysis skills\nExcellent written and verbal communication skills\nAdditional Information\nWhy us\nWe\u2019re a high-performance and driven team but we don\u2019t forget to celebrate success\nWe offer strong career and international opportunities for high performers\nWe invest heavily in our products and our people\nWe offer training and support from experienced subject matter experts and managers plus dedicated learning & development time\nExperian Careers - Creating a better tomorrow together\nFind out what its like to work for Experian by clicking here","9":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. As digital pioneers with 20,000 people and 53 offices around the globe, our experience spanning technology, data sciences, consulting and customer obsession \u2013 combined with our culture of curiosity and relentlessness \u2013 enables us to accelerate our clients\u2019 businesses through designing the products and services their customers truly value. Publicis Sapient is the digital business transformation hub of Publicis Groupe. For more information, visit publicissapient.com.\nJob Description\nPublicis Sapient is looking for Senior Manager  (in-office 2-3 days per week) to join our team of bright thinkers and doers. You will team up with top-notch technologists to enable real business outcomes for our enterprise clients by translating their needs into transformative solutions that provide valuable insight. Working with the latest data technologies in the industry, you will be instrumental in helping the world\u2019s most established brands evolve for a more digital future.\nYour Impact: \nWork closely with our clients providing evaluation and recommendations of design patterns and solutions for data platforms with a focus on batch, near-real time, structured and unstructured data \nDefine SLAs, SLIs, and SLOs with inputs from clients, product owners, and engineers to deliver data-driven interactive experiences \nProvide expertise, proof-of-concept, prototype, and reference implementations of architectural solutions for Azure Data Platform\nProvide technical inputs to agile processes, such as epic, story, and task definition to resolve issues and remove barriers throughout the lifecycle of client engagements\nCreation and maintenance of infrastructure-as-code and CI\/CD for Azure environment using tools such as Terraform and Ansible\nMentor, support and manage team members\nQualifications\nYour Skills And Experience: \nDemonstrable experience in enterprise level data platforms involving implementation of end-to-end data pipelines \nHands-on experience with at Azure  \nExperience with column-oriented database technologies (e.g., Synapse), NoSQL database technologies (e.g., DynamoDB, Cosmos DB, etc.) and traditional database systems (e.g., SQL Server, Oracle, MySQL)\nExperience in architecting data pipelines and solutions for both streaming and batch integrations using tools\/frameworks like Azure Data Factory, Azure functions and Stream analytics \nMetadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, and Azure Purview\nTest plan creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks\nData modeling, querying, and optimization for relational, NoSQL, timeseries, graph databases, data warehouses and data lakes\nData processing programming using SQL, Python, and similar tools\nLogical programming in Python, Spark, PySpark, Java, Javascript, and\/or Scala\nCloud-native data platform design with a focus on streaming and event-driven architectures\nParticipate in integrated validation and analysis sessions of components and subsystems on production servers\nData ingest, validation, and enrichment pipeline design and implementation\nSDLC optimization across workstreams within a solution \nBachelor\u2019s degree in Computer Science, Engineering, or related field\nSet Yourself Apart With: \nCertifications in Azure \nExperience working with code repositories and continuous integration\nUnderstanding of development and project methodologies\nAdditional Information\nPay Range:$108,000 -$210,000\nBenefits of Working Here:\nFlexible vacation policy; time is not limited, allocated, or accrued\n16 paid holidays throughout the year\nGenerous parental leave and new parent transition program\nTuition reimbursement \nCorporate gift matching program \nAs part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at hiring@publicissapient.com or you may call us at +1-617-621-0200.","10":"At Definitive Healthcare, our passion is to transform data, analytics and expertise into healthcare commercial intelligence. We help clients uncover the right markets, opportunities and people, so they can shape tomorrow\u2019s healthcare industry. Our SaaS platform creates new paths to commercial success in the healthcare market, so companies can identify where to go next.  \nOur employees are kind, collaborative, energetic, approachable and driven. On top of that, we value the unique perspectives, backgrounds and voices of our employees. Why? Because their diverse experiences drive new ideas and help us build a better community. \nFor over 10 years, we\u2019ve built a collaborative culture driven by employees who share a passion for improving the healthcare ecosystem, enjoy giving back to the local community and value diversity and inclusion.  \nOne of the hallmarks of our culture is our commitment to community service. Through the DefinitiveCares program, employees can work with their choice of more than 40 charitable organizations, supporting causes from hunger and homelessness to healthcare, LGBTQ+ issues, racial justice, women\u2019s initiatives and more. 2021 marked the sixth year that we had 100% employee participation in DefinitiveCares. \nWe also provide a range of opportunities for employees to connect with each other. Employees can join any of our employee run affinity groups supporting causes such as women\u2019s empowerment, LGBTQ+, Black, indigenous and people of color (BIPOC), disabilities and working parents and potential for many more. Affinity groups often enable greater education companywide through training, events and speaker series. \nWe\u2019re also a great place to work. For five years in a row, we\u2019ve been recognized by the Boston Business Journal and the Boston Globe as a best place to work in Massachusetts. In 2022, Energage recognized us for Culture Excellence in Compensation & Benefits, Innovation, Great Leadership, Purpose & Value and Work-Life Flexibility! \nThink you\u2019d be a good addition to our team? Explore our available positions here. We\u2019d love the chance to get to know you.  \nYour challenge: \nAs a Senior Big Data Engineer, you will join our growing Engineering team. You will work with teams of big data and software engineers to build data solution utilizing big data technologies such as Databricks, Snowflake, etc., Leveraging scala or python you will develop data pipelines to transform\/wrangle\/integrate the data into different data zones. You will enhance your skillset by learning from your seniors and share your knowledge to build sustainable solution. You will hold accountability for technical decisions.\nThe Senior Big Data Engineer at Definitive Healthcare:\nEnsures solutions are built using databricks, snowflake according to business and technical specifications.\nDeploy and support highly optimized solutions with a focus on automation.\nSupport an error-free, predictable, high-performing platform in AWS\nActively Contributes to architectural discussions around our data.\nPerforms code reviews\nIs always thinking of better ways to do something\nIsn\u2019t afraid to fail.\nProvide leadership to the ongoing maturity of the development process, coach\/mentor the development team on best practices and methodologies for enhanced solution development.\nCares deeply about quality\nStay up to date on the relevant technologies, plug into user groups, understand trends and opportunities.\nSkills we\u2019re looking for:\nMust be results driven, customer focused, technologically savvy, and skilled at working in an agile development environment.\nDeep expertise in working with data (Structured, Unstructured etc.,)\nStrong Experience with at-least one scripting language i.e., Python, Scala, Java, C++ etc.,\nDeep Understanding of distributed computing principles\nData modeling and processing fundamentals with large-scale (> 50B rows) data\nExperience with Apache Spark using Scala and Spark SQL (Batch, streaming)\nDemonstrated ability to create normalized and star-schema database designs using database modeling techniques. Superior understanding of normalization and denormalization.\nExpert Knowledge of Big Data PaaS components in the cloud, such as Databricks, Snowflake\nWorking knowledge of RDBMS, NoSQL and Graph databases\nKnowledge of Hadoop, Spark, and HDFS\nExperience with containerization \nExperience with automation technologies such as Argo, Oozie, Airflow\nKnowledge of Linux\/Unix\n Why we love Definitive, and why you will too!\nIndustry leading products\nWork hard, and have fun doing it\nIncredibly fast growth means limitless opportunity\nFlexible and dynamic culture\nWork alongside some of the most talented and dedicated teammates\nDefinitive Cares, our community service group, gives all of us a chance to give back\nCompetitive benefits package including great healthcare benefits and a 401(k) match\nWhat our Employees are saying about us on Glassdoor: \n \u201cGreat Work atmosphere, great work life balance, excellent company to work for, amazing top notch product, incredible customer service, lots of tools to help you succeed.\u201d\n-Business Development Manager\n\u201cGreat team. Amazing growth. Employees are treated very well.\u201d\n-Research Analyst\n\u201cI have waited 36 years to work at a dream job for a dream company and I am so happy to have finally got there.\u201d\n-Profile Analyst\n  If you don\u2019t fit all of these qualifications, but believe you\u2019re still a great fit, feel free to apply and tell us why in your cover letter.\n  If you are a California, Colorado, New York City or Washington resident and this role is a remote role, you can receive additional information about the compensation and benefits for this role, which we will provide upon request.\n  Definitive Hiring Philosophy\nDefinitive Healthcare is an equal opportunity employer that celebrates diversity and is committed to creating an inclusive workplace with equal opportunity for all applicants and teammates. Our goal is to recruit the most talented people from a diverse candidate pool regardless of race, color, religion, age, gender, gender identity, sexual orientation or any other status. If you\u2019re interested in working in a fast growing, exciting working environment \u2013 we encourage you to apply!\n  Privacy \nYour privacy is important to us. Please review our Candidate Privacy Notice which tells you how we use and process your personal information\n  Please note: All communications regarding the hiring process at Definitive Healthcare will come directly from one of our corporate recruiters or coordinators with an @definitivehc.com email address. We will never request any money transfer or purchase of equipment with a promise of reimbursement. If you receive any suspicious communications, please reach out to careers@deinfitivehc.com to confirm your status in the application process. ","11":"Responsibilities\nDesign and further development of our existing and future dashboards and reporting based on Power BI, Azure DataBase and Azure DataFactory\nAnalysis, conception, design and implementation of new requirements from the business departments on the basis of Power BI, Azure DataBase and Azure DataFactory\nCollaboration with business departments in process analysis, conception and design of solutions as well as their documentation\nSetting up ETL flows respectively connecting new systems to Azure DataBase \/ Azure DataFactory\nApplication administration (monitoring, user and authorisation management)\nKey-User support\nRequirements\n3-5 years of experience in a similar data-related role, using Microsoft technologies\nCompleted technical education in Informatics (e.g. higher technical school or university) or equivalent qualification within business field\nDeep knowledge with Power BI, Azure DataBase and Azure DataFactory\nGood knowledge of ETL (Extract, Transform, Load)\nKnowledge of relational databases and data modelling\nKnowledge of SAP-BW is an advantage\nVery good English language skills\nBenefits\nA competitive package, depending on level of experience. You can work remote (hybrid) and you will also be provided with private insurance and extra benefits. You will have the opportunity to work in a motivating and multicultural environment as well as on global scale projects. You will have the opportunity to build a long-run career in a well-established multinational company.","12":"Unternehmensbeschreibung\nBei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch.\nDie Robert Bosch GmbH freut sich auf Deine Bewerbung!\nStellenbeschreibung\nIm Gesch\u00e4ftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen \u2013 von hocheffizienten Antrieben \u00fcber das erste serienreife ABS f\u00fcrs Pedelec bis hin zu smarten Connectivity-L\u00f6sungen. F\u00fcr eine nachhaltige Mobilit\u00e4t, die Spa\u00df macht.\nDu bist Expert:in f\u00fcr den Bereich Data Engineering bei Bosch eBike Systems und stellst die relevanten Daten den Nutzern unserer Cloud-basierten Datenplattform zur Verf\u00fcgung.\nDu programmierst gerne und beherrschst Python und SQL. Zu Deinem Repertoire z\u00e4hlen au\u00dferdem ausgepr\u00e4gte Kenntnisse \u00fcber die performante Verarbeitung und Speicherung gro\u00dfer Datenmengen sowohl in Data Lakes als auch in Data Warehouse Systemen.\nIm Rahmen Deiner T\u00e4tigkeit f\u00fchrst Du Code-Reviews durch und definierst Best Practices und Leitplanken f\u00fcr die Entwicklung von Data Pipelines. \nWir unterst\u00fctzen Dich, damit Du Deine Kreativit\u00e4t in dem Bereich entfalten kannst und bieten Design Reviews mit anderen erfahrenen Kolleg:innen und Interessengruppen an.\nDu baust Deine Data Pipelines robust und mit einem hohen Fokus auf Observability, um eine einfache Fehleranalyse zu erm\u00f6glichen.\nZudem \u00fcbernimmst Du Verantwortung f\u00fcr deine entwickelten Daten Pipelines auch w\u00e4hrend des Betriebs und entwickelst diese kontinuierlich weiter, um eine optimale Qualit\u00e4t und Zuverl\u00e4ssigkeit sicherzustellen.\nDu hast Spa\u00df daran, dein Wissen weiterzugeben und agierst als Mentor:in f\u00fcr Junior Kolleg:innen im Team. Es macht Dir Spa\u00df mit dem Daten-Team, den Fachbereichen, der IT und den Kolleg:innen im fachlichen Diskurs die beste L\u00f6sung zu identifizieren.\nQualifikationen\nAusbildung: abgeschlossenes Hochschulstudium (Master\/Diplom\/Promotion) der Wirtschaftsinformatik oder eines vergleichbaren Studienganges\nPers\u00f6nlichkeit und Arbeitsweise: kommunikativ, selbstreflektiert, getting-things-done-Mindset, stetig lernbereit, Interesse f\u00fcr Innovationen im Arbeitsgebiet, eigenverantwortlich, l\u00f6sungs- und kundenorientiert, pragmatisch und problembewusst\nErfahrungen und Know-how: 5 Jahre Berufserfahrung als Data Engineer sowie Erfahrung im Aufbau von zuverl\u00e4ssigen Data Pipelines; Erfahrung in der agilen Softwareentwicklung (SCRUM, Kanban) und Erfahrung in der Datenmodellierung sowie in unterschiedlichen Ans\u00e4tzen f\u00fcr Daten Architekturen; Erfahrung im\nArbeiten in multinationalen Teams\nKnow-How: Breites Wissen \u00fcber unterschiedliche Technologien im Bereich Big Data Engineering (z.B. Databricks \/Spark, Snowflake, Apache Airflow, dbt, Kafka) sowie fundierte Kenntnisse in relevanten Programmiersprachen (Python, SQL, Scala) und CI\/CD (Gitlab CI\/CD, Jenkins); Au\u00dferdem Kenntnisse der Daten-Analyse, des Daten-Managements und der Softwareentwicklung\nBegeisterung: Spa\u00df daran, Wissen an andere zu vermitteln\nSprachen: sehr gute Deutsch- und Englischkenntnisse in Wort und Schrift\nZus\u00e4tzliche Informationen\nIn diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente.\n\nBewirb Dich jetzt in nur 3 Minuten!\nDu m\u00f6chtest Remote oder in Teilzeit t\u00e4tig sein - wir bieten tolle M\u00f6glichkeiten des mobilen Arbeitens sowie unterschiedliche Teilzeitmodelle. Sprich uns gerne dazu an.\nDu hast Fragen zum Bewerbungsprozess?\nNelly Ehrmann (Personalabteilung)\n+49 711 811 27525\nDu hast fachliche Fragen zum Job?\nDaniel Grimm (Fachabteilung)\n+49 7121 35 18668\nInteressierst Du Dich f\u00fcr diese oder weitere Stellen?\nDann bewerbe Dich auf die Virtual JobFair@BOSCH und verschaffe Dir einen \u00dcberblick \u00fcber die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de\/events\/                                        ","13":"Company Profile\nWith studios around the world, Keywords Studios is a leading technical services provider for global video games and beyond. With locations in Asia, the Americas and Europe, Keywords Studios has a breadth and depth in multiple industry-leading service lines including Art, Engineering, Audio, Functionality QA, Localization, Localization QA and Player Support. Working across all major platforms, in over 50 different languages, Keywords Studios delivers support for its clients across the globe.\nRole Overview\nThe Business Intelligence Data Analyst will become a subject matter expert for BI (data & analytics) on all intelligence-related tasks. The Analyst will work independently and in a team environment performing requirements gathering, data analysis, process mapping, test case definition, development, and collaboration across multiple business units and projects.\nRequirements\nLocated in Romania, no sponsorship required\nExcellent written and oral communication skills.\nExcellent time management and organizational skills.\nDetail oriented but able to understand the big picture.\nAbility to analyze and document complex business processes.\nExperience communicating with business users.\n3+ years\u2019 experience with Power BI\nProficiency with DAX and M languages\nProficiency with Python\n2-3 years\u2019 experience with Spark\/Databricks.\nStrong SQL Server SQL skills and experience tuning queries, Working knowledge of data warehouse.\nAdditional Preferred Qualifications\nStatistical computing experience\nExposure to the Azure Data Platform (Data Factory, etc.)\nExposure with DevOps implementation practices\nScrum methodology delivery experience\nDuties and Responsibilities\nDevelop and implement interactive analytic reports and dashboards.\nTranslate business requirements into ETL and report specifications.\nDevelop and implement ETL processes, reports and queries in support of business analytics.\nPerform data analysis to troubleshoot data issues with the BI solutions and data integration processes\nEnsure compliance with security policies and practices in accordance with internal and external audit governing bodies.\nSupport data governance processes.\nProvide technical and business knowledge support to the team.\nSupport data governance processes.\nBenefits\nOur employees are our most valuable resource; therefore we provide them with a competitive compensation package commensurate with skills and experience, excellent benefits, high level of job satisfaction and a casual and fun work environment.\n\nExtensive Medical insurance provided by Medicover and their partner network in Romania.\nDays off for special personal events, according to the Internal Regulations, e.g. marriage, childbirth, compassionate leave and exams days off for obtaining professionally relevant certifications.\nA monthly allowance of 650RON which you will be able to use for a wide range of benefits, that are relevant to you: medical\/dental services for you and\/or your family members, access to sports clubs, meal tickets, private pension, personal development courses (e.g. IT, accounting, finance, HR, foreign languages, driving courses), tourism in Romania, public transportation subscription, gifts, utility or phone\/Internet bills, access to cultural events, etc.\nLearning & Development to help you reach your true maximum potential by providing access to training and digital resources relevant for your area of expertise.","14":"Our mission is to make biology easier to engineer. Ginkgo is constructing, editing, and redesigning the living world in order to answer the globe\u2019s growing challenges in health, energy, food, materials, and more. Our bioengineers make use of an in-house automated foundry for designing and building new organisms. Today, our foundry is actively developing multiple organisms to make different products across multiple industries.\nAs a Computational Biologist working on the Design Team, you\u2019ll support Ginkgo's RNA cell engineering programs by designing and analyzing high-throughput experiments using a variety of synthetic biology and genomic approaches. You\u2019ll develop novel computational tools that expand Ginkgo's mammalian cell engineering toolbox. As part of the Design Team, you will partner with an interdisciplinary team of bench scientists, computational biologists, data scientists, and software engineers, to develop world-changing tools to engineer biology. \nThe successful candidate will bring their deep knowledge of mammalian gene regulation,  transcription and RNA biology to design, support, and analyze synthetic biology projects within the foundry. The candidate will bring knowledge and experience in modern molecular biology techniques applied to higher eukaryotes. To be successful in this role, you will think big and execute systematically. You will draw on your fluency in gene therapy, mammalian cell engineering and NGS to design, analyze and interpret large scale screens. You will put your organizational and communication muscles to work every day as you work closely with teams across Ginkgo.\nPlease note: we recognize that not all candidates may meet the entire list of Desired Experience and Capabilities. We\u2019re eager to train the right candidates for this role, and encourage those who meet at least two-thirds of the criteria to apply.\n#LI-DW1\nResponsibilities\nSupport Ginkgo\u2019s mammalian cell engineering teams with your expertise in mammalian biology, providing the knowledge needed to design, screen and test novel cell lines, vectors and molecules designing megabases of DNA for each project.\nAnalyze integrated internal and external data to advance mammalian cell engineering programs focused on RNA therapeutic tool development.\nHelp maintain computational biology software owned by the Design Team.\nTroubleshoot moderate- to high-complexity technical problems, proposing biological design solutions in the dry lab, and maintaining familiarity with protocols (e.g. cell culture, diagnostic\/QC, assay design, and execution) in the wet lab.\nCollaborate with stakeholders across Ginkgo to create the next generation of synthetic biology tools (e.g. algorithms, data structures, predictive models, software pipelines, and\/or experimental approaches) that yield step changes in our ability to engineer mammalian cell lines.\nMaintain high-quality documentation of your work and discoveries, creating written reports, technical presentations for internal or external audiences, electronic lab notebooks, internal database records, code comments, and software documentation.\nDesired Experience and Capabilities\nPhD (or equivalent experience) in computational biology, genomics, RNA biology, mRNA therapeutics, quantitative biology, or other relevant field. Interdisciplinary work is strongly preferred.\nSubject matter expertise in RNA molecular biology, mRNA expression systems or mRNA therapeutics development as evidenced by publication in journals or patents.\n2+ years of professional experience (grad school counts) working with mammalian genome engineering tools, such as CRISPR\/Cas systems, recombinases, and viral vectors. \nProficiency with at least one software programming language (Python preferred). Knowledge of best practices for collaborative software development (version control systems, test-driven development, and good documentation habits). Familiarity with cloud services (e.g. AWS) is preferred.\nFirst-hand technical experience in at least two of the following areas: synthetic biology, bioinformatics, RNA biology, structural RNA biology,  transcriptomics, translatomics, gene regulation, post transcriptional regulation, sequence analysis, genomics, NGS analysis, machine learning, and quantitative modeling of biological systems.\nDemonstrated ability to meet the demands of multiple concurrent projects.\nStrong curiosity about (and comfort working in) areas of biology previously unknown to you and, at times, your peers.\nWe look forward to hearing from you. Please send us the following:\nA r\u00e9sum\u00e9 or curriculum vitae\nA sample of your code. A GitHub profile, if you have one, is preferred. Otherwise, attached files are ok.\nWe also feel it\u2019s important to point out the obvious here \u2013 there\u2019s a serious lack of diversity in our industry and it needs to change. Our goal is to help drive that change. Ginkgo is deeply committed to diversity, equality, and inclusion in all of its practices, especially when it comes to growing our team. We hope to continue to build a company whose culture promotes inclusion and embraces how rewarding it is to work with engineers from all walks of life. Making biology easier to engineer is a tough nut to crack \u2013 we can\u2019t afford to leave any talent untapped.\nIt is the policy of Ginkgo Bioworks to provide equal employment opportunities to all employees and employment applicants.\nTo learn more about Ginkgo, visit www.ginkgobioworks.com\/press\/ or check out some curated press below:What is it really like to take your company public via a SPAC? One Boston biotech shares its journey (Fortune)Ginkgo Bioworks resizes the definition of going big in biotech, raising $2.5B in a record SPAC deal that weighs in with a whopping $15B-plus valuation (Endpoints News)Ginkgo Bioworks CEO on scaling up Covid-19 testing: \u2018If we try, we can win\u2019 (CNBC)Ginkgo raises $70 million to ramp up COVID-19 testing for employers, universities (Boston Globe)Ginkgo Bioworks Redirects Its Biotech Platform to Coronavirus (Wall Street Journal)Ginkgo Bioworks Provides Support on Process Optimization to Moderna for COVID-19 Response (PRNewswire)The Life Factory: Synthetic Organisms From This $1.4 Billion Startup Will Revolutionize Manufacturing (Forbes)Synthetic Bio Pioneer Ginkgo Raises $290 Million in New Funding (Bloomberg)Ginkgo Bioworks raises $350 million fund for biotech spinouts (Reuters)Can This Company Convince You to Love GMOs? (The Atlantic)\nWe also feel that it\u2019s important to point out the obvious here \u2013 there\u2019s a serious lack of diversity in our industry, and that needs to change. Our goal is to help drive that change. Ginkgo is deeply committed to diversity, equity, and inclusion in all of its practices, especially when it comes to growing our team. Our culture promotes inclusion and embraces how rewarding it is to work with people from all walks of life.  \nWe\u2019re developing a powerful biological engineering platform, so we must remain mindful of the many ways our technology can \u2013 and will \u2013 impact people around the world. We care about how our platform is used, and having a diverse team to build it gives us the best chance that it\u2019s something we\u2019ll be proud of as it continues to grow. Therefore, it\u2019s critical that we incorporate the diverse voices and visions of all those who play a role in the future of biology.\nIt is the policy of Ginkgo Bioworks to provide equal employment opportunities to all employees and employment applicants.","15":"Company Description\nWe help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.\nJob Description\nThis Research Engineer is responsible for developing and supporting the engineering components of Verisk\u2019s wind vulnerability models that cover multiple regions and perils, including perils such as straight-line wind, tornadic wind, hail, snow, and freezing temperatures.  General responsibilities include identifying the impact that these perils can have on the built environment, including physical damage which can result in monetary loss to buildings\/infrastructure, contents, and loss of use (downtime).  In this role, you will work closely with a team of structural engineers and atmospheric scientists to perform probabilistic risk assessments for the built environment, and present and explain results to internal stakeholders and external clients. \nThe evolving nature of research work at Verisk creates unique and challenging problems that spark innovation and growth and creates opportunities for its employees. A successful candidate should have a desire to use problem-solving skills in applying sound engineering principles to solve unique and challenging problems in the fields of civil\/structural engineering and risk assessment.  It is expected that candidates will be highly motivated, detail-oriented, well-organized, able to perform high-quality self-directed research, have outstanding written and verbal communication skills, and be team-oriented.\nAbout the Day to Day Responsibilities of the Role\nAs a member of our Atmospheric Perils Vulnerability Team, your day-to-day responsibilities will include the following:\nData acquisition and analysis for the purpose of understanding building inventory and its vulnerability subjected to atmospheric-based hazards in multiple regions worldwide\nAnalytical analyses and research aimed towards the development of vulnerability functions and monetary loss curves for structural and non-structural building and infrastructure components subjected to hazards such as wind, tornadoes, hail, and snow for several regions of interest worldwide\nImplementation of research into AIR\u2019s portfolio risk analysis models, including programming loss simulation codes and analysis tools, and probabilistic assessment validation\nUse of GIS tools for data visualization and analysis\nReal-time and virtual building damage assessments due to natural catastrophes during and after significant events\nPreparation and presentation of work at staff internal and client external meetings as well as technical writing for internal and external publications and client-facing documentation\n#LI-SM1\nQualifications\nAbout You and How You Can Excel in This Role\nPh.D. in Wind Engineering, Structural Engineering, Civil Engineering, and\/or other relevant fields\nExperience in performance-based design, probabilistic and stochastic risk assessment and modeling, and reliability theory with applications to the field of structural engineering\nProficient in C\/C++, MATLAB, R, and\/or FORTRAN\nDemonstrated data mining skills (SQL and\/or statistical analysis)\nExcellent written and verbal communication skills\nStrong organizational and excellent documentation skills\nKnowledge of GIS applications (e.g. ArcView) and SQL server is a plus\nAdditional Information\nAt the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.\u202f  \nOur global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.  \nBut why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.  \nIt\u2019s the reason Verisk is part of the UN Global Compact sustainability initiative. It\u2019s why we made a commitment to balancing 100 percent of our carbon emissions. It\u2019s the aim of our \u201creturnship\u201d program for experienced professionals rejoining the workforce after time away. And, it\u2019s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers\u2019 problems.\u202f  \nAt its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do. \nAt Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career.\u202fWe have received the Great Place to Work\u00ae Certification for the 7th consecutive year. We\u2019ve been recognized by Forbes as a World\u2019s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.  Verisk\u2019s Statement on Racial Equity and Diversity supports our commitment to these values and affecting positive and lasting change in the communities where we live and work.  \nVerisk Analytics is an equal opportunity employer.\nAll members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and\/or expression, sexual orientation, veteran's status, age or disability.\nhttp:\/\/www.verisk.com\/careers.html\nUnsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume. \nConsumer Privacy Notice","16":"Company Description\nTeamViewer is a leading global technology company that provides a cutting-edge platform to remotely access, control and support devices of any kind. Our software solutions empower our users and customers to bridge distances and digitalize their processes through seamless connectivity.\nOur team is committed to quality and passionately leading the way in the fields of Augmented Reality, Internet of Things and Artificial Intelligence. With over 1.400 employees from more than 80 nationalities in 20+ locations worldwide, we are one global family. We believe that bringing together people from different backgrounds and experiences leads to better, more innovative solutions. One of the keys to our success is our culture, which enables employees to learn, grow, and contribute in meaningful ways.\nAre you courageous and want to make an impact? Then join our winning team and help us create a world that works better.\nJob Description\nJoin our Reporting and Analytics team and help us create transparency and actionable insights in a global innovative environment where more than 600,000 customers use products with more than 2.5 billion installations \nBuild analyses and insightful reports on financial, sales, marketing, product and operational topics\nWork closely with our Data Engineers in defining data models and enriching existing data\nProactively support internal stakeholders on utilizing our data and defining meaningful KPIs\nMaintain and improve our existing reporting portfolio\nOptimize flows and processes in the Data Warehouse to work with large amounts of data of a product which has millions of users all over the world\nManage our internal backlog and actively prioritize based on business impact\nQualifications\nUniversity or college degree in Computer Science, Mathematics, Statistics, Information Systems or any other related subject\nAt least 3 years of relevant professional experience in the field of Business Intelligence and Analytics\nAdvanced knowledge of SQL and BI tools (e.g. Tableau, Power BI or QlikView)\nApache-Airflow, DBT and Docker expertise are beneficial\nBackground in working with AWS or Google cloud solutions is an advantage\nExcellent grasp of business contexts \/ processes and a basic understanding of agile development methods\nAnalytical skills, and the ability to work both independently and as part of a team\nFluency in English is mandatory, further languages such as German are a plus\nAdditional Information\nOnsite Onboarding in our HQ office for an optimal start\nGreat compensation and benefits packages including company achievement bonus and stock-based options, regular salary reviews\nAccess to Corporate Benefits platform with many discounts\nRegular Team events and company-wide celebrations\nOpen door policy, no dress code rules, frequent all Hands and Leadership Lunches\nWork From Abroad Program allowing up to 40 days of work outside your contracting country\nWe celebrate diversity as one of core values, join and drive one of the c-a-r-e initiatives together with us!\nTeamViewer is an equal opportunities employer and is committed to building an inclusive culture where everyone feels welcome and supported. We C-A-R-E and understand that our diverse, values-driven culture makes us stronger. As we continue to grow as a company, we also focus on enabling our employees to grow both personally and professionally. We are proud to have an open and embracing workplace environment that will empower you to be your best no matter your gender, civil or family status, sexual orientation, religion, age, disability, education level, or race.","17":"At Beyond Finance, we\u2019ve made it our mission to help everyday Americans escape the endless cycle of crippling debt and step into a brighter financial future. Through compassionate, individualized care, supportive user-centric technology, and customized financial solutions, we\u2019ve helped over 200,000 clients on their path to a debt-free life.\nWhile we\u2019re proud of what we\u2019ve already accomplished (over $1 billion in resolved debt), we're searching for new collaborators to help us get to the next level! If you\u2019re looking to join a forward-thinking, rapidly growing organization with helping people as its number one goal, we want to hear from you.\nAbout the Role\nAs a Sr. Business Intelligence Engineer  your primary day-to-day tasks will include working with stakeholders and using Looker and Snowflake. You will use this tech stack to deliver business value in the form of:\nDeveloping business modeling layer in Looker\nLooker dashboards\nAutomated data extracts\nETL (refining & curating data)\nThe ideal candidate would :\nHave 2+ years of experience with modern day visualization tools like Tableau, Looker, Qlik\nExpertise in SQL (3-5 years exp)\nExcellent communication skills\nAbility to translate business requirements into technical specifications\nAbility to simplify complex technical jargon into easy to understand business language\nKnowledge of data warehousing and modeling concepts\nFamiliar with Github or similar tool for code management\nSelf starter, quick learner, able to juggle multiple priorities and work in a fast paced environment\nWhy Join Us?\nWhile you make a difference for others, we\u2019ll work to make a difference for you, providing an uplifting, collaborative work environment and benefits that reflect your value to us. For eligible full-time employees, we offer:\nConsiderable employer contributions for health, dental, and vision programs\nHybrid work models\nGenerous PTO, paid holidays, and paid parental leave\n401(k) matching program\nMerit advancement opportunities\nCareer development & training\nAnd finally, our team spirit and culture! We cultivate an environment of community, connection, and belonging across our entire organization.\nBeyond Finance does not accept unsolicited resumes from individual recruiters or third-party recruiting agencies in response to job positions.  No fee will be paid to their parties who submit unsolicited candidates directly to Beyond Finance employees or the Beyond Finance HR team.  No placement fee will be paid to any third party unless such a request has been made by the Beyond HR team.","18":"Opis firmy\n  Opis oferty pracy\nWide\u0142ki wynagrodzenia przewidziane przy tym stanowisku to (umowa o prac\u0119):\nmid: 12 300 - 17 600 PLN brutto\nsenior: 16 100 - 23 200 PLN brutto\nModel pracy hybrydowej wed\u0142ug ustale\u0144 lidera i zespo\u0142u.\n Ofert\u0119 kierujemy do os\u00f3b, kt\u00f3re:\nBardzo dobrze znaj\u0105 SQL\nPosiadaj\u0105 do\u015bwiadczenie z co najmniej jednym typem baz danych: Oracle, PostgreSQL, MySQL, BigQuery\nBiegle pos\u0142uguj\u0105 si\u0119 Google Sheets (Google Suite), MS Excel\nPosiadaj\u0105 do\u015bwiadczenie z narz\u0119dziami raportowymi takimi jak: Google Data Studio, Tableau, Power BI, Cognos\nPotrafi\u0105 sprawnie zarz\u0105dza\u0107 czasem i pracowa\u0107 w zespole\nOczekuj\u0105 pracy, kt\u00f3ra ma g\u0142\u0119bszy sens (nie tylko \u201cmanagement zleci\u0142\u201d) i realny wp\u0142yw na decyzyjno\u015b\u0107 kadry zarz\u0105dzaj\u0105cej\nPotrafi\u0105 szuka\u0107 efektywnych rozwi\u0105za\u0144 do wymaga\u0144 stawianych przez u\u017cytkownik\u00f3w\nChc\u0105 si\u0119 ci\u0105gle rozwija\u0107 i aktualizowa\u0107 swoj\u0105 wiedz\u0119\nDodatkowym atutem b\u0119dzie:\nPodstawowa umiej\u0119tno\u015b\u0107 programowania w j\u0119zyku Python\nPodstawowa znajomo\u015b\u0107 Google Apps Script\nWiedza oraz do\u015bwiadczenie w modelowaniu, tworzeniu i utrzymaniu proces\u00f3w ETL\nZnajomo\u015b\u0107 zagadnie\u0144 zwi\u0105zanych Airflow, Google Composer, Dataproc, Spark\nDo\u015bwiadczenie w pracy w \u015brodowisku GCP\nDlaczego mia\u0142(a)by\u015b z nami pracowa\u0107?\nZapewnisz dane niezb\u0119dne do rozwoju system\u00f3w wspomagaj\u0105cych dzia\u0142alno\u015b\u0107 zespo\u0142\u00f3w finans\u00f3w oraz kadry zarz\u0105dzaj\u0105cej\nB\u0119dziesz odpowiada\u0107 za prezentacj\u0119 wybranych danych oraz automatyzacj\u0119 proces\u00f3w raportowych w obszarze Technologii oraz Finans\u00f3w \nB\u0119dziesz wspiera\u0107 automatyzacj\u0119 istotnych proces\u00f3w biznesowych i back officowych\nZajmiesz si\u0119 tworzeniem i wsparciem utrzymania proces\u00f3w ETL oraz przygotowaniem agregat\u00f3w danych \nOdpowiesz za rozw\u00f3j proces\u00f3w raportowych w oparciu o wymagania biznesowe przy u\u017cyciu Google Data Studio\nB\u0119dziesz mie\u0107 realny wp\u0142yw na kluczowe KPI Allegro\nZaanga\u017cujesz si\u0119 w zr\u00f3\u017cnicowane projekty z obszaru styku Finans\u00f3w i Technologii,\nOtrzymasz mo\u017cliwo\u015b\u0107 rozwoju w obszarze BI i AI&ML oraz umiej\u0119tno\u015bci zwi\u0105zanych z programowaniem w j\u0119zyku Python\nZe swojej strony oferujemy:\nModel pracy hybrydowej, kt\u00f3ry ustalisz z liderem i zespo\u0142em. Mamy \u015bwietnie zlokalizowane biura ( z w pe\u0142ni wyposa\u017conymi kuchniami i parkingami dla rower\u00f3w) i znakomite narz\u0119dzia pracy (podnoszone biurka, interaktywne sale konferencyjne)\nBonus roczny do 10% wynagrodzenia rocznego liczony z kwoty brutto (zale\u017cny od Twojej oceny rocznej oraz wynik\u00f3w firmy)\nBogaty pakiet \u015bwiadcze\u0144 pozap\u0142acowych w systemie kafeteryjnym \u2013 Ty decydujesz z czego korzystasz (do wyboru mamy m.in. pakiety medyczne, sportowe, lunchowe, ubezpieczenia, bony na zakupy)\nZaj\u0119cia angielskiego op\u0142acane przez nas i skoncentrowane na specyfice Twojej pracy\nHackathony, turystyk\u0119 zespo\u0142ow\u0105, bud\u017cet szkoleniowy oraz wewn\u0119trzna platforma MindUp (m.in. szkolenia z zakresu organizacji pracy, sposobu komunikacji, motywacji do pracy oraz r\u00f3\u017cnych technologii i zagadnie\u0144 merytorycznych)\nWy\u015blij nam swoje CV i sprawd\u017a dlaczego #dobrzetuby\u0107","19":"Unternehmensbeschreibung\nDie Bosch Sensortec GmbH ist ein international f\u00fchrender Anbieter von Sensorl\u00f6sungen auf der Basis mikroelektromechanischer Systeme (MEMS) im Bereich der Unterhaltungselektronik. Wir entwickeln und vermarkten Schl\u00fcsseltechnologien f\u00fcr Smartphones und Tablets, Hearables, Wearables, Smartglasses, Augmented und Virtual Reality Anwendungen, Spielkonsolen und vieles mehr. Unsere Sensoren verbessern das Wohlbefinden und den Lebensstil der Menschen und erm\u00f6glichen Applikationen der Unterhaltungselektronik die Welt um uns herum wahrzunehmen. MEMS-Sensoren sind somit ein wesentlicher Bestandteil der Basis einer vernetzten Welt. Die Bosch Sensortec GmbH ist eine hundertprozentige Tochtergesellschaft der Robert Bosch GmbH.                                         \nDie Bosch Sensortec GmbH freut sich auf Ihre Bewerbung!\nStellenbeschreibung\nAls Teil unseres Teams gewinnen Sie einen Einblick in unsere Abteilung, verantwortlich f\u00fcr die Entwicklung zuk\u00fcnftiger Intertialsensoren und Sensorsysteme im Bereich Consumer Electronics. Wir implementieren technische Innovationen und erm\u00f6glichen dadurch herausragende Sensorsystemeigenschaften und stellen die zuverl\u00e4ssige Systemintegration und Testdurchf\u00fchrung f\u00fcr die Serienproduktion sicher.\nSie unterst\u00fctzen bei Vorbereitung, Durchf\u00fchrungen und Auswertung von Inertial Sensor Messungen  \nSie sind zust\u00e4ndig f\u00fcr die Definition und Implementierung der Auswertung von umfangreichen Charakterisierungs- und Erprobungsdaten mittels Werkzeugen aus dem Bereich Big Data Analytics & Data Science und entwickeln kreative L\u00f6sungen in Python, Knime, Tableau oder Power BI\nSie unterst\u00fctzen bei der Entwicklung datengetriebener Konzepte und Algorithmen zur Verbesserung von ausgew\u00e4hlten Leistungsmerkmalen und verifizieren diese anhand Labormessungen\nSie verfolgen die Abstimmung und Harmonisierung der entwickelten L\u00f6sungen mit Abteilungs- und Firmenweiten Big Data Teams\nSie sind Teil eines internationalen und multikulturellen Entwicklungsteams\nQualifikationen\nPers\u00f6nlichkeit: Kommunikative Kompetenz und kreatives Denken, sowie Teamgeist\nArbeitsweise: Selbstst\u00e4ndige, strukturierte und analytische Arbeitsweise\nErfahrungen und Know-How: Erfahrung mit Big Data oder Machine Learning \/ KI.\nQualifikation: Verst\u00e4ndnis von Werkzeugen der Datenverarbeitung und Visualisierung (z.B. Knime, Power BI, Tableau). Gute Kenntnis einer Programmiersprache, bevorzugt Python.\nSprachen: Gute Englischkenntnisse, Deutschkenntnisse sind w\u00fcnschenswert\nAusbildung: Laufendes Master-Studium der Informatik, Mathematiker, Physik oder eine vergleichbare Ausbildung\nZus\u00e4tzliche Informationen\nDas Bosch PreMaster Programm (GapYear Programm) ist ein zweistufiges Qualifizierungsprogramm f\u00fcr engagierte Bachelor-Absolventinnen und Absolventen, die das Ziel haben, ein Masterstudium zu absolvieren. Nach dem Bachelor bietet die erste Phase bis zu 12 Monaten praktische Erfahrung, um die fachlichen und unternehmerischen Zusammenh\u00e4nge kennenzulernen. Die zweite Phase umfasst das Masterstudium und beinhaltet weitere Events und Seminare sowie pers\u00f6nliche Betreuung durch einen Mentor auf dem Weg zum erfolgreichen Abschluss.\nBeginn: nach Absprache\nVielfalt und Inklusion sind f\u00fcr uns keine Trends, sondern fest verankert in unserer Unternehmenskultur. Daher freuen wir uns \u00fcber alle Bewerbungen: unabh\u00e4ngig von Geschlecht, Alter, Behinderung, Religion, ethnischer Herkunft oder sexueller Identit\u00e4t.\nSie haben Fragen zum Bewerbungsprozess?\nSamuel Zinn (Personalabteilung)\n+49 7121 35-33717\nSie haben fachliche Fragen zum Job?\nHolger W\u00fcst (Fachabteilung)\n+49 7121 35-31522\nWeitere Information auch online unter:\nhttps:\/\/www.bosch.de\/karriere\/dein-einstieg\/absolventinnen-und-absolventen\/premaster-program\/","20":"Company Description\nAt Palo Alto Networks\u00ae everything starts and ends with our mission:\nBeing the cybersecurity partner of choice, protecting our digital way of life.\nWe have the vision of a world where each day is safer and more secure than the one before. These aren\u2019t easy goals to accomplish \u2013 but we\u2019re not here for easy. We\u2019re here for better. We are a company built on the foundation of challenging and disrupting the way things are done, and we\u2019re looking for innovators who are as committed to shaping the future of cybersecurity as we are.\nWe\u2019re changing the nature of work. Palo Alto Networks is evolving to meet the needs of our employees now and in the future through FLEXWORK, our approach to how we work. From benefits to learning, location to leadership, we\u2019ve rethought and recreated every aspect of the employee experience at Palo Alto Networks.  And because it FLEXes around each individual employee based on their individual choices, employees are empowered to push boundaries and help us all evolve, together.\nJob Description\nYour Career\nPrisma Access\u2122 (formally GlobalProtect Cloud Service) provides protection straight from the cloud to make access to the cloud secure. It combines the connectivity and security you need - and delivers it everywhere you need it. Using cutting-edge public and private cloud technologies extending the next-generation security protection to all cloud services, customers on-premise remote networks and mobile users.\nWe\u2019re building a world-class data analytics platform for Prisma Access. Our software stack spans multiple platforms and technologies. If you have a proven data engineering background and a broad software development skill set, and enjoy working on products with a diverse tech-stack, then this position could be the perfect fit.\nYour opportunity:\nCreate and maintain optimal big data pipeline architecture\nIdentify, design, and implement data processing improvements - optimizing data delivery, re-designing infrastructure for greater scalability, etc\nRapidly prototype ideas in an agile team with quickly evolving requirements\nMaintain high quality standards and promote best practices within the team\nBuild the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and\/or other cloud-provider (e.g. AWS, GCP) technologies\nBuild analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics\nCreate data tools for analytics and data scientist team members that assist them in building and optimising our product into an innovative industry leader\nWork with data and analytics experts to strive for greater functionality in our data systems\nQualifications\nYour Experience:\nWe are looking for a candidate with 5+ years of experience in a Data Engineering role, who should also have experience using the following software\/tools:\nExperience with relevant big data tools (e.g. Beam, Spark, Kafka, etc)\nExperience with relational SQL and NoSQL databases, e.g. MySQL, Postgres and MongoDB, etc.\nExperience with various, related AWS and GCP cloud services: EC2, EMR, RDS, Redshift, Pub\/Sub, BigQuery, DataFlow\nIn addition, we\u2019re looking for candidates with the following experience and skills:\n4 year Computer Science Bachelor's degree (or equivalent)\nStrong Java software-development expertise\nAn excellent working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases\nExperience building and optimizing \u2018big data\u2019 data pipelines, architectures and data sets\nA conceptual thinker who can articulate and execute a vision from concept to production\nWorking knowledge of message queuing, stream processing, and highly scalable \u2018big data\u2019 data stores\nStrong understanding of cloud infrastructure (e.g. AWS, GCP) products, services and technologies\nStrong analytic skills related to working with unstructured datasets\nExcellent communication skills (written and verbal)\nExperience supporting and working with cross-functional teams in a dynamic environment\nExcellent problem-solving skills\nCandidates with experience in multiple programming languages and other platforms will be highly regarded.\nAdditional Information\nThe Team\nOur engineering team is at the core of our products \u2013 connected directly to the mission of preventing cyberattacks. We are constantly innovating \u2013 challenging the way we, and the industry, think about cybersecurity. Our engineers don\u2019t shy away from building products to solve problems no one has pursued before.\nWe define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.\nOur Commitment\nWe\u2019re trailblazers that dream big, take risks, and challenge cybersecurity\u2019s status quo. It\u2019s simple: we can\u2019t accomplish our mission without diverse teams innovating, together.\nWe are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com.\nPalo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.\nCovid-19 Vaccination Information for Palo Alto Networks Jobs\nVaccine requirements and disclosure obligations vary by country.\nUnless applicable law requires otherwise, you must be vaccinated for COVID or qualify for a reasonable accommodation if:\nThe job requires accessing a company worksite\nThe job requires in-person customer contact and the customer has implemented such requirements\nYou choose to access a Palo Alto Networks worksite\nIf you have questions about the vaccine requirements of this particular position based on your location or job requirements, please inquire with the recruiter.","21":"Company Description\nTransforming businesses, driving success: SmarTek21\nSmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev\/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients\nJob Description\nSmarTek21 is looking for a hands-on Big Data Solution Architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.  \nQualifications\n\u2022 Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python.\n\u2022 Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks.\n\u2022 Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP).\n\u2022 Solid understanding of enterprise strategies for data security and data governance.\n\u2022 Experience in practice development, architecture, and consulting or product development.\n\u2022 Experience delivering data analytics projects and architecture guidelines.\n\u2022 Experience in engaging with enterprise architects. Non-technical Skills:\n\u2022 Excellent oral and written communication and presentation skills.\n\u2022 Ability to handle ambiguous situations and take trade-off decisions.\n\u2022 Strong problem solving and analytical skills to break down complex problems into smaller components.\n\u2022 Ability and willingness to perform in a team environment.\nRequirements:\n\u2022 Understand prospect\/customer\/partner technology landscape.\n\u2022 Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation.\n\u2022 Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers\/partners.\n\u2022 Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints.\n\u2022 Collaborate with the engineering team to create proof-of-concepts (POCs).\n\u2022 Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices.\n\u2022 Demonstrate business value of proposed solutions or current products to prospects and customers.\nSalary Range: $200,000-$215,000 (may be subject to change outside of WA State)\nAdditional Information\nWhat Is in It for You:\nPaid Time off \u2013 start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service.\nPaid Holidays - 8 paid holiday a year in addition to your PTO.\nHealth Insurance for FT employees \u2013 we pay 100 % premium of medical, dental and vision.\nHealth Insurance for FT employee\u2019s family \u2013 we pay 50% of premium for medical, dental and vision for dependents.\n401(k) \u2013 we administer 401(K) retirement contribution for FT employees.\nLife Insurance\/Short Term and Long-Term Disability \u2013 at no cost to you\nOpportunities for internal promotions\/career advancement\nFamily friendly work hours (closed on weekends and paid holidays)\nSmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and\/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class.","22":"Company Description\nThe future. It\u2019s on you. You & Western Digital.\nWe\u2019ve been storing the world\u2019s data for more than 50 years. Once, it was the most important thing we could do for data. Now we\u2019re helping the world capture, preserve, access and transform data in a way only we can.\nThe most game-changing companies, consumers, professionals, and governments come to us for the technologies and solutions they need to capture, preserve, access, and transform their data.\nBut we can\u2019t do it alone. Today\u2019s exceptional data challenges require your exceptional skills. It\u2019s You & Us. Together, we\u2019re the next big thing in data. \nWestern Digital\u00ae data-centric solutions are found under the G-Technology\u2122, HGST, SanDisk\u00ae, Tegile\u2122, Upthere\u2122, and WD\u00ae brands.\nJob Description\nDo you love working with people and data? We are looking for a highly collaborative individual who is passionate about being part of a world-class People Analytics team. This is an exciting opportunity for an individual who believes in the power of inclusion and is enthusiastic about bringing an organization\u2019s people data to life. The People Data Analyst will work closely with HR and business leaders to deliver insights based on quantitative and qualitative data that strengthens data-driven decision-making and evolves a culture of growth and innovation.\nIf you thrive in a fast-paced, dynamic environment, are looking to be a part of a team that is developing exciting new processes, and you are eager to take on new opportunities and challenges with a sense of urgency and enthusiasm, then this could be an exciting opportunity for you.\nESSENTIAL DUTIES AND RESPONSIBILITIES: \nPartner with HR team members, leaders, and stakeholders across Western Digital to develop a deep understanding of current and emerging HR use cases and challenges, identify priorities for research and execute impactful research projects.\nProvide strategic support to the Human Resources function in the areas of people data, metrics, and reporting. \nCreates, maintains, and ensures quality assurance of key people data sets, reports, and metrics. \nDesigns and implements self-service reporting tools and data management that reflects the complexity of the business\nDesigns and implements dashboards that present data in a meaningful and actionable framework for leadership.\nDesign, build and deploy the analytical\/ BI reports like People Insights & Collaboration using enterprise-level tools and technologies.\nConnect and analyze multiple sources of organizational data to provide actionable insights on HR strategies\nResponsible for analyzing and visualizing the various domain-specific data.\nProvide subject matter expertise and advice on People analytics topics and data collection\nCommunicate research findings to HR groups and senior leaders relating findings to technical and non-technical audiences\nPresent research insights both internally and outside the organization to become a thought leader in this space\nCollaborate with People Analytics and IT team members to access data and explain data requirements\nProducing the weekly, monthly, and quarterly scheduled reports, including Executive Management Information and Workforce Metrics, in an accurate and timely manner\nSupporting the effort of data integrity and data governance\nDemonstrate ethics and judgment when dealing with confidential data and research with underrepresented communities\nStay current on research and best practices, summarizing findings and recommendations for enhancing current processes and practices\nQualifications\n8-10 years of professional-level work experience with an emphasis on HR and People Analytics Deep subject-matter expertise in HR domain, and\/or closely related areas.\nExpertise on migrating tableau dashboards to PowerBI. Enable all tableau features while converting to PowerBI.\nExcellent communication skills with demonstrated ability to build strong relationships within an organization\nComfortable presenting information and ideas to HR and Business Leaders\nAdvanced SQL Knowledge ( Oracle, Teradata )\nWorking experience and\/or familiarity with PowerBI\/Tableau, Python, R or related tools.\n5+ years of experience with PowerBI\/Tableau, OBIEE, Alteryx, or related tools\nStrong business and human resources acumen, understanding internal and external market forces, operating priorities and Finance\/ROI\nExceptional interpersonal skills with people across geographies, functions, and levels of the organization\nStrong Project Management skills, ability to prioritize and meet deadlines and measure progress and success and manage multiple projects with competing deadlines\nAbility to handle highly confidential data\nThrives in a fast-paced, complex environment\nHighly motivated self-starter who takes initiative\nGoal-oriented, proactive, accountable, and passionate about driving results\nMaintains a positive attitude and forward-thinking approach despite challenges\nShows personal commitment and acts to continuously learn and improve\nActively seeks out information about a wide variety of cultures and viewpoints\nStrong organizational skills with exceptional attention to detail and a strong design instinct\nPreferred:\nBachelor\u2019s\/Master\u2019s degree, Ph.D. a plus, with a focus or specialization in HR and\/or in a field emphasizing people research in organizations (e.g., Industrial\/Organizational Psychology, Organizational Behavior, Management, Organizational Development)\nExperience conducting research in organizations, including research design, data collection, statistical analysis, interpretation of results, and making actionable recommendations\nAbility to select and apply appropriate statistical methods to people research problems in organizations\nAdditional Information\nBecause Western Digital thrives on the power of diversity and is committed to an inclusive environment where every individual can thrive through a sense of belonging, respect, and contribution, we are committed to giving every qualified applicant and employee an equal opportunity.  Western Digital does not discriminate against any applicant or employee based on their protected class status and complies with all federal and state laws against discrimination, harassment, and retaliation, as well as the laws and regulations set forth in the \"Equal Employment Opportunity is the Law\" poster.\nPart of creating a diverse and inclusive workplace includes ensuring that all qualified applicants and employees are provided equal consideration for any available opportunity.  Western Digital is committed to offering opportunities to applicants with a disability.  If you need a reasonable accommodation, email us at Careers.Accommodations@WDC.com.  In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying.","23":"Company Description\nBosch Sensortec GmbH is a technology leader in sensing solutions based on microelectromechanical systems (MEMS) and dedicated to the consumer electronics world. We develop and market key technologies for smartphones and tablets, hearables, wearables, smartglasses, augmented and virtual reality applications, gaming devices and many more. Our sensors improve people\u2019s well-being and lifestyle and enable consumer electronic devices to sense the world around us. MEMS sensors are therefore an essential part of the foundation for a connected world. Bosch Sensortec GmbH is a wholly owned subsidiary of Robert Bosch GmbH.     \nBosch Sensortec GmbH is looking forward to your application!\nJob Description\nAs part of our team you get an insight into our department being responsible for the development of our next generation consumer inertial sensors and sensing systems. We implement technological innovations enabling advanced sensor system performance and ensure reliable system integration and testing for high volume and high-quality mass production.\nYou support in preparation, execution and evaluation of inertial sensor measurements\nYou are responsible for the definition and implementation of evaluation templates for large characterization and qualification datasets, by applying tools of the big data and data science domain and you develop creative solutions in Python, Knime, Tableau or Power BI\nYou support the development of data driven concepts and algorithms for the improvements of selected sensor key performance parameters and verify those by dedicated lab measurements\nYou align and harmonize your solutions with other department and company stakeholders\nYou are part of an international and multicultural development team\nQualifications\nPersonality: Positive team player with good communication skills, creative thinking\nWorking Practice: Experience in Big Data and Machine Learning \/ AI.\nExperience and Knowledge: Understanding of statistics and visualization tools e.g. Knime, Power BI, Tableau. Mastering of a programming language, preferable Python\nLanguages: Very good spoken and written English skills, German is a plus\nEducation: Current Master studies in Computer or Data Science, Mathematics, Physics or similar major\nAdditional Information\nThe Bosch PreMaster Program (Gap Year Program) is a two-stage qualification program for committed graduates with Bachelor's degrees who want to complete a Master's degree. After the Bachelor's degree, the first phase provides up to 12 months' practical experience for familiarization with technical and business interrelationships. The second phase comprises the Master's course and includes additional events and seminars as well as personal mentoring on the road to successful completion. \nNeed support during your application?\nSamuel Zinn (Human Resources) \n+49 7121 35-33717\nNeed further information about the job?\nHolger W\u00fcst (Functional Department)\n+49 7121 35-31522\n Further information can be found online:\nhttps:\/\/www.bosch.de\/en\/career\/your-entry\/graduates\/premaster-program\/","24":"As a mid-level or senior-level Business Intelligence Developer, you\u2019ll play a crucial role in fostering collaboration and building partnerships across the organization. Your main goals will be to develop BI reporting solutions and drive operational efficiency and effectiveness. Your expertise in BI reporting solutions will be invaluable in co-developing products and sharing knowledge with other teams. By providing insights and valuable predictive information, you\u2019ll equip business teams and leaders with the tools to highlight potential risks and opportunities that drive the need for change. Your contributions will have a significant impact on the company\u2019s success, and you\u2019ll be a vital part of a team dedicated to delivering innovative solutions that drive business growth.\nYou\u2019ll achieve this by enabling data-driven decisions and empowering stakeholders to make informed choices based on actional insights from your reports and dashboards and by:\nDesigning and developing reporting solutions using IBM Cognos and Tableau as per business requirements\nProviding expertise in data visualization and graphical report design\nParticipating in upgrade and migration projects from legacy to future state\nWorking closely with business and data development teams to drive requirements to completion\nMaintaining and supporting existing business intelligence solutions\nMaintaining knowledge of industry standards, best practices, and upcoming product releases\nIdentifying new opportunities to leverage data, integrate and enhance business value\nMentoring other developers in utilizing the tools\nAssisting in other areas of the department and company as necessary\nSupporting enterprise BI strategy and organizational change management\nDefining, setting up, and executing test cases to validate that the solution meets business requirements\nProviding consultative support and advice on technology projects led by business partners\nWorking with business partners to understand BI reporting and analytical requirements\nProviding technical support on ad-hoc queries on the usage of the BI application\nAssisting users in building ad-hoc reports and analysis\nEnvisioning future use cases for reporting and analytical solutions\n\nRequirements\nBachelor\u2019s in IT, Computer Science, or related field or equivalent experience\nMid-level: 3-5 years experience in BI development\nSenior-level: 6-10 years experience in enterprise BI development\nExperience creating complex reports, dashboard applications, and scorecards\nExperience with 2-3 of the following tools: Microstrategy - AWS Enterprise Version 2021; Tableau; Informatica - Power Center Version & DEI - Version; IBM Cognos Analytics; SAS\nExperience with SQL, with proven ability to write efficient queries\nExperience working directly with business teams to address ad-hoc queries and provide guidance on challenges they are facing\nExperience writing reports over various data sources, including Oracle, Teradata, SQL Server databases, etc.\nExperience working with AWS, Azure, Databricks\nStrong problem-solving and data analysis skills\nAbility to follow processes and execute project deliverables in a timely manner\nExperience capturing business requirements and providing solutions\nExperience coordinating with the team across the geographical regions\nStrong written and verbal communication skills\nStrong analytical and problem-solving skills with the ability to effectively negotiate with other teams to create a mutually beneficial solution\nSolid understanding of data modeling concepts\nAbility to manage and prioritize multiple requests\nProven ability and desire to grow technical skill set\nExperience with or desire to learn and work with mobile reporting solutions\nExperience with Agile development methodology\nTHIS POSITION REQUIRES RESIDENCY IN MARYLAND OR NORTHERN VIRGINIA and is PARTIAL REMOTE 2 DAYS A WEEK. THIS POSITION IS NOT ELIGIBLE FOR A FULL REMOTE SCHEDULE. Hiring candidates with a permanent residence within commuting distance to Columbia, MD.\nMust be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future. Must be able to obtain a Public Trust Clearance. Fully-vaccinated status for COVID-19 is required as a condition of employment.\nThe salary range for this role takes into account the wide range of factors that are considered in making compensation decisions, including but not limited to skill sets; experience and training; education and certifications; and other business and organizational needs.\n\nABOUT NEXT PHASE SOLUTIONS AND SERVICES, INC.\nInnovation. It\u2019s What Defines Us.\nNext Phase Solutions and Services, Inc. provides insights and solutions for healthcare, engineering and science research. Next Phase commits to creating an environment where our employees achieve their full potential, increase their productivity, and expand their professional and personal horizons. We look for bright, innovative people that achieve results, understand the importance of being a productive and supportive team member, and put the customer\u2019s satisfaction first. Next Phase leadership is looking for new leaders, scientific and technical subject matter experts, and technically savvy people that are interested in putting forth the effort and commitment needed to grow our company.\nWill you join us to share in the success?\nNext Phase Solutions and Services, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\nBenefits\nWe offer a competitive total compensation and benefits package. Benefits include, but are not limited to:\nHEALTH AND WELLNESS BENEFITS\nMedical Insurance (three healthcare plans to choose from), Dental Insurance, and Vision Insurance\nFlexible Spending Account (FSA) and Health Savings Account (HSA)\nCompany-sponsored Wellness Program\nWELL-BEING PROGRAM\nOur Well-being programs offer a variety of benefits that support our employee\u2019s physical, financial and lifestyle wellness. Enjoy walks around a beautiful lake, work out in our on-site gym, grab a healthy snack, enjoy bagel Fridays and lunches, attend yoga, benefit from a hybrid flex schedule, join a Fitbit group or sports team, or get some great financial advice \u2013 just to name a few of the well-being program benefits.\nPERSONAL INSURANCE BENEFITS\nCompany-paid Life Insurance\nCompany-paid AD&D Insurance\nCompany-paid Short-term and Long-term Disability Insurance\nPAID LEAVE\nCompetitive paid-time-off programs\nPaid holidays\nPaid Maternity leave for mothers recovering from the birth of a child\nRETIREMENT\n401K plan with 5% employer contribution (employee contributions are not required to receive 5% employer contribution)\nPROFESSIONAL DEVELOPMENT\nEmployees are reimbursed for professional development activities including classes, books, technical certification\/testing fees, professional dues\/subscriptions, professional licenses required for a position\nPET INSURANCE\nChoose from two options to help keep your pets happy and healthy","25":"Job Description\nAbout You\nWe are looking for a Big Data Engineer to work with large data volumes read from scattered information sources in an organization's technology infrastructure.\nYou bring to Applaudo the following competencies:\n2+ years of experience with Scala and Spark\n3+ years of data delivery, ETL (extract, transform and load) and data warehouse design, analysis, and programming experience.\nExperience with Apache Hive and Apache Hudi.\nExperience with Google Cloud Platform (Big Query).\nExperience with an excellent grasp of relational and dimensional data modeling.\nStrong mathematical, statistical, and analytics skills.\n1+ year of Agile experience.\nEnglish is required, as you will work directly with US-based clients.\nYou will be accountable for the following responsibilities:\nExtracting data from different data sources and transferring it into a data warehouse environment.\nDesigning, maintaining, and implementing transactional and analytical data storage structures.\nDesign, build and maintain data pipelines, consuming for multiple sources, and servicing multiple tenants.\nElaborate informative, expressive, and meaningful reports that support business decision-making processes through the information provided.\nReporting and subsequently translating the emanating results into good technical and consistent data designs.\nWork schedule from 9:30am until 7:30pm India Standard Time \nQualifications\nTechnical Skills:\n2+ years of experience with Scala and Spark (Apache Hive and Apache Hudi).\nExperience with Google Cloud Platform (Big Query).\nAdditional Information\nHere at Applaudo Studios values as trust, communication, respect, excellence and team work are our keys to success. We know we are working with the best and thus treat each other with respect and admiration without asking.\nSubmit your application today, and don't miss this opportunity to join the Best Digital team in the Region!\nWe truly appreciate all the hard and outstanding work our team makes every day at Applaudo Studios, and that's why the perks that we offer, are deeply thought and designed as a way to thank them for their commitment and excellence.\nSome of our perks and benefits:\nWork from home\nFlexible schedule\nCelebrations\nSpecial discounts\nEntertainment area\nFlexible work spaces\nGreat work environment\nPrivate medical insurance\n*Benefits may vary according to your location and\/or availability. Request further information when applying.","26":"The world of payment processing is rapidly evolving, and businesses are looking for loyal and strategic partners, to help them grow.\nNuvei (Nasdaq: NVEI) (TSX: NVEI) is bringing payments up to speed. Our future-proof technology allows businesses to accept cutting-edge payment options, optimize new revenue streams, and get the most out of their stack. We believe in turning payment barriers into accelerants, propelling businesses forward with tailored solutions. With a single integration and advanced customization tools, Nuvei delivers unsurpassed flexibility that enables businesses to adapt quickly and enter new markets seamlessly.\nAt Nuvei, we live our core values, and we thrive on solving complex problems. We\u2019re dedicated to continually improving our product and providing relentless customer service. We are always looking for exceptional talent to join us on the journey!\n\nYour Mission\nWe are looking for a self-driven intelligence analyst to join our international sales team. The person on this position will manage analysis and prepare complex presentations. This function requires a highly organized, self-motivated, willing-to-learn, resourceful, and solutions-oriented individual who execute well in a dynamic environment while working on multiple projects.\nKey responsibilities include, but are not limited to:\nCollaborate with other teams to understand their needs and work with them to provide reporting efficiencies and analyses to achieve set goals.\nUse BI\/analytics tools and CRM tools (SQL precisely).\nUse BI tools to manipulate and summarize data and design dashboards to present information in a visually compelling way.\nCoordinate with other team members on data collection, analyses, and synthesis of information.\nAble to manage time, workload, and responsibilities effectively.\nBe actively engaged in learning about the fintech industry and finding relevant insights.\n\nKey responsibilities include, but are not limited to:\n2+ years working experience in a data centric role.\nKnowledge & expertise in analytics.\nGood verbal communication skills.\nAbility to organize complex information in a concise and user-friendly way.\nSuperior Excel skills.\nComfortable interfacing with people at all levels within the organization and in various locations.\nStrong organization skills and detail oriented.\nAbility to multi-task in a dynamic environment is essential.\nAggressive self-starter, ability to work both independently and as a team member.\nProficient English.\n\nNuvei is an equal-opportunity employer that celebrates collaboration and innovation and is committed to developing a diverse and inclusive workplace. The team at Nuvei is comprised of a wealth of talent, skill, and ambition. We believe that employees are happiest when they\u2019re empowered to be their true, authentic selves. So, please come as you are. We can\u2019t wait to meet you.\nBenefits\nLong Term Incentive Plan that creates an opportunity for all employees to financial benefit from Nuvei\u2019s growth\n2.5 additional days of annual leave a quarter, if company hit quarterly targets\nA challenging job in a fast developing, international company.\nFriendly work environment where you can thrive and develop your skills.\nCareer advancement possibilities.\nCompetitive remuneration package.\nNuvei offers a wide variety of additional benefits which include Additional Health insurance incl Dentist, Sport card, Food vouchers, Employee discounts card, Seminars and conferences tickets, Playroom, and many others additional perks.\nWorking Language\nEnglish (written and spoken) is the language used most of the time, as work colleagues, clients, and strategic suppliers are geographically dispersed.\n\nPlease send your resume in English.","27":"Are you looking to be in a workplace where colleagues inspire one another? Are you interested in competitive and impactful benefits? Do you prefer flexible work arrangements? \nWe are seeking a talented and experienced Product Owner to join our team of experts focused on designing and building microservices that leverage Big Data and Artificial Intelligence (AI) to identify and act on personal information in the RelativityOne platform. This successful candidate will lead the development and execution of the product roadmap to ensure the commercial success of both Text IQ for Data Breach and Text IQ for Personal Information offerings. \nResponsibilities:\nDevelop and execute on the product roadmap that supports the Text IQ for Data Breach and Text IQ for Personal Information offerings. \nCollaborate with cross-functional teams (including engineering, operations, marketing, sales, and customer success) to ensure successful product delivery and customer adoption. \nIdentify market trends, customer needs, and competitive insights to inform product strategy and roadmap. \nCreate user stories and prioritize the product backlog to align with the overall product vision and goals. \nWork closely with the engineering team to deliver high-quality product features and functionality, and ensure timely product delivery. \nDefine and measure product success metrics, and use data to continuously improve product performance and user satisfaction. \nCommunicate product strategy, roadmap, and progress to internal and external stakeholders. \nCollaborate with the go-to-market teams to develop effective product positioning, messaging, and launch plans. \nCollect, analyze, and summarize data from disparate sources to drive conclusions and recommendations. \nWork independently and effectively in a results-oriented, efficient environment. \nDeliver products and ensure customer success through strong project management and team leadership. \nCommunicate effectively with stakeholders at all levels, including senior leadership. \nManage and prioritize multiple tasks and projects simultaneously. \nYour skills:\nBS or BA degree; 7+ years of work experience, with at least 5 in product management. \nStrong problem-solving skills, including ability to dissect complicated technical problems, simplify experiences, and innovate on behalf of our customers. \nStrong technical acumen and working knowledge of software architectures and AI\/ML. \nStrong business knowledge to help build go-to-market machinery for existing and new products. \nSolid understanding of software development lifecycle and agile methodologies. \nAbility to collaborate with and lead teams of all levels and disciplines within an organization, from engineers to senior leadership. \nA history of developing and owning product roadmaps to drive business outcomes. \nExperience collecting, analyzing, and summarizing data from disparate sources to drive conclusions and recommendations. \nEntrepreneurial spirit and ability to work independently and effectively in a results-oriented, efficient environment. \nStrong track record of delivering products and ensuring customer success. \nOrganized, with the ability to communicate effectively with stakeholders. \nExcellent written and verbal communication skills. \nExperience working with international teams is a plus. \nRelativity is a diverse workplace with different skills and life experiences\u2014and we love and celebrate those differences. We believe that employees are happiest when they're empowered to be their full, authentic selves, regardless how you identify.\nBenefit Highlights:Comprehensive health, dental, and vision plansParental leave for primary and secondary caregivers Flexible work arrangementsTwo, week-long company breaks per yearUnlimited time offLong-term incentive programTraining investment program\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.","28":"Company Description\nThrough Columbia University's Pre-College Programs, high schoolers from around the globe prepare for the college experience through exploratory coursework and community activities over seven weeks in the summer. This highly selective program is open to academically exceptional high school students, entering grades 9\u201312 and freshman year of college.\nJob Description\nColumbia University\u2019s Pre-College Programs for High School Students is seeking qualified candidates to develop and teach online courses during Summer \u201923. \nPlease Note: Course(s) and course availability is subject to change.  \n2 Week Courses: (Sessions 1& 2)\nBig Data, Machine Learning, and their Real World Applications\n1 Week Courses: (Session 3)\nBig Data, Machine Learning, and their Real World Applications\nCourse descriptions and schedule information can be found via the links above. \nOnline Course Dates: All classes meet Monday-Friday\nSession 1: July 3rd- July 14th (8 -11am or 12-3pm or 5-8pm)\nSession 2: July 17th- July 28th (8 -11am or 12-3pm or 5-8pm)\nSession 3: August 7th- August 11th (10 -12pm & 1-3pm)\nResponsibilities:\nDevelop course content, syllabus, lesson plans, and assigned work\nLead and attend all online class sessions\nEstablish and maintain a dynamic in-class environment tailored for our high school population\nEvaluate student work and write a holistic evaluation of each participant after the course ends\nMonitor and address student concerns and inquiries (you will have around 20-24 students)\nAttend and complete all required online trainings\nQualifications\nGraduate degree or equivalent professional or academic background\nExpertise in the pertinent subject matter\nAptitude for teaching\nAdditional Information\nHiring Salary Ranges:\nSessions 1 & 2 Online: $3,300 - $4,200\nSession 3 Online:  $2,200 - $2,800\nAdditional Information:\nPlease specify which courses you would be interested in teaching.  Course descriptions and schedule information are available via the links above\nPlease submit a resume inclusive of teaching experience as well as formal teaching evaluations (if available)\nApplicants must have U.S. work authorization and will need to be in the U.S. while teaching\nApplicants may not hold a concurrent appointment with Columbia for the duration of their appointment\nOnce hired, applicants are required to submit to a third party background check and complete Protection of Minors training in addition to other training(s) mandated by the University\nAll Columbia University faculty and staff must follow the COVID-19 vaccination protocol. Learn more about the vaccination requirements here: https:\/\/covid19.columbia.edu\/\nAll your information will be kept confidential according to EEO guidelines.\nColumbia University is an Equal Opportunity\/Affirmative Action employer.","29":"Company Description\nOur culture is defined by our values and our deep commitment to help our clients succeed. We are a division of the 38th largest company in the world and bring to bear the strength of a very large network of interconnected Hitachi companies. At the same time we remain absolutely committed to the nimble agility that helped us grow Hitachi Solutions from three founding partners to nearly 2,000 consultants, developers and support personnel all around the globe.\nHitachi Solutions is a leader in providing industry solutions based on Microsoft Dynamics AX and Microsoft Dynamics CRM. Hitachi Solutions provides its customers with industry focus, software industry domain expertise, and proven tier-1 people. Hitachi Solutions works with its customers to understand their unique formula for success and develops solutions that improve their business and attain measurable results.2011, 2009, 2006 & 2005 Microsoft Dynamics Partner of the Year (Finalist 2008, 2007). Microsoft Global Dynamics Award (Global Dynamics Partner of the year) 2014. \nHitachi Solutions is a core IT company of the Hitachi Group, which employs some 400,000 people worldwide. Through systems integration, we provide ideal solutions and products for customers. Headquartered in Tokyo, Japan, Hitachi Solutions' reach extends to group companies in Japan and abroad, working with a worldwide network of alliance partners. We bring solutions and products to diverse countries and regions including Asia, the United States and Europe. The flagship company in the Hitachi Group's information and communication system solutions business, Hitachi Solutions also offers solutions for social innovation such as smart cities.  \nFor more information on Hitachi Solutions, please visit: https:\/\/web.hitachi-solutions.com\nJob Description\nRequirements:\nA minimum of 5+ years full-time experience using VertiPaq\nAble to quickly provide both M and DAX solutions\nHands-on experience working in Business Intelligence, Data Engineering or Data Science\nUnwavering ability to quickly propose solutions by recalling the latest best practices learned from MVP & Product Team articles, MSFT documentation, whitepapers, and community publications\nA passion for understanding and integrating business semantics into technology solutions\nExcellent communication, presentation, influencing, and reasoning skills\nAbility to lead projects\nFamiliarity with the Azure data platform, e.g., ADLS, SQL Server, ADF, Databricks etc.\n We would like to see a blend of the following technical skills:\nInformation Design\nDAX, M, PowerShell, and T-SQL\nVertiPaq and MashUp engine knowledge\nPower BI Desktop, Power BI Dataflows, Tabular Editor, DAX Studio, and VertiPaq Analyzer\nPower BI Service architecture design and administration\nData modelling using the Kimball methodology\nAzure Data Factory , Azure Data Leak, Azure Services.","30":"Company Description\nIt all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app, bringing a better way to send, spend, invest, borrow and save to our millions of monthly active users. With a mission to redefine the world's relationship with money by making it more relatable, available and accessible, at Cash App you'll have the opportunity to make a real-world impact with your career.\nToday, Cash App has thousands of employees around the world with a culture geared toward creativity, collaboration and impact. We\u2019ve been a distributed team since day one, and continue to value working across time zones and continents both remotely and in our Cash App offices.\nOur offices are great, but many of our roles can be done remotely from the countries where Block operates. We tailor our experience to champion our employees\u2019 creativity and productivity wherever they are. \nJob Description\nThe BI Team at Cash App enables our teams to make impactful business decisions. Our BI Engineers handle everything from data architecture and modeling to data pipeline tooling and dashboarding. As a Senior BI Engineer at Cash App, you will report to the BI Manager and work with Analysts, Data Scientists, Software Engineers and Product Managers to lay the foundation for analyzing our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, to informing product development. You will build, curate, document, and manage key datasets and ETLs to increase the impact of the entire team.\n\nYou will:\nCreate brand new and optimize existing data models for the most widely used Cash App events, entities, and processes\nStandardize business and product metric definitions in curated and optimized datasets\nBuild pipelines out of our data warehouse\nTeach (and encourage) others to self-serve while building tools that make it simpler and faster for them to do so\nPromote data, analytics, and data model design best practices\nCreate dashboards that help our teams understand the performance of the business and help them make decisions\nQualifications\nYou have:\nBackground\/knowledge in Computer Science, Applied Math, Engineering, Stats, Physics, or a something comparable\n5+ years of industry experience building complex, scalable ETLs for a variety of different business and product use cases\nAn interest in advancing Cash App's vision of building products for economic empowerment - this should be something that legitimately excites you\nTechnologies we use and teach:\nSQL (MySQL, Snowflake, BigQuery, etc.)\nAirflow, Looker and Tableau\nPython and Java\nAdditional Information\nBlock takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate\u2019s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.\n\nZone A: USD $152,100 - USD $185,900\nZone B: USD $144,500 - USD $176,700\nZone C: USD $136,900 - USD $167,300\nZone D: USD $129,300 - USD $158,100\nTo find a location\u2019s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information. \nBenefits include the following:\nHealthcare coverage\nRetirement Plans including company match \nEmployee Stock Purchase Program\nWellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance \nPaid parental and caregiving leave\nPaid time off\nLearning and Development resources\nPaid Life insurance, AD&D. and disability benefits \nPerks such as WFH reimbursements and free access to caregiving, legal, and discounted resources \nThis role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans.\nWe\u2019re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace.\nBlock is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.\nWe believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible. \nLearn more about our efforts to promote inclusion and diversity at block.xyz\/inclusion\nAdditionally, we consider qualified applicants with criminal histories for employment on our team, assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.\nBlock, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.","31":"Unternehmensbeschreibung\nWir bei rheindata beraten unsere Kunden in den Bereichen Big Data, Business Intelligence und Data Science. Wir sind ein buntes Team aus den unterschiedlichsten Fachbereichen wie z.B. Mathematik, VWL, Informatik oder Physik. Uns ist wichtig, dass wir uns weiterbilden k\u00f6nnen und offen sind, unser Wissen zu teilen. Bei uns gibt es wenig B\u00fcrokratie, stattdessen kurze und flache Entscheidungswege und gro\u00dfes Mitspracherecht. Wenn du also Lust hast, uns kennenzulernen\u2026 los geht\u00b4s!\nStellenbeschreibung\nAls BI Berater ETL\/ELT (m\/w\/d)\narbeitest du in unterschiedlichen BI Projekten bei unseren Kunden und entwickelst kreative und innovative BI L\u00f6sungen,\nentwickelst du ETL\/ELT Strecken und zudem orchestrierst und parallelisierst du Ladestrecken,\nerstellst du SQL-basierte Datenbank-Abfragen,\narbeitest du mit strukturierten und unstrukturierten Daten\nund bist du offen f\u00fcr neue Technologien und gibst dein Wissen auch gerne weiter.\nQualifikationen\nDas bringst du mit:\nEinige Jahre praktische Erfahrung im BI Bereich,\nein abgeschlossenes Studium in einem MINT (Mathematik, Informatik, Wirtschaftsinformatik, -mathematik, Physik o.\u00e4.)- oder wirtschaftswissenschaftlichen (BWL, VWL, o.\u00e4.) Fach,\nKommunikationsst\u00e4rke,\nDeutschkenntnisse auf muttersprachlichem Niveau (C2),\nEnglisch flie\u00dfend in Wort und Schrift.\nZudem verf\u00fcgst du \u00fcber Kenntnisse z.B. in:\nSSIS, Talend oder Informatica\nSQL\nErfahrung in Cloud-Plattformen wie Azure, AWS oder GCP\nZus\u00e4tzliche Informationen\nDas bieten wir dir:\n6 Wochen Urlaub im Jahr und in jedem f\u00fcnften Jahr sogar 10 Wochen\neine deinen Bed\u00fcrfnissen entsprechende Einarbeitungsphase mit Begleitung deines Mentors,\ndie M\u00f6glichkeit zu individuell gestaltbaren Sabbaticals,\ndie Teilnahme an unserem Mitarbeiter-Beteiligungsprogramm,\neine kostenlose M-Mitgliedschaft bei Urban Sports Club und verg\u00fcnstigte Konditionen bei L- und XL-Tarifen\nneben einem attraktiven Verg\u00fctungspaket erh\u00e4ltst du nat\u00fcrlich ein Notebook und ein Smartphone sowie weitere Zusatzleistungen wie z.B. Jobticket, JobRad oder betriebliche Altersvorsorge\nje nach Projektgegebenheiten, die M\u00f6glichkeit im Homeoffice zu arbeiten \u2013 wobei du in unserem B\u00fcro im belgischen Viertel nat\u00fcrlich auch immer willkommen bist.","32":"Company Description\nWe\u2019re the world\u2019s leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business.\nJob Description\nOVERVIEW:\nMake the team that changes the way the world experiences sport.\nSportradar is the leading global provider of sports betting and sports entertainment products and services. Since 2001, we have occupied a unique position at the intersection of the sports, media and betting industries; providing sports federations, news media, consumer platforms and sports betting operators with a range of solutions to help grow their business.\n Managed Trading Services\u202f(MTS) is a holistic solution that enables Wagering Operators to future-proof their business by offering services such as risk management and advanced marketing tools. The Operational Account Management Team, (which sits within MTS) performs an important role by acting as the main point of contact between our growing client base and Sportradar. Subsequently, we\u2019re looking for a dedicated, Business Intelligence Analyst for our OAM department who will support our unit by developing interactive analytical applications, scheduled customer reports and ad hoc customer report requests. The Business Intelligence Analyst will also recommend and implement improvements into our reporting processes that will allow us to automate specific requests coming from our client base.\n THE CHALLENGE:\nDeliver state-of-the-art data analytics and reporting solutions leveraging our data.\nDevelopment of data visualizations and reports using statistical packages for analyzing datasets (Excel, PowerBI)\nPeriodic reporting: automatic setup and distribution of reports\nPresent ideas and solutions to business users and software developers in a clear and understandable way.\nPropose new, innovative ways of using data to improve our products and services\nParticipate in Data modelling for reporting and analytics.\nCo-create and deliver an ambitious business intelligence roadmap in close coordination with various business and technical stakeholders in the Sportradar\n YOUR PROFILE:\nDemonstrated technical expertise in the following areas: business intelligence tools, design & development of data analytics solutions and reports, querying databases.\nPrior experience working on projects related to data management and\/or business intelligence.\nThe successful candidate will be practiced in hands-on development of software or analytics solutions. Knowledge of VBA beneficial.\nComfortable presenting to Senior OAM Management with good verbal and written communication skills\nExperience working with Amazon Redshift, Amazon Athena and\/or Microsoft SQL Server are a benefit as is knowledge of Qlik View\/Qlik Sense, Qlik NPrinting,\nNB: Must have previous experience working in the sports betting industry.\n Sportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences.\n Additional Information\nSportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences ","33":"Company Description\nOctopus \nOctopus is a group of innovative, entrepreneurial businesses investing in the people, ideas and industries that will help to change the world. We are experts in financial services and energy, and we\u2019re also a certified B Corp, meaning we care as much about the impact of our investments as the returns they generate. Today we manage more than \u00a312.6* billion on behalf of retail and institutional investors. Our energy supply business is one of the fastest growing companies in the UK, reaching 3.1 million customers in just five years, and is the only supplier to be recommended by Which? four years in a row. \nOctopus Energy, Octopus Giving, Octopus Moneycoach, Octopus Investments, Octopus Renewables, Octopus Real Estate, Octopus Ventures, Octopus Wealth and Seccl Technology are all part of Octopus Group. Visit\u202foctopusgroup.com. \n*Funds Under Management data includes undrawn commitments, funds under advisory mandates, funds monitored and the Octopus Cash service as of 31st December 2021 \nJob Description\nWe are looking for a Senior Power BI Developer to join the Data Insights team within Octopus Investments.  This is an opportunity to join a growing team in an exciting period of transformation where you will be at the forefront of shaping how the business uses data & insight.  You will be the \u2018go-to PowerBI person\u2019 in the team, spearheading the development and rollout of PowerBI across the business.\nCore responsibilities will include:\nProviding end-to-end delivery of enterprise-level Power BI solutions for OI.\nGathering, clarifying, and developing requirements with stakeholders.\nLeading the architectural design, governance, and adoption of Power BI.\nUsing a working knowledge of modern data warehousing frameworks to work closely with the Data Engineering team to define data solutions.\nBuilding and delivering Power BI training.\nOwnership of the Power BI development roadmap.\nCreating and maintaining complete and accurate solution design documents.\nQualifications\nEssential experience & characteristics:\nExperience developing end-to-end Power BI reporting and analytics solutions\nExcellent knowledge SQL, DAX, and Power Query (M)\nStrong understanding of data modelling concepts\nProficiency in data visualisation and report design\nExperience working in or alongside data engineering teams to deliver data solutions\nExperience of designing and delivering Power BI training.\nGreat people skills - this role will involve working with lots of internal stakeholders both technical and non-technical.\nDesire to learn new technologies and continuously develop new skills and expertise.\nNice to have:\nWorking knowledge of DBT.\nExperience of coaching more junior team members.\nExperience working for a similar, fast paced Financial Services company.\nAdditional Information\nOur Values \nAt Octopus we don't just focus on what we do but also how we do it. Everyone shares our values of being straightforward, helpful and bold. And while these are the principles that guide us as an organisation. \nWhat we offer\n\ud83d\udcb0  A competitive salary, bonus, pension and share incentive plan\n\u2708\ufe0f Take what you need holiday\n\ud83c\udfe1 Flexible working \n\u2693 Anchor (our wellness hub) which includes Headspace, one to one coaching through Sanctus, Parent Cloud, Digital GP, Shout & more\n\ud83d\udc6a Enhanced family leave policies\n\u2764\ufe0f Life insurance, critical illness cover and income protection\n\ud83c\udfe5 Private medical insurance for you and your family\n\ud83d\ude97 Electric vehicle leasing\n\ud83c\udf0d The option to work overseas up to a month per year","34":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to Know our Team: \nPartner Development is a team of creative entrepreneurs that develop solutions for Agoda\u2019s accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.\nIn this role you'll get to\nAs a Data Analyst in the PD Analytics team, you will be using data and modeling techniques to identify opportunities and build models and tools to improve efficiency and effectiveness for Agoda's supply team. \nKey activities involved include but not limit to:\nApply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations\nOwn end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development\nBuild dashboards, identify new and track key metrics to closely monitor team\u2019s performance and identify quick and long term opportunities for improvements\nWork closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified\nSupport global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization\nWhat you'll need to succeed \nBachelor\u2019s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline\n3-6 years experience working in a business analysis, data analysis, reporting or business strategy role\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\nCoding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\nData visualization tool experience such as with Tableau or your weapon of choice.\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","35":"Company Description\nVericast is a premier marketing solutions company that accelerates profitable revenue growth for the thousands of businesses it serves directly by influencing consumer purchasing and transaction behavior at scale while engaging with over 120 million households daily.  We are recognized as leading providers of incentives, advertising, marketing services, transaction solutions, customer data and cross-channel campaign management, and intelligent media delivery that create millions of customer touch points annually for their clients.  For more information, visit http:\/\/www.vericast.com or follow Vericast on LinkedIn.\nJob Description\nValassis Digital (a division of Vericast) is seeking a Principal Software Engineer to develop services, tools, bots, and workflows for our big data processing infrastructure.\nThe Big Data Platform Team owns and operates the world-class big data processing infrastructure that over a dozen engineering teams use to power their 24\/7 technical marketing products. We own and operate a large hadoop+spark processing cloud on which we store 6PB of data, and run 30 thousand jobs every day. We write a fabric of java microservices and bots to manage all those jobs, extend hadoop's functionality, and help us operate and optimize our investment. We write custom data streaming services that ingest and curate 100TB of data each day that drives the entire advertising data ecosystem. We also participate in all our users' groundbreaking workflow projects so that we can constantly stay abreast of our developer's tooling needs.\nWhat you're like:\nThis position is perfect for a far-sighted engineer who always wants to be the first to apply cutting-edge technologies to solve complex business and engineering problems. You want to have a leading voice on our team and across our organization. You will work throughout the software lifecycle including customer interaction and product planning, requirements analysis, architecture, directing our team of developers, development, testing and operations. If you are energized by the thought of developing new system stacks and tools for big data processing and analytics we want to talk to you. If you have worked on big data engineering, cloud migration, or infrastructure tooling projects, we want to talk to you. If you have ever worked on a collection of data workflows or a service mesh and thought 'I could make this better', we want to talk to you!\nWhat you'll do:\nWork with our users, architects, and product leaders to architect and plan our data platforms\nDesign, develop, and maintain the software and systems that make up the data platform that runs our entire business\nPartner with the Data Engineering and Data Science teams who use our platform to diagnose, predict and address scaling problems\nWork on new products initiatives to provide design support and establish best practices\nContribute to our team\u2019s growing set of development platforms, tools, processes, and products\nQualifications\nExperience working on big data systems and technologies with emphasis on the Hadoop platform\nGeneral knowledge of design patterns & UML with a few years of taking a lead on architectural design and development\nProficiency in Java, Scala, or Python programming; exposure to microservices and Spark dataframe programming.\nProficiency in networking, Thrift, Spring Framework and\/or Spring Boot for microservices is a plus. \nUnderstand RDMS and proficiency in DML, SQL & PL\/SQL a plus\nHands on experience with Spark; exposure to Kafka and YARN or similar technologies\nExperience with migration of infrastructure from on-prem to cloud or vice versa is a big advantage\nCuriosity to learn and apply new technologies and a background full of diverse design challenges\nExcellent problem-solving abilities\nExcellent verbal, graphical, and written communication skills\nExperience with agile development methodologies\n\nYour qualifications:\nBS\/MS in Computer Science or other technical discipline (with significant computer coursework)\n10+ recent years of professional software development experience using java, scala, or python\n3+ recent years working with the hadoop+spark big data platform or similar\nAdditional Information\nSalary:  180,000-200,000 with 10% bonus opportunity\nThe ultimate compensation offered for the position will depend upon several factors such as skill level, cost of living, experience, and responsibilities.\nVericast offers a generous total rewards benefits package that includes medical, dental and vision coverage, 401K and flexible PTO. A wide variety of additional benefits like life insurance, employee assistance and pet insurance are also available, not to mention smart and friendly coworkers!\nAt Vericast, we don\u2019t just accept differences - we celebrate them, we support them, and we thrive on them for the benefit of our employees, our clients, and our community.\u202fAs an Equal Opportunity employer, Vericast considers applicants for all positions without regard to race, color, creed, religion, national origin or ancestry, sex, sexual orientation, gender identity, age, disability, genetic information, veteran status, or any other classifications protected by law. Applicants who have disabilities may request that accommodations be made in order to complete the selection process by contacting our Talent Acquisition team at talentacquisition@vericast.com. EEO is the law. To review your rights under Equal Employment Opportunity please visit: www.dol.gov\/ofccp\/regs\/compliance\/posters\/pdf\/eeopost.pdf.\n#LI-TE1\n#LI-Remote","36":"Company Description\nThrough Columbia University's Pre-College Programs, high schoolers from around the globe prepare for the college experience through exploratory coursework and community activities over seven weeks in the summer. This highly selective program is open to academically exceptional high school students, entering grades 9\u201312 and freshman year of college.\nJob Description\nColumbia University\u2019s Pre-College Programs for High School Students is seeking qualified candidates to develop and teach on-campus (i.e., in person) during Summer \u201923. \nPlease Note: Course(s) and course availability is subject to change.  \nThree week courses (Sessions 1 & 2):\nBig Data, Machine Learning, and their Real World Applications\nCourse descriptions and schedule information can be found via the links above. \nOn Campus Dates: All classes meet during the day Monday-Friday\nSession 1: June 26th - July 14th\nSession 2: July 18th - August 4th\nResponsibilities:\nDevelop course content, syllabus, lesson plans, and assigned work\nLead and attend all in-person class sessions\nEstablish and maintain a dynamic in-class environment tailored for our high school population\nEvaluate student work and write a holistic evaluation of each participant after the course ends\nMonitor and address student concerns and inquiries (you will have around 20-24 students)\nAttend and complete all required online trainings\nQualifications\nGraduate degree or equivalent professional or academic background\nExpertise in the pertinent subject matter\nAptitude for teaching\nAdditional Information\nHiring Salary Ranges: \nSessions 1 & 2 on-campus: $6,150-$7,850\nPlease specify which session(s) you would be interested in teaching.  Course descriptions and schedule information are available via the links above.\nPlease submit a resume inclusive of teaching experience as well as formal teaching evaluations (if available)\nApplicants must have U.S. work authorization and will need to be in the U.S. while teaching\nApplicants may not hold a concurrent appointment with Columbia for the duration of their appointment\nOnce hired, applicants are required to submit to a third party background check and complete Protection of Minors training in addition to other training(s) mandated by the University\n All Columbia University faculty and staff must follow the COVID-19 vaccination protocol. Learn more about the vaccination requirements here: https:\/\/covid19.columbia.edu\/\nAll your information will be kept confidential according to EEO guidelines.\nColumbia University is an Equal Opportunity\/Affirmative Action employer.\n ","37":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nOverview:\nThe Agoda Content department is currently looking for a curious and questioning self-starter and proactive analyst, who will help drive decision making with insights from content, marketing and partner performance data.\nYou will get the opportunity to own analytical projects to direct our department\u2019s focus, and prioritize our actions. By joining Agoda, you will become part of a truly international team, with leading experts of different backgrounds coming from 50+ countries around the world. This is a genuine opportunity to gain valuable experience in a challenging and cutting-edge tech environment. The ideal candidate would have a passion for high-converting content, great user-experience, data and analysis tools and methods. This position reports to the Associate Director of Content Operations, in Bangkok, Thailand.\n  Main responsibilities:\nUnderstand Content goals and KPIs and be able to align reports and insights based on them. Identify and investigate trends, anomalies and opportunities to improve Agoda\u2019s Content strategy.\nIdentify content opportunities that drive customer value, bookings and conversion\nHelp build business cases around the opportunity and get buy-in from stakeholders\nEnsure appropriate data\/tools\/dashboards to measure execution and enable deeper analysis\nTrack execution and report up in regular updates\nWork with product, data\/BI team and IT to create data resources and build appropriate reporting\nWork with Content team leads to understand their business needs and identify opportunities in terms of team actions prioritization and focus.\nUse multiple data sources to report Content projects insights and impact; support Content tests and experiments.\nEncourage and train the Content team in best practice use of Agoda data, analysis techniques and interpretation.\nCoordinate with other Cross Functional departments like Analytics, Partner Services, and Product Owners\nUse Web-Analytics for Research and Analysis\nRequirements:\nBachelor degree or higher\n2+ years of relevant experience\nExperience \/ knowledge in statistics, SQL, Python\/R, Tableau and advanced Excel \u2013 required\nAbility to demonstrate data manipulation using data warehouse and create meaningful insight and visualization\nExperience \/ knowledge in Vertica and \/ or Impala \u2013 advantage\nExperience in generating data and \/ or preparing experiments for product development \u2013 advantage\nProfessional characteristics:\nAttentive to detail and committed to data integrity\nKeen and curious nature; able and willing to share your opinion\nOrganized; able to manage multiple, competing priorities and deliver results under tight deadlines\nAble to communicate effectively; fluent in English \u2013 both spoken and written\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","38":"Company Description\nIn India, Bosch is a leading supplier of technology and services in the areas of Mobility Solutions, Industrial Technology, Consumer Goods, and Energy and Building Technology. Additionally, Bosch has in India the largest development center outside Germany, for end to end engineering and technology solutions. The Bosch Group operates in India through twelve companies.  Bosch set-up its manufacturing operation in 1951, which has grown over the years to include 18 manufacturing sites, and seven development and application centers. Bosch Group in India employs over 31,000 associates and generated consolidated revenue of about \u20a8. 21,450 crores* (2.66 billion euros) in 2018 of which \u20a8. 15,824 crores* (1.96 billion euros) from third party. The Group in India has close to 18,000 research and development associates.\nJob Description\nShape the future: As data scientist you will translate business needs into technical solutions and help to develop advanced models for the analysis of large-scale data.\nAct customer-oriented: You support the local and global controller community with the implementation of an AI based forecasting tool.\nLive Cooperation: You become part of our Controlling team in Bangalore and work in an interdisciplinary project across the time-zones.\nTake responsibility: You will be responsible to further develop and implement predictive analytics solutions for our internal customers.\nQualifications\nEducation: Successfully completed degree (min. Bachelors) in the field of data science, computer science or in the commercial field, with focus on data science or computer science.\nExperience: Ideally 2+ years with predictive analytics or machine learning algorithms. Time series knowledge is a plus.\nAdditional Information\nPersonality:\u202fKeen to learn new technologies and share knowledge, a team player with strong analytical and problem solving skills, eager to take on responsibility.\nWorking style: Independent, structured and solution-oriented.\nKnow-How: MS Excel, Phyton, KNIME, MS PowerBI\nEnthusiasm: Interested in controlling in connection with IT tools as well as fun and understanding of numbers and complex interrelationships\nLanguages: fluent in English (written and spoken)","39":"Description de l'entreprise\nLa mission de CS GROUP : \u00eatre \u00e0 la pointe des technologies pour garantir la s\u00e9curit\u00e9 de tous dans un monde en pleine mutation. L\u2019expertise reconnue du groupe lui permet d\u2019intervenir l\u00e0 o\u00f9 les enjeux sont les plus critiques : a\u00e9ronautique, d\u00e9fense, \u00e9nergie, spatial. Et, aussi, l\u00e0 o\u00f9 les r\u00e9ponses sont \u00e0 inventer ou \u00e0 r\u00e9inventer : lutte anti-drones, cybers\u00e9curit\u00e9\u2026\nNotre esprit Tech et pragmatique, ainsi que notre agilit\u00e9 d\u2019ETI nous permettent d\u2019allier proximit\u00e9, engagement et innovation, pour diffuser notre culture \u00e0 tous les niveaux : dans la relation client, dans le mode de management interne, dans notre engagement social et environnemental\u2026\nEt bien s\u00fbr, dans le d\u00e9veloppement de votre carri\u00e8re, notre ambition est de faire de vous un collaborateur accompli : formations, revue de carri\u00e8re, mobilit\u00e9, programme ambassadeur\u2026\nNous sommes engag\u00e9s \u00e0 vos c\u00f4t\u00e9s, au service de votre \u00e9panouissement professionnel !\nDescription du poste\nNous recrutons un.e Architecte Plateforme Big Data pour rejoindre notre Business Unit INDUSTRIE au sein de la Business Line Digitalisation Processus & Applications M\u00e9tier. Elle accompagne nos clients dans leurs probl\u00e9matiques associ\u00e9es \u00e0 la transformation digitale. Nos offres se d\u00e9clinent autour de la digitalisation des processus industriels et du SI M\u00e9tiers.\nVotre mission :\nDans un contexte technologique et motivant, o\u00f9 la curiosit\u00e9 technique est n\u00e9cessaire, vous serez int\u00e9gr\u00e9 \u00e0 l\u2019\u00e9quipe en charge des plateformes Big Data.\nVotre mission sera de configurer des serveurs, plateformes et services pour les solutions Big Data \u00e0 destination de diff\u00e9rents groupes utilisateurs ou \u00e9quipes de d\u00e9veloppement dans un contexte Agile et DevOps.\nVous r\u00e9aliserez diff\u00e9rentes activit\u00e9s parmi celles dont l\u2019\u00e9quipe est en charge :\n- Comprendre les besoins et identifier les diff\u00e9rentes briques qui vont y r\u00e9pondre ;\n- Participer \u00e0 la r\u00e9alisation de POC, \u00e0 la configurations des plateformes et aux d\u00e9ploiements ;\n- Administrer les plateformes, g\u00e9rer et planifier les activit\u00e9s d\u2019op\u00e9rations et de monitoring ;\n- Assurer le support techniques aux \u00e9quipes des projets h\u00e9berg\u00e9s ;\n- Assurer la veille technologique et participer \u00e0 la d\u00e9marche d\u2019am\u00e9lioration continue ;\n- Faire le suivi technique des activit\u00e9s et le reporting au responsable de service.\nEnvironnement technique :\n- Linux (Redhat), Windows Server\n- IaC : Ansible, CDK, Terraform\n- Monitoring : Prometheus, Nagios, Ambari, Splunk, Grafana\n- S\u00e9curit\u00e9 : AD \/ Kerberos\u2026\n- IAM : SSO solutions, Keycloak\n- Conteneurisation :  Kubernetes, Docker, Helm\n- Langages : Python, Bash, Spark, Java\n- Stockage : S3, Private object storage, DFS, NFS.\nQualifications\nQui \u00eates-vous ?\n\nDe formation ing\u00e9nieur informatique ou \u00e9quivalent universitaire (Bac+5), vous avez au moins 3 ans d\u2019exp\u00e9rience. La ma\u00eetrise des environnements Big Data, plateformes et outils, notamment Hadoop (HDP), Kubernetes (Rancher), Spark, Elasticsearch et AWS, est n\u00e9cessaire \u00e0 l\u2019exercice de votre fonction. Vous avez des comp\u00e9tences dans les domaines de la s\u00e9curit\u00e9 et de la gestion des identit\u00e9s et acc\u00e8s (IAM).\nUn niveau d\u2019anglais courant est requis.\nVous \u00eates organis\u00e9.e et vous savez faire preuve de capacit\u00e9 d\u2019analyse ? Vous \u00eates curieux.se et rigoureux.se, et avez le sens du service client ? Alors vous \u00eates la p\u00e9pite que nous recherchons !\nA comp\u00e9tences \u00e9gales, ce poste est ouvert aux personnes en situation de handicap.\nInformations suppl\u00e9mentaires\nQui sommes-nous ?\nLa Business Unit INDUSTRIE contribue aux d\u00e9veloppements de programmes dans les domaines de la simulation, la transformation digitale et le d\u00e9veloppement de syst\u00e8mes critiques. Elle est un acteur r\u00e9f\u00e9rent sur l\u2019Intelligence de la donn\u00e9e (Data Engineering & Data Science), la digitalisation des processus (PLM), la simulation num\u00e9rique, le d\u00e9veloppement de logiciels embarqu\u00e9s & certifi\u00e9s ainsi que la s\u00e9curisation des syst\u00e8mes (cybers\u00e9curit\u00e9).\nPourquoi choisir CS GROUP ?\nPour notre fili\u00e8re Expert qui valorise vos comp\u00e9tences techniques, notre engagement dans l\u2019innovation avec un budget R&D de 30 millions d\u2019euros\/an, nos engagements soci\u00e9taux et environnementaux : index d\u2019\u00e9galit\u00e9 professionnelle \u00e0 86\/100, partenaire de l\u2019association Elles bougent, membre de la plan\u00e8te Tech Care etc.\nEt bien s\u00fbr : la possibilit\u00e9 de t\u00e9l\u00e9travailler, un programme de cooptation, la compl\u00e9mentaire sant\u00e9, les RTT, le CE.\nN\u2019attendez plus, partagez votre CV et additionnons nos talents !\nLa suite des \u00e9v\u00e9nements :\nSi votre profil est un match, vous aurez un entretien technique avec un de nos Responsables op\u00e9rationnels. Puis, vous rencontrerez Emeline lors d\u2019un entretien RH.  \n #CSGROUP #hiring #LI-Hybrid #LI-EQ1 #DevOps","40":"Company Description\nWe\u2019re over 2,700 strong across the globe. We\u2019re scientists, strategists, creatives, and innovators. We value individual brilliance and build a strong foundation for Teamwork across all our business. We love the challenge of our industry. We\u2019re changing lives and redefining success every step of the way.\nYou are dynamic. You are curious. You are more than your job. For you, excellence isn\u2019t just a word; it\u2019s the measure for all you do. You\u2019re passionate. Driven. Dedicated. You can\u2019t stand mediocrity. And you might be the team member we're looking for. \nJob Description\nPSI CRO is looking for a hands-on, experienced Database Architect & ETL Developer who is a visionary, self-directed and comfortable supporting the various data & analytics needs of multiple teams, systems, and products. In this role, the Database Architect\/ETL Developer will be responsible for requirements, analyzing, designing, coding & testing various databases & ETL processes required by the Data Platform team to build world class data lakes, databases, and data repositories utilizing both Microsoft SQL Servers as well as cutting-edge Azure cloud data technologies.\nRequirements:\nDemonstrated ability to have successfully completed multiple, complex technical projects and create high-level design and architecture of the solution, including class, sequence, and deployment infrastructure diagrams.\nDevelop and maintain documentation of the data architecture, data flow and data models of the data warehouse appropriate for various audiences.\nEnsure new features and subject areas are modelled to integrate with existing structures and provide a consistent view.\nProvide input on Azure technologies and industry best practices in the field of data warehouse architecture and modelling.\nTake ownership or assistance of technical solutions from design and architecture perspective for projects from conceptual phase through architecture, feasibility, design, and implementation\nMaintain, monitor, upgrade and secure the SQL Server\/Azure platform in partnership with established vendor.\nDevelop ETL (extract, transform and load) processes to populate Data Marts and Warehouses\nDevelop systems integrations across between traditional databases and modern Cloud APIs.\nFollow established Software Development Lifecycle (SDLC) activities and AGILE including Analysis, Design, Development, UAT, Pilot, Testing & lessons learned.\nDesign, model and develop across both Relational Databases and Data Warehouse and Synapse\nTroubleshoot data integrations\/data feeds between systems.\nQualifications\n5+ Years\u2019 Experience in SQL Server Database Management\n5+ Years\u2019 Experience in SQL Server Database Development and SQL scripting (T-SQL)\nMust have experience with at least one end to end implementation of Azure cloud data warehouse\nExpertise in Azure \u2013 data modelling, ELT using Azure ADF pipelines, implementing complex stored Procedures and standard DWH and ETL concepts.\nExpertise in Azure advanced concepts like setting up resource monitors, RBAC controls, virtual warehouse sizing, query performance tuning, Zero copy clone, time travel and understand how to use these features.\nExpertise in deploying Azure features such as data sharing, events, and lake-house patterns\nHands-on experience with Azure utilities, PySpark, ADF, Synapse, Big Data model techniques using Python or similar.\n3+ years of hands-on experience with on prem and Azure Data warehouse, ETL, BI projects, Azure Synapse.\nAdditional Information\nIf you feel it is time to make your skills and knowledge visible within a growing company with true focus on its people, then PSI is the right choice for you.","41":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. As digital pioneers with 20,000 people and 53 offices around the globe, our experience spanning technology, data sciences, consulting and customer obsession \u2013 combined with our culture of curiosity and relentlessness \u2013 enables us to accelerate our clients\u2019 businesses through designing the products and services their customers truly value. Publicis Sapient is the digital business transformation hub of Publicis Groupe. For more information, visit publicissapient.com.\nJob Description\nPublicis Sapient is looking for Senior Manager  (in-office 2-3 days per week) to join our team of bright thinkers and doers. You will team up with top-notch technologists to enable real business outcomes for our enterprise clients by translating their needs into transformative solutions that provide valuable insight. Working with the latest data technologies in the industry, you will be instrumental in helping the world\u2019s most established brands evolve for a more digital future.\nYour Impact: \nWork closely with our clients providing evaluation and recommendations of design patterns and solutions for data platforms with a focus on batch, near-real time, structured and unstructured data \nDefine SLAs, SLIs, and SLOs with inputs from clients, product owners, and engineers to deliver data-driven interactive experiences \nProvide expertise, proof-of-concept, prototype, and reference implementations of architectural solutions for Azure Data Platform\nProvide technical inputs to agile processes, such as epic, story, and task definition to resolve issues and remove barriers throughout the lifecycle of client engagements\nCreation and maintenance of infrastructure-as-code and CI\/CD for Azure environment using tools such as Terraform and Ansible\nMentor, support and manage team members\nQualifications\nYour Skills And Experience: \nDemonstrable experience in enterprise level data platforms involving implementation of end-to-end data pipelines \nHands-on experience with at Azure  \nExperience with column-oriented database technologies (e.g., Synapse), NoSQL database technologies (e.g., DynamoDB, Cosmos DB, etc.) and traditional database systems (e.g., SQL Server, Oracle, MySQL)\nExperience in architecting data pipelines and solutions for both streaming and batch integrations using tools\/frameworks like Azure Data Factory, Azure functions and Stream analytics \nMetadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, and Azure Purview\nTest plan creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks\nData modeling, querying, and optimization for relational, NoSQL, timeseries, graph databases, data warehouses and data lakes\nData processing programming using SQL, Python, and similar tools\nLogical programming in Python, Spark, PySpark, Java, Javascript, and\/or Scala\nCloud-native data platform design with a focus on streaming and event-driven architectures\nParticipate in integrated validation and analysis sessions of components and subsystems on production servers\nData ingest, validation, and enrichment pipeline design and implementation\nSDLC optimization across workstreams within a solution \nBachelor\u2019s degree in Computer Science, Engineering, or related field\nSet Yourself Apart With: \nCertifications in Azure \nExperience working with code repositories and continuous integration\nUnderstanding of development and project methodologies\nAdditional Information\nPay Range:$108,000 -$210,000\nBenefits of Working Here:\nFlexible vacation policy; time is not limited, allocated, or accrued\n16 paid holidays throughout the year\nGenerous parental leave and new parent transition program\nTuition reimbursement \nCorporate gift matching program \nAs part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at hiring@publicissapient.com or you may call us at +1-617-621-0200.","42":"At Databricks we work on some of the most complex distributed processing and machine learning problems in the world and our customers challenge us daily with interesting new big data and AI use cases. As Director, Resident Solutions Architects at Databricks, you will provide strategic leadership for delivering professional services engagements to high-value Databricks customers, helping shape the future big data and machine learning landscape for leading Fortune 500 organisations. You will report directly to the regional Vice President of Field Engineering.\nIn the Director, Resident Solutions Architects role, you will will lead a team of exceptional Resident Solution Architects, responsible for core aspects of building and managing the Resident Solutions Architect team. Through your oversight and mentorship, this team will guide our largest customers, implementing pipelines spanning data engineering through model building and deployment, plus other technical tasks to help customers get value out of their data with Databricks. Your responsibilities will include hiring and developing the team, and providing oversight of customer projects to ensure they are managed and delivered to target and exacting standards.\n  The impact you will have:\nYou will achieve regional team targets for billable utilisation and hiring\nYou will partner with account executives, customer success and field engineering leaders while guiding Resident Solutions Architects to achieve success with professional services projects with customers\nHelp resolve customer concerns on strategic accounts and professional services engagements\nAnalyze operational processes, escalation procedures and perform training needs assessments for identifying opportunities for services delivery improvements and contribution to customers.\nManage a team of Resident Solution Architects and act in a supportive manager capacity, including handling escalations, mentoring team members, building a career path for the assigned team members.\nWhat we look for:\nGreat at hiring qualified candidates and mentoring \/ growing leaders\nHave experience in hiring, mentoring and growing Team Leads, Managers & Senior Managers\nHave experience scaling field and\/or technical teams from scratch to 50+ - ideally at hyper-growth speed\nGreat at instituting processes for technical field members to drive efficiency and effectiveness\nHave experience in building and operationalising a technical specialist\nLeadership experience experience managing consultant\/delivery teams or solution architects\nSignificant prior individual contributor experience, as a hands-on technical solutions architect that will allow you to act in a supportive manager capacity with technical architects that report to you\nExperience driving software platform adoption in Fortune 500 organisations in markets such as: Finance, Media, Retail, Telco, Energy, and Healthcare\nImplement a project schedule with experience with customer engagement\nExperience with Databricks products, Spark ecosystem, and direct competitors\nUp to 30% of travel (depending on Covid regulations)\nBenefits\nPrivate hospital plan and extras coverage\nLife, disability and income protection coverage\nSuperannuation\nEquity awards\nPaid parental leave\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nBusiness travel insurance\nMental wellness resources\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.\n  Compliance\nIf access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.","43":"Job Description\nThis is a new role for a BI Developer to develop Business Intelligence Solutions for internal customers. Solutions developed are used to aid process and drive business decisions in all departments.  Interacting with key stakeholders at all levels of business the role has a strong customer focus. The successful candidate is expected to work collaboratively with their internal customers to provide solutions that are accurate, have integrity and are of value to the business. \nPlease note that while the role will come under our hybrid working policy it will require the successful candidate to come into the office two days per week at our head office in Salford Quays.\nWhat does the job involve?\nThe key responsibilities of the role are as follows:\nIdentifying and refining data and reporting requirements from key stakeholders.\nDevelop reporting.\nVisualising and reporting data findings creatively in a variety of formats.\nThinking strategically about uses of data and how data use interacts with data design.\nPerforming data studies and data discovery around new data sources or new uses for existing data sources.\nData extraction from multiple sources for reporting purposes.\nCore Competencies and skills: \nMicrosoft BI Stack - SSRS, SSIS\nSQL Server 2014-2019\nVisual Studio\nData Warehouse knowledge\nComfortable commenting code and documenting solutions\nComfortable with source controlling developments (Git\/Bucket)\nAble to adhere to coding and development standards\nGood knowledge of IT products and systems\nGood analytical and problem-solving skills\nGood communication skills and comfortable working with both technical and non-technical teams\nAble to prioritise work effectively and multitask\nMS Office including Word, Excel, Outlook, and PowerPoint\nCustomer focused\nFlexible approach to work - team player\nAdaptable to changing environment.\nEmbraces continuous self-learning\nDesirable competencies and skills:\nKnowledge and experience of creating Data Marts\nPower BI \u2013 DAX, Power Query\nPython\nPower Shell\nPerformance Tuning\nJIRA \/ Confluence.\nAnalysis of large data sets\nAJ Bell is one of the fastest-growing investment platform businesses in the UK offering an award-winning range of solutions that caters for everyone, from professional financial advisers, to DIY investors with little to no experience. We have over 449,000 customers using our award-winning platform propositions to manage assets totalling more than \u00a371.5 billion. Our customers trust us with their investments, and by continuously striving to make investing easier, we aim to help even more people take control of their financial futures.\nHaving listed on the Main Market of the London Stock Exchange in December 2018, AJ Bell is now a FTSE 250 company.\nHeadquartered in Manchester with offices in central London and Bristol, we now have over 1100 employees and have been named one of the Sunday Times \u2018100 Best Companies to Work For\u2019 for five consecutive years.\nThere are opportunities for growth and professional development for employees wanting to progress within their career including induction training and our study support scheme which is part of our benefits package.\nThere is an active programme of social events throughout the year, which are open to all employees.\nIn return we will provide all the training and support you need in order to develop within your role.\nWhat we offer:\nCompetitive starting salary\nGenerous holiday allowance of 25 days, increasing up to 30 days with service, plus bank holidays\nHoliday buy\/sell scheme\nHybrid working policy\nCasual dress code\nDiscretionary bi-annual bonus\nContributory pension scheme\nBuy as you earn share scheme\nFree shares scheme\nPaid study support for qualifications\nEnhanced maternity\/paternity scheme from day one\nBike loan\nSeason ticket loan portal\nDiscounted PMI and Dental\nOn-site gym and personal trainer led classes\nPaid volunteering opportunities\nFree social events and more\nAJ Bell is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and all employees are empowered to bring their whole self to work.\nWe do not discriminate on the basis of race, sex, gender identity, sexual orientation, age, pregnancy, religion, physical and mental disability, marital status and any other characteristics protected by the Equality Act 2010. All decisions to hire are based on qualifications, merit and business need.","44":"Leading the future in luxury electric and mobilityAt Lucid, we set out to introduce the most captivating, luxury electric vehicles that elevate the human experience and transcend the perceived limitations of space, performance, and intelligence. Vehicles that are intuitive, liberating, and designed for the future of mobility. We plan to lead in this new era of luxury electric by returning to the fundamentals of great design \u2013 where every decision we make is in service of the individual and environment. Because when you are no longer bound by convention, you are free to define your own experience. Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we\u2019re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you.\nYou will play one of the leading roles in the implementation of core enterprise systems for Lucid, including cross-functional business processes, coordination of core business data, and delivery of business enabling solutions.  You will bridge the technical and functional worlds while engaging with broad functional teams, including Supply Chain, Purchasing, Logistics, Manufacturing, Finance, HR, and Engineering. To be successful in this role, you will need to establish strong partnerships and have a hands-on approach to managing data and business processes from the ground up. As a result, you will gain a comprehensive understanding of the EV manufacturing processes and enterprise management systems. Other things you should know about this position are:\n\u2022You will be part of the evolution of a game changing electric vehicle manufacturer.\u2022You will be a peer with some of the brightest people with working experience in the greatest companies of our time: Tesla, BMW, Ford, Apple, Amazon, and more.\u2022You will be prepared for a career in cutting edge business fields like cloud ERP, data science, design for manufacturing, and strategic sourcing. \nResponsibilities:\nWorking with the business to analyze requirements, design and configure SAP system.\nWrite functional specification, work with technical team to guide, test and deploy system solutions\nTroubleshooting production issues and provide SAP system support as and when needed\nParticipate in ongoing technology evaluations and keep up with technology trends and industry standards.\nSuggest system improvements based on technology, best practices, or changing requirements.\nProvide regular management updates on advantages and potential opportunities for new technologies and automation.\nTrain\/Mentor junior staff members as appropriate.\n  Minimum Qualifications:\nBachelor's degree in Computer Science, Information Systems or equivalent\n10+ years previous experience working across a range of SAP implementations, support, and system upgrade projects.\nDeep and broad SAP SD experience in a global capacity\nDeep understanding of different business processes, including logistics, warehouse, procurement, manufacturing, finance with a focus on OTC\nProficient in end-to-end process design\/development and integration with cross-functional areas with SAP\nExperience in OTC integration with Salesforce and other eCommerce systems\nAbility to prioritize, document, organize & follow up. \nPreferred Qualifications:\nExperience working in a dynamic and fast pace environment\nExperience in automotive industry is a plus\nExperience in SAP VMS (Vehicle Management System) Industry solution is a plus\nStrong oral and written communication skills\nAbility to work well and collaborate with other teams of various skills\nAnalytical skills coupled with technical creativity and vision\nCustomer service oriented with strong interpersonal and leadership skills\nTime management and prioritizing skills\nSelf-motivator able to take tasks or projects and run with them\nLucid maintains your privacy according to its Candidate Privacy Notice. If you are a California resident, please refer to our California Candidate Privacy Notice.\nAt Lucid, we don\u2019t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations.\nNotice regarding COVID-19 protocols  At Lucid, we prioritize the health and wellbeing of our employees, families, and friends above all else. In response to the novel Coronavirus all new Lucid employees, whose job will be based in the United States may or may not be required to provide original documentation confirming status as having received the prescribed inoculation (doses). Vaccination requirements are dependent upon location and position, please refer to the job description for more details. Individuals in positions requiring vaccinations may seek a medical and\/or religious exemption from this requirement and may be granted such an accommodation after submitting a formal request to and the subsequent review and approval thereof by our dedicated Covid-19 Response team. To all recruitment agencies: Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes.","45":"About the Role\nYou will be responsible for designing and developing tests and associated software tools to ensure the best possible customer experience.  You will identify, generate, and evaluate data and metrics for testing our computational biology pipelines. You will work closely with software engineers and scientists to identify requirements and develop test plans and test cases for new and existing products.   You will identify possible edge cases outside normal usage and develop tests to ensure support of a broader range of data. You will work with software support to help resolve customer issues.  You will develop new tools to automate tests, support development, and contribute to existing automation.\nWhat You Will Be Doing\nLead a small team of test engineers testing 10x pipelines.\nPlan design, develop, and automate test plans against software releases.\nWork with software engineers and computational biologists to develop tests, define test metrics and troubleshoot\/resolve issues.\nReport test issues and results in a consistent and timely manner.\nSupport troubleshooting of customer issues.\nTest installations over a range of operating systems.\nMinimum Requirements  \nBS\/MS in computer science, bioinformatics, computational biology, or equivalent.\nExperience with Python, Bash, Linux, and Git.\n4 years experience in bioinformatics or software testing\nPreferred Qualifications\nExperience leading small to medium-sized projects.\nExperience in designing and developing validation, verification, and regression tests.\nExperience in bioinformatics applications and DNA sequencing.\nExperience with continuous integration systems (Jenkins, Travis).\nExperience with image processing tools (e.g. OpenCV) and algorithms.\nExperience in JavaScript.\nExperience with issue tracking systems (Jira).\nExperience in Go, Rust, and\/or R is a plus.\nExperience with Amazon Web Services and\/or VMWare is a plus.\n#LI-RT1\n Below is the base pay range for this full time position.  The actual base pay will depend on several factors unique to each candidate, including one\u2019s skills, qualifications, and experience.  At 10x, base pay is also just one component of the Company\u2019s total compensation package.  This role is also eligible for 10x\u2019s equity grants, its comprehensive health and retirement benefit programs, and its annual bonus program or sales incentive program.  Your 10x recruiter can share more about the Company\u2019s total compensation package during the hiring process.\nPay Range$163,800\u2014$200,200 USD\nAbout 10x Genomics\nAt 10x Genomics, accelerating our understanding of biology is more than a mission for us. It is a commitment. This is the century of biology, and the breakthroughs we make now have the potential to change the world.\n\nWe enable scientists to advance their research, allowing them to address scientific questions they did not even know they could ask. Our tools have enabled fundamental discoveries across biology including cancer, immunology, and neuroscience.\n\nOur teams are empowered and encouraged to follow their passions, pursue new ideas, and perform at their best in an inclusive and dynamic environment. We know that behind every scientific breakthrough, there is a deep infrastructure of talented people driving the life sciences industry and making it possible for scientists and clinicians to make new strides. We are dedicated to finding the very best person for every aspect of our work because the innovations and discoveries that we enable together will lead to better technologies, better treatments, and a better future. Find out how you can make a 10x difference. \nIndividuals seeking employment at 10x Genomics are considered without regards to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, or sexual orientation, or any other characteristic protected by applicable law.\n10x does not accept unsolicited applicants submitted by third-party recruiters or agencies. Any resume or application submitted to 10x without a vendor agreement in place will be considered unsolicited and property of 10x, and 10x will not pay a placement fee.\n   ","46":"Company Description\n\u00bfApasionad@ de lo digital, los datos, el IoT o la IA y con ganas de ayudar a un equipo din\u00e1mico y ambicioso a escala humana?\u202f \nLlevamos m\u00e1s de 20 a\u00f1os asesorando a empresas y administraciones y acompa\u00f1\u00e1ndolas en la puesta en marcha de sus proyectos de transformaci\u00f3n en Francia y en el extranjero.\u202f\u202f\u202f \nPara ello, nos apoyamos tanto en el apalancamiento tecnol\u00f3gico como en la fuerza de nuestro ADN basado en la inteligencia colectiva, la agilidad y el esp\u00edritu emprendedor.\u202f\u202f\u202f \nPresentes en los cinco continentes y con m\u00e1s de 5.000 empleados, nuestro objetivo es superar los 1.000 millones de euros de ingresos en 2024. La innovaci\u00f3n est\u00e1 en el centro de nuestro desarrollo y participamos en \u00e1reas vinculadas a los cambios tecnol\u00f3gicos de los grandes grupos, como Big Data, IoT, Blockchain e Inteligencia Artificial.\u202f\u202f \nNuestros valores:\nInteligencia colectiva\u202f \nAgilidad\u202f \nEmprendimiento \/ Intrapreneurship\u202f \nPromoci\u00f3n de la diversidad\nCompromiso (empleados, socios, escuelas, asociaciones...)\u202f\u202f \nRespeto del ser humano y calidad de vida en el trabajo\u202f\u202f \nApertura de esp\u00edritu e inclusi\u00f3n\nJob Description\n\u00bfCu\u00e1l ser\u00e1 tu rol?\nDise\u00f1o y desarrollo de soluciones de acceso al mercado basadas en la integraci\u00f3n de productos nuevos y existentes con aplicaciones y servicios de terceros.\nDefinici\u00f3n de buenas pr\u00e1cticas de desarrollo, pruebas autom\u00e1ticas y despliegue.\nTrabajar activamente en la optimizaci\u00f3n y eficiencia de los procesos de desarrollo de software.\nImplementaci\u00f3n de alertas y m\u00e9tricas oportunas para medir las soluciones.\nAdem\u00e1s de desarrollar, deber\u00e1s colaborar en el dise\u00f1o t\u00e9cnico de las soluciones para cumplir con el marco de arquitectura de referencia en microservicios.\nGarantizar que el software tenga la calidad necesaria tanto en el mantenimiento como en el nuevo software que se desarrolle.\nImplementar controles de calidad del software.\nGarantizar que el software cumple con las mejores pr\u00e1cticas de seguridad definidas.\nQualifications\n\u00bfQu\u00e9 nos gustar\u00eda encontrar?\nExperiencia con tecnolog\u00edas como:\nJava\nUX Shell Script\nRest \/ JSON\nSQL\nOracle\nGitHub y GitLab\nJenkins (CloudBees)\nPython\nHadoop\nImpala, Hive, Spark y\/o Scala\nKafka\nNoSQL.\nExperiencia y conocimiento de frameworks y tecnolog\u00edas como:\nSpring Boot\nAPIs\nTesting\nBig Data\nOpenShift\nDocker Hub y Kubernetes\nSonar\nKiuwan\nFortify\nIdiomas: Ingl\u00e9s y Espa\u00f1ol\nAdditional Information\n\u00bfQu\u00e9 te ofrecemos?\nContrato laboral indefinido y a jornada completa\nPack Smart Office para que puedas trabajar c\u00f3modamente desde casa \nFormaci\u00f3n y desarrollo profesional \nBeneficios y ventajas como seguro m\u00e9dico privado, seguro de vida, almuerzo y tarjetas de transporte como parte del paquete de remuneraci\u00f3n flexible \nPosibilidad de formar parte de un equipo multicultural y trabajar en proyectos internacionales \nPuesto h\u00edbrido ubicado en M\u00e1laga\nPosibilidad de gestionar permisos de trabajo\nSi has le\u00eddo hasta aqu\u00ed y tienes ganas de sumarte a este reto, no dudes en aplicar... estaremos encantados de conocerte!!!","47":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to Know our Team: \nThe Supply Analytics team is a team of creative entrepreneurs that develop solutions for Agoda\u2019s non-accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek.  Utilizing our strong brand and resources, we build new channels to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. \nThe Opportunity:  \nThe role sits within the Supply Analytics team under Central Supply Team, where new business ideas, and partnership types are incubated and scaled. We are looking for a\u202fSenior BI Analyst\u202fwhose main focus areas are providing visibility and insights for people-related issues through Business Intelligence tools like Tableau and SQL, managing data warehouses, building ETL processes, and helping build other tools to optimize the business. This role will be involved in strategic projects and work closely with commercial owners and business stakeholders, using data to identify and translate business needs and opportunities into actionable initiatives.\nIn this Role, you\u2019ll get to:\nTranslate internal briefs into analytical projects (to include refining the initial brief and asking the \u2018right questions\u2019, working through potential hypotheses and storyboarding the output)\nUse and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders.\nProactively identify opportunities for growth within supply and the wider business.\nDrive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply.\nIdentify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence.\nAutomate manual operational processes and present back on time savings gained through modernization of business operations\nWhat you\u2019ll Need to Succeed:\n4+ years of experience in analytics\/data science\/insights\/strategy.\nBachelor\u2019s degree ideally in a business or quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance).\n3+ years of experience with BI & analytics tools (SQL, Tableau, Metabase, Data Studio, or similar technologies)\n2+ years of solid project management\nGood stakeholder management experience. Comfortable presenting to senior leadership and C-suite.\nStrong experience in finding data insights and provide business recommendation to the business\nA hacker\u2019s mindset \u2013 the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping.\nExcellent communicator with superior written, verbal, presentation and interpersonal communication skills.\nData driven in both decision making and performance measurement.\nExtreme comfort in ambiguous, fast-paced environment.\nAbility to multi-task, prioritize and coordinate resources.\nIt\u2019s Great if you Have:  \nTravel industry \/ e-commerce \/ tech \/ consulting experience.\nExperience in conducting A\/B testing experimentation (a plus)\nA good understanding of statistical modelling knowledge or any machine learning technique knowledge is a plus (regression, logistic regression, random forest, etc.)\n  #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","48":"Company Description\nAt Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people\u2019s lives. Our promise to our associates is rock-solid: we grow together, we enjoy our work, and we inspire each other.\n\nThe Bosch Center of Competence Big Data and AI is searching for new highly motivated colleagues in our international DevOps team. As DevOps Engineer for our new Big Data platform on Microsoft Azure public cloud, you will play a crucial role for further developing and enhancing our platform services, thus creating significant benefit for Bosch business. Your focus will be on Infrastructure as Code (IaC) and automation of deployment and maintenance processes. Our team is looking forward to your application!\n Job Description\nTasks:\nAs DevOps Engineer for Cloud Data Platform services you act as a IT infrastructurespecialist.\nYou drive industrialization of the cloud based Bosch divisions platforms through further automation of deployment, configuration, upgrade, and maintenance processes.\nPart of your work also entails developing new datalake platform features supportinginfrastructure automation, monitoring, and platform security.\nIn your responsibility lies the development of Infrastructure as Code scripts and small applications for automation (deployment, configuration) purposes.\nYour tasks also include testing and evaluating new product features in close alignment with project stakeholders, internal customers, and vendors.\nYou contribute actively with the setup of reusable infrastructure as code modules across our different cloud platform teams.\nQualifications\nProfile:\nAt least 3 years of hands-on experience as a Software or DevOps engineer in cloud based\nBig Data and Analytics frameworks (e.g. Azure Data Lake, Apache Spark, Databricks)\nAdvanced experience with the Microsoft Azure ecosystem and common cloud concepts like infrastructure as code, e.g. Terraform\nGood knowledge in version control tools (e.g. git) and in CI\/CD Pipeline tools (e.g. Azure,DevOps)\nGood knowledge of at least one scripting language (Bash, PowerShell or Python)\nIdeally knowledge of Cloud security\nAbility to move easily between conceptual and implementation level Willingness to learn, understand and adapt to new technologies\nAnalytical thinking skills, initiative, ability to succeed in a complex environment\nWillingness to work in a larger team including customers and enjoy working in an international team\nYou are communicative, flexible, goal-oriented\nUniversity degree in Computer Science, Information Technology, Engineering or related fields\nVery good command of English - both written and spoken\nAdditional Information\nBenefits:\nWe would like to offer you number of amenities for you and your loved ones.\n Work #LikeABosch:\n\u2022 Contract of employment  and a competitive salary (together with annual bonus)\n\u2022 Flexible working hours with home office after the pandemic as well\n\u2022 Referral Bonus Program\n\u2022 Copyright costs for IT employees\n\u2022 Canteen in the office with co-financed lunches\n Grow #LikeABosch:\n\u2022 Complex environment of working, professional support and possibility to share knowledge and best practices\n\u2022 On-going development opportunities in a multinational environment\n\u2022 Broad access to professional trainings, conferences and webinars\n\u2022 Language courses\n Live #LikeABosch:\n\u2022 Private medical care and life insurance\n\u2022 Multisport card and sports teams\n\u2022 Number of benefits for families (for instance summer camps for kids)\n\u2022 Non working days on the 24th and 31st of December\n\u2022 Discounts for Bosch products","49":"Are you inspired by invention? Is problem solving through teamwork in your DNA? Do you like the idea of seeing how your work impacts the bigger picture? Answer yes to any of these and you\u2019ll fit right in here at Amazon Robotics. We are a smart team of doers who work passionately to apply cutting edge advances in robotics and software to solve real-world challenges that will transform our customers\u2019 experiences. We invent new improvements every day. We are Amazon Robotics and we will give you the tools and support you need to invent with us in ways that are rewarding, fulfilling, and fun.\n\nAmazon Robotics empowers a smarter, faster, more consistent customer experience through automation. Amazon Robotics automates fulfillment center operations using various methods of robotic technology including autonomous mobile robots, sophisticated control software, language perception, power management, computer vision, depth sensing, machine learning, object recognition, and semantic understanding of commands. Amazon Robotics has a dedicated focus on research and development to continuously explore new opportunities to extend its product lines into new areas.\n\nAmazon Robotics internship\/co-op opportunities will be based out of the Greater Boston Area in our state-of-the-art facility in Westborough, MA. Both campuses provide a unique opportunity to have direct access to robotics testing labs and manufacturing facilities.\n\nAmazon Robotics (AR) is looking for a motivated Business Intelligence Engineer Co-op with a passion for delivering insightful and influential solutions to challenging and ambiguous problems. A practiced analyst, who uses data engineering, statistics, data visualization, and data science to influence decision making in cross-functional teams. We are seeking an individual who can think holistically through compound problems to understand how systems work together to define and execute projects which drive improvements to robotic architecture or design.\n\nKey job responsibilities\nYou will work cross-functionally with product development teams and leaders throughout the organization to deliver projects aimed at characterizing and improving the performance of new robotic automation technology in Amazon's network of warehouses. In this role, you will use a combination of unified and disparate data sources to uncover insights delivered through decision-driving analytics white-papers and automated data visualizations to influence the development and deployment of cutting edge robotic technology. You will collaborate with Data Scientists, Data Engineers, and development teams to define and deliver world class analytics tools and insights to shape the robotic technology landscape.\n\nAbout the team\nThe Robotic Manipulation Organization develops technology that tackles some of Amazon's most challenging material handling problems at scale. We are a highly collaborative group, designing and delivering robotic manipulation solutions that integrate cutting edge perception and motion planning algorithms with state of the art hardware. Thinking big and delighting our customers motivates this group of passionate technologists.\nBasic Qualifications\n\nCurrently enrolled in a Bachelor\u2019s\/Master's (or higher) in analytically rigorous field such as Data Science, Statistics, Computer Science, Industrial Engineering, Econometrics or other equivalent discipline with a graduation date after May\/June 2024\nMust be eligible and available for a full-time (40h \/ week) internship between July 10 to December 15, 2023\nProficient understanding of data modelling, descriptive statistics, and SQL\nExcellent written and verbal communication skills and the ability to succinctly summarize key findings\nWorking knowledge of Python or R for exploratory data analysis and modeling\n\nPreferred Qualifications\nKnows how to ingest, process, persist, and analyze data with a strong technical insight to address customer challenges\nAbility to work successfully in an ambiguous environment, to meet tight deadlines and prioritize workload even when faced with conflicting priorities\n\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https:\/\/www.amazon.jobs\/en\/disability\/us.","50":"Company Description\nSSENSE (pronounced [es-uhns]) is a global technology platform operating at the intersection of culture, community, and commerce. Headquartered in Montreal, it features a mix of established and emerging luxury brands across womenswear, menswear, kidswear, and Everything Else.\nSSENSE has garnered critical acclaim as both an e-commerce engine and a producer of cultural content, generating an average of 100 million monthly page views. Approximately 80% of its audience is between the ages of 18 to 40. It is privately held and has achieved high double digit annual growth and profitability since its inception.\nJob Description\nReporting to the Senior Director of Global Operational Excellence & Continuous Improvement, the Manager of Data Visibility, Governance, and Product is responsible for leading the design, development, and successful implementation of current and future data visualisation, reporting standards, and workflow data products for Operations. They will oversee a team of analysts that translate business requirements into technical reporting requirements across all end-to-end processes, define the metrics, and then build the data products and corresponding dashboards that will be a cornerstone of all Operational roles and training programs at SSENSE. The incumbent will ensure data visualisation, metric, and KPI standards are clearly defined ahead of our global network expansion plans over the coming 1-3 years.\nRESPONSIBILITIES\nData visibility, governance, and product design (75%)\nDevelop and lead the Operations Visualization & Data Governance transformation plan that will standardise and operationalize all data points related to physical and systemic movement of products within the SSENSE Network, spanning operational process paths to C-suite executive-level reporting\nTranslate and develop standard metrics for reporting, and collaborate with the Product and Engineering, and Data Platform team to determine the right mechanism for delivering the reports and insights to maximize how they are used and actioned by Operational teams\nDevelop, and implement reporting solutions with AWS tools like Athena, Tableau, and operational reporting capabilities available through operational systems\nWork closely with all Operational teams and executive leadership to ensure clear and consistent metric definitions, comprehensive capture and up-to-date documentation of operational reporting and analytical reporting requirements \nOversee all data, metric, and dashboard development by the direct team; define the internal development process and stakeholder engagement model, establishing quality measures for product delivery; achieve and maintain best-in-class benchmarks for adoption rates\nDevelop prioritised roadmap for scaling visibility, maturity, automation, and real-time capability for all operational process paths in tandem with process maturity assessment; design agile approach for near-term output and ongoing, ad hoc request management\nImplement design principles and templates for data visualisation and governance across Operations that guides all dashboard development in current and future state\nCollaborate with the Product and Data Platform teams to define and demarcate data accessibility and tools for analysis vs. standardised user interface for operational process and reporting\nPartner with Business Process Owners and Operations leadership to implement standard metrics based on industry best practices to integrate with company-wide metric reporting \nImplement continuous improvement processes for refining \/ streamlining data or visualisation standards, as well as change management practices for deployment; inclusive of scalable approach to deprecating and removing legacy reports and dashboards\nPilot workflow tools that support predictive analytics and algorithmic recommendations\nOversee successful migration of reporting, visualisation, and workflow tools with existing system or product changes (e.g., WMS); partner with Product teams to define requirements of new systems or product implementation (e.g., YMS, LMS); ensuring successful integration with data governance and reporting standards\nPartner directly with the Data Platform team and the Product and Engineering teams to develop a design of the future for these collaterals and corresponding data architecture\nPeople leadership and development (25%)\nWork with Senior Leadership to gauge and monitor team engagement and implement solutions to create a transparent, collaborative and productive work environment \nCollaborate with Senior Leadership to establish the department short term objectives for the department and ensure the team's are engaged towards achieving them \nHold weekly one-on-ones, conduct performance reviews, analyze individual KPIs and assess promotion readiness to help each contributor evolve in their roles\nProvide mentorship and development opportunities to team members, catalyzing growth through coaching and team building\nQualifications\nREQUIREMENTS\nBachelors Degree in Computer Science, Information Systems, Mathematics, Statistics, Data Science, Software Engineering, or another relevant field \nA minimum of 5 years of professional, hands-on data management\/Operations and analytics experience, with at least 3 years of formal management experience leading highly developed data management and analytical professionals, ideally in fast-paced Fulfillment industry, Distribution, Logistics or Production\/Manufacturing environment\nExtensive experience with data manipulation and data visualisation tools, such as Tableau for reporting and dashboarding is essential\nExtensive experience with data manipulation using SQL or other means to extract and transform data is a must\nAnalytical mindset and experience working with business and technical teams to define key metrics, KPIs, definitions, and governance standards, along with the process to manage and maintain them over time is a must\nExperience with Operational SAAS systems and their reporting capabilities (pros and cons) is a plus\nExperience leading teams in information design principles and data visualisation methods, best practices, and software packages and APIs such as Tableau or equivalent analytics tools\nStrong written and verbal communication skills in English and French\nSKILLS\nStrong organisational and time management skills \nAdvanced data analysis skills, and an expert in using supporting tools\nStrong collaboration and prioritisation skills\nAbility to identify, prioritise and articulate high impactful initiatives\nThe ability to translate operational issues into workable data solutions\nCreative out-of-the-box thinking with excellent problem-solving abilities\nTeam player with solid leadership and interpersonal skills\nStrong communication skills, with an ability to influence cross-functional teams\nAdditional Information\nWORLD CLASS TECHNOLOGY \nTechnology is at the core of everything we do at SSENSE. Driven by an engineering mindset and a problem-solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the SSENSE offering. \nWORLD CLASS TEAM\nThe SSENSE tech team is responsible for an international headless commerce platform. Working in an agile environment, our squads are made up of experienced innovators in Product Management, QA, Design, DevOps, Software Development, Machine Learning, Data Engineering, and Security. Headquartered in Montreal, our technology organization has been growing at a rate of 2X year-over-year and is doubling once again in 2021 as we expand across Canada, US, and Europe.  \nWORLD CLASS PLATFORM \nThe SSENSE platform runs on Amazon Web Services making use of serverless microservices across web, mobile and app. Our event-source architecture already achieves over 10,000 requests \/ second and growing at an unmatched pace, currently unseen across the industry.  Our data-driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in Machine Learning techniques. Our automated continuous improvement DevOps model (making use of both blue \/ green and canary deployments) results in an average of 50 production releases every day.  \nRead more about us on our SSENSE Tech Blog.","51":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to know our team:\nPartner Development is a team of creative entrepreneurs that develop solutions for Agoda\u2019s accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.\nIn this role you'll get to\nThis role is designed to mainly growth opportunity identification among mid to long tail hotels, experiment execution and data tracking within Partner Development team for the global teams. You will get to work directly with the regional team to design and put in place global experimentation and initiatives to drive tangible impact in each market.\nKey activities involved include but not limit to:\nApply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations\nOwn end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development\nBuild dashboards, identify new and track key metrics to closely monitor team\u2019s performance and identify quick and long term opportunities for improvements\nWork closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified\nSupport global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization\nWhat you'll need to succeed \nBachelor\u2019s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline\n4-8 years experience working in a business analysis, data analysis, reporting or business strategy role\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\nCoding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\nData visualization tool experience such as with Tableau or your weapon of choice.\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","52":"Company Description\nREF25129J\nAt NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking for a Senior Big Data Software Engineer to join our ciValue Technology team in Israel.\nThe ciValue division of NIQ is a leading provider of AI-powered customer analytics, personalization, and brand collaboration platform. Serving dozens of retailers and brands across the world using cutting-edge big-data, real-time analytics, and data-science automation. Our solution is disrupting existing data & media monetization model by enabling retailers to remain in control of their revenue.\nJob Description\nWe believe that building a great product and teams starts with amazing, diverse-minded, and bright people who make an impact, generate creative & innovative ideas and take on new perspectives.\u202f \nThe Big Data Software Engineer is responsible for building new data solutions for our rapidly expanding customer base and working with the top data ingestion technologies in an open, collaborative, and innovative environment. \nResponsibilities\nBe responsible for Data flow stages from definition to architecture, including Data acquisition, Data set acceptance criteria, and Data Science integration. \nArchitecture designing and customizing technological solutions for large-scale data processing. \nDevelop and deploy real-time and batch data processing infrastructures and pipelines. \nTake responsibility to explore technologies to scale up the Data ecosystem to handle rapid Big Data growth. \nWork closely with Data Science team to embed ML \/ AI algorithms into the product.\nWork with cloud, DevOps, application, and client teams to make sure your solution is solving significant business problems in a robust, scalable manner. \nUse cutting-edge technologies: Python, Airflow, Java, Kubernetes, Spark, Scala, Kafka.\nQualifications\n4+ years of backend engineering work experience in production environments (Data environments, Big Data processing, Database techniques). \nExperience in Big Data \u2013 Spark \/ Kafka \/ Flink. \nProven experience with Python and Java\/Scala.\nExperience in the design and development of scalable Big Data solutions.\nExperience working with SQL & NO-SQL Databases \u2013 PostgreSQL, DataLake, Columnar DB.\nExperience in Kubernetes, containers & Helm is a plus.\nAbility to learn new technologies and work in a dynamic fast-paced environment.\nResult-driven, pragmatic, and innovative. \nExperience with Cloud technology is an advantage.\nExcellent English communication skills spoken and written. \nBachelor's or Master\u2019s degree in Computer Science, Computer Engineering or related field.\nFull-time position in our office in Yokneam (Hybrid) \n#LI-SG\nAdditional Information\nAbout NIQ\nNIQ, the world\u2019s leading consumer intelligence company, reveals new pathways to growth for retailers and consumer goods manufacturers. With operations in more than 100 countries, NIQ delivers the most complete and clear understanding of consumer buying behavior through an advanced business intelligence platform with integrated predictive analytics. NIQ delivers the Full View. \nNIQ was founded in 1923 and is an Advent International portfolio company. For more information, visit NIQ.com \n Want to keep up with our latest updates? Follow us on: LinkedIn | Instagram | Twitter | Facebook\nOur commitment to Diversity, Equity, and Inclusion\nNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us.\nWe are proud to be an Equal Opportunity\/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide.\nLearn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https:\/\/nielseniq.com\/global\/en\/news-center\/diversity-inclusion\/\nNIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process.","53":"Company Description\nPublicis Media harnesses the power of modern media through global agency brands Performics, Spark Foundry, Starcom and Zenith. A key business solution of Publicis Groupe ([Euronext Paris FR0000130577, CAC 40], Publicis Media\u2019s digital-first, data-driven global practices deliver client value and drive growth in a platform-powered world. It is present in more than sixty countries with over 23,000 employees worldwide.\nJob Description\nWe are seeking a driven individual with a proven track record of scalable and innovative business intelligence solutions. He\/she shines when serving as a consultant to the business and is genuinely interested in understanding the objectives of complex and evolving projects. In this role, you will champion and advocate the use of Alteryx and Tableau to create an environment of self-service analytics. The candidate must be a self-starter with a sense of urgency and a commitment to quality and professionalism.\n Responsibilities:\nAnalyze business needs and partner with stakeholders to provide a strategic solution\nWork independently on end to end solutions, from data analysis to ETL design and development through to the final visual dashboard\nCollaborate across the organization to build solutions that achieve business objectives\nGuide stakeholders with operational decisions that impact data structures and connectivity\nBring best practices in data architecture and data visualization to the table\nBuild tools in a generic fashion for reuse across other solutions\nDevelop technical documentation for each solution\nManage projects in an agile environment\nQualifications\nMinimum Bachelor\u2019s Degree in Computer Sciences, Information Technology, or its equivalent\n3+ years\u2019 experience with Tableau\n1+ years\u2019 experience with AWS core+ services (EC2, S3, Lambda, Redshift, Glue)\n1+ years\u2019 experience with Python\n3+ years\u2019 experience with data visualization\nComfortable with data warehousing concepts, preparing data, and configuring automated workflows\nExcellent communication and presentation skills as well as an analytical mindset\nExperience with complex logic\nStrong data analysis skills\nExperience connecting and merging disparate datasets\nStrong organizational skills & attention to detail\nPossess a desire to work for a fast-paced, results-based company\nExperience managing multiple projects simultaneously\n Required Skills:\nExperience with media and ad tech platforms (Ad Servers, Media Planning and Buying systems, DSP\u2019s, Programmatic, etc)\nSQL\nAdobe Site Catalyst\nGoogle Analytics\nBasic knowledge of ETL, data modeling, data warehouse, extracting and manipulating large record of data\nAdditional Information\nCompensation Range: $106,500 - $167,500 annually. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. For this role, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off.\nAll your information will be kept confidential according to EEO guidelines.","54":"Company Description\nBosch Global Software Technologies Private Limited (BGSW) is a 100% owned subsidiary of Robert Bosch GmbH. We are one of the world\u2019s leading global suppliers of technology and services, offering end-to-end Engineering, IT, and Business Solutions.\nWith a global footprint and presence in US, Europe, Japan, China, and the Asia Pacific region, we are at the forefront of designing, developing, and executing IoT ecosystems through our all-encompassing capability within the 3 aspects of IoT \u2013 Sensors, Software, and Services.\nWe have always focused on improving the quality of the life of people, providing newer revenue-generating opportunities, and improving operational efficiencies for enterprises through an array of solutions. With our unique ability to offer end-to-end solutions that connect Sensors, Software, and Services, we enable businesses to move from the traditional to digital or improve businesses by introducing a digital element in their products and processes.\nJob Description\n\u00b7        Passionate about data and how it can make a difference?\n\u00b7        Interested in learning how to create a strategy and execute the same?\n\u00b7        Want to be part of a vibrant global Power BI community with some of the most passionate people?\n\u00b7        Committed to making a difference with a role with vast opportunities to grow and excel?\nIf your answer to all above questions is \u201cYes\u201d, then the role is for you! We are looking for passionate and dynamic associate who want to be part of this exciting journey.\nWhat you\u2019ll do?\nYou will work as part of our global DevOps teams to provide data solutions for our internal customers across the globe. In collaboration with our product owners and business experts you will create and improve Power BI Reports and meaningful Premium Data Sets. You will be able to explore the full world of our business data platform to generate insights and derive actions. You will be responsible to drive continuous improvement engagements and be part of a problem-solving culture\nTake responsibility: You will work with our internal customers and international team of developers to design and implement Power BI Reports and Power BI Premium Datasets.\nHelp shape the future: As an employee of the global cross-functional Business Intelligence team (xBI), you will work on the future steering of Bosch.\nUse freedom and creativity: We live agile values so that you can contribute your ideas and experiences for the benefit of the team and the company.\nThink entrepreneurially: As part of the leading in-house provider for data and analytics-based solutions within Bosch, you will experience the start-up spirit with us and make your contribution through entrepreneurial thinking and acting.\nLive Cooperation: You will work in an interdisciplinary and international team supported by internal and external service providers as well as in direct exchange with our internal customers.\nPersonality: Team player, committed, responsible and flexible\nQualifications\nEducation: Graduate \/ Postgraduate in Engineering (preferably Computer Science) \/ MBA \/ MCA  \nExperience: 5+ years of experience working as a Power BI developer (rare exceptions for highly skilled developers). Professional experience in the field of BI and Data Warehouse. Working knowledge of Microsoft BI and Azure stack. Prolific experience with data analytics and data warehousing environments. Experience in translating business requirements into set of analytical tasks.\nWay of working: Agile, analytical, proactive, result, solution-oriented and high code\/solution quality.\nAdditional Information\nKnow-How:\n\u00b7        Collection and analysis of complex requirements and creation of solution concepts\n\u00b7        Ability to tackle complex problems independently or by collaborating with other team members\n\u00b7        Conception and implementation of data analysis, data strategies and visualizations\n\u00b7        Working knowledge on how to extract data from SQL, transform data through SQL backend, Power Query, DAX.\n\u00b7        Familiarity with BI concepts such as ETL design, analytics, and reporting\n\u00b7        Excellent troubleshooting and analytical skills\n\u00b7        Experience in DAX queries, Power BI, Building Analysis Services tabular models (SSAS)\n\u00b7        Solid understanding of data warehousing concepts including the common schema architectures, dimensions, facts, aggregate facts, and data marts. Data Vault knowledge and Azure certificates will be beneficial.\n\u00b7        Certification in Power BI will be an added advantage\n\u00b7        Good understanding of Agile and leveraging Agile to deliver consistent business results\nEnthusiasm: Passion for data, data solutions and its integration, developing interdisciplinary approaches and products for customers and presenting complex issues in a simple manner\nLanguages: Fluent in English, written and spoken to collaborate with developers and communicate with customers.","55":"We currently have a vacancy for an Enterprise Architect (Big Data) fluent in English, to offer his\/her services as an expert who will be based in Brussels. The work will be carried out either in the company\u2019s premises or on site at customer premises. In the context of the first assignment, the successful candidate will be integrated in the team of the company that will closely cooperate with a major client\u2019s IT team on site.\nYour tasks\nSupport designing and follow up deployment of new data processing workflows, especially the Analytics Data Models and Data processing\/ Data flows;\nAnalyse, clarify, and document priorities for each set of requirements to ensure they are implemented within applicable constraints (timing, contractual, technology, infrastructure);\nEnsure that the design of the system will fulfil the business requirements and non-functional requirements (volume, scalability, stability, confidentiality, security, integrity, availability, usability).\nRequirements\nUniversity degree in IT combined with minimum 13 years of IT professional experience;\nMinimum 5 years of professional experience as Enterprise Architect working in Analytics or Big Data project responsible for data\/functional\/IT architecture and at least 4 years of specialised experience in data architecture, experience in design of large-scale IT systems and high availability;\nStrong experience in business process analysis, business needs analysis, Use cases, , users stories and producing functional specifications;\nGood knowledge of interoperability technology (e.g. APIs, web services, message oriented middleware, service oriented bus);\nGood knowledge of service implementation patterns (synchronous, asynchronous, request\/response), distributed system design and messaging layer;\nCapability for modelling components, data modelling, data processing models, service interfaces, service data and reference models;\nCapacity to review and assess the quality, integrity and completeness of the various IT and Business specification documentation such as IT Architecture documents, conceptual and logical data models, use case specification, user interface specification, Web service specification, business specification (BPMs);\nExcellent command of the English language.\nBenefits\nIf you are seeking a career in an exciting and dynamic company, where you will offer your services as part of a team of a major European Institution, operating in an international, multilingual and multicultural environment where you can expect real chances to make a difference, please send us your detailed CV in English, quoting reference: (14886\/03\/23).\nWe offer a competitive remuneration (either on contract basis or remuneration with full benefits package), based on qualifications and experience. All applications will be treated as confidential.\nEUROPEAN DYNAMICS (www.eurodyn.com)is a leading Software, Information and Communication Technologies company, operating internationally (Athens, Brussels, Luxembourg, Copenhagen, Stockholm, London, Nicosia, Hong-Kong, Valetta, etc). The company employs over 600 engineers, IT experts and consultants (around 3% PhD, 36% MSc and 53% BSc or equivalent). We design and develop software applications using state-of-the-art technology. The group generates annual revenues in the range of EURO 40 million, with an EBITDA in the range of 20%. The value of our contract portfolio exceeds EURO 250 million. EUROPEAN DYNAMICS is a renowned supplier of IT services to government institutions, multinational corporations, public administrations and multinational companies, research and academic institutes.\nAs part of our dedication to the diversity of our workforce, we are committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, disability, sexual orientation, gender identity, or religion.\nEUROPEAN DYNAMICS (ED) adheres to the General Data Protection Regulation principles by applying its Privacy Policy as published in www.eurodyn.com\/privacy. By submitting an application to this position and by sharing your personal data with ED, you acknowledge and accept its Policy and authorise ED to process your personal data for the purposes of the company's recruitment opportunities, in line to the Policy.\nFurthermore, when providing your data, it is up to you to explicitly consent that your data can be assessed for future job openings, for as long as you do not withdraw such consent. If you do not consent, we will not be able to consider the data you provide to us for future job openings.","56":"Company Description\nSSENSE (pronounced [es-uhns]) is a global technology platform operating at the intersection of culture, community, and commerce. Headquartered in Montreal, it features a mix of established and emerging luxury brands across womenswear, menswear, kidswear, and Everything Else.\nSSENSE has garnered critical acclaim as both an e-commerce engine and a producer of cultural content, generating an average of 100 million monthly page views. Approximately 80% of its audience is between the ages of 18 to 40. It is privately held and has achieved high double digit annual growth and profitability since its inception.\nJob Description\nReporting to the Senior Director of Global Operational Excellence & Continuous Improvement, the Manager of Data Visibility, Governance, and Product is responsible for leading the design, development, and successful implementation of current and future data visualisation, reporting standards, and workflow data products for Operations. They will oversee a team of analysts that translate business requirements into technical reporting requirements across all end-to-end processes, define the metrics, and then build the data products and corresponding dashboards that will be a cornerstone of all Operational roles and training programs at SSENSE. The incumbent will ensure data visualisation, metric, and KPI standards are clearly defined ahead of our global network expansion plans over the coming 1-3 years.\nRESPONSIBILITIES\nData visibility, governance, and product design (75%)\nDevelop and lead the Operations Visualization & Data Governance transformation plan that will standardise and operationalize all data points related to physical and systemic movement of products within the SSENSE Network, spanning operational process paths to C-suite executive-level reporting\nTranslate and develop standard metrics for reporting, and collaborate with the Product and Engineering, and Data Platform team to determine the right mechanism for delivering the reports and insights to maximize how they are used and actioned by Operational teams\nDevelop, and implement reporting solutions with AWS tools like Athena, Tableau, and operational reporting capabilities available through operational systems\nWork closely with all Operational teams and executive leadership to ensure clear and consistent metric definitions, comprehensive capture and up-to-date documentation of operational reporting and analytical reporting requirements \nOversee all data, metric, and dashboard development by the direct team; define the internal development process and stakeholder engagement model, establishing quality measures for product delivery; achieve and maintain best-in-class benchmarks for adoption rates\nDevelop prioritised roadmap for scaling visibility, maturity, automation, and real-time capability for all operational process paths in tandem with process maturity assessment; design agile approach for near-term output and ongoing, ad hoc request management\nImplement design principles and templates for data visualisation and governance across Operations that guides all dashboard development in current and future state\nCollaborate with the Product and Data Platform teams to define and demarcate data accessibility and tools for analysis vs. standardised user interface for operational process and reporting\nPartner with Business Process Owners and Operations leadership to implement standard metrics based on industry best practices to integrate with company-wide metric reporting \nImplement continuous improvement processes for refining \/ streamlining data or visualisation standards, as well as change management practices for deployment; inclusive of scalable approach to deprecating and removing legacy reports and dashboards\nPilot workflow tools that support predictive analytics and algorithmic recommendations\nOversee successful migration of reporting, visualisation, and workflow tools with existing system or product changes (e.g., WMS); partner with Product teams to define requirements of new systems or product implementation (e.g., YMS, LMS); ensuring successful integration with data governance and reporting standards\nPartner directly with the Data Platform team and the Product and Engineering teams to develop a design of the future for these collaterals and corresponding data architecture\nPeople leadership and development (25%)\nWork with Senior Leadership to gauge and monitor team engagement and implement solutions to create a transparent, collaborative and productive work environment \nCollaborate with Senior Leadership to establish the department short term objectives for the department and ensure the team's are engaged towards achieving them \nHold weekly one-on-ones, conduct performance reviews, analyze individual KPIs and assess promotion readiness to help each contributor evolve in their roles\nProvide mentorship and development opportunities to team members, catalyzing growth through coaching and team building\nQualifications\nREQUIREMENTS\nBachelors Degree in Computer Science, Information Systems, Mathematics, Statistics, Data Science, Software Engineering, or another relevant field \nA minimum of 5 years of professional, hands-on data management\/Operations and analytics experience, with at least 3 years of formal management experience leading highly developed data management and analytical professionals, ideally in fast-paced Fulfillment industry, Distribution, Logistics or Production\/Manufacturing environment\nExtensive experience with data manipulation and data visualisation tools, such as Tableau for reporting and dashboarding is essential\nExtensive experience with data manipulation using SQL or other means to extract and transform data is a must\nAnalytical mindset and experience working with business and technical teams to define key metrics, KPIs, definitions, and governance standards, along with the process to manage and maintain them over time is a must\nExperience with Operational SAAS systems and their reporting capabilities (pros and cons) is a plus\nExperience leading teams in information design principles and data visualisation methods, best practices, and software packages and APIs such as Tableau or equivalent analytics tools\nStrong written and verbal communication skills in English and French\nSKILLS\nStrong organisational and time management skills \nAdvanced data analysis skills, and an expert in using supporting tools\nStrong collaboration and prioritisation skills\nAbility to identify, prioritise and articulate high impactful initiatives\nThe ability to translate operational issues into workable data solutions\nCreative out-of-the-box thinking with excellent problem-solving abilities\nTeam player with solid leadership and interpersonal skills\nStrong communication skills, with an ability to influence cross-functional teams\nAdditional Information\nWORLD CLASS TECHNOLOGY \nTechnology is at the core of everything we do at SSENSE. Driven by an engineering mindset and a problem-solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the SSENSE offering. \nWORLD CLASS TEAM\nThe SSENSE tech team is responsible for an international headless commerce platform. Working in an agile environment, our squads are made up of experienced innovators in Product Management, QA, Design, DevOps, Software Development, Machine Learning, Data Engineering, and Security. Headquartered in Montreal, our technology organization has been growing at a rate of 2X year-over-year and is doubling once again in 2021 as we expand across Canada, US, and Europe.  \nWORLD CLASS PLATFORM \nThe SSENSE platform runs on Amazon Web Services making use of serverless microservices across web, mobile and app. Our event-source architecture already achieves over 10,000 requests \/ second and growing at an unmatched pace, currently unseen across the industry.  Our data-driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in Machine Learning techniques. Our automated continuous improvement DevOps model (making use of both blue \/ green and canary deployments) results in an average of 50 production releases every day.  \nRead more about us on our SSENSE Tech Blog.","57":"Who is DigitalOnUs by Tech Mahindra?\nAt Tech Mahindra, we have a culture of driving positive change, celebrating each moment, and empowering all to Rise drives us to dream, do, and become more. By living our culture, both as individuals and as a team, we establish and advance our presence as a brand that is global, innovative, and caring. Our culture also leads the way for us to be and become a Company with a Purpose. We try to achieve this by making responsibility personal and adopting sustainability as a way of life at Tech Mahindra.\nOur service offerings are aligned to the changing world of our customers. Our portfolio of services range from designing strategy to delivering impact. We are Software Engineers, Technical Architects, Cloud and DevOps specialists. But the most important, we are dreamers, creators and challengers. Each day, we strive to make great come alive.\nOur technology partners are Hashicorp, Google Cloud, AWS, Oracle, SFDC, BMC, HPE, Pega, VMware, Cisco, IBM, SAP, Dell EMC, Microsoft and Service Now.\nAt Tech Mahindra, we are more than 140,000 employees with presence in more than 90 countries. Our DigitALL philosophy focuses on transforming clients' businesses across Products, Services, Business Models and Reimagined Business Processes, leading to new Revenue Opportunities, Enhanced Customer Experience, Operational Efficiency, Reduced Risk, and a better Society.\nWe are always looking for the brightest candidates to come and we offer a work environment with everything you need to be your best. Does Ambition, Success, Fun, Friends & Learning define your idea of a career? Join us and be part of our family!\nWe're looking for a passionate, product-focused Sr Data Analyst\/ Power BI  who has hacked systems in creative ways, and who are curious about new languages, technologies, and trends. We believe that working hard is a byproduct of loving what you do and not something that can be assured on a timesheet.\n  Location: Mexico - Remote\nQuailifications we are looking for:\nMinimum 5+ years of experience working directly with Powe BI.\nPerform data model design and implementation\nData experience (data architecture, data modeling, data engineering)\n3+ years of experience with writing and debugging SQL queries.\nHave proven experience in visual analytics best practices, development processes, and knowledge of typical BI & analytics too. (Power BI, Qlik Sense, Tableau, etc.)\nAbility to integrate reporting components from multiple data sources\nEffective analytical, conceptual, and problem-solving skills.\nAbility to work concurrently across multiple technologies (e.g. Power BI, Qlik Sense, Tableau) depending upon specific needs of the client\nAbility to manage multiple parallel assignments and meets specified milestones\nExperience in optimizing dashboards with focus on usability, performance, flexibility and standardization\nExperience in end-to-end implementation of BI projects for developing a portfolio of scorecards, KPIs, reports & dashboards.\nWhat you can expect from us\nAt DigitalOnUs by TechMahindra, what distinguishes us from other teams is the comfortable environment which engenders trust within teams and with our customers. Trust and openness leads to quality, innovation, commitment to deliverables, efficiency and cost-effectiveness for all our customers.\nWork with some truly remarkable IT engineers, architects, specialists and more.\nWe\u2019re growing at a phenomenal pace and we\u2019d like some company.\nHear your voice, nurture your talent and help you strengthen your foot print!\nBenefits above the law\nMentorship, and opportunities to grow and learn\n  ID:2301\nIf you apply for this opportunity we will get you resume and its contain personal data whose treatment has been authorized by its owner for Digital OnUs, S. de RL de CV (the \"Company\u201d). If you are not the owner of this information or have no relation whatsoever with the subjects treated in it, you are requested in the most attentive way not to make copies of it and \/ or its attached files and delete it immediately, under the risk of being considered as responsible for the unauthorized treatment of personal data in accordance with the Federal Law on Protection of Personal Data Held by Private Parties, its Regulations, and other applicable regulations. If you are the owner of personal data in possession of the Company and wish to obtain further information regarding the processing of your personal data or the exercise of your ARCO rights, please consult our integral privacy notice on the website https:\/\/www.digitalonus.com\/privacy-policy\/","58":"Company Description\nThe Bosch Group is a leading global supplier of technology and services. It employs roughly 394,500 associates worldwide (as of December 31, 2020). According to preliminary figures, the company generated sales of 71.6 billion euros in 2020. Its operations are divided into four business sectors: Mobility Solutions, Industrial Technology, Consumer Goods, and Energy and Building Technology.\nThe Bosch Group comprises Robert Bosch GmbH and its roughly 440 subsidiaries and regional companies in some 60 countries. If its sales and service partners are included, then Bosch is represented in roughly 126 locations. This worldwide development, manufacturing, and sales network is the foundation for further growth.\nRBVH - Robert Bosch Engineering and Business Solutions Vietnam Company Limited is 100% owned subsidiary of Robert Bosch GmbH. \nRBVH has started its operations from 19th October, 2010 at E-Town2 in HCMC. This engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide IT (SAP Consulting, JAVA Development\u2026.) and Business Services (Finance and accounting, Economics, Purchasing, Logistics, Translations Japanese-English-Japanese, Information Security ) solutions to the Bosch group of companies globally. \nJob Description\nDesigning and coding Hadoop applications to analyze data collections.\nCreating data processing frameworks.\nExtracting data and isolating data clusters.\nTesting scripts and analyzing results.\nTroubleshooting application bugs.\nMaintaining the data security.\nProducing Hadoop development documentation.\nQualifications\nBachelor degree in IT\/ Computer Science or relevant background\nHave at least 1 year of experience in the relevant technologies\nExperience in the Hadoop ecosystem and its components: HDFS, Yarn, MapReduce, Apache Spark (Python\/Scala), Apache Sqoop, Apache Impala, Apache Avro, Apache Flume, Apache Kafka\nPreferred: having certificate CCA175 \u2013 Spark and Hadoop Developer\nDesigned and developed ETL process\nExperienced in Unix with Scripting experience is preferred\nShould have strong knowledge on concepts of data warehousing models, data ingestion patterns, data quality and data governance\nExperience on the Hadoop systems with good understanding and knowledge of Hadoop cluster\nGood at English communication skills\nAdditional Information\n          Committed 13-month bonus\n         Collaboratively yearly performance bonus\n         Meal & Parking allowances\n         Premium insurance (PVI) for employee and 2 family members\n         Overseas training programs and working onsite opportunity\n         Good benefits of Trade Union activities, team building and company trip.\n         Opportunity to work in global projects of fast developing company and being a part of innovation team contributing initiative ideas to the hi-tech world.\n         Engage in our diverse training programs which surely help strengthen both your personal and professional skills","59":"Company Description\nThe Bosch Group is a leading global supplier of technology and services. In 2013, its roughly 281,000 associates generated sales of 46.4 billion Euros. Since the beginning of 2013, its operations have been divided into four business sectors: Automotive Technology, Industrial Technology, Consumer Goods, and Energy and Building Technology. \nThe Bosch Group comprises Robert Bosch GmbH and its roughly 360 subsidiaries and regional companies in some 50 countries. If its sales and service partners are included, then Bosch is represented in roughly 150 countries. This worldwide development, manufacturing, and sales network is the foundation for further growth\nRBVH - Robert Bosch Engineering and Business Solutions Vietnam Company Limited is 100% owned subsidiary of Robert Bosch GmbH. \nRBVH has started its operations from 19th October, 2010 at e-Town2 in HCMC. This engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide IT (SAP Consulting, JAVA Development\u2026.) and Business Services (Finance and accounting, Economics, Purchasing, Logistics, Translations Japanese-English-Japanese, Information Security ) solutions to the Bosch group of companies globally. \nJob Description\nCreate data model based on data source\nGenerate different kinds of PowerBI report\nRequirement verification\nTask estimation\nUnit Testing\nQualifications\nBachelor degree in IT\/ Computer Science or relevant background\nHave at least 2 years of experience in Power BI development\nHands-on \u0084experience in SQL Query in SQL server\n\u0084Hands-on \u0084experience in SQL Server Integration Services (SSIS)\n\u0084Hands-on \u0084experience in SQL Server Reporting Services (SSRS)\n\u0084Good at unit testing and integration test strategies\n\u0084Willing to support team members\/others on DB-related tasks\n\u0084Good English communication skills\n\u0084Must be able to multi-task and deal with changing priorities\nAdditional Information\nWhy BOSCH?\nBecause we don't just follow trends, we create them.\nBecause together we turn ideas into reality, working every day to make the world of tomorrow a better place. Do you have high standards when it comes to your job? So do we. At Bosch, you will discover more than just work.\nBenefits and Career Opportunities\nWorking in one of the Best Places to Work in Vietnam\nJoin a dynamic and fast growing global company (English-speaking environment)\n13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal\n100% monthly basic salary and mandatory social insurances in 2-month probation\nOnsite opportunities: short-term and long-term assignments\n15++ days of annual leave + 1 day of birthday leave\nPremium health insurance for employee and 02 family members\nFlexible working time\nLunch and parking allowance\nVarious training on hot-trend technologies\/ foreign language (English\/Chinese\/Japanese) and soft-skills\nFitness & sport activities: football, badminton, yoga, Aerobic\nFree in-house entertainment facilities and snack\nJoin in various team building, company trip, year-end party, tech talks and a lot of charity events","60":"GRAIL is a healthcare company whose mission is to detect cancer early, when it can be cured. GRAIL is focused on alleviating the global burden of cancer by developing pioneering technology to detect and identify multiple deadly cancer types early. The company is using the power of next-generation sequencing, population-scale clinical studies, and state-of-the-art computer science and data science to enhance the scientific understanding of cancer biology, and to develop its multi-cancer early detection blood test. GRAIL is headquartered in Menlo Park, CA with locations in Washington, D.C., North Carolina, and the United Kingdom. GRAIL, LLC is a wholly-owned subsidiary of Illumina, Inc. (NASDAQ:ILMN). For more information, please visit www.grail.com.\nThe Data Engineering group, within the Software - Technology organization, is looking to hire a Bioinformatics Data Engineer (BXDE) to partner with computational, engineering and clinical study teams in developing data solutions for the GRAIL product pipeline. \nThe BXDE will partner with scientists and statisticians to support efficient and accurate capture and transfer of sample information and analysis results through GRAIL\u2019s analysis systems. As such, the BXDE will become proficient in GRAIL\u2019s analysis system architecture, including primarily GRAIL\u2019s LIMS for laboratory data; Electronic Data Capture (EDC) for clinical study data; the Bioinformatics Pipeline for sequence analysis and cancer classification data; and TidyData, the system that aggregates, packages, and serves datasets created from LIMS, EDC, and Pipeline outputs. \nThe BXDE will also collaborate with software engineers and scientists to develop and produce analysis-ready datasets for clinical research and product development. The BXDE will develop code and procedures to support dataset generation, perform QC, and troubleshoot issues that arise during dataset generation. The BXDE will also collect requirements, develop prototypes, and collaborate on production implementations of new reporting-related features as needed.\nThe BXDE will learn analysis requirements by reading laboratory protocols, Statistical Analysis Plans, and other analysis planning documents and meeting with scientists, biostatisticians, and other stakeholders. \nAdditionally the BXDE may have opportunities to collaborate on statistical analyses and creation of analysis reports and interactive data visualizations.\n\n\n\nRESPONSIBILITIES\nSupport successful scientific analyses by ensuring scientists can focus on analyses and not have to learn all of the nuances of GRAIL\u2019s analysis systems\nEnsure that at the end of sample and data processing, TidyData can generate a complete and accurate analysis-ready dataset\nDevelop and support processes for analysis dataset creation, QC, and release\nDevelop standards and procedures to improve efficiency of new dataset implementation\nCollect user requirements and develop custom reporting features as well as prototypes for future production reporting features\nDefine dataset QC procedures, report templates, and automated reports for streamlined execution of QC procedures\nMaintain data integrity and quality throughout the data lifecycle, including ensuring clinical study-related blinding where appropriate.\nPREFERRED BACKGROUND\nBS or MS in a scientific field (life science, computer science, engineering, mathematics, statistics, bioinformatics, etc.).\nExperience with R or Python programming is required\nExperience with basic concepts of molecular biology is required\nExperience with cross-functional collaboration while ensuring data quality and commitment to analysis reproducibility is required\nExcellent interpersonal communication (written and verbal) and organizational skills is required\nExcellent team player with a demonstrated track record of success in a cross-functional team environment. Consistent commitment to delivering on team goals with a sense of shared urgency is required\nExperience in the field of molecular diagnostics is a plus\nExperience with CDISC data models is a plus\nExperience with Amazon Web Services is a plus\nExperience with data visualization and analytics tools is a plus\nThe estimated, full-time, annual base pay scale for this position is $111,000 - $150,000.  Actual base pay will consider skills, experience, and location. \nBased on the role, colleagues may be eligible to participate in an annual bonus plan tied to company and individual performance, or an incentive plan. We also offer a long-term incentive plan to align company and colleague success over time.\nIn addition, GRAIL offers a progressive benefit package, including flexible time-off, a 401k with a company match, and alongside our medical, dental, vision plans, carefully selected mindfulness offerings.\nGRAIL is an Equal Employment Office and Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status. We will reasonably accommodate all individuals with disabilities so that they can participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\nFollowing extensive monitoring, consideration of business implications, and advice from internal and external experts, GRAIL US has made the decision to require that all U.S. employees be \u201cFully Vaccinated\u201d with the COVID-19 vaccine. \u201cFully Vaccinated\u201d is defined as two weeks after both doses of a two-dose vaccine (e.g. Pfizer or Moderna) or two weeks since a single-dose vaccine (e.g. Johnson & Johnson) has been administered. Absent a qualifying exemption, all GRAIL US employees are to comply with this requirement, including providing documentation of such vaccination status, as a condition of employment. Anyone unable to be vaccinated, either because of a sincerely held religious belief or a medical condition or disability that prevents them from being vaccinated, can request a reasonable accommodation for consideration by GRAIL.","61":"Company Description\nPublicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients\u2019 businesses through creating the products and services their customers expect.\nJob Description\nAs a  Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.\n\nYour role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.\n\nAs a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration.\nQualifications\n Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS \/ Azure \/ GCP)\nExperience delivering end to end Big Data solutions on premise and\/or on Cloud\nKnowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases\nExpertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions\nProficiency in Java and Scala programming languages (Python a plus)\nExpertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.)\nExperience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub\/Sub etc.)\nExpertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc.\nKnowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding\nKnowledge of performance tuning, optimization and scaling solutions from a storage\/processing standpoint\nExperience building DevOps pipelines for data solutions, including automated testing\nYou\u2019ll Also Likely Have Some Of The Following\nKnowledge of containerization, orchestration and Kubernetes engine\nAn understanding of how to setup Big data cluster security (Authorization\/ Authentication, Security for data at rest, data in transit)\nA basic understanding of how to manage and setup Monitoring and alerting for Big data clusters\nExperience of orchestration tools \u2013 Oozie , Airflow , Ctr-M or similar\nExperience of MPP style query engines like Impala, Presto, Athena etc.\nKnowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\nExposure to data governance, catalog, lineage and associated tools would be an added advantage\nA certification in one or more cloud platforms or big data technologies\nAny active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV\/POC, hackathon)\nAdditional Information\nThere is a superb package of benefits waiting for you at Publicis Sapient.\nWe cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension.\nThe learning opportunities here are endless. Most importantly, of course, there\u2019s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine.\nFlexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services.","62":"Are you inspired by invention? Is problem solving through teamwork in your DNA? Do you like the idea of seeing how your work impacts the bigger picture? Answer yes to any of these and you\u2019ll fit right in here at Amazon Robotics. We are a smart team of doers who work passionately to apply cutting edge advances in robotics and software to solve real-world challenges that will transform our customers\u2019 experiences. We invent new improvements every day. We are Amazon Robotics and we will give you the tools and support you need to invent with us in ways that are rewarding, fulfilling, and fun.\n\nAmazon Robotics empowers a smarter, faster, more consistent customer experience through automation. Amazon Robotics automates fulfillment center operations using various methods of robotic technology including autonomous mobile robots, sophisticated control software, language perception, power management, computer vision, depth sensing, machine learning, object recognition, and semantic understanding of commands. Amazon Robotics has a dedicated focus on research and development to continuously explore new opportunities to extend its product lines into new areas.\n\nAmazon Robotics internship\/co-op opportunities will be based out of the Greater Boston Area in North Reading, MA. Campuses provide a unique opportunity to have direct access to robotics testing labs and manufacturing facilities.\n\nKey job responsibilities\nAmazon Robotics Storage Technologies is looking for a Business Intelligence Engineer intern\/co-op to analyze robotic systems, improve program dashboards, and to create data pipelines through AWS. A successful Co-op candidate will use data and technology to seek improvements or find disruptions in current storage field operations. In addition, a successful team member seeks opportunities to deep dive issues and influence future decisions. Candidates should have experience in business analytics, data science, data visualization, data engineering, and communicating analyses effectively. Amazon Robotics\u2019 culture encourages innovation and expects co-ops to take a high level of ownership in all tasks.\n\nKey Responsibilities for the Co-op:\nAnalyze historical data to gauge relative performance metric changes, highlighting causation.\nAnalyze data related to NPI storage solutions to evaluate expected vs actual system performance and entitlement\nWork with partner teams to onboard data from other Amazon data providers\nWrite queries to pull data and act as a thought partner through the design phase of NPI solutions\nSupport existing dashboards making edits to the underlying SQL, metric definitions, and customer facing visualizations\nEvaluate and observe data practices in your own work and throughout the team, always insisting on the highest standards\n\nAbout the team\nThe Robotic Storage Technology Analytics team (RST-A) is comprised of data scientists and Business Intelligence Engineers who support data exploration and analysis to support Amazon Robotics (AR) fulfillment buildings and new product development. We conduct relevant, insightful analysis and communicate the results through white papers, dashboards, and presentations. Our methods include design of experiments, statistical modeling, financial analysis, data pipelining, exploratory data analysis, metric generation, and data visualization.\nBasic Qualifications\n\nCurrently enrolled in Bachelor's or higher in an analytically rigorous field (Mathematics, Data Science, Statistics, Computer Science, Industrial Engineering, Econometrics) or other equivalent discipline with a graduation date after May\/June 2024\nMust be eligible and available for a full-time (40h \/ week) 6-month co-op between July to December 2023\nExperience building dashboards in Tableau or other relevant data visualization tool (Looker, PowerBI, Grafana, etc.)\nWrite high-quality and optimized SQL queries to retrieve datasets\nBasic understanding of Python or R for exploratory data analysis and modeling\nAbility to communicate analytic results effectively across stakeholder groups\n\nPreferred Qualifications\nPursuing a Master\u2019s or higher in an analytically rigorous field (Mathematics, Data Science, Statistics, Computer Science, Industrial Engineering, Econometrics) or other equivalent discipline\nUnderstanding of statistics, specifically random variable distributions and A\/B tests\nFamiliarity with AWS tools and products for data engineering and data science such as S3, Glue, Sagemaker, and Athena\n\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https:\/\/www.amazon.jobs\/en\/disability\/us.","63":"Company Description\n  Job Description\nWide\u0142ki wynagrodzenia przewidziane przy tym stanowisku to (umowa o prac\u0119):\nmid: 12 300 - 17 600 PLN brutto\nsenior: 16 100 - 23 200 PLN brutto\nModel pracy hybrydowej wed\u0142ug ustale\u0144 lidera i zespo\u0142u.\n Ofert\u0119 kierujemy do os\u00f3b, kt\u00f3re:\nBardzo dobrze znaj\u0105 SQL\nPosiadaj\u0105 do\u015bwiadczenie z co najmniej jednym typem baz danych: Oracle, PostgreSQL, MySQL, BigQuery\nBiegle pos\u0142uguj\u0105 si\u0119 Google Sheets (Google Suite), MS Excel\nPosiadaj\u0105 do\u015bwiadczenie z narz\u0119dziami raportowymi takimi jak: Google Data Studio, Tableau, Power BI, Cognos\nPotrafi\u0105 sprawnie zarz\u0105dza\u0107 czasem i pracowa\u0107 w zespole\nOczekuj\u0105 pracy, kt\u00f3ra ma g\u0142\u0119bszy sens (nie tylko \u201cmanagement zleci\u0142\u201d) i realny wp\u0142yw na decyzyjno\u015b\u0107 kadry zarz\u0105dzaj\u0105cej\nPotrafi\u0105 szuka\u0107 efektywnych rozwi\u0105za\u0144 do wymaga\u0144 stawianych przez u\u017cytkownik\u00f3w\nChc\u0105 si\u0119 ci\u0105gle rozwija\u0107 i aktualizowa\u0107 swoj\u0105 wiedz\u0119\nDodatkowym atutem b\u0119dzie:\nPodstawowa umiej\u0119tno\u015b\u0107 programowania w j\u0119zyku Python\nPodstawowa znajomo\u015b\u0107 Google Apps Script\nWiedza oraz do\u015bwiadczenie w modelowaniu, tworzeniu i utrzymaniu proces\u00f3w ETL\nZnajomo\u015b\u0107 zagadnie\u0144 zwi\u0105zanych Airflow, Google Composer, Dataproc, Spark\nDo\u015bwiadczenie w pracy w \u015brodowisku GCP\nDlaczego mia\u0142(a)by\u015b z nami pracowa\u0107?\nZapewnisz dane niezb\u0119dne do rozwoju system\u00f3w wspomagaj\u0105cych dzia\u0142alno\u015b\u0107 zespo\u0142\u00f3w finans\u00f3w oraz kadry zarz\u0105dzaj\u0105cej\nB\u0119dziesz odpowiada\u0107 za prezentacj\u0119 wybranych danych oraz automatyzacj\u0119 proces\u00f3w raportowych w obszarze Technologii oraz Finans\u00f3w \nB\u0119dziesz wspiera\u0107 automatyzacj\u0119 istotnych proces\u00f3w biznesowych i back officowych\nZajmiesz si\u0119 tworzeniem i wsparciem utrzymania proces\u00f3w ETL oraz przygotowaniem agregat\u00f3w danych \nOdpowiesz za rozw\u00f3j proces\u00f3w raportowych w oparciu o wymagania biznesowe przy u\u017cyciu Google Data Studio\nB\u0119dziesz mie\u0107 realny wp\u0142yw na kluczowe KPI Allegro\nZaanga\u017cujesz si\u0119 w zr\u00f3\u017cnicowane projekty z obszaru styku Finans\u00f3w i Technologii,\nOtrzymasz mo\u017cliwo\u015b\u0107 rozwoju w obszarze BI i AI&ML oraz umiej\u0119tno\u015bci zwi\u0105zanych z programowaniem w j\u0119zyku Python\nZe swojej strony oferujemy:\nModel pracy hybrydowej, kt\u00f3ry ustalisz z liderem i zespo\u0142em. Mamy \u015bwietnie zlokalizowane biura ( z w pe\u0142ni wyposa\u017conymi kuchniami i parkingami dla rower\u00f3w) i znakomite narz\u0119dzia pracy (podnoszone biurka, interaktywne sale konferencyjne)\nBonus roczny do 10% wynagrodzenia rocznego liczony z kwoty brutto (zale\u017cny od Twojej oceny rocznej oraz wynik\u00f3w firmy)\nBogaty pakiet \u015bwiadcze\u0144 pozap\u0142acowych w systemie kafeteryjnym \u2013 Ty decydujesz z czego korzystasz (do wyboru mamy m.in. pakiety medyczne, sportowe, lunchowe, ubezpieczenia, bony na zakupy)\nZaj\u0119cia angielskiego op\u0142acane przez nas i skoncentrowane na specyfice Twojej pracy\nHackathony, turystyk\u0119 zespo\u0142ow\u0105, bud\u017cet szkoleniowy oraz wewn\u0119trzna platforma MindUp (m.in. szkolenia z zakresu organizacji pracy, sposobu komunikacji, motywacji do pracy oraz r\u00f3\u017cnych technologii i zagadnie\u0144 merytorycznych)\nWy\u015blij nam swoje CV i sprawd\u017a dlaczego #dobrzetuby\u0107","64":"Company Description\nSSENSE (pronounced [es-uhns]) is a global technology platform operating at the intersection of culture, community, and commerce. Headquartered in Montreal, it features a mix of established and emerging luxury brands across womenswear, menswear, kidswear, and Everything Else.\nSSENSE has garnered critical acclaim as both an e-commerce engine and a producer of cultural content, generating an average of 100 million monthly page views. Approximately 80% of its audience is between the ages of 18 to 40. It is privately held and has achieved high double digit annual growth and profitability since its inception.\nJob Description\nReporting to the Senior Director of Global Operational Excellence & Continuous Improvement, the Manager of Data Visibility, Governance, and Product is responsible for leading the design, development, and successful implementation of current and future data visualisation, reporting standards, and workflow data products for Operations. They will oversee a team of analysts that translate business requirements into technical reporting requirements across all end-to-end processes, define the metrics, and then build the data products and corresponding dashboards that will be a cornerstone of all Operational roles and training programs at SSENSE. The incumbent will ensure data visualisation, metric, and KPI standards are clearly defined ahead of our global network expansion plans over the coming 1-3 years.\nRESPONSIBILITIES\nData visibility, governance, and product design (75%)\nDevelop and lead the Operations Visualization & Data Governance transformation plan that will standardise and operationalize all data points related to physical and systemic movement of products within the SSENSE Network, spanning operational process paths to C-suite executive-level reporting\nTranslate and develop standard metrics for reporting, and collaborate with the Product and Engineering, and Data Platform team to determine the right mechanism for delivering the reports and insights to maximize how they are used and actioned by Operational teams\nDevelop, and implement reporting solutions with AWS tools like Athena, Tableau, and operational reporting capabilities available through operational systems\nWork closely with all Operational teams and executive leadership to ensure clear and consistent metric definitions, comprehensive capture and up-to-date documentation of operational reporting and analytical reporting requirements \nOversee all data, metric, and dashboard development by the direct team; define the internal development process and stakeholder engagement model, establishing quality measures for product delivery; achieve and maintain best-in-class benchmarks for adoption rates\nDevelop prioritised roadmap for scaling visibility, maturity, automation, and real-time capability for all operational process paths in tandem with process maturity assessment; design agile approach for near-term output and ongoing, ad hoc request management\nImplement design principles and templates for data visualisation and governance across Operations that guides all dashboard development in current and future state\nCollaborate with the Product and Data Platform teams to define and demarcate data accessibility and tools for analysis vs. standardised user interface for operational process and reporting\nPartner with Business Process Owners and Operations leadership to implement standard metrics based on industry best practices to integrate with company-wide metric reporting \nImplement continuous improvement processes for refining \/ streamlining data or visualisation standards, as well as change management practices for deployment; inclusive of scalable approach to deprecating and removing legacy reports and dashboards\nPilot workflow tools that support predictive analytics and algorithmic recommendations\nOversee successful migration of reporting, visualisation, and workflow tools with existing system or product changes (e.g., WMS); partner with Product teams to define requirements of new systems or product implementation (e.g., YMS, LMS); ensuring successful integration with data governance and reporting standards\nPartner directly with the Data Platform team and the Product and Engineering teams to develop a design of the future for these collaterals and corresponding data architecture\nPeople leadership and development (25%)\nWork with Senior Leadership to gauge and monitor team engagement and implement solutions to create a transparent, collaborative and productive work environment \nCollaborate with Senior Leadership to establish the department short term objectives for the department and ensure the team's are engaged towards achieving them \nHold weekly one-on-ones, conduct performance reviews, analyze individual KPIs and assess promotion readiness to help each contributor evolve in their roles\nProvide mentorship and development opportunities to team members, catalyzing growth through coaching and team building\nQualifications\nREQUIREMENTS\nBachelors Degree in Computer Science, Information Systems, Mathematics, Statistics, Data Science, Software Engineering, or another relevant field \nA minimum of 5 years of professional, hands-on data management\/Operations and analytics experience, with at least 3 years of formal management experience leading highly developed data management and analytical professionals, ideally in fast-paced Fulfillment industry, Distribution, Logistics or Production\/Manufacturing environment\nExtensive experience with data manipulation and data visualisation tools, such as Tableau for reporting and dashboarding is essential\nExtensive experience with data manipulation using SQL or other means to extract and transform data is a must\nAnalytical mindset and experience working with business and technical teams to define key metrics, KPIs, definitions, and governance standards, along with the process to manage and maintain them over time is a must\nExperience with Operational SAAS systems and their reporting capabilities (pros and cons) is a plus\nExperience leading teams in information design principles and data visualisation methods, best practices, and software packages and APIs such as Tableau or equivalent analytics tools\nStrong written and verbal communication skills in English and French\nSKILLS\nStrong organisational and time management skills \nAdvanced data analysis skills, and an expert in using supporting tools\nStrong collaboration and prioritisation skills\nAbility to identify, prioritise and articulate high impactful initiatives\nThe ability to translate operational issues into workable data solutions\nCreative out-of-the-box thinking with excellent problem-solving abilities\nTeam player with solid leadership and interpersonal skills\nStrong communication skills, with an ability to influence cross-functional teams\nAdditional Information\nWORLD CLASS TECHNOLOGY \nTechnology is at the core of everything we do at SSENSE. Driven by an engineering mindset and a problem-solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the SSENSE offering. \nWORLD CLASS TEAM\nThe SSENSE tech team is responsible for an international headless commerce platform. Working in an agile environment, our squads are made up of experienced innovators in Product Management, QA, Design, DevOps, Software Development, Machine Learning, Data Engineering, and Security. Headquartered in Montreal, our technology organization has been growing at a rate of 2X year-over-year and is doubling once again in 2021 as we expand across Canada, US, and Europe.  \nWORLD CLASS PLATFORM \nThe SSENSE platform runs on Amazon Web Services making use of serverless microservices across web, mobile and app. Our event-source architecture already achieves over 10,000 requests \/ second and growing at an unmatched pace, currently unseen across the industry.  Our data-driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in Machine Learning techniques. Our automated continuous improvement DevOps model (making use of both blue \/ green and canary deployments) results in an average of 50 production releases every day.  \nRead more about us on our SSENSE Tech Blog.","65":"Binance is the global blockchain company behind the world\u2019s largest digital asset exchange by trading volume and users, serving a greater mission to accelerate cryptocurrency adoption and increase the freedom of money.\nAre you looking to be a part of the most influential company in the blockchain industry and contribute to the crypto-currency revolution that is changing the world?\nAbout Binance Accelerator Programme Binance Accelerator Programme is a concise 3 - 6 months programme designed to have an immersive experience in the rapidly expanding Web3 space.  You will be given the opportunity to experience life at Binance and understand what goes on behind the scenes of the worlds\u2019 leading blockchain ecosystem. Alongside your job, there will also be a focus on networking and development, which will expand your professional network and build transferable skills to propel you forward in your career. \nWho may applyCurrent students, fresh graduates, and candidates who are mid-career switchers.\nData driven based business is the core in helping  to use cloud native platform to serve tens of millions of crypto-currency users. Engineers and Data Scientists across the company use the data platform to do interesting and impactful analysis for continuous innovations.\nAs a data scientist, you will have the opportunity to leverage rich data (PB-level scalability) and state-of-art machine learning infrastructure to develop data products which are used by our tens of millions of crypto-currency users.\nYou will collaborate with a strong team of engineers, data analysts, business operation and product\/marketing managers to define and build solutions, features, algorithms and products based off our rich data and cutting-edge machine learning technology.\nResponsibilities:\nFacilitate data collection that will allow the identification of crypto address owners\nWork closely with the Data Science team, who will guide your data collection strategy\nRequirements:\nExperience in making transactions on the blockchain\nBroad understanding of blockchain technology and existing ecosystem\nExperience in investigation of blockchain cyber crimes is plus\nKnowledge of DeFi ecosystem (DEX, Lending Platform, etc) is plus","66":"Title: Data Engineer II \/ BI Analyst (Growth and Acquisition)\nReporting to: Lead Data Engineer\nLocation: United States \/ Remote, requires U.S. work authorization\nTerm: Permanent Full Time\nCompensation: $90,000\nDeadline: Applications reviewed on a rolling basis, target start mid April\nAbout WorkMoney\nWorkMoney is a nonprofit organization dedicated to lowering costs and raising incomes for all Americans to make American life more affordable and American families more economically secure. We provide products, services, perks, benefits, tips, and tools to help members improve their financial lives. We are a trusted source of information about financial matters, economic policy, and public debates about the economy. In 2023, we will be increasing our presence and investment across a broader range of paid, owned, earned and shared channels which will enable us to advance our core vision that everyone in America can afford to live a good life. You can find out more about WorkMoney at workmoney.org and Facebook.\nWhy are we looking for a Data Engineer \/ BI Analyst?\nIn our first two years of operation, we built things fast and relied on a web of vendors, platforms, staff, and consultants to do so. As the organization grows and the work becomes more complex, we\u2019ve invested in growing our Data Science & Analytics team to increase internal capacity to manage our data environment and build the foundations for making smart data-informed decisions across platforms. With significant investments being made in our web presence and growth programs this year, we\u2019re ready to add another member to our team to take one of our largest programs to the next level.\nRequirements\nWhat are we looking for?\nWorkMoney is looking for a Data Engineer to build and monitor pipelines to various social media platforms and internal data systems, while also analyzing existing processes and investigating problem areas. Successful candidates will have experience with owning and building APIs, investigating and diagnosing data inaccuracies, and managing external relationships with relevant vendors. We also need someone who can analyze the data and create reporting dashboards to showcase performance and other program metrics. This role will be a combination of engineering and analytics as we build out the program and analyze incoming data to show progress. A unique role for a solutions oriented engineer who wants to flex their technical and cross-functional communication skills.\nResponsibilities\nBuild, test, and monitor APIs to various social media platforms (including but not limited to Google, Facebook, Snapchat, etc.)\nTroubleshoot data issues with various internal and external partners, such as missing data and repairing broken pipelines\nCreate and maintain documentation and training materials\nMaintain reporting dashboards to communicate insights across the organization\nRespond to requests for data and reporting in a timely manner\nMust Haves\nPractical experience designing and controlling APIs for consistency, simplicity, and extensibility\nProficiency with SQL\nProficiency with AWS and Redshift integrations\nAbility to analyze and communicate data in clear visualizations and dashboards, such as creating infrastructure and schema diagrams\nSelf-motivated problem solver with a knack for sniffing out data inaccuracies\nScope out new tools and recommend improvements to current systems and processes\nBig picture thinker with excellent communication skills\nNice to Haves\nExperience working with and managing external consultants or vendors\nKnowledge of other data programming languages\nExperience working at high-growth companies and interest in building systems that can scale with increased traffic and larger datasets\nBenefits\nWe\u2019re proud to offer generous benefits like competitive pay, expansive paid time off options, and employer contributions to retirement and student loan repayment. The salary for this role is $90,000 annually and as part of our commitment to pay transparency and equity in our organization, the salary for this position is not negotiable. WorkMoney covers the premiums for healthcare, dental, and vision plans so you don\u2019t have to, offers a 6% 401K employer match, four weeks paid vacation, generous paid family and medical leave, and annual allowances for remote work and professional development.\nWhy join our team?\nOur workplace is dynamic and we aren\u2019t afraid to pivot when things don\u2019t work. We\u2019re mission driven, hard working, and scrappy AF. We have a good time working on hard things, and embrace the line \u2018feedback is a gift\u2019. We jump in to help each other, and make time to reflect when things go well and not so well. The truth of the matter is: we\u2019re doing cool stuff with really cool people and having a great time doing it.\nWorkMoney is an equal opportunity employer. WorkMoney prohibits unlawful discrimination against any employee or applicant for employment based on age, color, disability, gender, marital status, national origin, religion, sexual orientation, expression, gender identity, veteran\u2019s status, or any other basis prohibited by law. We see diversity of all kinds as a necessary precondition to doing our work well and strive to build a team that reflects the diverse composition of America itself. We strongly encourage applicants from historically under-represented communities to apply.\nTo Apply\nFollow the link to the application page, complete the required fields, and submit a resume. Applications will be reviewed on a rolling basis.\n**Please do not reach out directly to any team members. If you\u2019d like additional information or to check the status of your application, email careers@workmoney.org.**","67":"Unternehmensbeschreibung\nM\u00f6chtest du deine Ideen in nutzbringende und sinnvolle Technologien verwandeln? Ob im Bereich Mobility Solutions, Consumer Goods, Industrial Technology oder Energy and Building Technology \u2013 mit uns verbesserst du die Lebensqualit\u00e4t der Menschen auf der ganzen Welt. Willkommen bei Bosch.\nDie Robert Bosch GmbH freut sich auf deine Bewerbung!\nStellenbeschreibung\nDu bist verantwortlich f\u00fcr die Data Analytics und Visualisierung von Produkt- und Fertigungsdaten.\nDu erweiterst bereits existierende Business Intelligence (BI) L\u00f6sungen.\nDu koordinierst und begleitest die Roll-Outs dieser L\u00f6sungen und stimmst dich mit den AnwenderInnen, Leitung von Arbeitsgruppen ab.\nDu \u00fcberpr\u00fcfst die Funktionalit\u00e4t und unterst\u00fctzt die ProduktmanagerInnen in der Anwendung durch zum Beispiel Trainings und Schulungen.\nQualifikationen\nAusbildung: \u00fcberdurchschnittlich abgeschlossenes Hochschulstudium (Bachelor) im Bereich Informatik, Ingenieurwissenschaften, Naturwissenschaften, Wirtschaftsingeniurwesen und konkrete Absicht im Anschluss ein Masterstudium aufzunehmen\nArbeitsweise: Teamf\u00e4hig, durchsetzungsverm\u00f6gen, systematisch, proaktiv, kreativ\nErfahrungen und Know-how: Technisches Verst\u00e4ndnis, erste Programmiererfahrung in Big Data Technologien wie Python, BI-Tools und Statistik und C#, Spotfire, SQL\/Impala, Tableau, KNIME.\nBegeisterung: Interesse an IT-affiner T\u00e4tigkeit im Produktionsumfeld\nSprachen: gute Deutsch- und Englischkenntnisse\nZus\u00e4tzliche Informationen\nDas Bosch PreMaster Programm ist ein zweistufiges Qualifizierungsprogramm f\u00fcr engagierte Bachelor-Absolventinnen und Absolventen, die das Ziel haben, ein Masterstudium zu absolvieren. Nach dem Bachelor bietet die erste Phase bis zu 12 Monaten praktische Erfahrung, um die fachlichen und unternehmerischen Zusammenh\u00e4nge kennenzulernen. Die zweite Phase umfasst das Masterstudium und beinhaltet weitere Events und Seminare sowie pers\u00f6nliche Betreuung durch einen Mentor auf dem Weg zum erfolgreichen Abschluss.\nBeginn: ab September 2022 \/ nach Absprache\nDu hast Fragen zum Bewerbungsprozess?\nMichelle Kurz (Personalabteilung)\n+49(7121)35-33122\nDu hast fachliche Fragen zum Job?\nAlexander G\u00f6lz (Fachabteilung)\n+49 (7121) 35-2741","68":"Unternehmensbeschreibung\nDo you want beneficial technologies being shaped by your ideas? Whether in the areas of mobility solutions, consumer goods, industrial technology or energy and building technology \u2013 with us, you will have the chance to improve quality of life all across the globe. Welcome to Bosch.                       \nThe Bosch Engineering GmbH is looking forward to your application!\nStellenbeschreibung\nAffinity for new programming languages and analysis of big data in the vehicle SW development. Among your tasks are:\nCreation of queries and metrics\nCreation of dashboards\n You support us with advice and assistance in the creation and revision of Splunk dashboards.\n You take part in implementation activities for upcoming automation endeavors as part of our team.\n After an initial set up and Splunk training remote working is possible.\nStart: September 2022 \nTime: 6 months\nQualifikationen\nPersonality: You work in a self-sufficient, thorough and target oriented manner. You have a knack for programming and dealing with large data sets supported by good communication skills and a friendly demeanor.\n Way of working: You are thorough, detail oriented and excel at working in a team.\n Know-How: Knowledge in dealing with data base systems and the use of applications for data analysis and visualization (SQL\/Azure\/Grafana\/Tableau or similar). Ideally experience with SPLUNK and proficiency in the use of the SPLUNK-SPL. Basic proficiency in Python.\n Enthusiasm: You are initiative and have strong interests in new technologies.\n Language: English or German proficiency on a professional level. \n Education: Enrolled student (f\/m\/div.) in a study program with a Computer Science or IT related background, e.g. Computer Science, Mathematics with focus on machine learning\/optimization, Computer Engineering or Engineering Informatics. \nPrerequisite for the internship is the matriculation at a university. Please enclose with your application a current certificate of enrollment, study and examination regulations and, if applicable, a valid work and residence permit for Germany.\nZus\u00e4tzliche Informationen\nNeed support during your application?\nDaniela Schneider (Human Resources)\n+49(7062)911-9555\nNeed further information about the job?\nSebastian Pollak (Functional Department)\n+49 173 6199307","69":"Here at Mindera, we are continuously developing a fantastic team, and would love it for you to join us.\nAs a Business Intelligence Engineer you will be responsible for building, maintaining, scaling, and integrating big data based platforms. Notwithstanding, you will also be engaged with the Data Science team in setting up and automating the Data Science models\/algorithms for production use.\nThis is a fantastic opportunity for someone who is passionate about Data and is excited to use different tools to provide data insight for further analysis and drive business decisions.\nNational and international expected travelling time varies according to project\/client and organizational needs: 0%-15% estimated.\nRequirements\nYou are good at:\nHave expert knowledge in SQL\nDesigning and building data models, either using Kimball Dimensional Modelling or Data Vault.\nFamiliar with troubleshooting and debugging implementations to quickly and efficiently measure data integrity; analysing implementations for problems and proactively managing issues\nWorking in a multi-disciplinary team\nWorking with GitHub (Preferably experience)\nworking with DBT Cloud (Preferably experience )\nUsing Fivetran (It would be a bonus)\nBenefits\nThe Things We Really Care About:\nHealth Insurance, because health comes first\nFlexible working hours\nOpen holidays, take the time you need for yourself\nProfit distribution for everyone\nMindera Annual Trip, Sports, and sharing groups to connect and have fun!\nTraining & conferences, create your own training plan\nChild Care vouchers\nOther Good Things:\nChoose Laptop & Peripherals that best suit your needs\nHotspot with unlimited usage (PT), for work or Netflix ;)\nWe have amazing offices in Porto, Aveiro, and Coimbra if you want to physically connect with minders. Remote is also an option.\nAt the offices, we have a wide range of snacks to keep you fed and healthy\nPartnerships with local businesses\n\nMost of all You get to work with a bunch of great people, where the whole team owns the project together in a politics-free environment. Our culture reflects our lean and self-organization attitude. We encourage our colleagues to take risks, make decisions, work in a collaborative way and talk to everyone to enhance communication. Freedom and Responsibility go hand in hand, and we value commitment, feedback, and empathy.\n\nAbout Mindera\nAt Mindera we use technology to build products we are proud of, with people we love.\nSoftware Engineering Applications, including Web and Mobile, are at the core of what we do at Mindera.\nWe partner with our clients, to understand their products and deliver high-performance, resilient and scalable software systems that create an impact in their users and businesses across the world.\nYou get to work with a bunch of great people, where the whole team owns the project together.\nOur culture reflects our lean and self management attitude. We encourage our colleagues to take risks, make decisions, work in a collaborative way and talk to everyone to enhance communication.\nWe are proud of our work and we love to learn all and everything while navigating through an Agile, Lean and collaborative environment.\nCheck out our Blog and our Handbook!\nOur offices are located: Porto, Portugal | Aveiro, Portugal | Coimbra, Portugal | Leicester, UK | San Diego, USA | San Francisco, USA | Chennai, India | Bengaluru, India | Cluj-Napoca, Romania | Blumenau, Brazil","70":"We're Cruise, a self-driving service designed for the cities we love.\nWe\u2019re building the world\u2019s most advanced, self-driving vehicles to safely connect people to the places, things, and experiences they care about. We believe self-driving vehicles will help save lives, reshape cities, give back time in transit, and restore freedom of movement for many.\nCruisers have the opportunity to grow and develop while learning from leaders at the forefront of their fields. With a culture of internal mobility, there's an opportunity to thrive in a variety of disciplines. This is a place for dreamers and doers to succeed.\nIf you are looking to play a part in making a positive impact in the world by advancing the revolutionary work of self-driving cars, join us.\nCruise is looking for a Fleet Reliability and Engineering Data Analyst for the Commercial Operations team to support us in our scaling efforts. This role will involve analyzing data to cultivate a deeper understanding of our AVs in the field and working with various teams across the organization to accelerate scalable improvements within our growing fleet. If you want to play a critical role in an autonomous future, let's chat!\nWhat you\u2019ll be doing:\nDesign and develop models, analyses, and dashboards using large data sets to report on and improve overall fleet reliability.\nGenerate data-driven insights and build out business cases to drive improvements within the fleet.\nPartner with Data Science and Data Engineering in developing new data resources for the team.\nHelp identify and drive continuous improvement opportunities.\nWhat you must have:\nBachelor's degree or proven experience\nProficiency in Google Sheets\/Excel, SQL, and data visualization tools ( (e.g. Tableau, PowerBI, Looker, Plotly, Data Studio)\nAbility to extract concrete insights from data\nStrong work ethic and excitement to collaborate with cross functional teams\nBonus points!\nA degree in Statistics, Economics, Mathematics, Computer Science or similar field\nComfort independently learning new data tables and writing\/validating queries of your own design.\nExperience or interest in AV or transportation space.\nThe salary range for this position is $91,900 - 135,000. Compensation will vary depending on location, job-related knowledge, skills, and experience. You may also be offered a bonus, restricted stock units, and benefits. These ranges are subject to change.\nWhy Cruise?\nOur benefits are here to support the whole you:\nMedical \/ dental \/ vision, AD+D and life insurance\nSubsidized mental health benefits\nOne Medical membership\nFlexible Spending Account \nMonthly wellness stipend\n401(k) match \nPaid time off: vacation, sick, public health emergency, jury duty, bereavement and company holidays. \nPaid parental, family care and medical leave\nFamily care benefits: fertility benefits, Dependent Care Flexible Spending Account (subsidized by Cruise).\nNon-remote employees: Pre-tax Commuter Benefit Plan, healthy meals and snacks \nCruiseFlex - a working policy for US-Based Cruisers that lets you and your manager find what working style is best for you, whether it\u2019s primarily in-person, primarily at home or a combination of home and in-office time.\nWe\u2019re Integrated\nThrough our partnerships with General Motors and Honda, we are the only self-driving company with fully integrated manufacturing at scale.\nWe\u2019re Funded\nGM, Honda, Microsoft, T. Rowe Price & Walmart have invested billions in Cruise. Their backing for our technology demonstrates their confidence in our progress, team, and vision and makes us one of the leading autonomous vehicle organizations in the industry. Our deep resources greatly accelerate our operating speed.\nWe\u2019re Independent\nWe have our own governance, board of directors, equity, and investors. Our independence allows us to not just work on the edge of technology, but also define it.\nWe\u2019re Vested\nYou won\u2019t just own your work here, you\u2019ll have the potential to own equity in Cruise, too. We are competing in a market that is projected to grow exponentially, which gives our company valuation room to grow.\nRecurring Liquidity Opportunity (RLO) - a unique equity program where employees, both current and former, have the option to sell any amount of their vested equity on a recurring basis, currently quarterly.\nWe\u2019re Safety Conscious\nWe integrate #staysafe, our top priority at Cruise, into our everyday work. Through our Safety Management System, every Cruiser is asked to do their part by reporting any potential issues or hazards they observe and making continuous improvements. You\u2019ll be able to contribute to safety at Cruise, no matter your job function or title.\nCruise LLC is an equal opportunity employer. We strive to create a supportive and inclusive workplace where contributions are valued and celebrated, and our employees thrive by being themselves and are inspired to do the best work of their lives. \nWe seek applicants of all backgrounds and identities, across race, color, ethnicity, national origin or ancestry, citizenship, religion, sex, sexual orientation, gender identity or expression, veteran status, marital status, pregnancy or parental status, or disability. Applicants will not be discriminated against based on these or other protected categories or social identities. Cruise will consider for employment qualified applicants with arrest and conviction records, in accordance with applicable laws.\nCruise is committed to the full inclusion of all applicants. If reasonable accommodation is needed to participate in the job application or interview process please let our recruiting team know or email HR@getcruise.com.\nWe proactively work to design hiring processes that promote equity and inclusion while mitigating bias. To help us track the effectiveness and inclusivity of our recruiting efforts, please consider answering the following demographic questions. Answering these questions is entirely voluntary. Your answers to these questions will not be shared with the hiring decision makers and will not impact the hiring decision in any way. Instead, Cruise will use this information not only to comply with any government reporting obligations but also to track our progress toward meeting our diversity, equity, inclusion, and belonging objectives.\nNote to Recruitment Agencies: Cruise does not accept unsolicited agency resumes. Furthermore, Cruise does not pay placement fees for candidates submitted by any agency other than its approved partners.","71":"Job Description\nNielsenIQ\u2019s technology teams are working on our new Connected platform, a unified, global, open data ecosystem powered by Microsoft Azure. Our clients around the world rely on NielsenIQ\u2019s data and insights to innovate and grow.\nAs an Engineer, you\u2019ll be part of a team of smart, highly skilled technologists who are passionate about learning, data mining and prototyping cutting-edge technologies. Right now, our platform is based in Python, R, Elastic search, Kafka, NiFi, Mongo, Postgres and Snowflake.\nAs an Engineer, you will collaborate with other Engineers, Development teams, Product Owners & Scrum Masters to realize critical business goals. Our team is co-located and agile, with central technology hubs in Europe, Canada, and India.\nResponsibilities :\nWrite complex algorithms to get an optimal solution for real time problems\n Qualitative analysis and data mining to extract data, discover hidden patterns, and develop predictive models based on findings\nUse distributed computing to validate and process large volumes of data to deliver insights\nEvaluate technologies we can leverage, including open-source frameworks, libraries, and tools\nInterface with product and other engineering teams on a regular cadence\nQualifications\n3+ years of applicable data engineering experience, including Python& RESTful APIs\nStrong fundamentals in data mining & data processing methodologies\nStrong knowledge of data structures, algorithms and designing for performance, scalability and  availability\nSound understanding of Big Data & RDBMS technologies, such as SQL, Hive, Spark, Databricks, Snowflake or Postgresql\nOrchestration and messaging frameworks: Airflow, Messaging Frameworks (Kafka)\nExperience in Azure or any cloud computing\nGood experience working in containerization framework, Docker is a plus.\nExperience in agile software development practices and DevOps is a plus\nKnowledge of and Experience with Kubernetes is a plus\nExcellent English communication skills, with the ability to effectively interface across cross-functional technology teams and the business\nMinimum B.S. degree in Computer Science, Computer Engineering or related field\nAdditional Information\nEnjoy a flexible and rewarding work environment with peer-to-peer recognition platforms. \nRecharge and revitalize with help of wellness plans made for you and your family. \nPlan your future with financial wellness tools. \nStay relevant and upskill yourself with career development opportunities. \nAbout NIQ\nNIQ, the world\u2019s leading consumer intelligence company, reveals new pathways to growth for retailers and consumer goods manufacturers. With operations in more than 100 countries, NIQ delivers the most complete and clear understanding of consumer buying behavior through an advanced business intelligence platform with integrated predictive analytics. NIQ delivers the Full View. \nNIQ was founded in 1923 and is an Advent International portfolio company. For more information, visit NIQ.com \n Want to keep up with our latest updates? Follow us on: LinkedIn | Instagram | Twitter | Facebook\nOur commitment to Diversity, Equity, and Inclusion\nNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us.\nWe are proud to be an Equal Opportunity\/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide.\nLearn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https:\/\/nielseniq.com\/global\/en\/news-center\/diversity-inclusion\/\nNIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process.","72":"Join an innovative company developing a cutting-edge AI platform and knowledge graph that promises to transform how life science organizations work together. By harnessing the power of generative technology, this platform has the potential to unlock unprecedented insights and accelerate scientific discovery. With a focus on collaboration, this company is poised to impact life sciences and beyond significantly.\nThis operating system allows every scientist and biotech company to work together in the same sandbox, quickly building upon each other's creations.\nThe company is looking to revolutionize the way data is utilized in its field with its advanced knowledge graph and generative AI platform. By eliminating the limitations of data interoperability, they can seamlessly combine various data types and sources into a cohesive, comprehensive narrative. This breakthrough technology opens up new opportunities for scientific discovery and collaboration.\nKey Details to Catch your Eye\nTeam members are encouraged to be self-starters and work purposefully.\nYou\u2019ll be the first Data Engineer on the team, but you\u2019ll still be working closely with other team members.\nAgile software development process in a fast-paced environment.\nRequirements\nYour Skills\n3+ years as a Data Engineer or related fields (Semi Sr\/Sr).\nStrong knowledge of Python and Pandas.\nProficient understanding of Apache Airflow.\nFamiliar with NoSQL databases like Redis and MongoDB and graph databases like Neo4j.\nBachelor\u2019s degree or equivalent.\nEnglish Proficiency.\nHow You\u2019ll Stand Out\nKnowledge of various file formats, including JSON and XML.\nUnderstanding of Spark.\nExperience with data lineage frameworks like OpenLineage.\nThe Screening Process\nVerification by the BEON team.\nCoding challenge.\nTechnical Interview with the CTO and Head fo Data.\nCultural interview.\nTotal expected timeframe: 5-7 days.\nAbout BEON.tech\nBEON.tech connects the brightest Latin American talent with the most innovative and disruptive U.S. companies. You\u2019ll get access to a custom-vetted pool of full-time, long-term, remote software jobs with compensation comparable to U.S.-based positions.\nTo join BEON.tech is to be in a devs-first company, which means you are the priority when it comes to decision-making, client selection, and growth planning.\nDevelop your career at the pace you deserve.\nBenefits\nUSD compensation comparable to U.S.-based positions.\nA US$ 1,500 welcome package to get you started with the right gear.\nHealth insurance.\nInternet service.\nTrip to Headquarters in Buenos Aires.\nFlexible payments in crypto, wire transfer, Wise, PayPal, or Payoneer.\nEnglish conversation club & workshops.\nRewards Program: Win prizes every month by participating in weekly challenges. The annual winner will earn a trip for two to NYC!\nPsychotherapy sessions.\nUnlimited reskilling in Udemy, Educaci\u00f3n IT & O\u2019Reilly.","73":"Job Description\nAbout You\nWe are looking for a Big Data Engineer to work with large data volumes read from scattered information sources in an organization's technology infrastructure.\nYou bring to Applaudo the following competencies:\n2+ years of experience with Scala Spark\n3+ years of data delivery, ETL (extract, transform and load) and data warehouse design, analysis, and programming experience.\nExperiencie with Google Cloud Plattform.\nExperience with an excellent grasp of relational and dimensional data modeling\nStrong mathematical, statistical, and analytics skills\n1+ year of Agile experience\nEnglish is required, as you will work directly with US-based clients.\nYou will be accountable for the following responsibilities:\nExtracting data from different data sources and transferring it into a data warehouse environment.\nDesigning, maintaining, and implementing transactional and analytical data storage structures.\nDesign, build and maintain data pipelines, consuming for multiple sources, and servicing multiple tenants\nExperience in one or more of the following DBMS: PostgreSQL, MySQL, Google Cloud Datastore, Cosmos\nExperience in one or more of the following programming languages: Scala, PL\/SQL, Java\nExperience in one or more of the following cloud environment tools: GCP\nElaborate informative, expressive, and meaningful reports that support business decision-making processes through the information provided.\nReporting and subsequently translating the emanating results into good technical and consistent data designs.\nQualifications\nTechnical Skills:\n2+ years of experience with Scala Spark\nExperience with cloud environment tools\nAdditional Information\nHere at Applaudo Studios values as trust, communication, respect, excellence and team work are our keys to success. We know we are working with the best and thus treat each other with respect and admiration without asking.\nSubmit your application today, and don't miss this opportunity to join the Best Digital team in the Region!\nWe truly appreciate all the hard and outstanding work our team makes every day at Applaudo Studios, and that's why the perks that we offer, are deeply thought and designed as a way to thank them for their commitment and excellence.\nSome of our perks and benefits:\nWork from home\nFlexible schedule\nCelebrations\nSpecial discounts\nEntertainment area\nFlexible work spaces\nGreat work environment\nPrivate medical insurance\n*Benefits may vary according to your location and\/or availability. Request further information when applying.","74":"Company Description\nWe help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.\nJob Description\nAnalyze business requirements and develop the necessary analytical solutions such as worksheets and liveboards.\nIncorporate Azure DevOps in daily development cycles and deployments.\nTroubleshoot production incidents as identified by QA.\nContribute to excellent user experience from a customer perspective.\nQualifications\nMinimum of a bachelor\u2019s degree or equivalent in Computer Science, Information Systems, Engineering, or Mathematics\nMinimum of 2 years of experience in development using business intelligence tools such as ThoughtSpot, Spotfire, Power BI, or other browser-based BI applications.\nMinimum of 2 years of experience working in an Agile software development environment.\nKnowledgeable of data modeling techniques such as Kimball data modeling and data warehouses.\nProficiency with database technologies MySQL (Aurora), MSSQL, Oracle, S3, Redshift, Snowflake or equivalent.\nTechnical Knowledge in Python \/ Java \/ C++ and\/or C#.\nProficiency with version control systems (GIT).\nA deep desire to drive efficiency through process and methodology improvements.\nMotivated by working in a collaborative environment with individuals from multiple departments.\nExcellent verbal and written communication skills.\nExcellent technical, problem-solving, and troubleshooting instincts.\nGeneral work office\/remote work conditions.\nAbility to work extended hours as needed to meet deadlines.\nOccasional after hours support for deployments.\nAdditional Information\niiX, a Verisk business and member of the Verisk Insurance Underwriting group, is a nationwide provider of insurance underwriting and employment reports. Our systems make it quick and easy for our over 20,000 customers to get real-time reports through one of several platforms. iiX provides high-tech, innovative products and services combined with excellent customer service. To learn more about iiX\u202fplease visit us at:\u202fwww.iix.com. We are proud to be a part of the Verisk family of companies! \nAt the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.\u202f  \nOur global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.  \nBut why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.  \nIt\u2019s the reason Verisk is part of the UN Global Compact sustainability initiative. It\u2019s why we made a commitment to balancing 100 percent of our carbon emissions. It\u2019s the aim of our \u201creturnship\u201d program for experienced professionals rejoining the workforce after time away. And, it\u2019s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers\u2019 problems.\u202f  \nAt its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do. \nAt Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career.\u202fWe have received the Great Place to Work\u00ae Certification for the 7th consecutive year. We\u2019ve been recognized by Forbes as a World\u2019s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.  Verisk\u2019s Statement on Racial Equity and Diversity supports our commitment to these values and affecting positive and lasting change in the communities where we live and work.\nVerisk Analytics is an equal opportunity employer.\nAll members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and\/or expression, sexual orientation, veteran's status, age or disability.\nhttp:\/\/www.verisk.com\/careers.html\nUnsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.\nConsumer Privacy Notice","75":"Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the \u2018Cloud Ambassador\u2019 across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.\n\nWould you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?\n\nIf you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success\n\n\nKey job responsibilities\n\u2022 First and foremost this is a customer support role \u2013 in The Cloud.\n\u2022 On a typical day, a Support Engineer will be primarily responsible for solving customer\u2019s cases through a variety of customer contact channels which include telephone, email, and web\/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue.\n\u2022 Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach\/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools\/script to help the team, or work with leadership on process improvement and strategic initiatives.\n\u2022 Career development: We promote advancement opportunities across the organization to help you meet your career goals.\n\u2022 Training: We have training programs to help you develop the skills required to be successful in your role. We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you haven\u2019t been exposed to yet.\n\u2022 Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events.\n\u2022 AWS Support Engineering has 24\/7\/365 operation model and work schedule will be required to include nights, weekends and holidays.\n\n\nA day in the life\nEvery day will bring new and exciting challenges on the job while you:\n\u2022 Learn and use groundbreaking technologies\n\u2022 Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs\n\u2022 Interact with leading technologists around the world\n\u2022 Work directly with Amazon Web Services teams to help reproduce and resolve customer issues\n\u2022 Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services\n\u2022 Drive customer communication during critical events\n\u2022 Drive projects that improve support-related processes and our customers\u2019 technical support experience\n\u2022 Write tutorials, how-to videos, and other technical articles for the customer community\n\u2022 Work on critical, highly complex customer problems that may span multiple AWS services\n\n\nAbout the team\nINCLUSIVE TEAM CULTURE\n\nHere at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon\u2019s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.\n\nWORK\/LIFE BALANCE\n\nOur team puts a high value on work-life balance. It isn\u2019t about how many hours you spend at home or at work; it\u2019s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.\n\nMENTORSHIP\/CAREER GROWTH\n\nOur team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we\u2019re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.\nBasic Qualifications\n\nStrong Linux\/Unix system administrator skills\nIntermediate programming\/scripting skills. Ideally in Java or Python, but will consider experience in other Object Oriented and Functional languages\nUnderstanding of networking principles and ability to troubleshoot (DNS, TCP\/IP, HTTP)\nFoundational knowledge of databases and Structured Query Language (SQL)\nUnderstanding of Virtualization and\/or cloud computing\nGood understanding of security best practices\nExceptional customer focus \/ Customer service experience\nGood understanding of distributed computing environments and methodologies\nCandidates must have excellent oral and written communication skills in Korean and basic writing\/reading skills in English\nFlexibility to work weekend shifts\n\nPreferred Qualifications\nExperience in Apache Hadoop, Apache Spark, Apache Hive, and Presto or ETL skills with working\nExperience in DynamoDB or NoSQL technologies like MongoDB or Cassandra\nIn depth experience in the Hadoop Ecosystem including Apache Spark and Presto\nExperience in NoSQL\nExperience in data Data Lake architecture and administration\nExperience managing full application stacks from the OS up through custom applications\nPrior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker\nExcellent knowledge of Hadoop architecture, administration and support\n\n\nWhat if I\u2019m not an expert in all the preferred qualifications listed on the job description? That\u2019s okay. That\u2019s our preferred list, not a required listed. We hire smart people who can dive deep so we\u2019re more interested in the areas that you do know instead of those you haven\u2019t been exposed to yet. Speak to an AWS recruiter and we will be happy to provide you with more information about this role or guide you to the best possible match for your profile and your career interests.\n\n\uc544\ub9c8\uc874\uc740 \uad6c\uc131\uc6d0\uc758 \ub2e4\uc591\uc131\uacfc \ud3ec\uc6a9\uc801 \uae30\uc5c5\uc815\ucc45 \ubc0f \uc870\uc9c1\ubb38\ud654\ub97c \ub9cc\ub4e4\uc5b4 \uac00\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uc544\ub9c8\uc874\uc740 \uacf5\uc815\ud55c \uae30\ud68c\ub97c \uc81c\uacf5\ud558\uba70, \uc778\uc885, \uad6d\uc801, \uc131\ubcc4, \uc131\ubcc4\uc815\uccb4\uc131, \uc131\uc801\uc9c0\ud5a5, \ub098\uc774, \ubcf4\ud6c8, \uc7a5\uc560\uc5ec\ubd80 \ub4f1 \uc5c5\ubb34\uc218\ud589\uc640 \uad00\ub828\uc5c6\ub294 \ub2e4\uc591\uc131\uc744 \ucc28\ubcc4\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n#aws-kr-premiumsupport-ap\n#AWSKOREA","76":"The AWS Partner Organization is looking for a talented Business Intelligence Engineer (BIE) to help drive the strategy for AWS Programs, an important driver of AWS revenue worldwide. AWS is the world\u2019s leading cloud provider with the most comprehensive and broadly adopted portfolio of cloud services and a vibrant, innovative community of customers and partners. Millions of customers\u2014including the fastest-growing startups, largest enterprises, and leading government agencies\u2014are using AWS to lower costs, become more agile, and innovate faster.\n\nAWS customers transform and reinvent their businesses through the cloud and the AWS Partner Network (APN) is helping to dramatically accelerate that innovation. There are tens of thousands of APN Partners across the globe. More than 90% of Fortune 100 companies and the majority of Fortune 500 companies utilize APN Partner solutions and services.\n\nThis is excellent opportunity for a BIE interested in joining AWS. Given the scope and breadth of the Programs business for AWS, you will have the opportunity to learn about all the AWS services, global revenue drivers and leading AWS end customers. This position also provides exposure to AWS senior leadership. BI is core to the Program strategy and this position will play a central role in supporting leadership doc reviews with AWS S-team members.\n\nKey job responsibilities\n\nAs a BIE of the global Programs analytics, you will own the reporting and insights for this large growth business, influencing the global vision and strategic direction. This is an exciting opportunity for a Business Intelligence Engineer who wants to develop innovative ways of interacting with and interpreting business metrics, and shape the future of a growth AWS business. Your work will encompass the end-to-end development of self-service reporting, analytical investigations and automation solutions. You will use your excellent communication and technical skills to translate a variety of business problems into analytical solutions, collaborating with and challenging business owners (Program leaders, Partner Development leaders, Finance and Marketing) to make better decisions on behalf of AWS and our customers.\n\nAbout the team\n\nOur team puts a high value on work-life balance. Striking a healthy balance between your personal and professional life is crucial to your happiness and success here, which is why we aren\u2019t focused on how many hours you spend at work or online. Instead, we encourage you to have a more productive and well-balanced life\u2014both in and outside of work.\n\nMentorship & Career Growth\n\nOur team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we\u2019re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.\n\nInclusive and Diverse Culture\n\nHere at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have twelve employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon\u2019s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.\n\nTenured AWS employees welcome to apply\nBasic Qualifications\n\n3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience\nExperience with data visualization using Tableau, Quicksight, or similar tools\nExperience with data modeling, warehousing and building ETL pipelines\nExperience writing complex SQL queries\n\nPreferred Qualifications\nBachelors Degree\n\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https:\/\/www.amazon.jobs\/en\/disability\/us.","77":"Company Description\nFinc3 is a group of high-end online marketing companies with over 150 employees that work in the areas of  \nE-Commerce and marketplace management (Finc3 Commerce)  \nB2B performance marketing (BizMut)\nAnalytics- and CRM-consulting (Finc3 Marketing Services) \nWe pride ourselves in offering a fast-paced place to learn, a competitive salary, high-end tools to use and challenging problems to solve. \nFinc3 Commerce \u2013 one of our companies with specialists in e-commerce, marketplace and Amazon management \u2013 is currently looking for a motivated BI Developer (f\/m\/d) to help us scale or software as a service reporting solution whilst working towards bridging the gap between business processes and business intelligence for our clients.  \nThe position can either be part-time (min. 80%) or full-time and is located in Hamburg. \nJob Description\nWhat we want you to achieve \nYou help us in scaling our software as a service reporting solution \nYou translate business needs to technical specifications \nYou optimize Power BI data models of our products & custom client solutions \nYou develop and execute database queries and conduct performance analyses \nYou identify & implement data transformations along the data pipeline \nYou work closely with our software developers and product managers on our SaaS solution \nYou collaborate with our business analysts on custom client projects \nYour focus will be on Business Intelligence projects, but you will also gain a broad understanding of our business and understand the industry \nQualifications\nWhat we want you to contribute \nYou have successfully completed studies in the field of computer science, informatics or number driven studies \nYou have 4+ years of experience with business intelligence tools. At least wo of those with Microsoft Power BI \/ Power Query   \nYou have previously worked as a BI Developer or comparable position \u2013 preferably with a DBA responsibility \nYou are an expert in SQL \nKnowledge of Python is a benefit but no must \nYou are a self-motivated person, eager to learn and to expand your own know-how daily \nYou are highly analytical, show self-initiative and can prioritize tasks independently \nYou possess excellent written and verbal communication skills in English \nAdditional Information\nWhat we offer \nA highly dynamic company that belongs to the leading agencies in Europe, especially for Amazon consulting and marketing \nInteresting insights in several companies from traditional German and international brands to online pure players  \nGaining a lot of responsibility for your own projects and great development opportunities  \nEncouragement of your individual career development based on the Gallup StrengthsFinder and an unlimited learning budget  \nA positive client relationship \u2013 we do not only work at eye level internally, but also with all our clients \nA zero bullshit attitude: we know what we are doing and strive to be thought leaders in our services  \nDiversity and inclusion are fostered in our company values and build our foundation for sustainable business success  \nA very positive and truly international working culture with more than 30 nationalities  \nBenefit from many company events, afterworks, getaways and internal support \u2013 we enjoy working together and it shows!  \nA competitive salary and a modern workplace right in the center of Hamburg \nFlexible working hours and the possibility for remote work \nEnjoy our yearly sunshine office abroad  \nBike leasing \nAn attractive pension plan \nHVV-ProfiTicket    \nLunch allowance \nAnd much more... \nFind out what our colleagues appreciate the most about working at Finc3 at our kununu page. \nYou think this might be a good fit? \nWe are looking forward to your application with CV, short explanation of your motivation, preferred starting date, and salary expectations via our Finc3 career website. ","78":"Company Description\nWelcome to SMG Swiss Marketplace Group AG\nWe are a pioneering network of online marketplaces and a leading European digital company that simplifies people's lives with forward-looking products.\nJob Description\nAs the new Business Intelligence Developer, you will be part of the Group Data Team (GDT). You will work together with data engineers, data architects, data product owners and diverse business domain stakeholders to make group-wide data more accessible, well-governed and understood.\nAs a contributor to the GDT, you will be responsible for delivering data products for our internal customers. To be effective in this position, you must be comfortable working with various business domains, a bottom-up management approach and be able to get up to speed with new technologies quickly.\n Role Ratio:\n60% Backend - data extraction, loading and transformation (ELT)\n40% Frontend - data visualization (charts and dashboard building)\n\nYour Responsibilities:\nMake use of the cloud infrastructure created by data engineers to extract, load and transform (ELT) data from different sources\/domains into the Group Business Intelligence platform\nDevelop reusable data assets (marts, reports, metrics, metadata) that reflect the business's needs and follow data protection guidelines\nApply data warehousing best practices to the data assets and monitor them to guarantee data completeness, uniqueness, consistency, validity, accuracy and timeliness\nFollow naming standards guidelines and perform technical data documentation in order to have data assets metadata flowing into the group data catalogue and downstream tools\nVersion code, deploy using continuous integration and continuous delivery tools, review code and test changes assuring data quality and business requirements satisfaction.\nImplement business-defined metrics and key performance indicators as a single source of truth\nWork closely with the BI Team Lead, Data Product Owner and Stakeholders to understand their needs\/requirements in order to design data visualizations that bring value, business insights capabilities and help the teams measure the impact of their work\nDevelop charts and dashboards using a cloud data visualization tool incorporating usability best practices and following SMG branding guidelines when designing it\nCollaborate with the remote teams making transparent your activities' progress and keeping Kanban board updated to keep track of tasks and documentation for future support on troubleshooting\nParticipate and collaborate with the data engineering, data product enablement and business intelligence teams in different workshops to define objectives and key results (OKRs) that are achievable in order to promote innovation and learning\nQualifications\n You have a Bachelor\u2019s or Master\u2019s Degree in Information Technology, Data Analytics, Management Information Systems, Computer Science, Artificial Intelligence, Data Science or a related technical\/data field\nYou have at least 2 years of professional experience working with Structured Query Language (SQL ansi)\nYou have at least 2 years of professional experience working with one data warehousing architecture (E.g. Star schema, Snowflake schema, One Big Table, Data Vault, Data Lake, etc)\nYou have at least 1 year of professional experience working with business intelligence or\/and analytics engineering or\/and data engineering or\/and data analysis\nYou have experience with at least one modern cloud data warehousing tool. E.g. BigQuery (preferably), Azure, Redshift, Snowflake, etc. \nYou have experience with at least one data visualization tool. E.g. Looker (preferably), Tableau, Power BI, etc.\nYou have experience with at least one code versioning tool. E.g. git (preferably), svn, etc.\nYou have experience with at least one code repository platform. E.g. Github (preferably), Bitbucket, etc.\nYou have strong interpersonal and collaboration skills, organization and attention to detail\nYou have the ability to take initiative and engage in discussions related to requirements and data products\nGood verbal and written communication skills in English. German is a plus.\n\n Nice to have experience with:\nOnline marketplaces and\/or digital businesses\nGoogle Cloud Platform data warehousing and business intelligence tools (BigQuery sql syntax, Looker as a LookML developer)\nData Build Tool (dbt core) as a data transformation tool\nThe git protocol and Github for code versioning and repository platforms\nAgile methodologies (E.g. Kanban, Scrum, Lean, etc)\nContinuous integration and continuous delivery (CI\/CD)\nAtlan data catalogue tool\nData mesh decentralized data architecture\nPython\nNotion\nJira\n Additional Information\nBenefits you'll love and why you should join us\nYour new team and the people you work with will consist of an international and diverse group of fantastic people.\nWe live a hybrid working model without fixed office days. You are welcome to work in our modern and spacious office in Zurich, or from your home base in Switzerland.\n In addition, SMG offers you:\n6 weeks of holidays (with the possibility to buy up to 10 additional days)\n40-hour week (flexitime) We take work-life balance seriously\n4 months' notice after the probationary period\nSBB Half-Fare Card\nYou travel 1st class by train between SMG sites in Switzerland\n18 weeks maternity and 6 weeks paternity leave (also in case of adoption)\nProfessional accident and supplementary insurance (100% covered by SMG)\nNo fixed office days (teams organize themself regarding onsite presence)\nIndependent counselling centre for personal and psychological problems\nGender-neutral fair pay with clearly defined career profiles\nChoose your hardware (Mac or Windows + 2 monitors for home)\nChoose your mobile phone (iPhone, Samsung or Pixel)\nFree Gym Facilities (Flamatt office only)\n Apply Now! We are looking forward to getting to know you!\n  SMG Swiss Marketplace Group Ltd. is a pioneering network of online marketplaces and an innovative European digital company that simplifies people\u2019s lives with groundbreaking products.\n\nSMG Swiss Marketplace Group Ltd. provides customers with the best tools to meet their life decision needs. The portfolio includes Real Estate (ImmoScout24, Homegate, Immostreet.ch, home.ch, Acheter-Louer.ch), Automotive (AutoScout24, MotoScout24, CAR FOR YOU), General Marketplaces (anibis.ch, tutti.ch, Ricardo) and Finance & Insurance (FinanceScout24). The company is owned by TX Group AG (31%), Ringier AG (29.5%), La Mobili\u00e8re (29.5%), and General Atlantic (10%).","79":"Company Description\nWe\u2019re the world\u2019s leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business.\nJob Description\nJob Description\nAre you passionate about Data Visualization?\n\nSportradar is seeking a curious and motivated BI Developer to join the fast paced and dynamic Trading Services Unit Operations team.\n\nYou will be responsible for the design, creation, and implementation of the reporting layer for our global Trading Services Operations. You will implement creative approaches to solving complex problems with ambiguous paths to resolution. In addition to building new features, you will constantly be improving and adding to existing reporting interfaces.\n\nThe role is a key member of the team that will help develop the vision and architecture for our Trading Services Data Infrastructure. The Trading Services Unit Operations team drives innovation and operational excellence through the projects they support across the Unit.\n\nYou will report directly to the Head of Trading Services Unit Operations and collaborate with management of our Trading Operations and Core BI\/Data teams to surface the answers to key operational and business questions.\n\nWhat You Will Do\n- Consolidate data from various sources via ETL processes\n- Qlik Sense Dashboard Development\n- Pro-actively Identify opportunities for new projects, using existing tools in new ways, using existing data differently, and generally demonstrating the value of data\n- Reining-in and centralizing reporting interfaces that have been developed in silo.\n- Driving best practices and technical excellence\n- Engaging with Trading BI\/Data projects throughout their lifespan; from conception, development, launch, and beyond\n- Being the main liaison with the Core BI\/Data Team for Trading Services\n- Lead the translation of business requirements into technical tasks.\n- Creating and maintaining technical documentation for BI Tools\n- Participate in Departmental knowledge transfer Programmes in order that they can transfer their knowledge to others in the Unit who will benefit\n- Proactively plan educational learning sessions in order to ensure that technical knowledge is developed so that appropriate new technology and techniques can be suggested in order to effectively meet business needs\nBasic Qualifications\n- Experience of working in BI Developer roles in support of BI and Analytics\n- Deep Understanding of SQL\n- Strong Data Visualization skills\n- Ability to present to senior stakeholders\n- Excellent communication skills\nPreferred Qualifications\n- Strong experience using Data Visualization tools (e.g., Qlik Sense)\n- Track record of having earned the trust of leadership by challenging norms and improving efficiency.\n- Ability to dive deep into data, existing processes, people, and technology to identify risks and opportunities.\n- Demonstrated ability to meet deadlines while working on multiple complex projects.\n- Demonstrated ability to work in global environments and with people\/teams from different cultural backgrounds.\n- Experience working with AWS (Amazon Web Services) (e.g Redshift and Athena)\nAbout Sportradar\nSportradar is a leading global provider of sports betting and sports entertainment products and services. Established in 2001, the company is well-positioned at the intersection of the sports, media and betting industries, providing sports federations, news media, consumer platforms and sports betting operators with a range of solutions to help grow their business.\nSportradar employs more than 2,300 full time employees across 19 countries around the world. It is our commitment to excellent service, quality and reliability that makes us the trusted partner of more than 1,600 customers in over 120 countries and an official partner of the NBA, NHL, MLB, NASCAR, FIFA and UEFA. We cover more than 750,000 events annually across 83 sports.\nWith deep industry relationships, Sportradar is not just redefining the sports fan experience; it also safeguards the sports themselves through its Integrity Services division and advocacy for an integrity-driven environment for all involved.\nAdditional Information\nSportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences ","80":"Unternehmensbeschreibung\nBei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch.\nDie Robert Bosch GmbH freut sich auf Deine Bewerbung!\nStellenbeschreibung\nIm Gesch\u00e4ftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen \u2013 von hocheffizienten Antrieben \u00fcber das erste serienreife ABS f\u00fcrs Pedelec bis hin zu smarten Connectivity-L\u00f6sungen. F\u00fcr eine nachhaltige Mobilit\u00e4t, die Spa\u00df macht.\nAls Data Analyst und Scientist bist Du der Experte, der aus Big Data Smart Data f\u00fcr den Bosch eBike Service macht und dabei sowohl eigene komplexe Projekte als auch Teilprojekte verantwortet. Deine Ergebnisse stellen eine wertvolle Zuarbeit f\u00fcr andere Projekte und Services dar.\nDu analysierst die uns vorliegenden Datenmengen mit dem Ziel, unsere Prozesse sowie unsere Angebote an den Fachhandel und Endkunden zu verbessern, damit wir unseren Wettbewerbsvorsprung ausbauen.\nDu bist intrinsisch motiviert, aus unstrukturierten Daten unterschiedlicher Quellen und Systemen Muster zu erkennen. Durch die Verbindung von weiteren und der Erschlie\u00dfung neuer Datenquellen definierst Du Anwendungsf\u00e4lle f\u00fcr den Bosch eBike Service. Gemeinsam mit den verschiedenen agilen Teams setzt Du diese Anwendungsf\u00e4lle um und begeisterst unsere Kunden.\nDas Technology Scouting und Benchmarking bzgl. neuer Analysemethoden f\u00fchrst Du selbst\u00e4ndig aktiv durch und leitest daraus m\u00f6gliche Anwendungen f\u00fcr Bosch eBike Systems ab.\nDu stellst die Anforderungen zur Etablierung neuer Datenpipelines und die Realisierung sicher. Dabei agierst Du sowohl bereichs\u00fcbergreifend als auch international und mit Zentralstellen von Bosch. Basierend auf Deinen Analysen f\u00fchrst Du datengetriebene Entscheidungen auf Leitungs- und Bereichsvorstandsebene herbei.\nEin Berichtswesen u. a. mittels einpr\u00e4gsamer Visualisierungen geh\u00f6rt zu Deinem Methodenbaukasten. Zudem sind advanced und predictive Analytics oder KI f\u00fcr Dich keine kryptischen K\u00fcrzel.\nDu bef\u00e4higst die eBike Kollegen in der Nutzung und Wiederverwendung Deiner Analysen und bereitgestellter Dashboards.\nQualifikationen\nAusbildung: abgeschlossenes Hochschulstudium (Master\/Diplom\/Promotion) der Informatik, der Wirtschaftsinformatik oder eines vergleichbaren Studienganges; idealerweise Master in Data Analytics\nErfahrungen und Know-how: mehrj\u00e4hrige Berufserfahrung im IT-Bereich wie Software-, Datenbankentwicklung, Big Data und Analytics-Technologien sowohl on-Premise als auch in der Cloud; Erfahrung mit Machine Learning und von k\u00fcnstlicher Intelligenz getriebenen Anwendungen; KPI-Wissen im Web und App Kontext; Grundkenntnisse des Datenschutzes und den gesetzlichen Regularien im Umgang mit Data und Customer Analytics von Vorteil; Erfahrung in der abteilungs- und gesch\u00e4ftsbereichs\u00fcbergreifenden Koordination in einem internationalen Umfeld\nPers\u00f6nlichkeit und Arbeitsweise: Deine Arbeitsweise zeichnet sich durch Selbstst\u00e4ndigkeit und Struktur aus; Du bist zielgerichtet, kommunikationsstark und \u00fcberzeugend; Du arbeitest gerne im Team; Dein Handeln ist von unternehmerischem Denken getrieben\nSprachen: verhandlungssicheres Deutsch und Englisch in Wort und Schrift\nZus\u00e4tzliche Informationen\nIn diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente. Wir bieten tolle M\u00f6glichkeiten des remoten Arbeitens sowie unterschiedliche Teilzeitmodelle bis hin zum Jobsharing. Sprich uns gerne dazu an.\n\nVielfalt und Inklusion sind f\u00fcr uns keine Trends, sondern fest verankert in unserer Unternehmenskultur. Daher freuen wir uns \u00fcber alle Bewerbungen:\u202funabh\u00e4ngig von Geschlecht, Alter, Behinderung, Religion, ethnischer Herkunft oder sexueller Identit\u00e4t.\n\nDu hast Fragen zum Bewerbungsprozess?\nNina Sier (Personalabteilung)\n+49 711 811 27525\nDu hast fachliche Fragen zum Job?\nPatrick Millen (Fachabteilung)\n+49 7121 35 39465\nInteressierst Du Dich f\u00fcr diese oder weitere Stellen? Dann bewerbe auf die Virtual JobFair@BOSCH und verschaffe Dir einen \u00dcberblick \u00fcber die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de\/events\/                                        ","81":"Are you looking to be in a workplace where colleagues inspire one another? Are you interested in competitive and impactful benefits? Do you prefer flexible work arrangements? \nWe are seeking a talented and experienced Product Owner to join our team of experts focused on designing and building microservices that leverage Big Data and Artificial Intelligence (AI) to identify and act on personal information in the RelativityOne platform. This successful candidate will lead the development and execution of the product roadmap to ensure the commercial success of both Text IQ for Data Breach and Text IQ for Personal Information offerings. \nResponsibilities:\nDevelop and execute on the product roadmap that supports the Text IQ for Data Breach and Text IQ for Personal Information offerings. \nCollaborate with cross-functional teams (including engineering, operations, marketing, sales, and customer success) to ensure successful product delivery and customer adoption. \nIdentify market trends, customer needs, and competitive insights to inform product strategy and roadmap. \nCreate user stories and prioritize the product backlog to align with the overall product vision and goals. \nWork closely with the engineering team to deliver high-quality product features and functionality, and ensure timely product delivery. \nDefine and measure product success metrics, and use data to continuously improve product performance and user satisfaction. \nCommunicate product strategy, roadmap, and progress to internal and external stakeholders. \nCollaborate with the go-to-market teams to develop effective product positioning, messaging, and launch plans. \nCollect, analyze, and summarize data from disparate sources to drive conclusions and recommendations. \nWork independently and effectively in a results-oriented, efficient environment. \nDeliver products and ensure customer success through strong project management and team leadership. \nCommunicate effectively with stakeholders at all levels, including senior leadership. \nManage and prioritize multiple tasks and projects simultaneously. \nYour skills:\nBS or BA degree; 7+ years of work experience, with at least 5 in product management. \nStrong problem-solving skills, including ability to dissect complicated technical problems, simplify experiences, and innovate on behalf of our customers. \nStrong technical acumen and working knowledge of software architectures and AI\/ML. \nStrong business knowledge to help build go-to-market machinery for existing and new products. \nSolid understanding of software development lifecycle and agile methodologies. \nAbility to collaborate with and lead teams of all levels and disciplines within an organization, from engineers to senior leadership. \nA history of developing and owning product roadmaps to drive business outcomes. \nExperience collecting, analyzing, and summarizing data from disparate sources to drive conclusions and recommendations. \nEntrepreneurial spirit and ability to work independently and effectively in a results-oriented, efficient environment. \nStrong track record of delivering products and ensuring customer success. \nOrganized, with the ability to communicate effectively with stakeholders. \nExcellent written and verbal communication skills. \nExperience working with international teams is a plus. \nRelativity is a diverse workplace with different skills and life experiences\u2014and we love and celebrate those differences. We believe that employees are happiest when they're empowered to be their full, authentic selves, regardless how you identify.\nBenefit Highlights:Comprehensive health, dental, and vision plansParental leave for primary and secondary caregivers Flexible work arrangementsTwo, week-long company breaks per yearUnlimited time offLong-term incentive programTraining investment program\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.","82":"We are expanding our development teams and although we don\u2019t care much about titles, we call this role Data Engineer with Power BI experience and the key is having experience and knowledges in Cloud, and a constant desire to keep learning. Our vision is to build multidisciplinary teams which directly manage projects in an AGILE way to find and implement the best solutions \ud83d\ude0a\n\nWhat will you do?\nYou will participate developing projects from scratch with the collaboration of the team.\nYou will participate in the design of architectures and decisions making in a constructive environment and with co-creation dynamics.\nYou will be a key player in the development of good practices, clean and reusable code.\nYou will develop ETLs with Spark (Python\/Scala).\nYou will develop projects in the cloud (Azure\/AWS).\nAnalyzing, querying, and transforming data using DAX.\nYou will build scalable pipelines with different technologies: Airflow, data factory\u2026\nRequirements\nWhat are we looking for?\nMore than 3 years in Software\/data engineering experience.\nSolid experience in Python or Scala and Spark processing large volumes of data.\nSolid Cloud experience (Azure or AWS).\nExperience with Power BI (visualization, modeling, DAX)\nExperience working with tabular models.\nExperience in creating data pipelines (CI\/CD).\nKnowledge of SQL and NoSQL databases.\nExperience with Databricks, Data Factory, Synapse, Apache Airflow, etc.\nHigh level of English and German.\nA team player.\nBenefits\nWhat do we offer?\nSalary determined by the market and your experience \ud83e\udd11\nFlexible schedule 35 Hours \/ Week \ud83d\ude0e (no salary reduction)\nFully remote work (optional) \ud83c\udf0d\nIndividual budget for training and free Microsoft certifications \ud83d\udcda\nMonthly bonus for electricity and Internet expenses at home \ud83d\udcbb\nPlain Camp (annual team-building event) \ud83c\udfaa\nBirthday day off \ud83c\udf34\ud83e\udd73\n\u2795 The pleasure of always working with the latest technological tools!\n\nWith all this information you already know a lot about us. Will you let us know you better?\nThe selection process? Simple, just 3 steps: a call and 2 interviews with the team \ud83e\udd18\nAnd you may wonder\u2026 Who is Plain Concepts?\nPlain Concepts is made up of 400 people who are passionate about technology, driven by the change towards finding the best solutions for our customers and projects.\nThroughout the years, the company has grown thanks to the great technical potential we have and relying on our craziest and most innovative ideas. We currently have over 14 offices in 6 different countries. Our main goal is to keep growing as a team, developing the best and most advanced projects in the market.\nWe truly believe in the importance of bringing together people from different backgrounds and countries to build the best team, with a diverse and inclusive culture.\nWhat do we do at Plain Concepts?\nWe are characterized for having a 100% technical DNA. We develop customized projects from scratch, technical consultancy, training, and our own product: Sidra Data Platform \ud83d\udc9c\nWe don\u2019t do bodyshopping or outsourcing\nOur teams are multidisciplinary, and the organizational structure is flat and horizontal\nWe are very committed to AGILE values\nLiving is sharing: We help, support, and encourage each other to expand our knowledge internally and also towards the community (with conferences, events, talks\u2026)\nWe always look for creativity and innovation, even when the idea might seem crazy to others\nTransparency is key to any relationship\nWe make our clients\u2019 ideas and solutions a reality with a high degree of technical excellence, for more information you can visit our website:\n\n\u27a1 https:\/\/www.plainconcepts.com\/case-studies\/\n\nAt Plain Concepts, we certainly seek to provide equal opportunities. We want diverse applicants regardless of race, colour, gender, religion, national origin, citizenship, disability, age, sexual orientation, or any other characteristic protected by law.","83":"Company Description\nTalan est un cabinet de conseil en innovation et transformation par la technologie.\nDepuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en \u0153uvre leurs projets de transformation et d\u2019innovation en France et \u00e0 l'international. Pr\u00e9sent sur cinq continents, le groupe pr\u00e9voit de r\u00e9aliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant\u00b7e\u00b7s et vise \u00e0 d\u00e9passer la barre du milliard d\u2019\u20ac de CA \u00e0 horizon 2024.\nLe Groupe met l'innovation au c\u0153ur de son d\u00e9veloppement et intervient dans les domaines li\u00e9s aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.\nPr\u00e9sent dans les \u00e9v\u00e9nements incontournables du secteur, comme Viva Technology, Talan prend r\u00e9guli\u00e8rement la parole sur les enjeux de ces technologies r\u00e9volutionnaires aux c\u00f4t\u00e9s d'acteurs majeurs du secteur et de parlementaires (Syntec Num\u00e9rique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny\u2026).\nTalan est une entreprise responsable, attach\u00e9e \u00e0 la diversit\u00e9. Des am\u00e9nagements de poste peuvent \u00eatre organis\u00e9s pour tenir compte des personnes en situation de handicap.\nRetrouvez nos engagements RSE ici et nos actions en faveur de la diversit\u00e9 ici\nJob Description\nAu c\u0153ur de la strat\u00e9gie Data du groupe, Talan recherche un(e) Architect(e) Data capable d\u2019accompagner les projets, les avant-ventes, avec une approche de bout en bout, sur toute la cha\u00eene de valeur de la donn\u00e9e. \nQui sommes-nous ? \nLe p\u00f4le Data Intelligence est compos\u00e9 de +200 experts (AMOA Data, Agile Data, Data Gov, Data Streaming, Data Engineer, Data Analyst\u2026), vous intervenez sur des projets de modern data platform et d\u2019innovation pour accompagner les entreprises vers une organisation Data Driven. \nNos r\u00e9alisations tournent autour de th\u00e9matiques telles que : \nMove to cloud\u202f: passer du on-premise vers une modern data platform, \u2026 \nReal time :\u202fstreaming, change data capture\u2026 \nMod\u00e9lisation DWH\u202f: DataVault et Dimensionnelle, \nData Warehouse as Service:\u202fSnowflake, BigQuery, Redshift, Azure Synapse\u2026 \nData Virtualisation\u202f: acc\u00e9l\u00e9rer l\u2019acc\u00e8s aux donn\u00e9es, \nNous intervenons autant dans des DSI que dans des direction m\u00e9tiers, dans des modes forfaitaires ou en r\u00e9gie. \nVenez int\u00e9grer notre communaut\u00e9 d'experts Data chez Talan\u202f! \nTalan renforce\u202fsa communaut\u00e9 au sein du p\u00f4le Data pour intervenir sur les diff\u00e9rents projets de nos clients grands comptes. \nNous sommes \u00e0 la recherche d\u2019un Architect Data capable d\u2019accompagner le d\u00e9marrage des projets sur la mise en place d\u2019une\u202fplateforme modern data, d\u00e9finition des solutions \u00e0 mettre en place, dimensionnement, s\u00e9curisation, participer aux avants ventes\u202f: r\u00e9daction, soutenance\u2026 \nLes responsabilit\u00e9s d\u2019un Architect Data comprennent des activit\u00e9s d\u2019expertise, de mentoring - coaching, d\u2019avant-vente et de s\u00e9curisation de projet au forfait. Vous devrez faire preuve d\u2019un \u00e9tat d\u2019esprit \u00e0 la fois innovant, m\u00e9thodique, orient\u00e9 solution (et non probl\u00e8me\u202f!), et communiquant. \nVotre but ultime sera de garantir l\u2019excellence d\u2019une \u00e9quipe de sp\u00e9cialistes, pi\u00e8ce maitresse de la r\u00e9alisation de projets \u00e0 forts enjeux pour nos clients. \nVOTRE ROLE SUR NOS PROJETS:\nEn mission\u202f: analyse des exigences techniques, d\u00e9finition des normes et bonnes pratiques, r\u00e9daction de document d\u2019architecture, aide \u00e0 la mise en place des solutions, s\u00e9curisation des acc\u00e8s, d\u00e9finition des r\u00f4les et acc\u00e8s \nCoacher techniquement les \u00e9quipes \nAvant-vente\u202f: participation aux r\u00e9ponses \u00e0 appel d\u2019offre au forfait \nCommunication\u202f: \u00e9criture d\u2019article, animation d\u2019\u00e9v\u00e8nement \nVeille\u202f: sur les solutions Data, m\u00e9thodologie de datawarehousing, ... \nVOTRE ROLE CHEZ TALAN :\nBenchmark de solutions et conseil aupr\u00e8s de nos clients sur les solutions technologiques \u00e0 adopter, en lien avec leurs besoins \nR\u00e9alisation de POC (Proof Of Concept) \nParticipation \u00e0 des projets internes et partage de connaissances au sein de nos \u00e9quipes \nPartage de connaissances et formations interne \nEnsemble r\u00e9alisons de nouveaux projets Talantueux!!\n Qualifications\nVOTRE PROFIL:\nConnaissance des syst\u00e8mes de f\u00e9d\u00e9rations d\u2019identit\u00e9s, et des m\u00e9canismes d\u2019authentification \nMaitrise des techniques de Data management, de DataViz \nM\u00e9thodologie de conception et de mod\u00e9lisation d\u2019entrep\u00f4t \/ lac de donn\u00e9es \nDesign d\u2019architecture technique et applicative \nBonnes connaissances des technologies Data en g\u00e9n\u00e9rale (stockage, ingestion et transformation de donn\u00e9es, data visualisation, data sharing, API Management, cloud provider\u2026)  \nForce de proposition \nQualit\u00e9 r\u00e9dactionnelle, vulgarisation \nAutonomie, organisation, sens du partage \nExcellente communication \nOrientation m\u00e9tier \nAlors n'attendez plus ! Postulez vite !\nAdditional Information\nAVANTAGES :\nTop 5 du Palmar\u00e8s Great Place to Work \nManagement de proximit\u00e9 par des experts \nOrganisation sous forme de\u202fcommunaut\u00e9s \nUn parcours excellence Agile DevOps \nFinancement de plusieurs certifications officielles \u00e0 l\u2019ann\u00e9e gr\u00e2ce \u00e0 nos partenaires \u00e9diteurs \nUn acc\u00e8s \u00e0 la plateforme CampusTalan avec plus de 1000 formations disponibles d\u00e8s votre arriv\u00e9e \nUne mobilit\u00e9 interne facilit\u00e9e \nUn engagement aupr\u00e8s des travailleurs en situation de handicap \nDes \u00e9v\u00e9nements et afterworks r\u00e9guliers \nSi\u00e8ge parisien situ\u00e9 \u00e0 Charles-De-Gaulle Etoile \nTickets restaurants digitalis\u00e9s \nMutuelle d\u2019entreprise prise en charge \u00e0 100% \nPrime vacances \nPrime de participation \nPrimes de cooptation \nActionnariat \n1% logement \nPartenaire de l'organisme Mobility dans le cadre de l'accompagnement \u00e0 la mobilit\u00e9 et \u00e0 la recherche de logement \nRTT ","84":"At Jamf, people are at the core of everything we do. We do what\u2019s right for our customers, our employees, our communities and our world. We take pride in simplifying technology for tens of thousands of customers around the globe and helping organizations succeed with Apple.\n  Jamf operates as a choice-based office model. Choose to work in the office, connect 100% remote from your home, or find the blend that works best for you.\n SUMMARY\nAt Jamf, we empower people to be their best selves and do their best work. The business Intelligence group at Jamf manages and delivers insights about company data so businesses can make informed decisions. Through the core disciplines of data management and data analytics the team delivers data visualizations and analytics while managing the data infrastructure to support our growing systems at Jamf. The Business Intelligence Data Architect II is an integral member of data management, responsible for ensuring we have the right data architecture to deliver on our vision to democratize data to users and consumers across major business lines. By development of a Business Intelligence and Analytics framework to put accurate and current data to the people who need to make business decisions.\nThe Business Intelligence Data Architect II will collaborate closely with stakeholders, Enterprise Architecture, Data Analysts, Data Engineers, end-users and other members across the company in the design, orchestration, and management of our corporate data within our ecosystem - ensuring our data is secured, governed, and consumed by major business lines at Jamf resulting in a data-driven culture.\nRESPONSIBILITIES\nProvide feasible, efficient, and performant data solutions and implementations for our business.\nCollaborating cross-functionally to define and prioritize requirements for data needed from internal and external sources to support analytics and decision making.\nWork with engineering and analyst teams to capture and delivered required data to the Enterprise Data Platform while meeting multi-dimensional standards for data quality.\nDevelop key performance measures for data integration, quality, and operations.\nBuild a framework of principles to ensure data integrity across the business (including but not limited to ERP, CRM, BI, Data warehouse, external interfaces etc.)\nManage and help build a robust and scalable Data Integration pipeline of the ETL\/ELT process\nUnderstand and document data flow throughout critical business systems\nWork with stakeholder groups on definition of a Unified Data Model that serves as the foundation for the single source of truth for all product, customer and reference data used for BI & analytics.\nUse the best-fit data warehousing methodologies and modeling techniques\nAssists with cloud Infrastructure design best practices, templates, and processes.\nHelp achieve and maintain compliance with regulatory, legal and company standards.\nParticipate an active contributor to how Jamf evolves Data Governance practices and influence the adoption of data standards.\nEnsure that the BI Data Architecture strategy and roadmap is aligned to the business and technology strategies.\nContribute to, participate in, and deliver architectures through architecture reviews.\nAdvocate of data security principles and ensure appropriate security practices are incorporated into solutions\/capabilities.\nMentor\/coach team members in data architecture, engineering and dimensional modelling.\nSKILLS AND EXPERIENCE\nMinimum 3 years of Data Architecture experience including but not limited to:\nExperience in architecting and implementing Business Intelligence and Data warehouse platforms, Master data management and data integration (Required)\nExperience in business intelligence and analytics architecture framework: ability to collect, integrate, and store the data so it is accessible and actionable (Required)\nMinimum 5 years of experience in Logical and Physical data modelling. (Required)\nDemonstrated experience using Agile\/Scrum frameworks and software development workflows (Required)\nAbility to lead technical initiatives, communicate with leadership and guide projects (Required)\nExperience communicating project direction and status with stakeholders (Required)\nComfortable with resolving conflicting viewpoints and achieving agreement (Required)\nExperience coaching teams on modelling\nExperience integrating data governance functions into the data delivery process\nStrong understanding of cloud platforms, databases, and data capabilities to source, integrate, manage, and leverage data\nAbility to understand existing and new technologies and lead their adoption across the enterprise\nEDUCATION & CERTIFICATIONS\n4 Year\/ Bachelor\u2019s degree in Science, Technology, Engineering, Mathematics, or related field (Required)\nA combination of relevant experience and education may be considered \n  At Jamf, people are at the core of everything we do. We do what\u2019s right for our customers, our employees, our communities and our world. We take pride in simplifying technology for tens of thousands of customers around the globe and helping organizations succeed with Apple.\nJamf operates as a choice-based office model. Choose to work in the office, connect 100% remote from your home, or find the blend that works best for you.\n What is a Jamf?\nYou go above and beyond for others, are willing to help, and support the team around you. You value and learn from different perspectives. You are curious and resourceful, a problem-solver, self-driven and constantly improving. You are excited by not knowing what may lie ahead. You are willing to take risks, try new things, even fail just to do it better next time. You\u2019re not a jerk. You are someone who cares about doing the right thing.\n\nWhat does Jamf do?\nJamf extends the legendary Apple experience people enjoy in their personal lives to the workplace. We believe the experience of using a device at work or school should feel the same, and be as secure as, using a personal device. With Jamf, IT and security teams are able to confidently manage and protect Mac, iPad, iPhone and Apple TV devices, easing the burden of updating, deploying and securing the data used by their end-users. Jamf\u2019s purpose is to simplify work by helping organizations manage and secure an Apple experience that end-users love and organizations trust.\n  We are free-thinkers, can-doers and problem crushers with a passion for helping customers empower their workforce to focus on their jobs, not the hassles of managing technology \u2013 freeing nurses to care, teachers to teach and businesses to thrive. We have over 2,500 employees worldwide who are encouraged to bring their whole selves to work each and every day.\n  Get social with us and follow the conversation at #OneJamf\n  #LI-REMOTE","85":"Company Description\nIt all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app, bringing a better way to send, spend, invest, borrow and save to our millions of monthly active users. With a mission to redefine the world's relationship with money by making it more relatable, available and accessible, at Cash App you'll have the opportunity to make a real-world impact with your career.\nToday, Cash App has thousands of employees around the world with a culture geared toward creativity, collaboration and impact. We\u2019ve been a distributed team since day one, and continue to value working across time zones and continents both remotely and in our Cash App offices.\nOur offices are great, but many of our roles can be done remotely from the countries where Block operates. We tailor our experience to champion our employees\u2019 creativity and productivity wherever they are. \nJob Description\nThe BI Team at Cash App enables our teams to make impactful business decisions. Our BI Engineers handle everything from data architecture and modeling to data pipeline tooling and dashboarding. As a Senior BI Engineer at Cash App, you will report to the BI Manager and work with Analysts, Data Scientists, Software Engineers and Product Managers to lay the foundation for analyzing our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, to informing product development. You will build, curate, document, and manage key datasets and ETLs to increase the impact of the entire team.\n\nYou will:\nCreate brand new and optimize existing data models for the most widely used Cash App events, entities, and processes\nStandardize business and product metric definitions in curated and optimized datasets\nBuild pipelines out of our data warehouse\nTeach (and encourage) others to self-serve while building tools that make it simpler and faster for them to do so\nPromote data, analytics, and data model design best practices\nCreate dashboards that help our teams understand the performance of the business and help them make decisions\nQualifications\nYou have:\nBackground\/knowledge in Computer Science, Applied Math, Engineering, Stats, Physics, or a something comparable\n5+ years of industry experience building complex, scalable ETLs for a variety of different business and product use cases\nAn interest in advancing Cash App's vision of building products for economic empowerment - this should be something that legitimately excites you\nTechnologies we use and teach:\nSQL (MySQL, Snowflake, BigQuery, etc.)\nAirflow, Looker and Tableau\nPython and Java\nAdditional Information\nBlock takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate\u2019s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.\n\nZone A: USD $152,100 - USD $185,900\nZone B: USD $144,500 - USD $176,700\nZone C: USD $136,900 - USD $167,300\nZone D: USD $129,300 - USD $158,100\nTo find a location\u2019s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information. \nBenefits include the following:\nHealthcare coverage\nRetirement Plans including company match \nEmployee Stock Purchase Program\nWellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance \nPaid parental and caregiving leave\nPaid time off\nLearning and Development resources\nPaid Life insurance, AD&D. and disability benefits \nPerks such as WFH reimbursements and free access to caregiving, legal, and discounted resources \nThis role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans.\nWe\u2019re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, veteran status, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. \nWe believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible. Want to learn more about what we\u2019re doing to build a workplace that is fair and square? Check out our I+D page. \nAdditionally, we consider qualified applicants with criminal histories for employment on our team, assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.\nBlock, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.","86":"Company Summary:\nTessera Therapeutics is pioneering Gene Writing\u2122\u2014 a new biotechnology designed to offer scientists and clinicians the ability to write small and large therapeutic messages into the genome, thereby curing diseases at their source. Gene Writing holds the potential to become a new category in genetic medicine, building upon recent breakthroughs in gene therapy and gene editing while eliminating important limitations in their reach, utilization, and efficacy. Tessera Therapeutics was founded by Flagship Pioneering, a life sciences innovation enterprise that conceives, resources, and develops first-in-category companies to transform human health and sustainability.\n  Position Summary:\nTessera is seeking a talented and motivated Computational Biologist to join our expanding Data Sciences team.  You will tackle challenging bioinformatics and computational biology problems to advance our understanding of Gene Writing and help accelerate programs to the clinic.  You will contribute scientific, technical, and leadership expertise to a multidisciplinary team, emphasizing conceptualization, experimentation, data analysis, presentation, and strategic planning. \n  Key Responsibilities:\nWork collaboratively with our platform and Biology teams to enable scientific discovery and progression through data analysis, data visualization, and data integration.\nBuild and implement data analysis pipelines and storage solutions for various forms of sequencing primarily related to genotoxicity analysis, including Amplicon sequencing, long-read sequencing, One-seq, and chimeric read analysis.\nDesign computational methods to combine and analyze off-target events, characterize mutations, and disentangle experiment-related features toward new biological hypotheses, providing project support to gene therapy project teams.\nAnalyze human variations and how these variations may alter the genotoxic potential of our elements, onboarding relevant methods and datasets.\nIdentify and acquire relevant public and third-party \u2018omics data and perform integrative data analyses to generate insights that address strategic biological questions critical to Tessera\u2019s core mission.\nDesign and development of pipelines in a cloud environment with a standard software life cycle approach, releasing full documentation, and validation of the methods with statistical benchmarking.\nOperationalize data analysis aspects of relevant molecular assays to maximize the design, build, test cycle for platform and pipeline candidates.\nStructure and store data to enable data reuse, data mining, and machine learning, supporting data standardization and high-level data integration.\nCreate compelling data visualizations and result presentations for internal and external dissemination.\n\n  Basic Qualifications:\nPh.D.\/M.S. in Computational Biology, Bioinformatics, or related quantitative discipline.\n8+ years of industry experience in discovery research.\nProficient with experimental design, data processing, statistical analysis, and bioinformatics analysis\/reporting of next-generation sequencing data.\nExperience analyzing gene therapy, gene editing, in vitro\/vivo assay, genetics, genomics and cell biology data.\nProficient interaction with experimental biologists to provide feedback on raw sequencing data quality.\nStrong grounding in biology or medicine.\nStrong data visualization skills and experience.\nFluency in one or more programming languages with bioinformatics applications (R, Python).\nTrack record of success working in a fast-paced, cross-functional, and rapidly growing organization.\nOutstanding written and verbal communication skills, ability to work with colleagues from diverse scientific backgrounds and cultures.\n  Preferred Qualifications:\nExperience with recent advances in gene therapy and development of gene editing platforms as therapeutics.\nFamiliarity with short and long-read next-generation sequencing platforms (Illumina, PacBio, Nanopore).\nProficiency in handling large-scale sequencing data in a cloud environment (AWS preferred).\nProficiency in statistics and machine learning.\nExperience in virology or mobile genetic elements.\n  More About Flagship Pioneering\nFlagship Pioneering has conceived of and created companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune\u2019s \u201cChange the World\u201d list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies.\nFlagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.\n  Recruitment & Staffing Agencies:  Flagship Pioneering and its affiliated Flagship Lab companies (collectively, \u201cFSP\u201d) do not accept unsolicited resumes from any source other than candidates.  The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering\u2019s internal Talent Acquisition team.   Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto. \n ","87":"Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto \u201cBuilding Success Together\u00ae,\u201d Nisum has grown to over 1,800 professionals across the United States, Chile,Colombia, India, Pakistan and Canada. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today\u2019s world, with immersive and seamless experiences across digital and physical channels.\nWhat You'll Do\nDeep problem-solving skills to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement  \nCompetent in design\/implementation for reliability, availability, scalability, and performance \nDesigning and developing dashboards using Splunk\nWhat You Know\nOverall 5-8 years of experience working with Big Data using Spark\/Scala\nShould be well-versed in Core Java, and Java frameworks\nHas mentored junior software developers on design patterns, development best practices, and DevOps trade-offs\nExperienced with all ancillary technologies necessary for Internet applications: HTTP, TCP\/IP, POP\/SMTP, etc.\nHigh-scalability projects involving cloud-based infrastructure design and implementation\nWorking knowledge of object-oriented design and development skills\nSuccessful track record of developing quality software products and shipping production-ready software\nGood understanding of Web Services protocols such as REST, SOAP, and API design for extensibility and portability\nExperience debugging distributed systems with high data loads\nDeep knowledge of distributed data model\nShould have excellent communication and presentation skills\nShould have experience in AWS: Lambda, EC2.\nKnowledge of AWS EMR or Cloudera is a great plus.\nGood problem-solving and troubleshooting abilities\nAbility to multitask in a fast-changing environment\nShould be involved in working in an onsite\/offshore model\nShould have performed on all the stages of SDLC from Design to System Testing, implementation, and post-implementation\nEducation\nBS degree in computer science, computer engineering or equivalent\nBenefits\nIn addition to competitive salaries and benefits packages, Nisum India offers its employees some unique and fun extras:\nContinuous Learning - Year-round training sessions are offered as part of skill enhancement certifications sponsored by the company on an as need basis. We support our team to excel in their field.\nParental Medical Insurance - Nisum believes our team is the heart of our business and we want to make sure to take care of the heart of theirs. We offer opt-in parental medical insurance in addition to our medical benefits.\nActivities -From the Nisum Premier League's cricket tournaments to hosted Hack-a-thon, Nisum employees can participate in a variety of team building activities such as skits, dances performance in addition to festival celebrations.\nFree Meals - Free snacks and dinner is provided on a daily basis, in addition to subsidized lunch.\nNisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace.","88":"Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto \u201cBuilding Success Together\u00ae,\u201d Nisum has grown to over 1,800 professionals across the United States, Chile,Colombia, India, Pakistan and Canada. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today\u2019s world, with immersive and seamless experiences across digital and physical channels.\nWhat You'll Do\nDeep problem-solving skills to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement  \nCompetent in design\/implementation for reliability, availability, scalability, and performance \nDesigning and developing dashboards using Splunk\nWhat You Know\nOverall 5-8 years of experience working with Big Data using Spark\/Scala\nShould be well-versed in Core Java, and Java frameworks\nHas mentored junior software developers on design patterns, development best practices, and DevOps trade-offs\nExperienced with all ancillary technologies necessary for Internet applications: HTTP, TCP\/IP, POP\/SMTP, etc.\nHigh-scalability projects involving cloud-based infrastructure design and implementation\nWorking knowledge of object-oriented design and development skills\nSuccessful track record of developing quality software products and shipping production-ready software\nGood understanding of Web Services protocols such as REST, SOAP, and API design for extensibility and portability\nExperience debugging distributed systems with high data loads\nDeep knowledge of distributed data model\nShould have excellent communication and presentation skills\nShould have experience in AWS: Lambda, EC2.\nKnowledge of AWS EMR or Cloudera is a great plus.\nGood problem-solving and troubleshooting abilities\nAbility to multitask in a fast-changing environment\nShould be involved in working in an onsite\/offshore model\nShould have performed on all the stages of SDLC from Design to System Testing, implementation, and post-implementation\nEducation\nBS degree in computer science, computer engineering or equivalent\nBenefits\nIn addition to competitive salaries and benefits packages, Nisum India offers its employees some unique and fun extras:\nContinuous Learning - Year-round training sessions are offered as part of skill enhancement certifications sponsored by the company on an as need basis. We support our team to excel in their field.\nParental Medical Insurance - Nisum believes our team is the heart of our business and we want to make sure to take care of the heart of theirs. We offer opt-in parental medical insurance in addition to our medical benefits.\nActivities -From the Nisum Premier League's cricket tournaments to hosted Hack-a-thon, Nisum employees can participate in a variety of team building activities such as skits, dances performance in addition to festival celebrations.\nFree Meals - Free snacks and dinner is provided on a daily basis, in addition to subsidized lunch.\nNisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace.","89":"Company Description\nWe\u2019re a seven-time \u201cBest Company to Work For,\u201d where intelligent, talented people come together to do outstanding work\u2014and have a lot of fun while they\u2019re at it. Because we\u2019re a full-service consulting firm with a diverse client base, you can count on a steady stream of opportunities to work with cutting-edge technologies on projects that make a real difference.\nLogic20\/20's Global Delivery Model creates a connected experience for Logicians across geographies. You'll have access to projects in different locations, the technology to support Connected Teams, and in-person and online culture events in our Connected Hub cities.\nJob Description\nBring your skillset to an exciting and meaningful initiative where we are leveraging data science, artificial intelligence, and machine learning to mitigate wildfires. By proactively identifying and addressing issues with power lines and related equipment, we\u2019re increasing safety, saving lives, and protecting the environment. This is a highly visible, highly impactful project with implications for millions of customers.\nAs a Big\u202fData Engineer, you\u2019ll join our Data Management team to design and develop scalable data processing infrastructure. Applying an Agile approach, you\u2019ll work closely with our team of analysts, technical product owners, and data scientists to provide the structure for a highly anticipated solution. You\u2019ll leverage your balance of\u202ftechnical skills\u202fand business acumen to\u202fhelp the client better understand\u202ftheir core needs and technical capabilities. Your efforts will result in greater protection for the community and our environment, long-term.\nHear more about these efforts as Jeff Lovington shares his experience working in Data Science and Machine Learning for the Energy & Utilities sector.\nAbout the team\nThe Logic20\/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it\u2019s all in a day\u2019s work. As part of our team, you\u2019ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you\u2019re ready to level up in your career, you\u2019ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.\n\u201cWe build an environment where we really operate as one team, building up each other\u2019s careers and capabilities.\u201d \u2013 Adam Cornille, Director, Advanced Analytics\nAbout you\nYou are collaborative, working with partners to understand business needs and pain points\nYou are determined and able to manage obstacles while maintaining a positive outlook\nYou are patient and savvy in explaining technical benefits and deficits to non-technical audiences\nYou have a passion for learning new data tools and best practices\nYou have built large-scale machine learning pipelines, quickly developing and iterating solutions\nQualifications\nMust have 3+ years of implementation experience using PySpark\n5+ years of data engineering experience\nStrong understanding of high-performance ETL development with Python\nExperience with Big Data Technologies (Hadoop, Spark, MongoDB)\nExperience designing and developing cloud ELT and date pipeline with various technologies such as Python, Spark, PySpark, SparkSQL, Airflow, Talend, Matillion, DBT, and\/or Fivetran\nDemonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule\nPreferred\nExperience with Palantir\u2019s Foundry and LiDAR\nIdeal, but not required\nAn undergraduate degree in technology or business\nAgile, Scrum, and\/or SAFe experience and certifications\nExperience building data and computational systems that support machine learning\nKnowledge of AWS services\nExperience with modern software delivery practices, including source control, testing, and continuous delivery\nExperience with streaming data in Spark\nAdditional Information\nAll your information will be kept confidential according to EEO guidelines.\nCompensation range: $130,000 - $162,500 annually\nAbout Logic20\/20 \nTo learn more about Logic20\/20, please visit: https:\/\/www.logic2020.com\/careers\/life-at-logic  \nCore Values \nAt Logic20\/20, we are guided by three core values: Drive toward Excellence, Act with Integrity & Foster a Culture of We. These values were generated and agreed upon by our employees\u2014and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https:\/\/www.logic2020.com\/company\/our-values. \nLogic20\/20 Benefits\nWhy Logic20\/20? It\u2019s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k). \nYou will have \nCareer Development \u2013 A built-in program from day 1, providing a mentor and individually-directed training opportunities, plus access to leaders across the company \nPTO, Paid Holidays, & Voluntary Leave \u2013 Worry-free time off to recharge and pursue your personal goals \nCommunity & Committees \u2013 As part of our \u201cCulture of We,\u201d Logic20\/20 invests in providing many social, interest, and learning opportunities \nRecognition \u2013 From peer recognition, swag, and the chance to win a once-in-a-lifetime type of award, we make your Logic20\/20 journey stand out \nReferral Programs & Bonuses \u2013 Employee, project, and sales referral programs with paid incentives  \nEqual Opportunity Statement \nWe believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and\/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law. \nTo learn more about our DE&I initiatives, please visit: https:\/\/www.logic2020.com\/company\/diversity-equity-inclusion  \nPrivacy Policy \nDuring the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy. ","90":"Every day, tens of millions of people come to Roblox to explore, create, play, learn, and connect with friends in 3D immersive digital experiences\u2013 all created by our global community of developers and creators. \nAt Roblox, we\u2019re building the tools and platform that empower our community to bring any experience that they can imagine to life. Our vision is to reimagine the way people come together, from anywhere in the world, and on any device. We\u2019re on a mission to connect a billion people with optimism and civility, and looking for amazing talent to help us get there. \nA career at Roblox means you\u2019ll be working to shape the future of human interaction, solving unique technical challenges at scale, and helping to create safer, more civil shared experiences for everyone.\nWork with the most passionate and team-oriented people you'll ever meet. As a Big Data Software Engineer, you will be a key participant in helping our Data Infrastructure team shape the future of Roblox. You will report into the Engineering Manager of our Data Infrastructure Team. If you know what it takes to develop large-scale infrastructure to Analyze user behavior from 200 million monthly users , you'll fit right into our accomplished and ever-expanding engineering team.\nYou Will:\nHave primary responsibility in building the massive horizontally scalable streaming and ingestion services that feed not only our Data Lake, Data Warehouse but also business critical applications.\nOwn design, implementation, testing, and support of next-generation features related to scalability, reliability, robustness, usability, security, and performance of Roblox Core Data Pipeline.\nWork with our software stack such as: Kafka , Spark or Flink - the engines upon which we are building our next-generation streaming pipelines for Roblox scale.\nBe a part of a collaborative team: The Data Infrastructure Team and the Analytics Team are combined at Roblox to ensure that data processing and analytics are guided by the user needs -- ie. query patterns and product requirements.\nDesign Structures: For compact encoding of data for in-memory storage to enable in-stream computation-message fidelity from source to target: preserving message ordering guarantees across all nodes in the cluster.\nWork with our stakeholders to push innovation across Roblox.\nYou Have:\n8+ years of experience with different real-time data streaming technologies tools such as Kafka, Spark, Beam, Samza or Flink.\nExperience in Java and\/or Go at scale.\nFor roles that are based at our headquarters in San Mateo, CA: The starting base pay for this position is as shown below. The actual base pay is dependent upon a variety of job-related factors such as professional background, training, work experience, location, business needs and market demand. Therefore, in some circumstances, the actual salary could fall outside of this expected range. This pay range is subject to change and may be modified in the future.  All full-time employees are also eligible for equity compensation and for benefits.Annual Salary Range$283,780\u2014$331,640 USD\nYou\u2019ll Love: \nIndustry-leading compensation package\nExcellent medical, dental, and vision coverage\nA rewarding 401k program\nFlexible vacation policy\nRoflex - Flexible and supportive work policy \nRoblox Admin badge for your avatar\nAt Roblox HQ: \nFree catered lunches five times a week and several fully stocked kitchens with unlimited snacks\nOnsite fitness center and fitness program credit\nAnnual CalTrain Go Pass\nRoblox provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.","91":"Company Description\nVericast is a premier marketing solutions company that accelerates profitable revenue growth for the thousands of businesses it serves directly by influencing consumer purchasing and transaction behavior at scale while engaging with over 120 million households daily.  We are recognized as leading providers of incentives, advertising, marketing services, transaction solutions, customer data and cross-channel campaign management, and intelligent media delivery that create millions of customer touch points annually for their clients.  For more information, visit http:\/\/www.vericast.com or follow Vericast on LinkedIn.\nJob Description\nValassis Digital (a division of Vericast) is seeking a Principal Software Engineer to develop services, tools, bots, and workflows for our big data processing infrastructure.\nThe Big Data Platform Team owns and operates the world-class big data processing infrastructure that over a dozen engineering teams use to power their 24\/7 technical marketing products. We own and operate a large hadoop+spark processing cloud on which we store 6PB of data, and run 30 thousand jobs every day. We write a fabric of java microservices and bots to manage all those jobs, extend hadoop's functionality, and help us operate and optimize our investment. We write custom data streaming services that ingest and curate 100TB of data each day that drives the entire advertising data ecosystem. We also participate in all our users' groundbreaking workflow projects so that we can constantly stay abreast of our developer's tooling needs.\nWhat you're like:\nThis position is perfect for a far-sighted engineer who always wants to be the first to apply cutting-edge technologies to solve complex business and engineering problems. You want to have a leading voice on our team and across our organization. You will work throughout the software lifecycle including customer interaction and product planning, requirements analysis, architecture, directing our team of developers, development, testing and operations. If you are energized by the thought of developing new system stacks and tools for big data processing and analytics we want to talk to you. If you have worked on big data engineering, cloud migration, or infrastructure tooling projects, we want to talk to you. If you have ever worked on a collection of data workflows or a service mesh and thought 'I could make this better', we want to talk to you!\nWhat you'll do:\nWork with our users, architects, and product leaders to architect and plan our data platforms\nDesign, develop, and maintain the software and systems that make up the data platform that runs our entire business\nPartner with the Data Engineering and Data Science teams who use our platform to diagnose, predict and address scaling problems\nWork on new products initiatives to provide design support and establish best practices\nContribute to our team\u2019s growing set of development platforms, tools, processes, and products\nQualifications\nExperience working on big data systems and technologies with emphasis on the Hadoop platform\nGeneral knowledge of design patterns & UML with a few years of taking a lead on architectural design and development\nProficiency in Java, Scala, or Python programming; exposure to microservices and Spark dataframe programming.\nProficiency in networking, Thrift, Spring Framework and\/or Spring Boot for microservices is a plus. \nUnderstand RDMS and proficiency in DML, SQL & PL\/SQL a plus\nHands on experience with Spark; exposure to Kafka and YARN or similar technologies\nExperience with migration of infrastructure from on-prem to cloud or vice versa is a big advantage\nCuriosity to learn and apply new technologies and a background full of diverse design challenges\nExcellent problem-solving abilities\nExcellent verbal, graphical, and written communication skills\nExperience with agile development methodologies\n\nYour qualifications:\nBS\/MS in Computer Science or other technical discipline (with significant computer coursework)\n10+ recent years of professional software development experience using java, scala, or python\n3+ recent years working with the hadoop+spark big data platform or similar\nAdditional Information\nSalary:  180,000-200,000 with 10% bonus opportunity\nThe ultimate compensation offered for the position will depend upon several factors such as skill level, cost of living, experience, and responsibilities.\nVericast offers a generous total rewards benefits package that includes medical, dental and vision coverage, 401K and flexible PTO. A wide variety of additional benefits like life insurance, employee assistance and pet insurance are also available, not to mention smart and friendly coworkers!\nAt Vericast, we don\u2019t just accept differences - we celebrate them, we support them, and we thrive on them for the benefit of our employees, our clients, and our community.\u202fAs an Equal Opportunity employer, Vericast considers applicants for all positions without regard to race, color, creed, religion, national origin or ancestry, sex, sexual orientation, gender identity, age, disability, genetic information, veteran status, or any other classifications protected by law. Applicants who have disabilities may request that accommodations be made in order to complete the selection process by contacting our Talent Acquisition team at talentacquisition@vericast.com. EEO is the law. To review your rights under Equal Employment Opportunity please visit: www.dol.gov\/ofccp\/regs\/compliance\/posters\/pdf\/eeopost.pdf.\n#LI-TE1\n#LI-Remote","92":"Company Description\nWe\u2019re the world\u2019s leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business.\nJob Description\nOVERVIEW:\nMake the team that changes the way the world experiences sport.\nSportradar is the leading global provider of sports betting and sports entertainment products and services. Since 2001, we have occupied a unique position at the intersection of the sports, media and betting industries; providing sports federations, news media, consumer platforms and sports betting operators with a range of solutions to help grow their business.\n Managed Trading Services\u202f(MTS) is a holistic solution that enables Wagering Operators to future-proof their business by offering services such as risk management and advanced marketing tools. The Operational Account Management Team, (which sits within MTS) performs an important role by acting as the main point of contact between our growing client base and Sportradar. Subsequently, we\u2019re looking for a dedicated, Business Intelligence Analyst for our OAM department who will support our unit by developing interactive analytical applications, scheduled customer reports and ad hoc customer report requests. The Business Intelligence Analyst will also recommend and implement improvements into our reporting processes that will allow us to automate specific requests coming from our client base.\n THE CHALLENGE:\nDeliver state-of-the-art data analytics and reporting solutions leveraging our data.\nDevelopment of data visualizations and reports using statistical packages for analyzing datasets (Excel, PowerBI)\nPeriodic reporting: automatic setup and distribution of reports\nPresent ideas and solutions to business users and software developers in a clear and understandable way.\nPropose new, innovative ways of using data to improve our products and services\nParticipate in Data modelling for reporting and analytics.\nCo-create and deliver an ambitious business intelligence roadmap in close coordination with various business and technical stakeholders in the Sportradar\n YOUR PROFILE:\nDemonstrated technical expertise in the following areas: business intelligence tools, design & development of data analytics solutions and reports, querying databases.\nPrior experience working on projects related to data management and\/or business intelligence.\nThe successful candidate will be practiced in hands-on development of software or analytics solutions. Knowledge of VBA beneficial.\nComfortable presenting to Senior OAM Management with good verbal and written communication skills\nExperience working with Amazon Redshift, Amazon Athena and\/or Microsoft SQL Server are a benefit as is knowledge of Qlik View\/Qlik Sense, Qlik NPrinting,\nNB: Must have previous experience working in the sports betting industry.\n Sportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences.\n Additional Information\nSportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences ","93":"Company Description\nAt ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can\u2019t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. \nWith more than 7,400+ customers, we serve approximately 80% of the Fortune 500, and we're proud to be one of FORTUNE's 100 Best Companies to Work For\u00ae and World's Most Admired Companies\u00ae 2022.\nLearn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.\nUnsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.\nJob Description\nYou will be part of the ServiceNow Cloud Services Big Data Team.  The Big Data team is building the next-generation platform that collects, stores and provides real-time access to large amounts of data.\nYou will be driving the design and implementation of ServiceNow in-house real-time data visualization and analytics platform to support the growth of ServiceNow.\n What you get to do in this role:\nBring your innovation and experience in designing and developing the next generation data analytics platform using cutting-edge technologies. \nLead a global engineering team to drive end to end product design and implementation. \nStandardize processes for complete development cycle including design, implementation, unit testing, code review, testing automation etc. \nResearch and adopt the right technologies to improve the scalability and productivity of the engineering group. \nWork closely with key stakeholders and product owners to drive technical design for requirements of various use cases. \nCoordinate with cross-function teams (DevOps, network, QA, etc.) to ensure a smooth cycle from development to deployment.\nQualifications\nTo be successful in this role you have:\nHands-on experience architecting enterprise data analytics products with high scalability and performance.\n6+ years of software development experience along with strong troubleshooting and debugging skills.\nExpert level skills with JavaScript, NodeJS, Webpack, ReactJS or other modern UI frameworks, Java and REST API developments.\nBackground with data analytics, data visualization, BI tools and Hadoop ecosystem.\nAbility to produce high-quality software that is unit tested, code reviewed, and checked in regularly for continuous integration.\nSolid background in complicated SQL & data analytics.\nZeal for learning and adopting new ideas and patterns.\nStrong Computer Science fundamentals,  data structures, algorithms, and software design.\nAdditional Information\nServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.\nAt ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.\nIf you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.\nFor positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.\nPlease Note: Fraudulent job postings\/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.\n From Fortune. \u00a9 2022 Fortune Media IP Limited All rights reserved. Used under license.\nFortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","94":"Company at a GlanceOpenX is focused on unleashing the full economic potential of digital media companies. We do this by making digital advertising markets and technologies that are designed to deliver optimal value to publishers and advertisers on every ad served across all screens.\nAt OpenX, we have built a team that is uniquely experienced in designing and operating high-scale ad marketplaces, and we are constantly on the lookout for thoughtful, creative executors who are as fascinated as we are about finding new ways to apply a blend of market design, technical innovation, operational excellence, and empathetic partner service to the frontiers of digital advertising.\nWe are operating at a scale:100% Cloud-based (GCP) platformsOver 250 billion Ad requests every dayOver 120,000 CPU dailyOver 140 TB RAM dailyOver 50 PB of data per weekOver 1200 production deployments a month\nWho we are looking forOpenX is looking for a talented and highly motivated  Software Engineer  to help us innovate and improve our products. You will work in all aspects of agile application development, including both front-end and back-end systems. You will collaborate to design products that customers love and set OpenX apart.\nIf you're:- Open-minded - happy to give & receive feedback, not afraid to fail and move on- Proactive - always want to find a satisfying solution- Self-organized and self-motivated\nWe want to talk to you.\n\nThe OpportunityYou will work in all aspects of agile application development, including our enterprise platform that interfaces with a multitude of services that are dependent on to deliver billions of requests per day. Your opinions will be important in all phases of product development, starting from requirements to validation and deployment.Working on the enterprise platform, you will be working with multiple distributed teams to architect, create, and deliver new features and functionality in order to deliver the best possible advertising experience in the market. Scalability, performance, and rock-solid reliability are all factors to consider with every line you code.\nThe Team and Project:You will be part of the core data development team. Our exchange handles billions of ad requests daily connecting thousands of publishers with demand partners. Each request produces data events that have to be processed to extract business value from them. Daily our applications produce more than 1PB of data.Please note: all interview stages are run remotely \nWhat we offer\nWorking with the newest technologies such as Cloud Computing (GCP)\nExperienced Team (50% of the company are senior developers!)\nChallenges at work that are difficult to find anywhere else!\nSolving important problems in a scale\nJoining a company that is growing and scaling\nFlexible working hours & hybrid work option (we would like you to come to the office once every two weeks)\nKey responsibilites\nDesign large-scale data processing systems\nWork with Product to drive the requirements, and own the project end-to-end\nAnalyze and improve efficiency, scalability, and stability of applications\nThink long-term and be unsatisfied with band-aids\nIdentify unnecessary complexity and remove it\nRequired Qualifications\nIdeally 5+ years of experience in Java development for large-scale Hadoop environments including performance tuning and monitoring\nExpertise using an appropriate mix of applications in the big data ecosystem (Kafka, Spark, Hadoop MapReduce, Hive, YARN, Zookeeper, HBase, and other NoSql products)\nExperience with databases system design, RDBMs, and\/or NoSQL\nCloud experience with Google Cloud Platform or AWS, k8s, and Docker\nFluently speak algorithms, data structures, and platforms (Linux)\nCommunicative Polish and English\nDesired qualifications\/characteristics:\nBe comfortable using the right tools and languages for the job, even brand-new ones\nHave the ability to develop scalable, modular applications\nSCRUM \/ Agile environment experience\nExperience working in digital media, marketing technology, or advertising technology is a big plus\nGood written & oral communication skills\nGood sense of humor\nTeam player\nSelf-starter with the ability to independently identify and act on areas of improvement\nOur benefits\nAnnual performance bonus\nTax-deductible system due to copyright protection \nPrivate health care for you and your family (covered by OpenX)\nPrivate life and travel insurance (Covid insurance included)\nMultiKafeteria program \nTraining: access to the LinkedIn Learning platform, Tech workshops, English lessons\nHoliday Allowance\nPension scheme (PPK from PZU)\nAdditional paid day off \nFree parking lot \nAccess to peer to peer recognition platform\nMonthly work-from-home allowance and one-time payment when you join us to help you set up your home office\nWe celebrate team members' important personal milestones (vouchers, gifts)\nOpenX VALUESOur five company values form a solid bedrock serving to define us as a group and guide the company. Our values remind us that how we do things often matters as much as what we do.\nWE ARE ONEWe are one team. There are no exceptions. We are a group of strong and diverse individuals unified by a shared mission. We embrace challenges and win together as a team. We respect and care about our colleagues and cultivate an inclusive culture\nWE ARE CUSTOMER CENTRICWe innovate on behalf of our customers. We understand, respect, and listen carefully to our customers. We build great products to solve our customers\u2019 problems. We manage our customers\u2019 expectations clearly and honestly. We are a trusted partner to all of our customers - we act with integrity at all times. We care.\nOPENX IS OURSWe innovate on behalf of our customers. We understand, respect, and listen carefully to our customers. We build great products to solve our customers\u2019 problems. We manage our customers\u2019 expectations clearly and honestly. We are a trusted partner to all of our customers - we act with integrity at all times. We care.\nWE ARE AN OPEN BOOKWe understand and respect what each of us does. We are eager to teach and share what we know with others, both internally and externally. We are eager to learn from others and we ask questions internally and externally. \nWE EVOLVE FASTWe take responsible risks and own and learn from our mistakes. We recognize and repeat success. We actively seek out and provide constructive feedback. We adapt quickly and embrace change. We tackle growth and learning with real urgency. We are endlessly curious.\nOpenX is committed to equal employment opportunities. It is a fundamental principle at OpenX not to discriminate against employees or applicants for employment on any legally-recognized basis including, but not limited to: age, race, creed, color, religion, national origin, sexual orientation, sex, disability, predisposing genetic characteristics, genetic information, military or veteran status, marital status, gender identity\/transgender status, pregnancy, childbirth or related medical condition, and other protected characteristic as established by law.\nOpenX Applicant Privacy PolicyApplicants can review our Applicant Privacy Policy at any time by visiting the following link: https:\/\/www.openx.com\/privacy-center\/applicant-privacy-policy\/.\nEffective Date: March 1, 2022","95":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to Know our Team: \nPartner Development is a team of creative entrepreneurs that develop solutions for Agoda\u2019s accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.\nIn this role you'll get to\nAs a Data Analyst in the PD Analytics team, you will be using data and modeling techniques to identify opportunities and build models and tools to improve efficiency and effectiveness for Agoda's supply team. \nKey activities involved include but not limit to:\nApply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations\nOwn end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development\nBuild dashboards, identify new and track key metrics to closely monitor team\u2019s performance and identify quick and long term opportunities for improvements\nWork closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified\nSupport global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization\nWhat you'll need to succeed \nBachelor\u2019s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline\n3-6 years experience working in a business analysis, data analysis, reporting or business strategy role\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\nCoding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\nData visualization tool experience such as with Tableau or your weapon of choice.\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","96":"Company Summary:\nTessera Therapeutics is pioneering Gene Writing\u2122\u2014 a new biotechnology designed to offer scientists and clinicians the ability to write small and large therapeutic messages into the genome, thereby curing diseases at their source. Gene Writing holds the potential to become a new category in genetic medicine, building upon recent breakthroughs in gene therapy and gene editing while eliminating important limitations in their reach, utilization, and efficacy. Tessera Therapeutics was founded by Flagship Pioneering, a life sciences innovation enterprise that conceives, resources, and develops first-in-category companies to transform human health and sustainability.\n  Position Summary:\nTessera is seeking a talented and motivated Computational Biologist to join our expanding Data Sciences team.  You will tackle challenging bioinformatics and computational biology problems to advance our understanding of Gene Writing and help accelerate programs to the clinic.  You will contribute scientific, technical, and leadership expertise to a multidisciplinary team, emphasizing conceptualization, experimentation, data analysis, presentation, and strategic planning. \n  Key Responsibilities:\nWork collaboratively with our platform and Biology teams to enable scientific discovery and progression through data analysis, data visualization, and data integration.\nBuild and implement data analysis pipelines and storage solutions for various forms of sequencing primarily related to genotoxicity analysis, including Amplicon sequencing, long-read sequencing, One-seq, and chimeric read analysis.\nDesign computational methods to combine and analyze off-target events, characterize mutations, and disentangle experiment-related features toward new biological hypotheses, providing project support to gene therapy project teams.\nAnalyze human variations and how these variations may alter the genotoxic potential of our elements, onboarding relevant methods and datasets.\nIdentify and acquire relevant public and third-party \u2018omics data and perform integrative data analyses to generate insights that address strategic biological questions critical to Tessera\u2019s core mission.\nDesign and development of pipelines in a cloud environment with a standard software life cycle approach, releasing full documentation, and validation of the methods with statistical benchmarking.\nOperationalize data analysis aspects of relevant molecular assays to maximize the design, build, test cycle for platform and pipeline candidates.\nStructure and store data to enable data reuse, data mining, and machine learning, supporting data standardization and high-level data integration.\nCreate compelling data visualizations and result presentations for internal and external dissemination.\n  Basic Qualifications:\nPh.D.\/M.S. in Computational Biology, Bioinformatics, or related quantitative discipline.\n8+ years of industry experience in discovery research.\nProficient with experimental design, data processing, statistical analysis, and bioinformatics analysis\/reporting of next-generation sequencing data.\nExperience analyzing gene therapy, gene editing, in vitro\/vivo assay, genetics, genomics and cell biology data.\nProficient interaction with experimental biologists to provide feedback on raw sequencing data quality.\nStrong grounding in biology or medicine.\nStrong data visualization skills and experience.\nFluency in one or more programming languages with bioinformatics applications (R, Python).\nTrack record of success working in a fast-paced, cross-functional, and rapidly growing organization.\nOutstanding written and verbal communication skills, ability to work with colleagues from diverse scientific backgrounds and cultures.\n  Preferred Qualifications:\nExperience with recent advances in gene therapy and development of gene editing platforms as therapeutics.\nFamiliarity with short and long-read next-generation sequencing platforms (Illumina, PacBio, Nanopore).\nProficiency in handling large-scale sequencing data in a cloud environment (AWS preferred).\nProficiency in statistics and machine learning.\nExperience in virology or mobile genetic elements.\nMore About Flagship Pioneering\nFlagship Pioneering has conceived of and created companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune\u2019s \u201cChange the World\u201d list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies.\nFlagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.\nRecruitment & Staffing Agencies:  Flagship Pioneering and its affiliated Flagship Lab companies (collectively, \u201cFSP\u201d) do not accept unsolicited resumes from any source other than candidates.  The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering\u2019s internal Talent Acquisition team.   Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto. \n ","97":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nOverview:\nThe Agoda Content department is currently looking for a curious and questioning self-starter and proactive analyst, who will help drive decision making with insights from content, marketing and partner performance data.\nYou will get the opportunity to own analytical projects to direct our department\u2019s focus, and prioritize our actions. By joining Agoda, you will become part of a truly international team, with leading experts of different backgrounds coming from 50+ countries around the world. This is a genuine opportunity to gain valuable experience in a challenging and cutting-edge tech environment. The ideal candidate would have a passion for high-converting content, great user-experience, data and analysis tools and methods. This position reports to the Associate Director of Content Operations, in Bangkok, Thailand.\n  Main responsibilities:\nUnderstand Content goals and KPIs and be able to align reports and insights based on them. Identify and investigate trends, anomalies and opportunities to improve Agoda\u2019s Content strategy.\nIdentify content opportunities that drive customer value, bookings and conversion\nHelp build business cases around the opportunity and get buy-in from stakeholders\nEnsure appropriate data\/tools\/dashboards to measure execution and enable deeper analysis\nTrack execution and report up in regular updates\nWork with product, data\/BI team and IT to create data resources and build appropriate reporting\nWork with Content team leads to understand their business needs and identify opportunities in terms of team actions prioritization and focus.\nUse multiple data sources to report Content projects insights and impact; support Content tests and experiments.\nEncourage and train the Content team in best practice use of Agoda data, analysis techniques and interpretation.\nCoordinate with other Cross Functional departments like Analytics, Partner Services, and Product Owners\nUse Web-Analytics for Research and Analysis\nRequirements:\nBachelor degree or higher\n2+ years of relevant experience\nExperience \/ knowledge in statistics, SQL, Python\/R, Tableau and advanced Excel \u2013 required\nAbility to demonstrate data manipulation using data warehouse and create meaningful insight and visualization\nExperience \/ knowledge in Vertica and \/ or Impala \u2013 advantage\nExperience in generating data and \/ or preparing experiments for product development \u2013 advantage\nProfessional characteristics:\nAttentive to detail and committed to data integrity\nKeen and curious nature; able and willing to share your opinion\nOrganized; able to manage multiple, competing priorities and deliver results under tight deadlines\nAble to communicate effectively; fluent in English \u2013 both spoken and written\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","98":"Who We Are\nVerily is a subsidiary of Alphabet that is using a data-driven approach to change the way people manage their health and the way healthcare is delivered. Launched from Google X in 2015, Our purpose is to bring the promise of precision health to everyone, every day. We are focused on generating and activating data from a variety of sources, including clinical, social, behavioral and the real world, to arrive at the best solutions for a person based on a comprehensive view of the evidence. Our unique expertise and capabilities in technology, data science and healthcare enable the entire healthcare ecosystem to drive better health outcomes.\nVerily\u2019s internship is a paid 13 week program for rising seniors, either undergraduate or graduate students, who are interested in working at the intersection of technology, data science and healthcare. The program is designed for Computer Science and Data Science students, and again this year we encourage students who have been historically underrepresented in this field to explore the program, which is a pathway towards full-time employment within Verily. This includes but is not limited to: women, Black\/African-American, Latine\/Hispanic, Native American, people with disabilities, veterans, and members of the LGBTQ+ community.\nDescription\nOur Data Science group specializes in analyzing and building models to help make sense of large datasets resulting from bio-sensors, digital pathology, clinical informatics, molecular assays and patient surveys. We combine domain knowledge and programming expertise with statistical and machine learning knowledge to build scalable models and solutions that help power Verily\u2019s various product areas. For this position, we are looking for interns with experience and interest in computational biology.\nAs a Data Scientist intern working on Computational Biology, you will be joining a team making use of diverse \u2018omics data to improve biomarker and target discovery in different disease settings. You will help develop and implement methods to analyze and derive insights from large, disease-focused datasets from the Immune Profiler platform.\n**Join us for a unique 13 week internship that will take place May 15th to August 11th 2023 OR June 19th to September 15th 2023.\n  Responsibilities\nDevelop performant and reusable models and libraries from original architecture.\nReview literature related to the project area and integrate relevant domain knowledge.\nAnalyze complex \u2018omics data sets in combination with clinical and other data.\nCommunicate technical results and methods to cross-functional teams.\nQualifications\nMinimum Qualifications\nCurrently enrolled as a full-time student in a PhD program in a quantitative discipline (e.g., Computational Biology, Bioinformatics, Statistical Genetics, Computer Science, or related) with an anticipated graduation date at or before the end of 2024. \nAuthorization to work in the United States.\nExpertise in statistical data analysis, modeling, machine learning, and exploratory data analysis.\nProgramming experience in R. \nPreferred Qualifications\nExperience working with clinical study data in any disease setting.\nFamiliarity with software engineering practices and experience developing production software.\nProgramming experience in SQL and\/or bash. \nOutstanding oral and written communication and teamwork.\n  The US base pay range for this intern position is $50.48-$61.06. Our pay ranges are determined by role, education level, experience, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire pay ranges for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific pay range for your preferred location during the hiring process.\n  Why Join Us\nBuild What\u2019s Vital.\nAt Verily, you are a part of something bigger. We are a diverse team of builders innovating at the intersection of health and technology\u2014united by a shared spirit of curiosity, resilience and determination to make better health possible for all. This builder mindset means your fingerprints will be on the work that shapes the future of health. Fulfilling our precision health purpose starts with the health of our Veeps (what we call our employees), which is why we offer flexibility, resources, and competitive benefits to support you in your whole-person well being. We believe diversity of thought drives innovation\u2014we unite the brightest minds, and encourage all Veeps to bring their lived experience to work with them.\nIf this sounds exciting to you, we would love to hear from you.\nYou can find out more about our company culture on our LinkedIn Company Page and Verily Careers page.","99":"We are Kaizen Gaming\nKaizen Gaming is the leading GameTech company in Greece and one of the fastest-growing in Europe, with the Stoiximan brand in Greece and Cyprus and Betano in Germany, Romania, Bulgaria, Czech Republic, Portugal, Brazil, Chile, Peru, Ecuador and Canada. Our aim is to leverage cutting-edge Technology in order to provide the optimum experience to those who trust us for their entertainment.\nThe Role\nWe\u2019re looking for a Reporting Principal Engineer to join our Big Data reporting team, who will help teams devise elegant and performant solutions in response to real business problems, guide them in designing and implementing these solutions in code, as well as teach coding, testing, and performance analysis techniques, while also carrying out code reviews. Will frequently attend teams' scrum events (esp. refinements) and help teams' product owners shape a better understanding of the technical challenges involved. Production problems are usually escalated to Principal Engineer for triaging before landing in a team's backlog. Principal Engineers should also stay up to date on the latest technologies and drive their adoption.\n  The Team\nOur Big Data reporting team(s) consists of twelve members with diverse backgrounds and expertise in several fields including, but not limited to, Databricks\/ Delta lake\/ SQL Server\/ Azure Data Warehouse\/ SSRS\/ SSIS.\n  Responsibilities\nLead team enablement initiatives;\nOrchestrate the plan by motivating other team members and collaborating closely in achieving it;\nBreak the efforts down and work closely by guiding the reporting engineers through gaps to lead them to sound technical solutions;\nTechnical expertise and knowledge sharing. Present practices, innovations, and inventions inside and outside of the organization;\nPartner with management to find new potential talent;\nMentor engineers to take them to the next level of their careers;\nSet up cross-organization engineering best practice standards and guidelines. Create a culture where the contribution patterns and quality are paramount. They partner closely with teams to implement them.\n  Requirements\nMust have:\n8+ years of hands-on experience in writing complex, highly optimized SQL code for data manipulation and reporting;\n5+ years of experience in ETL\/ELT, Data Modeling, Data Warehouse Architecture and Reporting tools;\nKnowledge of Data Governance;\nTeam player, analytical thinker and problem solver, with ability to self-organize;\nFast learner - you will need to get up to speed on business, people and teams, infrastructure and the technologies used, as quickly as possible.\nNice to have:\nA bachelor's degree in a quantitative\/technical field (e.g. Computer Science, Statistics, Engineering) or equivalent industry experience;\nExperience in the Microsoft BI stack (SQL Server, SSRS, SSAS);\nExperience with Azure Data platforms such as Synapse Analytics, Data Lake, Databricks; \nExperience in programming languages preferable in Python or Scala;\nExposure to CI\/CD;\nExposure to an Agile team-working environment.\n  Kaizen Gaming Perks\n\ud83d\udd51 Work from home & remote working options.\n\ud83c\udfc3 A buddy will support you with your onboarding.\n\ud83d\udcb8Competitive salary package and bonus scheme.\n\ud83d\udc69\u200d\u2695\ufe0f Health and life insurance for you and your family.\n\ud83d\udcb0 Monthly allowance for lunch & commuting expenses.\n\ud83d\udcbbNice rigs - 2.5K monitor, latest i7, tons of RAM, fast SSD.\n\ud83d\udcda Pluralsight, unlimited access to Udemy & continuous training for all your learning and development needs.\n\u2b50Clear career paths & a developmental 360\u00b0 feedback framework.\n\u2708\ufe0f Relocation package and \"Brain Gain\" relocation bonus for Greek expats.\nRecruitment Privacy Notice\nRegarding the data you share with us, you may find and read our recruitment privacy notice here.","100":"We partner with the world\u2019s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency.\nHi There, This is Miguel from CI&T! I am a Talent Attracting Analyst looking for people located in Colombia for a Mid-Level Data\/ETL Engineer Position to work on a project in the Mortgage industry (USA).\nRequirements for this challenge: - High value on GCP experience (dataproc, dataplex), familiarity with SQL and ETL concepts. - Postgres\/Snowflake experience (nice to have).- Excellent written and verbal English communication skills.\nOur benefits: - Premium Healthcare- Meal voucher- Maternity and Paternity leaves.- Mobile services subsidy - Sick pay -Life insurance. -CI&T University - Colombian Holidays -Paid Vacations - And many others.\n#LI-MP1#MidseniorCI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters\u2019 identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow.\nAt CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas.\nWe strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies.","101":"Description de l'entreprise\nBusiness & Decision est un groupe international des services du num\u00e9rique, sp\u00e9cialis\u00e9, depuis sa cr\u00e9ation, dans l\u2019exploitation et l\u2019analyse de donn\u00e9es.\nBusiness & Decision conseille et d\u00e9ploie les solutions et les services les plus innovants pour accompagner les directions m\u00e9tier \u00e0 relever les d\u00e9fis majeurs de cr\u00e9ation de valeur de leurs organisations. Data Intelligence, Big Data, Data Gouvernance, v\u00e9ritables socles de l\u2019intelligence artificielle et de l\u2019exp\u00e9rience digitale, sont les domaines d\u2019expertise et de sp\u00e9cialisation du groupe.\nBusiness & Decision, filiale d\u2019Orange Business Services, emploie 2 500 talents dans 10 pays dans le monde et dans 14 villes en France.\nDescription du poste\nRattach\u00e9 \u00e0 un Manager Op\u00e9rationnel, vous int\u00e9grez des \u00e9quipes de projet et pouvez participer \u00e0 toutes les phases de mise en \u0153uvre de projets Big Data.\nVos missions :\nRecueil des besoins \u00e0 travers des sp\u00e9cifications ou des user stories\nD\u00e9veloppement \u00e0 travers des frameworks de calcul distribu\u00e9 (Spark, Flink, Beam, \u2026)\nMise en place ou exploitation de cha\u00eenes CI\/CD\nR\u00e9alisation des documentations\nIndustrialisation ou aide \u00e0 l\u2019industrialisation (Ansible, Terraform)\nQualifications\nDe formation informatique Bac+5, vous justifiez d\u2019au minimum 3 ans d\u2019exp\u00e9rience, , dans la mise en \u0153uvre de projets Big Data et vous ma\u00eetrisez le d\u00e9veloppement sur des syst\u00e8mes de calcul distribu\u00e9 (python, scala ou java \u00e0 travers des frameworks Spark, Beam, \u2026)\nLa ma\u00eetrise de l\u2019anglais est souhait\u00e9e pour intervenir aupr\u00e8s de nos clients internationaux.\nVotre curiosit\u00e9, votre autonomie et esprit d\u2019initiative sont des atouts pour d\u00e9velopper vos comp\u00e9tences et contribuer \u00e0 votre \u00e9volution. Votre esprit d\u2019\u00e9quipe favorisera votre int\u00e9gration au sein de l\u2019agence.\nInformations suppl\u00e9mentaires\nCe que nous vous proposons :\nUne carri\u00e8re dans un environnement multiculturel, dynamique et formateur,\nUne r\u00e9elle possibilit\u00e9 de t\u00e9l\u00e9travail,\nUn appui et un suivi r\u00e9gulier d\u2019un manager s\u00e9nior dans le m\u00e9tier,\nDes formations et les certifications associ\u00e9es au parcours de carri\u00e8re choisi (en environnement Microsoft mais aussi sur d\u2019autres offres Data),\nDes possibilit\u00e9s d\u2019activit\u00e9s compl\u00e9mentaires (avant-vente, formation, conseil, expertise, montage d\u2019offre, POC..),\nDes \u00e9v\u00e9nements festifs,\nUne int\u00e9gration au sein d\u2019une communaut\u00e9s d\u2019experts passionn\u00e9s\nPour aller plus loin\u202f: https:\/\/fr.blog.businessdecision.com\/\nVous \u00eates partant pour vivre l\u2019aventure ? Postulez d\u00e8s maintenant en nous envoyant votre CV.\nTous nos postes sont accessibles, \u00e0 comp\u00e9tences \u00e9gales, aux travailleurs en situation de handicap.","102":"We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas or take over sponsorship at this time.\nAbout the role:\nIn this role, you will design, develop, implement and maintain reporting functionality and analytic applications across multiple business units including Finance, Marketing, Operations and more. You will interface with Business Owners, leveraging our data infrastructure and Enterprise BI tools to facilitate faster decision-making, standardize key customer, loan, and business metrics, and support the company\u2019s strategic initiatives. You will also capture and translate requirements through a variety of techniques to create coherent report design documents leading to successful solutions.\nWe are looking for creative problem solvers who enjoy collaborating with others to build new data warehouses, data mart and business intelligence solutions, while supporting our existing applications. You will operate as an owner by completing the full life cycle of a project from understanding the business process and requirements through implementation and ongoing support.\nRequirements:\n6+ years of related experience building data warehouses and reporting\n6+ years of experience in the design and implementation of ETL\/ELT frameworks for complex data mart projects\n5+ years of experience in MicroStrategy and\/or Tableau or a comparable BI tool\n3+ years of experience in Python or other programming\nStrong knowledge of databases like PostgreSQL, Snowflake, etc. and data analysis skills \nStrong knowledge of dimensional modeling and Data Warehousing would be an advantage\nGood communication and interpersonal skills\nHighly motivated Team player\nA Bachelor\u2019s or Master\u2019s degree in Engineering, Computer Science, IT or related study\nBenefits & Perks:\nFlexible work schedule (In-office T\/W\/Th and remote M\/F for hybrid-eligible roles)\nHealth, dental, and vision insurance including mental health benefits\n401(k) matching plus a ROTH option\nPTO & paid holidays off\nSabbatical program\nSummer hours\nPaid parental leave\nPet insurance\nDEI groups (B.L.A.C.K. @ Enova, HOLA @ Enova, Women @ Enova, Pride @ Enova, South Asians @ Enova, APEX @ Enova, and Parents @ Enova)\nEmployee recognition and rewards program\nCharitable matching and a paid volunteer day\u2026Plus so much more!\nAbout Enova\nEnova International is a leading financial technology company that provides online financial services through our AI and machine learning-powered Colossus\u2122platform. We serve non-prime consumers and businesses alike, while offering world-class technology and services to traditional banks\u2014in order to create accessible credit for millions. \nBeing a values-driven organization is at the core of Enova\u2019s success. We live our values by listening to our customers, challenging assumptions, thinking big, setting high expectations, and hiring and developing the best. Through our values and our commitment to making Enova an awesome place to work, we maintain an environment of inclusion and culture where our employees can thrive. You can learn more about Enova\u2019s values and culture here. \nIt is our policy to provide equal employment opportunity for all persons and not discriminate in employment decisions by placing the most qualified person in each job, without regard to any other classification protected by federal, state, or local law. California Applicants: Click here to review our California Privacy Policy for Job Applicants.","103":"What if\u2026 you could join an organization that creates, resources, and builds life sciences companies that invent breakthrough technologies to transform human health and sustainability?\nCompany Summary:\nFL86, Inc. is a privately held, early-stage company developing a novel genomics platform and therapeutics for diseases with a large unmet need.\nFL86 was founded by Flagship Pioneering, an innovative enterprise that conceives, creates, resources, and grows first-in-category life sciences companies. Flagship Pioneering has created over 100 groundbreaking companies over the past twenty years, all of which are pioneering novel and proprietary biological, industrial, and engineering approaches to solve major needs in human health and sustainability. These companies include Moderna (MRNA) Generate Biomedicines, Sana Biotechnology (SANA), Tessera Therapeutics, Evelo Biosciences (EVLO), Indigo Agriculture, Seres Therapeutics (MCRB), Syros Pharmaceuticals (SYRS), and Rubius Therapeutics (RUBY). To date, Flagship has deployed over $2.5 billion in capital toward the founding and growth of its pioneering companies alongside more than $19 billion of follow-on investments from other institutions. In 2021, Flagship Pioneering was ranked 12th globally on Fortune\u2019s \u201cChange the World\u201d list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies.\nPosition Summary:\nWe are seeking a computational scientist (leveling flexible based on experience) who wants to leverage genomics data to identify new ways to treat human diseases. The candidate brings enthusiasm, intellectual curiosity, scientific rigor, and a deep-rooted desire to innovate in genomics. This role is based in the vicinity of Cambridge UK and hybrid work arrangements will be considered, but all applicants will require permission to work in UK. \nKey Responsibilities:\nBe an active member of a scientific team focused on the design and deployment of bioinformatics, with the end goal of developing new therapeutics for diseases with large unmet needs\nWork on collaborative project teams to design experiments and analyze results to address underlying genomics questions\nIdentify and integrate relevant structured and unstructured functional and genomics datasets into FL86\u2019s database\nDevelop and deploy statistical models to assess database for novel discoveries\nParticipate in ongoing work on method development and analysis\nCommunicate key findings to stakeholders across the company, in written and presentation formats\nCollaborate closely with other members across the organization\nRequirements:\nPhD, or equivalent work-experience, in cancer genetics, human genetics, statistical genetics, computational biology, bioinformatics, genomics or similar discipline is required\n0-5+ years of industry\/post-doc experience working with genomics data, with ability to process, analyze, and interpret genetic datasets\nCan write and interpret data analysis code\nCandidates with experience in (a) Target Discovery, (b) Writing and operating data pipelines, or (c) Human or Cancer Genomics analysis will be preferred\nStrong leadership, management, and collaboration skills\nExcellent verbal and written communication.\nAbility to work successfully in a matrix environment, prioritize and manage multiple tasks simultaneously, integrate cross-functional issues and balance competing priorities effectively.\nA high degree of energy, accuracy and attention to detail, and a passion for creating transformative medicines for patients with serious diseases\nLocation: Cambridge, England   Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.   Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, \u201cFSP\u201d) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering\u2019s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.","104":"Power BI Developer\nReporting to: Data & Reporting Manager\nLocation: Scale Space Building, 58 Wood Lane, London W12 7RZ.\n  We\u2019ve been pioneering embedded finance since 2007 and over the years, we\u2019ve worked in partnership with banks, SaaS providers, payment processors, checkout providers, and even the UK government \u2013 providing all they need to offer easy and frictionless revenue-based finance solutions to their SME customers through our API-powered funding platform.\nWe are in a very exciting period of growth, both within the UK and internationally, with teams based in London, Nottingham, USA and Scandinavia. As we continue to grow we are looking for talented and ambitious individuals to join us to reshape business finance.\nWe are proud to have been included in The Sunday Times Hiscox Tech Track 100 as one of the 100 fastest growing FinTechs in the UK for two years running.\n  Who are you? \n  The ideal candidate will have solid practical experience as a Power BI developer. Knowledge & experience of Power Apps and Power Automate is desirable but not essential. The candidate should feel comfortable across the whole data lifecycle \u2013 specifically with competent SQL skills.\n  The ability to confidently communicate up and down the stakeholder ladder is essential, as is the ability to advise, train and support our user base. A keen eye for detail is critical.\n  While technical skills are a necessary requirement, the key to success in this role is the ability to be able to understand and interpret user requirements across the business, often by challenging the status quo of methods and processes.\n    Responsibilities\n  Work collaboratively across all business functions to deliver Reporting.\nIdentify key improvements and requirements in reporting and processes.\nTranslate those business requirements into robust, scalable technical solutions\nCreate and test the quality and accuracy of reporting outputs before they are released.\nWork closely with the data engineers, analysts, and other core stakeholders to develop a data strategy across the business to leverage the data assets we have\n    We think you'll need\n  Significant experience with Power BI is a must.\nExperience with advanced Power BI functionality including Power Apps is very valuable but not a must-have\nExperience of managing and delivering reporting projects.\nUnderstanding of data modelling, with competent SQL skills.\nStrong data analysis, interpretation, and visualisation skills.\nKnowledge & experience of Power Apps and Power Automate is desirable but not essential.\nAn inquisitive mindset, proactive approach to problem solving and the ability to work both autonomously and collaboratively.\n    What happens next?\n  A lot of businesses talk about the importance of diversity and inclusion, at Liberis we want to make sure that we\u2019re genuinely fostering a highly inclusive culture that not only welcomes diversity, but celebrates it. Our commitment is not just surface level. We\u2019re on a mission to create a safe space where everyone and anyone, regardless of their background, can thrive. \n  It\u2019s not just the right thing to do. We also recognise that diverse teams perform better because we have so much to learn from one another. We think that\u2019s pretty cool, and if you do to then you\u2019re in the right place.  \n  We have a hive of activity happening around the business to make sure we\u2019re always pushing for more. Everyone is encouraged to get involved to help us to continue to build an excellent culture at Liberis.  \n  Think this sounds like the right next move for you? If you\u2019re not completely confident that you fit our exact criteria, get in touch! Humility is a wonderful thing and we are interested in hearing about what you can add to Liberis. You can reach us at talent@liberis.co.uk - we look forward to chatting with you! \n  #LI-CG1","105":"Company Description\nVisa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.\nWhen you join Visa, you join a culture of purpose and belonging \u2013 where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world \u2013 helping unlock financial access to enable the future of money movement.\nJoin Visa: A Network Working for Everyone.\nJob Description\nThis position is ideal for an engineer who is passionate about solving challenging business problems. You will be an integral part of the Payment Products Development team focusing on test automation. The candidate will be extensively involved in hands-on activities including POCs, design, documentation, and testing of new and existing functionality. Candidate must be flexible and willing to switch tasks based on team's needs.\nDevelop systems and processes to refine efficiency of automated testing solutions\nDesign and execute tests for applications and services\nDevelop and maintain tools for automation tracking and reporting\nReview product requirements and specifications and recommend improvements to ensure product testability\nRecommend areas of applications and services where automation would be beneficial\nPresent technical solutions, capabilities, considerations, and features in business terms\nEffectively communicate status, issues, and risks in a precise and timely manner\nPerform other tasks on data governance, system infrastructure, and other cross team functions on an as-needed basis\nThis is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs.\nQualifications\nWe are seeking team members that are passionate, visionary and insatiably inquisitive. Successful candidates frequently have a mix of the following qualifications:\n\n\u2022 Bachelor\u2019s Degree or an Advanced Degree (e.g. Masters) in Computer Science\/ Engineering, Information Science or a related discipline\n\u2022 Minimum of 3 years of quality assurance experience (with a concentration in data centric initiatives), with demonstrated expertise in leveraging standard testing best practice methodologies\n\u2022 Professional experience delivering test automation at the unit, business logic, and integration level testing\n\u2022 Experience building and writing code with unit level tests for REST APIs, and web applications\n\u2022 Experience writing code in Core Java and SQL\n\u2022 Working knowledge of Unix\/Linux\n\u2022 Experience using frameworks and tools like Junit, Selenium \/ WebDriver will be a plus point\n\u2022 Knowledge of Automated Test-Driven Development or Test-Driven Development (TDD)\n\u2022 Experience with one or more of the following database technologies: MySQL, Redis\n\u2022 Experience with data visualization and business intelligence tools like Tableau, or other programs highly desired\n\u2022 Experience working in an Agile environment\n\u2022 Knowledge of open-source Big Data eco-system is highly desirable\n\u2022 Demonstrated intellectual and analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style\n\u2022 Previous exposure to financial services is a plus, but not required\nAdditional Information\nVisa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.","106":"We partner with the world\u2019s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency.\nHi There, This is Mar\u00eda from CI&T! I am a Talent Attracting Analyst looking for people located in the USA for a Senior Data Ops Engineer Position to work on a project in the Mortgage Industry.\nRequirements for this challenge: - Cloud (Azure, GCP or AWS)- CI\/CD pipelines- Terraform.- Data Bases: SQL, Postgres, Dataproc, Dataplex- Excellent written and verbal English communication skills\nOur benefits: - Premium Healthcare- Meal voucher- Maternity and Paternity leaves.- Mobile services subsidy- Sick pay-Life insurance.-CI&T University-Colombian Holidays-Paid VacationsAnd many others.\n#LI-MJ1#MidSeniorCI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters\u2019 identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow.\nAt CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas.\nWe strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies.","107":"Who We Are\n23andMe, the leading consumer genetics and research company, has accumulated a wealth of genotypic and phenotypic information from participants committed to improving human health through advances in genomics. Our Therapeutics team in South San Francisco leverages this data to discover and develop new treatments that can offer significant benefits for patients with serious, unmet medical needs.\nThis dedicated research and drug development group identifies novel targets using 23andMe's genetic database and performs preclinical research to advance programs towards clinical development. We currently have programs across several therapeutic areas, including but not limited to oncology, respiratory, and cardiovascular diseases. More information about our Therapeutics team is available at https:\/\/therapeutics.23andme.com\/.\nWe are looking for an exceptional Computational Biologist to join our collaborative, cross-functional research team focused on discovery of novel therapeutic targets and interpretation of association signals from the world\u2019s largest database of genotypes and phenotypes. Successful candidates will have demonstrated experience analyzing large genetic, gene expression and functional genomics datasets using the best practices in statistics or machine learning. They will use rigorous quantitative reasoning, creativity, and understanding of molecular biology to develop computational tools to analyze high-throughput functional data and integrate it with human genetics to identify promising drug targets. Our team is very collaborative, and the ability to communicate ideas and results with other scientists is key.\n  What You'll Do\nBuild tools and develop computational methods to provide biological interpretation of genetic signals identified in the 23andMe database\nExtend existing target discovery efforts to incorporate additional data types and novel analysis methods\nWork collaboratively with members of Computational Biology, Statistical Genetics and Discovery Biology teams on integrative analysis of public and in-house generated gene expression and functional genomics data with the goals of elucidating disease biology\nProvide scientific expertise and leadership and drive complex projects forward\nMentor and manage PhD-level scientists \n  What You\u2019ll Bring\nPh.D. in Computational Biology, Bioinformatics, Biomedical Informatics, Biostatistics, Genetics, Computer Science, Statistics or a similar quantitative field\nExperience in interpretation and fine mapping of genetic association signals\nHands-on experience working with large scale *omics datasets\nExperience developing robust data analysis software in R and\/or Python\n5+ years of post-Ph.D. research work experience in an academic or for-profit setting\nDemonstrated success in leading complex projects with multiple contributors and\/or stakeholders\nExperience managing one or more Ph.D. level scientists\nDemonstrated ability to effectively work as part of interdisciplinary teams\nExceptional communication skills, with an ability to convey complex computational results to colleagues from a wide range of life sciences backgrounds\nAbility to work from 23andMe's office in South San Francisco a minimum of 2 days per week\n  Strongly Preferred\nIndustry experience in pharmaceutical or biotechnology research\n  About Us\n23andMe, headquartered in Sunnyvale, CA, is a leading consumer genetics and research company. Founded in 2006, the company\u2019s mission is to help people access, understand, and benefit from the human genome. 23andMe has pioneered direct access to genetic information as the only company with multiple FDA authorizations for genetic health risk reports. The company has created the world\u2019s largest crowdsourced platform for genetic research, with 80 percent of its customers electing to participate. The platform also powers the 23andMe Therapeutics group, currently pursuing drug discovery programs rooted in human genetics across a spectrum of disease areas, including oncology, respiratory, and cardiovascular diseases, in addition to other therapeutic areas. More information is available at www.23andMe.com.\nAt 23andMe, we value a diverse, inclusive workforce and we provide equal employment opportunity for all applicants and employees. All qualified applicants for employment will be considered without regard to an individual\u2019s race, color, sex, gender identity, gender expression, religion, age, national origin or ancestry, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, genetic information, military or veteran status, or any other basis protected by federal, state or local laws.  If you are unable to submit your application because of incompatible assistive technology or a disability, please contact us at accommodations-ext@23andme.com. 23andMe will reasonably accommodate qualified individuals with disabilities to the extent required by applicable law.\nPlease note: 23andMe does not accept agency resumes and we are not responsible for any fees related to unsolicited resumes. Thank you.\n\n\nPay Transparency\n23andMe takes a market-based approach to pay, and amounts will vary depending on your geographic location. The salary range reflected here is for a candidate based in the San Francisco Bay Area.  The successful candidate\u2019s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.San Francisco Bay Area Base Pay Range$168,000\u2014$252,000 USD","108":"The InMobi Story \nWe like big challenges. Building a new company in 2007 was no ordinary task. As the\u202frecession hit, the iPhone was born and launched a revolution.\u202fMobile advertising wasn\u2019t yet a thing, other than SMS, and venture capital funding was\u202fhard to come by for four guys in India.\u202f\u202f  \nYet with passion, foresight, and conviction \u2013\u202fInMobi\u202fcharted its own course, helping to\u202ftransform the way consumers engage with their phones and create today's booming\u202fapp economy wherein\u202fconsumers now spend 4.2 hours per day.\u202f  \nAfter fourteen years of innovation, our end-to-end advertising software platform, connected content and\u202fcommerce\u202fexperiences have formed a powerful engine for\u202fgrowth that activates audiences, drives\u202freal\u202fconnections, and diversifies revenue for\u202fcompanies around the world.  \nOur\u202fglobal organization of\u202fInMobians\u202fare excited to continue\u202fdiscovering and developing impactful\u202ftechnologies that will continue to transform people, businesses,\u202fand society. \n  Title: Head of Data Science, InMobi Ads Platform\nLocation: San Mateo\nPosition Summary:\nReporting to the\u202fChief Technology Officer, this person will be driving the overall vision and strategy for data science with the InMobi Ads Platform group and will play a foundational role in setting up the DS unit, in terms of hiring and driving the larger AI-first aspirations of the company. If you are looking for a technology company where you can\u202fdrive business outcomes\u202fin an ambitious,\u202fhigh-growth environment, then this is the place for you! \nThe Head of Data Science will design and launch innovative and complex analytic models, utilizing a blend of contemporary and traditional data mining techniques, and when applied to both structured and unstructured data sets, will drive insights and benefits not otherwise apparent. You should have business domain expertise to translate goals into data-based deliverables, using quantitative analysis, statistical modeling, predictive and prescriptive analytics, optimization and attribution algorithms, pattern detection analysis, etc.  \nYou will have knowledge of current AI and machine learning capabilities and advances in the field. And you should also be interested in the academics of data science, but more focused on practical application. You will be able to clearly articulate the purpose of data science solutions to key stakeholders and customers, and then translate those into action for the business. The solutions you and your teams provide will encompass such things as product innovations, create efficiencies and automation across the business, improve data architecture and system architecture, mitigate business risks, and create process improvements. \nWe are searching for an executive who thrives on describing a vision and inspiring a team to achieve it. We need a leader who will remove obstacles, break barriers, empower, communicate, and engage. Someone who truly harnesses advanced analytic data modeling systems to drive positive outcomes for our customers. From the defining of a strategy to the execution of it, you will also develop, collect, and report the objective metrics required to assure it. You will own driving employee engagement and increasing productivity across Data Science and into Engineering. \nThis is a\u202fsenior level role\u202fin which you will work directly with the CTO and the founders and\u202flead all the efforts\u202facross data science for the InMobi Ads Platform business. \n  The impact you\u2019ll make:\nDefine the overall vision for our data science applications, focused on up-leveling internal use of machine learning\nProvide technical leadership of overall architecture, ML approaches, performance monitoring, continuing improvement, and production deployments\nManage, develop, coach, and mentor a team of Data Scientists, machine learning engineers and big data specialists\nPartner with our business and product teams to help predict system behavior, establish metrics, identify bugs, and improve debugging skills\nEnsure data quality and integrity within our products as well as our teams\nTest performance of data-driven products\nPartner with our client-facing teams and customers to enhance products and develop client solutions applying critical thinking skills to remove extraneous inputs\nConceive, plan, and prioritize data projects\nLead data mining and collection procedures, especially focused on unstructured and siloed data sets\nBuild analytic systems and predictive models\nVisualize data and create reports\nExperiment with new models and techniques\nDrive the implementation of models into Production through various Engineering teams\nCreate a positive culture to maximize productivity and minimize attrition\n  The experience you'll need:\nMaster\u2019s or PhD in Statistics, Machine Learning, Mathematics, Computer Science, Economics, or any other related quantitative field. Equivalent work experience is also acceptable for the position.\nAt least 7 years of working experience in a data science position, preferably working as a Senior Data Scientist that progressed into a leadership position.\nA proven and successful track record of leading high-performing data analyst and data science teams leading through the successful performance of advanced quantitative analyses and statistical modeling that positively impact business performance.\nKnowledge of data management and visualization techniques\nExcellent understanding and knowledge of statistical analysis and predictive modeling\nPractical knowledge and solid understanding of machine learning tools and techniques. (e.g.  Python, Deep Learning Architectures, TensorFlow, PyTorch, Spark, Scala)\nAble to work with diverse teams (product, engineering, analytics, sales, services) and at various levels within the organization\nStrong interpersonal skills, demonstrating an ability to collaborate with and influence teams & key stakeholders\nStrong executive leadership presence and business mindset\n  About Us \nInMobi\u202fis the\u202fleading provider of content, monetization, and\u202fmarketing\u202ftechnologies\u202fthat fuel growth\u202ffor industries around the world.\u202fOur\u202fend-to-end advertising software platform, connected\u202fcontent\u202fand\u202fcommerce\u202fexperiences\u202factivate audiences, drive\u202freal\u202fconnections, and diversify revenue for businesses everywhere. With\u202fdeep\u202fexpertise and unique reach in mobile,\u202fInMobi\u202fis\u202fa\u202ftrusted\u202fand\u202ftransparent\u202ftechnology partner for marketers, content creators\u202fand\u202fbusinesses of all kinds.  \nIncorporated in Singapore,\u202fInMobi\u202fmaintains a large presence in\u202fSan Francisco and Bangalore and has operations in New York,\u202fChicago, Kansas City,\u202fLos Angeles,\u202fDelhi, Mumbai, Beijing,\u202fShanghai, Jakarta, Manila, Kuala Lumpur, Sydney, Melbourne,\u202fSeoul, Tokyo, London and Dubai. To learn more, visit\u202finmobi.com.\u202f\u202f  \n  Our Purpose  \nInMobi\u202fcreates transformative\u202fmobile\u202fexperiences and software platforms\u202fto positively impact people, businesses, and societies around the world.\u202f  \nWe believe that our\u202finnovations at\u202fthe intersection of artificial intelligence, commerce,\u202fand the\u202fcreator economy\u202fwill revolutionize the way\u202fconsumers use their mobile\u202fdevices.\u202fOur mission is\u202fto power our\u202fcustomers\u2019 growth with\u202finnovative content and commerce experiences that help\u202fthem\u202factivate their audiences and drive real connections. How do we do it?  \nAn End-to-End\u202fContent, Monetization, & Marketing\u202fPlatform the fuels industry growth  \nAI-Powered Audience Activation\u202ffor\u202fthe open content, media and marketing ecosystem  \nNew\u202fContent\u202fand Commerce\u202fexperiences\u202ffor a world of connected devices \n  Award-winning culture, best-in-class benefits:     \nCompetitive salary, bonus, and stocks     \nQuality medical, vision, dental     \n401(k) match     \nFlexible working hours    \nParent friendly health benefits and work environment\nWellness stipend    \nHealthy time off through a combination of PTO, sick days, and company-wide holidays    \n$400 to set up your own home office to thrive in a post COVID world\nPost-covid hybrid work model for employees close to our offices in New York, San Francisco, Irvine, and Kansas City \n  InMobi is an equal opportunity employer     \nInMobi is a place where everyone can grow. However you identify, and whatever background you bring with you, we invite you to apply if this sounds like a role that would make you excited to work. \nInMobi provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type.  All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. \nInMobi has implemented a mandatory COVID vaccination policy for all employees in the U.S. Employees who are unable to be vaccinated may request an exemption under certain circumstances. \n  #LI-BM1","109":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to Know our Team: \nThe Supply Analytics team is a team of creative entrepreneurs that develop solutions for Agoda\u2019s non-accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek.  Utilizing our strong brand and resources, we build new channels to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. \nThe Opportunity:  \nThe role sits within the Supply Analytics team under Central Supply Team, where new business ideas, and partnership types are incubated and scaled. We are looking for a\u202fSenior BI Analyst\u202fwhose main focus areas are providing visibility and insights for people-related issues through Business Intelligence tools like Tableau and SQL, managing data warehouses, building ETL processes, and helping build other tools to optimize the business. This role will be involved in strategic projects and work closely with commercial owners and business stakeholders, using data to identify and translate business needs and opportunities into actionable initiatives.\nIn this Role, you\u2019ll get to:\nTranslate internal briefs into analytical projects (to include refining the initial brief and asking the \u2018right questions\u2019, working through potential hypotheses and storyboarding the output)\nUse and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders.\nProactively identify opportunities for growth within supply and the wider business.\nDrive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply.\nIdentify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence.\nAutomate manual operational processes and present back on time savings gained through modernization of business operations\nWhat you\u2019ll Need to Succeed:\n4+ years of experience in analytics\/data science\/insights\/strategy.\nBachelor\u2019s degree ideally in a business or quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance).\n3+ years of experience with BI & analytics tools (SQL, Tableau, Metabase, Data Studio, or similar technologies)\n2+ years of solid project management\nGood stakeholder management experience. Comfortable presenting to senior leadership and C-suite.\nStrong experience in finding data insights and provide business recommendation to the business\nA hacker\u2019s mindset \u2013 the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping.\nExcellent communicator with superior written, verbal, presentation and interpersonal communication skills.\nData driven in both decision making and performance measurement.\nExtreme comfort in ambiguous, fast-paced environment.\nAbility to multi-task, prioritize and coordinate resources.\nIt\u2019s Great if you Have:  \nTravel industry \/ e-commerce \/ tech \/ consulting experience.\nExperience in conducting A\/B testing experimentation (a plus)\nA good understanding of statistical modelling knowledge or any machine learning technique knowledge is a plus (regression, logistic regression, random forest, etc.)\n  #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","110":"Description de l'entreprise\nRejoindre LINCOLN, c\u2019est rejoindre un cabinet de conseil reconnu pour son expertise data depuis plus de 30 ans, en proposant des prestations d\u2019expertise, de conseil et d\u2019accompagnement en Modern BI, Big Data et Science de la donn\u00e9e. \nVous progresserez au sein d\u2019une \u00e9quipe de 380 experts de l\u2019ing\u00e9nierie \nVous \u00e9voluerez ainsi dans un environnement technique stimulant et en constante \u00e9volution : architectures distribu\u00e9es ; s\u00e9curisation, configuration et optimisation de plateformes ; gouvernance QoD ; industrialisation de projets data science\u2026\nEnfin, vous perfectionnerez vos comp\u00e9tences gr\u00e2ce \u00e0 notre Lincoln Academy, v\u00e9ritable institut de formation interne et data-dock\u00e9.\nDescription du poste\nEn int\u00e9grant nos \u00e9quipes de consultants, vous participez \u00e0 la mise en \u0153uvre des solutions Big Data adapt\u00e9es aux enjeux de nos clients.\nNous recherchons pour l\u2019un de nos clients Grands Comptes deux data engineer Big Data :\nEn tant que de Data Engineer Big Data, vous aurez pour mission :\nMonter en comp\u00e9tences sur l\u2019TL BigL, d\u00e9velopp\u00e9 en interne en Shell Bash sur une base GCP\nD\u00e9velopper des cas d\u2019usage : architecture des traitements TL, mod\u00e9lisation Datawarehouse en CICD\nParticiper aux \u00e9volutions, \u00e0 la documentation du Framework et \u00e0 la gestion des livrables (Git)\nVous travaillez dans un contexte Agile et sur un environnement Unix \/ Linux\nQualifications\nDes fondamentaux th\u00e9oriques acquis en cursus \u00e9cole d\u2019ing\u00e9nieurs informatique ou universitaire avec une sp\u00e9cialisation IT, avec une exp\u00e9rience d\u2019au minimum 3 ans\nUne ma\u00eetrise de SQL, noSQL\nExp\u00e9rience requise sur Scala ou Java\nMa\u00eetrise sur l\u2019\u00e9cosyst\u00e8me Big Data : Hadoop, Spark, Kafka,\u2026\nUne connaissance de Google Cloud Platform est un vrai plus\nCI\/CD : Git \/ Jenkins \/ Nexus\nOutils de d\u00e9ploiement : Kubernetes, Docker, Ansible,\u2026\nLa cerise sur le g\u00e2teau: D\u00f4t\u00e9(e) d\u2019un bon relationnel, vous aimez travailler en \u00e9quipe","111":"Summary:\nAs a Senior or Lead Big Data DevOps Engineer, you will be working with a team responsible for setting up, scaling, and maintaining Big Data infrastructure and tools in private and public cloud environments.  \nMain Responsibilities:\nDriving improvement of the efficiency of Big Data infrastructure.\nCoordinating cross-team infrastructure and Big Data initiatives.\nLeading Big Data \u2013 related architecture and design efforts.\nEnsuring availability, efficiency, and reliability of the Big Data infrastructure.\nBuilding and supporting tools for operational tasks.\nEvaluating, designing, deploying monitoring tools\nDesign and implementation of DR\/BC practices and procedures.\nOn-call support of production systems.\nRequirements:\n7+ years of experience working with Hadoop, preferably Open Source\n3+ years of leading Big Data, DevOps, SRE, DBA, or development team.\nExperience setting up and running Hadoop clusters of 1000+ nodes.\nSolid knowledge of NoSQL databases, preferably Cassandra or ScyllaDB.\nExperience running and troubleshooting Kafka.\nWorking knowledge of at least one of: Terraform, Ansible, SaltStack, Puppet.\nProficiency in shell scripting.\nNice to have:\nExperience with Prometheus.\nExperience managing Showflake.\nSolid knowledge of Graphite and Grafana.\nPython or Perl scripting skills.\nExperience with installing and managing Aerospike.\nDBA experience with one of: PostgreSQL, MySQL, MariaDB.\n  Diversity, Equity and Inclusion at Zeta\n\nWe are committed to building diverse teams with different identities, backgrounds and perspectives.\n\nWe believe in providing a forum to connect at Zeta, to learn and celebrate differences. Our mission is to ensure we have an environment that enables a deep level of trust and belonging, so everyone feels invited to bring their whole selves to work, and to increase both diversity at Zeta as well as in the technology industry.\n\nZeta considers applicants for employment without regard to, and does not discriminate on the basis of an individual\u2019s sex, race, color, religion, age, disability, status as a veteran, or national or ethnic origin; nor does Zeta discriminate on the basis of sexual orientation or gender identity or expression.\n  About Zeta Global\n\nZeta Global is a data-powered marketing technology company with a heritage of innovation and industry leadership. Founded in 2007 by entrepreneur David A. Steinberg and John Sculley, former CEO of Apple Inc and Pepsi-Cola, the Company combines the industry\u2019s 3rd largest proprietary data set (2.4B+ identities) with Artificial Intelligence to unlock consumer intent, personalize experiences and help our clients drive business growth.\n\nOur technology runs on the Zeta Marketing Platform, which powers \u2018end to end\u2019 marketing programs for some of the world\u2019s leading brands. With expertise encompassing all digital marketing channels \u2013 Email, Display, Social, Search and Mobile \u2013 Zeta orchestrates acquisition and engagement programs that deliver results that are scalable, repeatable and sustainable.\n\nZeta Global Recognized in Enterprise Marketing Software and Cross-Channel Campaign Management Reports by Independent Research Firm\nhttps:\/\/www.prnewswire.com\/news-releases\/zeta-global-opens-ai--data-labs-in-san-francisco-and-nyc-300945353.html\n\nhttps:\/\/www.prnewswire.com\/news-releases\/zeta-global-recognized-in-enterprise-marketing-software-and-cross-channel-campaign-management-reports-by-independent-research-firm-300938241.html\n  #LI-PM1\n#LI-Remote\nPrimary Location Salary Range: $100,000.00 - $200,000.00","112":"We are Kaizen Gaming\nKaizen Gaming is the leading GameTech company in Greece and one of the fastest-growing in Europe, with the Stoiximan brand in Greece and Cyprus and Betano in Germany, Romania, Bulgaria, Czech Republic, Portugal, Brazil, Chile, Peru, Ecuador and Canada. Our aim is to leverage cutting-edge Technology in order to provide the optimum experience to those who trust us for their entertainment.\nThe Role\nWe\u2019re looking for a Reporting Engineer Team Lead to join our Big Data reporting team, who will lead the delivery of our reporting ecosystem. As a Reporting Engineer Team Lead (Big Data), you\u2019ll design, develop and maintain our data flows\/modeling to meet business analysis and reporting needs.\nEqually important, you will lead the reporting engineers by developing their skills and fostering a culture of open communication and support. Together with the Principal Engineer your goal will be to improve the team\u2019s performance, technical expertise and delivery velocity.\n  The Team\nOur Big Data reporting team(s) consists of twelve members with diverse backgrounds and expertise in several fields including, but not limited to, Databricks\/ Delta lake\/ SQL Server\/ Azure Data Warehouse\/ SSRS\/ SSIS.\n  Responsibilities\nLead the reporting engineers to adopt best practices in data system creation, data integrity, test design, analysis, validation, and documentation;\nTranslate business and functional requirements into robust, scalable, operable solutions;\nImplement and operate large-scale, high-volume, high-performance data structures for analytics and data science;\nImplement data transformation pipelines, using ETL\/ELT processes;\nHelp continually improve ongoing reporting and analysis processes, automating or simplifying self-service modeling and production support for customers.\n  Requirements\nMust have:\n6 years of hands-on experience in writing complex, highly optimized T-SQL code for data manipulation and reporting;\n4+ years of experience in ETL\/ELT, Data Modeling, Data Warehouse Architecture and Reporting tools;\n2+ years of experience in leading teams\nExperience in the Microsoft BI stack (SQL Server, SSRS, SSAS);\nAnalytical abilities & problem-solving skills;\nAbility to meet deadlines with high attention to detail and quality.\nNice to have:\nA bachelor's degree in a quantitative\/technical field (e.g. Computer Science, Statistics, Engineering) or equivalent industry experience;\nExperience with Azure Data platforms such as Synapse Analytics, Data Lake, Databricks; \nExperience in programming languages preferable in Python or Scala;\nExposure to CI\/CD;\nExposure to an Agile team-working environment.\n  Kaizen Gaming Perks\n\ud83d\udd51 Work from home & remote working options.\n\ud83c\udfc3 A buddy will support you with your onboarding.\n\ud83d\udcb8Competitive salary package and bonus scheme.\n\ud83d\udc69\u200d\u2695\ufe0f Health and life insurance for you and your family.\n\ud83d\udcb0 Monthly allowance for lunch & commuting expenses.\n\ud83d\udcbbNice rigs - 2.5K monitor, latest i7, tons of RAM, fast SSD.\n\ud83d\udcda Pluralsight, unlimited access to Udemy & continuous training for all your learning and development needs.\n\u2b50Clear career paths & a developmental 360\u00b0 feedback framework.\n\u2708\ufe0f Relocation package and \"Brain Gain\" relocation bonus for Greek expats.\nRecruitment Privacy Notice\nRegarding the data you share with us, you may find and read our recruitment privacy notice here.","113":"Description de l'entreprise\nBusiness & Decision est un groupe international des services du num\u00e9rique, sp\u00e9cialis\u00e9, depuis sa cr\u00e9ation, dans l\u2019exploitation et l\u2019analyse de donn\u00e9es.\nBusiness & Decision conseille et d\u00e9ploie les solutions et les services les plus innovants pour accompagner les directions m\u00e9tier \u00e0 relever les d\u00e9fis majeurs de cr\u00e9ation de valeur de leurs organisations. Data Intelligence, Big Data, Data Gouvernance, v\u00e9ritables socles de l\u2019intelligence artificielle et de l\u2019exp\u00e9rience digitale, sont les domaines d\u2019expertise et de sp\u00e9cialisation du groupe.\nBusiness & Decision, filiale d\u2019Orange Business Services, emploie 2 500 talents dans 10 pays dans le monde et dans 14 villes en France.\nDescription du poste\nAu sein de notre agence Rennaise, vous int\u00e9grez une \u00e9quipe projet et contribuez \u00e0 toutes les phases de mise en \u0153uvre d\u2019une application d\u00e9cisionnelle.\nVos principales missions :\nAnimer des \u00e9tudes de cadrage.\nAuditer des architectures DATA existantes\nD\u00e9ployer des infrastructures DATA cloud ou on-premise\nTransmettre ses comp\u00e9tences \u00e0 des profils ayant une trajectoire d\u2019expertise\nRester informer, se former et former sur les nouvelles solutions DATA\nDomaine de comp\u00e9tences techniques :\n Ma\u00eetrise des technologies du Big Data (Hadoop, Spark, Kafka, Nifi, ELK\u2026)\n Maitrise des outils de d\u00e9ploiement automatis\u00e9 et DEVOPS (ANSIBLE, JENKINS, DOCKER, KUBERNETES\u2026)\nConnaissance au moins d'une architecture Cloud (AWS, AZURE, GCP\u2026)\nConnaissances d'au moins un langage de programmation objets ou\/et de langage scripts (Java, Javascript, Scala, Python\u2026)\nConnaissances en solutions de bases de donn\u00e9es (SQL, NoSQL\u2026)\nQuelques exemples de missions actuelles :\nRevue d\u2019une architecture hybride Cloudera\/Azure pour un client souhaitant \u00e9voluer vers l\u2019industrie 4.0\nMise en place d\u2019une plateforme data sous Kubernetes \u00e0 base de composants open source pour b\u00e9n\u00e9ficier des avantages du cloud sur un environnement s\u00e9curis\u00e9 souverain\nIndustrialisation d\u2019outils de monitoring Kafka sous Ansible pour un client dans le secteur du transport\nQualifications\nProfil de formation bac+5, vous justifiez d'au moins 3 ans exp\u00e9riences significatives en qualit\u00e9 d'Ing\u00e9nieur DATA et BIG DATA. \nInformations suppl\u00e9mentaires\nCe que nous vous proposons :\nUne carri\u00e8re dans un environnement multiculturel, dynamique et formateur,\nDu temps d\u00e9di\u00e9 \u00e0 des chantiers innovants permettant de tester de nouvelles technologies\nUne r\u00e9elle possibilit\u00e9 de t\u00e9l\u00e9travail,\nUn appui et un suivi r\u00e9gulier d\u2019un manager s\u00e9nior dans le m\u00e9tier,\nDes formations et les certifications associ\u00e9es au parcours de carri\u00e8re choisi.\nDes possibilit\u00e9s d\u2019activit\u00e9s compl\u00e9mentaires (avant-vente, formation, conseil, expertise, montage d\u2019offre, POC..),\nDes \u00e9v\u00e9nements festifs,\nUne int\u00e9gration au sein d\u2019une communaut\u00e9s d\u2019experts passionn\u00e9s\nPour aller plus loin\u202f: https:\/\/fr.blog.businessdecision.com\/\nVous \u00eates partant pour vivre l\u2019aventure ? Postulez d\u00e8s maintenant en nous envoyant votre CV.\nTous nos postes sont accessibles, \u00e0 comp\u00e9tences \u00e9gales, aux travailleurs en situation de handicap.","114":"Company Description\nAt ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can\u2019t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. \nWith more than 7,400+ customers, we serve approximately 80% of the Fortune 500, and we're proud to be one of FORTUNE's 100 Best Companies to Work For\u00ae and World's Most Admired Companies\u00ae 2022.\nLearn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.\nUnsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.\nJob Description\nCompany Description\nAt ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can\u2019t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. \nWith more than 7,400+ customers, we serve approximately 80% of the Fortune 500, and we're on the 2021 list of FORTUNE World's Most Admired Companies\u00ae. \nLearn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.\nJob Description\nYou will be part of the ServiceNow Cloud Services Big Data Team.  The Big Data team is building the next-generation platform that collects, stores and provides real-time access to large amounts of data.\nWhat you get to do in this role:\u202f\u202f \n Build the next-generation libraries, APIs and data pipelines\nCreate tools, libraries, and frameworks for can be reused for multiple applications\nApply new technology and innovation to improve platform functionality\n Qualifications\nTo be successful in this role you have:\nExcellent Java programming skills with 4+ years experience using Java\nProficiency on scripting with shell and python\nGood understanding of Object-Oriented methodologies, design patterns and data Structures\nStrong skills working with SQL queries, including performance tuning, utilizing indexes\/partitions, and materialized views to improve query performance.\nWorking knowledge of hadoop components such as spark streaming, hdfs, hbase, yarn, hive and impala, kafka\nExceptional debugging, testing, and problem solving skills\nGood understanding of streaming technologies and real time analytics\nAbility to learn quickly in a fast-paced, dynamic team environment\nSelf-motivated and willing to expand skillset proactively\nSelf-disciplined, organized, strive for clean and maintainable code\nHighly effective communication and collaboration skill\n5 years of overall experience with at least 1 in big data\/analytics related positions.\nBS or MS Degree in Computer Science or equivalent experience.\nAdditional Information\nServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.\nAt ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.\nIf you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.\nFor positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.\nPlease Note: Fraudulent job postings\/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.\n  From Fortune. \u00a9 2022 Fortune Media IP Limited All rights reserved. Used under license.\nFortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","115":"Business Intelligence Developer\nReporting to: Data & Reporting Manager\nLocation: Scale Space Building, 58 Wood Lane, London W12 7RZ.\n  We\u2019ve been pioneering embedded finance since 2007 and over the years, we\u2019ve worked in partnership with banks, SaaS providers, payment processors, checkout providers, and even the UK government \u2013 providing all they need to offer easy and frictionless revenue-based finance solutions to their SME customers through our API-powered funding platform.\nWe are in a very exciting period of growth, both within the UK and internationally, with teams based in London, Nottingham, USA and Scandinavia. As we continue to grow we are looking for talented and ambitious individuals to join us to reshape business finance.\nWe are proud to have been included in The Sunday Times Hiscox Tech Track 100 as one of the 100 fastest growing FinTechs in the UK for two years running.\n  Who are you? \n  The ideal candidate will have solid practical experience as a Business Intelligence Developer. Knowledge & experience of Power Apps and Power Automate is desirable but not essential. The candidate should feel comfortable across the whole data lifecycle \u2013 specifically with competent SQL skills.\n  The ability to confidently communicate up and down the stakeholder ladder is essential, as is the ability to advise, train and support our user base. A keen eye for detail is critical.\n  While technical skills are a necessary requirement, the key to success in this role is the ability to be able to understand and interpret user requirements across the business, often by challenging the status quo of methods and processes.\n    Responsibilities\n  Work collaboratively across all business functions to deliver Reporting.\nIdentify key improvements and requirements in reporting and processes.\nTranslate those business requirements into robust, scalable technical solutions\nCreate and test the quality and accuracy of reporting outputs before they are released.\nWork closely with the data engineers, analysts, and other core stakeholders to develop a data strategy across the business to leverage the data assets we have\n    We think you'll need\n  Significant experience with Power BI is a must.\nExperience with advanced Power BI functionality including Power Apps is very valuable but not a must-have\nExperience of managing and delivering reporting projects.\nUnderstanding of data modelling, with competent SQL skills.\nStrong data analysis, interpretation, and visualisation skills.\nKnowledge & experience of Power Apps and Power Automate is desirable but not essential.\nAn inquisitive mindset, proactive approach to problem solving and the ability to work both autonomously and collaboratively.\n    What happens next?\n  A lot of businesses talk about the importance of diversity and inclusion, at Liberis we want to make sure that we\u2019re genuinely fostering a highly inclusive culture that not only welcomes diversity, but celebrates it. Our commitment is not just surface level. We\u2019re on a mission to create a safe space where everyone and anyone, regardless of their background, can thrive. \n  It\u2019s not just the right thing to do. We also recognise that diverse teams perform better because we have so much to learn from one another. We think that\u2019s pretty cool, and if you do to then you\u2019re in the right place.  \n  We have a hive of activity happening around the business to make sure we\u2019re always pushing for more. Everyone is encouraged to get involved to help us to continue to build an excellent culture at Liberis.  \n  Think this sounds like the right next move for you? If you\u2019re not completely confident that you fit our exact criteria, get in touch! Humility is a wonderful thing and we are interested in hearing about what you can add to Liberis. You can reach us at talent@liberis.co.uk - we look forward to chatting with you! \n  #LI-CG1","116":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to know our team:\nPartner Development is a team of creative entrepreneurs that develop solutions for Agoda\u2019s accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.\nIn this role you'll get to\nThis role is designed to mainly growth opportunity identification among mid to long tail hotels, experiment execution and data tracking within Partner Development team for the global teams. You will get to work directly with the regional team to design and put in place global experimentation and initiatives to drive tangible impact in each market.\nKey activities involved include but not limit to:\nApply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations\nOwn end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development\nBuild dashboards, identify new and track key metrics to closely monitor team\u2019s performance and identify quick and long term opportunities for improvements\nWork closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified\nSupport global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization\nWhat you'll need to succeed \nBachelor\u2019s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline\n4-8 years experience working in a business analysis, data analysis, reporting or business strategy role\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\nCoding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\nData visualization tool experience such as with Tableau or your weapon of choice.\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","117":"We partner with the world\u2019s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency.\nHi there, this is Salwa from CI&T! I am a Talent Attracting Analyst looking for people located in the USA for a Mid-Level Data\/ETL Engineer Position to work on a project in the mortgage industry.\nRequirements for this challenge: - High value on GCP experience (dataproc, dataplex), familiarity with SQL and ETL concepts. - Postgres\/Snowflake experience (nice to have).- Excellent written and verbal English communication skills.\nOur benefits: - Premium Healthcare- Meal voucher- Maternity and Paternity leaves.- Mobile services subsidy- Sick pay-Life insurance.-CI&T University-Colombian Holidays-Paid VacationsAnd many others.\n#LI-SC1#MidseniorCI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters\u2019 identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow.\nAt CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas.\nWe strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies.","118":"Binance is the global blockchain company behind the world\u2019s largest digital asset exchange by trading volume and users, serving a greater mission to accelerate cryptocurrency adoption and increase the freedom of money.\nAre you looking to be a part of the most influential company in the blockchain industry and contribute to the crypto-currency revolution that is changing the world?\nResponsibilities\nWork across all aspects of data from engineering to building sophisticated visualizations, machine learning models and experiments\nAnalyze and interpret large (PB-scale) volumes of transactional, operational and customer data using proprietary and open source data tools, platforms and analytical tool kits\nTranslate complex findings into simple visualizations and recommendations for execution by operational teams and executives\nProcessing confidential data and information according to guidelines\nManaging and designing the reporting environment, including data sources, security, and metadata\nTroubleshooting the reporting database environment and reports\nRequirements\nBachelor\u2019s degree from an accredited university or college in Computer Science or Math or Statistics\nProficient in data engineering, modeling and ETL - preferred experience with data sourcing and working with APIs\nExperience with data querying using languages such as SQL, GraphQL, Python \nAble to commit minimum 3 days per week for at least 6 months\nUnderstands project tokenomics and has good knowledge of the DeFi and Web 3.0 infrastructure landscape\nExperience in using tools such as Dune analytics, Nansen etc\nUnderstanding of addressing and metadata standards\nHigh-level written and verbal communication skills","119":"INTRACOM TELECOM is a global telecommunication systems and solutions vendor operating for over 40 years in the market. The company innovates in the wireless access and transmission field, offers a competitive telco software solutions portfolio and combines its offerings with a complete range of professional services.\nOur mission is to shape the future through technology and we recognize that human capital is the key factor to achieve this in today's business environment. Our company's highly specialized and experienced personnel are pivotal to achieving demanding objectives and advancing the capabilities of the company to better serve its customers.\nWithin this framework, we are looking for an experienced Big Data Solution Architect to join our Data Analytics team. As a Big Data Solution Architect, you will be responsible for designing and implementing large-scale, high-performance data solutions that meet the needs of our clients.\nResponsibilities:\nWork with clients in multiple industries including Telco, Finance, Utilities and Retail to understand their business requirements and design solutions that meet their needs\nDesign large-scale, high-performance data solutions using Big Data technologies such as Hadoop, Spark, Hive, MinIO, Trino and Kafka\nDesign data integration, storage, and retrieval solutions that meet performance and scalability requirements and coordinate development with teams of Data Engineers.\nWork with data scientists and analysts to build data pipelines and models for analysis and reporting\nCollaborate with infrastructure and DevOps teams to ensure data solutions are deployed and managed in a scalable and reliable manner\nStay up-to-date with the latest Big Data technologies and trends and recommend new solutions and approaches to clients\nRequirements\nBachelor's or Master's degree in Computer Science or a related field\nAt least 5 years of experience as a Big Data Solution Architect\nStrong experience with Big Data technologies such as Hadoop, Spark, Hive, and Kafka\nExperience designing and implementing large-scale data solutions\nExperience with data integration, storage, and retrieval solutions\nExperience with data modeling, data warehousing, and data visualization\nStrong understanding of cloud-based infrastructure and deployment models\nStrong communication skills and the ability to work effectively with clients and cross-functional teams\n\nIf you have a passion for solving complex data problems and enjoy working in a fast-paced, dynamic environment, we encourage you to apply for this exciting opportunity.\nBenefits\nINTRACOM TELECOM provides an excellent working environment which encourages team spirit, cooperation and continuous learning, in which the career prospects depend on each employee\u2019s performance. Remuneration is competitive and aligned with the company\u2019s credo \u201cour competitive advantage is our human capital\u201d.\nFurther, the facility of a company bus is convenient for every employee.\nEducation and continuous personal improvement constitute major priorities for the company to keep abreast with the technology evolution and maintain the high growth rate and its strategic position.\nOur company applies policies for equal opportunities irrespective of caste, national origin, religion, disability, gender, sexual orientation, union membership, political affiliation or age.","120":"Descripci\u00f3n de la empresa\n\u00bfApasionad@ de lo digital, los datos, el IoT o la IA y con ganas de ayudar a un equipo din\u00e1mico y ambicioso a escala humana?\u202f \nLlevamos m\u00e1s de 15 a\u00f1os asesorando a empresas y administraciones y acompa\u00f1\u00e1ndolas en la puesta en marcha de sus proyectos de transformaci\u00f3n en Francia y en el extranjero.\u202f\u202f\u202f \nPara ello, nos apoyamos tanto en el apalancamiento tecnol\u00f3gico como en la fuerza de nuestro ADN basado en la inteligencia colectiva, la agilidad y el esp\u00edritu emprendedor.\u202f\u202f\u202f \nPresentes en los cinco continentes y con m\u00e1s de 5.000 empleados, nuestro objetivo es superar los 1.000 millones de euros de ingresos en 2024. La innovaci\u00f3n est\u00e1 en el centro de nuestro desarrollo y participamos en \u00e1reas vinculadas a los cambios tecnol\u00f3gicos de los grandes grupos, como Big Data, IoT, Blockchain e Inteligencia Artificial.\u202f\u202f \nNuestros valores:\nInteligencia colectiva\u202f \nAgilidad\u202f \nEmprendimiento \/ Intrapreneurship\u202f \nPromoci\u00f3n de la diversidad\nCompromiso (empleados, socios, escuelas, asociaciones...)\u202f\u202f \nRespeto del ser humano y calidad de vida en el trabajo\u202f\u202f \nApertura de esp\u00edritu e inclusi\u00f3n\nDescripci\u00f3n del empleo\nComo Junior Big Data Developer, tu misi\u00f3n ser\u00e1 contribuir a la transformaci\u00f3n y evoluci\u00f3n continua de plataformas\nNecesitamos a alguien como t\u00fa para ayudarnos en diferentes frentes:\nTrabajar activamente en la optimizaci\u00f3n del software y la eficiencia de los procesos.\nTrabajar en el dise\u00f1o t\u00e9cnico para que las soluciones puedan cumplir con la arquitectura de referencia\nProponer dise\u00f1os de software para aplicaciones o componentes aplicando est\u00e1ndares, patrones y herramientas acordadas.\nContribuye a los requisitos t\u00e9cnicos de todos los productos\/funciones.\nRequisitos\nJava \/ Javascript\nConocimientos en distintas bases de datos (Oracle, postgre..)\nGithub\nJenkins\nDrools\nKafka\nMicroservicios (Spring Boot) \u2013 Openshift\nMetodolog\u00eda agile y herramientas: Jira, Confluence,\u2026\nActitud de ideas estrat\u00e9gicas y de innovaci\u00f3n para afrontar todo tiempo de situaciones\nDeseable: S3 , Elastic ,Angular y Flink\nEspa\u00f1ol e ingl\u00e9s flu\u00eddos\nInformaci\u00f3n adicional\nSi has le\u00eddo hasta aqu\u00ed y tienes ganas de sumarte a este reto, no dudes en aplicar... estaremos encantados de conocerte!!!","121":"Unternehmensbeschreibung\nBei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch.\nDie Robert Bosch GmbH freut sich auf Deine Bewerbung!\nStellenbeschreibung\nIm Gesch\u00e4ftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen \u2013 von hocheffizienten Antrieben \u00fcber das erste serienreife ABS f\u00fcrs Pedelec bis hin zu smarten Connectivity-L\u00f6sungen. F\u00fcr eine nachhaltige Mobilit\u00e4t, die Spa\u00df macht.\nDu bist Expert:in f\u00fcr den Bereich Data Engineering bei Bosch eBike Systems und stellst die relevanten Daten den Nutzern unserer Cloud-basierten Datenplattform zur Verf\u00fcgung.\nDu programmierst gerne und beherrschst Python und SQL. Zu Deinem Repertoire z\u00e4hlen au\u00dferdem ausgepr\u00e4gte Kenntnisse \u00fcber die performante Verarbeitung und Speicherung gro\u00dfer Datenmengen sowohl in Data Lakes als auch in Data Warehouse Systemen.\nIm Rahmen Deiner T\u00e4tigkeit f\u00fchrst Du Code-Reviews durch und definierst Best Practices und Leitplanken f\u00fcr die Entwicklung von Data Pipelines. \nWir unterst\u00fctzen Dich, damit Du Deine Kreativit\u00e4t in dem Bereich entfalten kannst und bieten Design Reviews mit anderen erfahrenen Kolleg:innen und Interessengruppen an.\nDu baust Deine Data Pipelines robust und mit einem hohen Fokus auf Observability, um eine einfache Fehleranalyse zu erm\u00f6glichen.\nZudem \u00fcbernimmst Du Verantwortung f\u00fcr deine entwickelten Daten Pipelines auch w\u00e4hrend des Betriebs und entwickelst diese kontinuierlich weiter, um eine optimale Qualit\u00e4t und Zuverl\u00e4ssigkeit sicherzustellen.\nDu hast Spa\u00df daran, dein Wissen weiterzugeben und agierst als Mentor:in f\u00fcr Junior Kolleg:innen im Team. Es macht Dir Spa\u00df mit dem Daten-Team, den Fachbereichen, der IT und den Kolleg:innen im fachlichen Diskurs die beste L\u00f6sung zu identifizieren.\nQualifikationen\nAusbildung: abgeschlossenes Hochschulstudium (Master\/Diplom\/Promotion) der Wirtschaftsinformatik oder eines vergleichbaren Studienganges\nPers\u00f6nlichkeit und Arbeitsweise: kommunikativ, selbstreflektiert, getting-things-done-Mindset, stetig lernbereit, Interesse f\u00fcr Innovationen im Arbeitsgebiet, eigenverantwortlich, l\u00f6sungs- und kundenorientiert, pragmatisch und problembewusst\nErfahrungen und Know-how: 5 Jahre Berufserfahrung als Data Engineer sowie Erfahrung im Aufbau von zuverl\u00e4ssigen Data Pipelines; Erfahrung in der agilen Softwareentwicklung (SCRUM, Kanban) und Erfahrung in der Datenmodellierung sowie in unterschiedlichen Ans\u00e4tzen f\u00fcr Daten Architekturen; Erfahrung im\nArbeiten in multinationalen Teams\nKnow-How: Breites Wissen \u00fcber unterschiedliche Technologien im Bereich Big Data Engineering (z.B. Databricks \/Spark, Snowflake, Apache Airflow, dbt, Kafka) sowie fundierte Kenntnisse in relevanten Programmiersprachen (Python, SQL, Scala) und CI\/CD (Gitlab CI\/CD, Jenkins); Au\u00dferdem Kenntnisse der Daten-Analyse, des Daten-Managements und der Softwareentwicklung\nBegeisterung: Spa\u00df daran, Wissen an andere zu vermitteln\nSprachen: sehr gute Deutsch- und Englischkenntnisse in Wort und Schrift\nZus\u00e4tzliche Informationen\nIn diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente.\n\nBewirb Dich jetzt in nur 3 Minuten!\nDu m\u00f6chtest Remote oder in Teilzeit t\u00e4tig sein - wir bieten tolle M\u00f6glichkeiten des mobilen Arbeitens sowie unterschiedliche Teilzeitmodelle. Sprich uns gerne dazu an.\nDu hast Fragen zum Bewerbungsprozess?\nNelly Ehrmann (Personalabteilung)\n+49 711 811 27525\nDu hast fachliche Fragen zum Job?\nDaniel Grimm (Fachabteilung)\n+49 7121 35 18668\nInteressierst Du Dich f\u00fcr diese oder weitere Stellen?\nDann bewerbe Dich auf die Virtual JobFair@BOSCH und verschaffe Dir einen \u00dcberblick \u00fcber die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de\/events\/                                        ","122":"Company Description\nWe help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.\nJob Description\nCustomer Experience  - Visualization Analyst (Power BI)\nResponsible for working with our business partners to create Power BI dashboards which help drive business decisions.\nModel the data by writing SQL queries\/Python codes to support dashboard requirements.\nHelp the team in enhancing existing dashboards.\nWorking with business partners to increase dashboards usage.\nGathers and analyzes data and develops architectural requirements at project level.\nResearches and evaluates emerging visualization technology, industry and market trends to create a long term roadmap for dashboards.\nCoaches and mentors team members.\nLong term development and Technical expertise in DW\/BI Practice, communicate well with all stakeholders, optimize objectives, leverage state of the art tools and best practices, integrate into corporate systems and deliver on time.\nShould have independently worked on designing and launching dashboards.\nQualifications\nSkills Required\nA minimum of 2-4 years of experience in data architecture and Modeling\nA Minimum of 2 years of experience on Power BI tool.\nDeep understanding in Dimensional Modelling, Data Analysis, Data Conversion\/Transformation and Database Design etc.\nKnowledge of SQL language is mandatory (python will be preferred).\nAdditional Information\nAt the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.\u202f  \nOur global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.  \nBut why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.  \nIt\u2019s the reason Verisk is part of the UN Global Compact sustainability initiative. It\u2019s why we made a commitment to balancing 100 percent of our carbon emissions. It\u2019s the aim of our \u201creturnship\u201d program for experienced professionals rejoining the workforce after time away. And, it\u2019s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers\u2019 problems.\u202f  \nAt its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do. \nAt Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career.\u202fWe have received the Great Place to Work\u00ae Certification for the fifth consecutive year. We\u2019ve been recognized by Forbes as a World\u2019s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.  Verisk\u2019s Statement on Racial Equity and Diversity supports our commitment to these values and affecting positive and lasting change in the communities where we live and work.  \nVerisk Analytics is an equal opportunity employer.\nAll members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and\/or expression, sexual orientation, veteran's status, age or disability.\nhttp:\/\/www.verisk.com\/careers.html\nUnsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume. \nConsumer Privacy Notice\nAt Verisk, the health and safety of our people is our number one priority.  Effective November 15, 2021, and subject to applicable law, all prospective hires for office based roles or roles that support any of our businesses\u2019 government contracts will be required to demonstrate that they are fully vaccinated against COVID-19 by their start date, or qualify for a legally-required medical or religious accommodation to this vaccination requirement, as a condition of employment. Hired candidates who do not demonstrate that they are fully vaccinated against COVID-19 by their start date, and who have not been approved for a legally-required medical or religious accommodation will no longer meet the requirements for employment and their offers of employment will be immediately rescinded, in accordance with applicable law.","123":"We partner with the world\u2019s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency.\nWe are looking for engineers who are passionate about data and DevOps eager to tackle big challenges using cloud and modern data processing technologies to be part of our team!\nYour mission: The main focus of this role is to solve non-trivial data engineering problems. This person will mostly work with a mix of structured and unstructured and use cloud and other state-of-the-art techniques and tools to help our customers achieve their business goals.\nWe are looking for someone who has experience with:- Analysing and organising raw data- Intellectual curiosity to find new and unusual ways how to solve data management issues - Defining, building, and delivering high-quality data pipelines - Experience with Cloud as Azure, AWS, or GCP when it comes to infrastructure design and setup- Technical expertise with data models, data mining, and segmentation techniques- Hands-on experience with SQL database design- Analytics services- Familiarity with MSSQL- Ability to write\/maintain custom scripts (powershell \/ bash \/ python)- Experience with DBT is a plus- Advanced oral and written communication skills in English. \nOur benefits:\n- Competitive Salary- Generous paid vacation days- Unlimited sick time- 100% paid health & dental benefits starting day one- Annual profit-sharing distribution- Retirement match- Paid parental leave- Dedicated career advisor- And so much more\u2026\n\n#LI-MR4#Midsenior\nCI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters\u2019 identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow.\nAt CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas.\nWe strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies.","124":"Are you inspired by invention? Is problem solving through teamwork in your DNA? Do you like the idea of seeing how your work impacts the bigger picture? Answer yes to any of these and you\u2019ll fit right in here at Amazon Robotics. We are a smart team of doers who work passionately to apply cutting edge advances in robotics and software to solve real-world challenges that will transform our customers\u2019 experiences. We invent new improvements every day. We are Amazon Robotics and we will give you the tools and support you need to invent with us in ways that are rewarding, fulfilling, and fun.\n\nAmazon Robotics empowers a smarter, faster, more consistent customer experience through automation. Amazon Robotics automates fulfillment center operations using various methods of robotic technology including autonomous mobile robots, sophisticated control software, language perception, power management, computer vision, depth sensing, machine learning, object recognition, and semantic understanding of commands. Amazon Robotics has a dedicated focus on research and development to continuously explore new opportunities to extend its product lines into new areas.\n\nAmazon Robotics co-op opportunities will be based out of the Greater Boston Area in our two state-of-the-art facilities in Westborough, MA and North Reading, MA. Both campuses provide a unique opportunity to have direct access to robotics testing labs and manufacturing facilities.\n\nAmazon Robotics (AR) is looking for a motivated Business Intelligence Engineer Co-op to analyze data sets, build dashboards, and deliver business reports focused on AR network performance. A successful intern candidate will be able to identify the right datasets for the problem statement and develop data visualizations in Tableau. They will incorporate data management fundamentals, and statistical analyses, and provide insights from the performance data of AR\u2019s robotics solutions across the Amazon network. While we don't assume mastery in all areas, successful team members have the willingness to learn new skills and the ability to effectively communicate with and influence decision-makers at all levels. Candidates should have experience in business analytics, data science, data visualization, and\/or data engineering. Amazon Robotics\u2019 culture encourages innovation and expects co-ops to take a high level of ownership in solving complex problems.\n\nKey job responsibilities\nThe BIE Co-op will be responsible for:\nOwn the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to support analytical and business needs\nWrite queries to pull data needed with standard query syntax; periodically identify more advanced methods of query optimization. Convert data to make it analysis-ready\nDesign, implement, and support platforms that provide business teams ad-hoc access to large datasets (e.g. data visualization tools for non-tech business users)\nRecognize and adopt best practices in reporting and analysis: data integrity, design, analysis, validation, and documentation\n\n\n\n\nAbout the team\nThe Performance and Insights Team at Amazon Robotics (AR) is responsible to monitor and examine the network performance of all AR products, across all customers and businesses. The Product Analysts, BIEs, and Date Engineers on our team work collaboratively leveraging their deep product experience and operational knowledge to generate insights on the health, status, and adoption of AR products and systems in field. As the new products mature into the General Availability phase, our Performance team will assume the responsibility for network level systems performance monitoring, reporting, and generating insights for AR and customer leadership.\nBasic Qualifications\n\nBasic Qualifications for the BIE Co-op role:\nCurrently enrolled in a Master\u2019s in an analytically rigorous field (Data Science, Statistics, Computer Science, Industrial Engineering, Econometrics) or other equivalent discipline\nMust graduate after May 2024\/June 2024\nMust be eligible and available for a full-time (40h \/ week) 6-month internship\/co-op\nExperience building dashboards in Tableau or other relevant data visualization tool (Looker, PowerBI, Grafana, etc.)\nWrite high-quality SQL queries to retrieve and analyze complex datasets\nBasic understanding of Python, R or other relevant scripting language\nExperience using quantitative methods to evaluate product\/system\/service performance\nDemonstrated ability to communicate effectively across stakeholder groups\n\n\nPreferred Qualifications\nUnderstanding of ETL processes\nPrevious experience or interest in business intelligence, data engineering, system engineering or operations engineering\nKnowledge of AWS (e.g Datalake, Athena, Sagemaker, S3, EC2, RDS)\nQuantitative and qualitative data analysis experience with demonstrated impact to a project or business use case, a track record of creative problem solving, and the desire to create and build new processes\n\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https:\/\/www.amazon.jobs\/en\/disability\/us.","125":"We\u2019re on the lookout for the curious, those who think big and want to define the world of tomorrow. At Amazon, you will grow into the high impact, visionary person you know you\u2019re ready to be. Every day will be filled with exciting new challenges, developing new skills, and achieving personal growth.\n\nHow often can you say that your work changes the world? At Amazon, you\u2019ll say it often. Join us and define tomorrow\n\nDo you enjoy solving complex problems and troubleshooting products? Are you passionate about developing test strategies, finding, and tracking bugs to resolution, and innovating on behalf of customers? Do you want to be a part of a fast-paced, ambiguous environment and contribute to one of the most visited sites on the Internet?\n\nAt Amazon, we hire the best minds in technology to innovate on behalf of our customers. The intense focus we have on our customers is why we are one of the world\u2019s most beloved brands \u2013 customer obsession is part of our company DNA. Business intelligence engineers use cutting-edge technology to solve complex problems and get to see the impact of their work first-hand.\n\nThe challenges business intelligence engineers solve for at Amazon are big and affect millions of customers, sellers, and products around the world. Our path is not always simple, so we are selective about who joins us on this journey. There is a certain kind of person who takes on this role at Amazon \u2013 someone who is excited by the idea of creating new products, features, and services from scratch while managing ambiguity and the pace of a company whose ship cycles are measured in weeks, not years.\nThe Amazon EU Student Programs Team are looking for ambitious students to join us as interns at the heart of our core consumer business! Internships are flexible in length to fit in with your university\u2019s placement scheme.\n\n\nKey job responsibilities\nDevelop analytical solutions to business problems that utilize the highest standards of analytical rigor and data integrity\nRecognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation\nWrite high quality code to retrieve and analyze data\nAnalyze and solve business problems at their root, stepping back to understand the broader context\nDesign pragmatic analyses and automated metrics that add value to your business area\nUnderstand data resources and how, when, and what to use (and what not to use).\nDevelop analyses (whether fully formed or exploratory) for the business\u2019 sake, not for analyses\u2019 sake\nSeek to understand the business objectives relevant to your area, and align your work to those objectives and seek to deliver business value\nProactively and continually, improve your level of knowledge about Amazon\u2019s business and relevant data resources\n\n\nA day in the life\nOur Business Intelligence Engineer builds data pipelines, reports, dashboards, and analyses to deliver metrics and insights to the business.\nOur Business Intelligence Engineers tackle some of the most complex challenges in large scale\ncomputing, work in small teams across the company to contribute to the e-commerce platform that's used by millions of people all over the world. With that in mind, we require applicants to demonstrate their technical skills in a number of areas.\n\n\nAbout the team\nIf you\u2019re insatiably curious and always want to learn more, then you\u2019ve come to the right place. Depending on your location, country, job status and other requirements, some or all of the following benefits may be available to you as an intern.\nCompetitive pay\nImpactful project and internship\/role deliverables\nHybrid working (team dependent)\nNetworking opportunities with fellow interns\nInternships events such as speaker series, intern panels, Leadership Principles sessions, Amazon writing skills sessions.\nMentorship and career development\n\nIf you\u2019re successful during your internship, you could be considered for a graduate role after finishing your university studies.\n\nInternship start dates vary throughout the year.\nInternship length is ideally 6 months.\n\nWe are committed to diversity, equity, and inclusion, and leveraging our unique perspectives to scale our impact and grow. Amazon has 13 affinity groups (https:\/\/www.aboutamazon.com\/affinity-groups), sometimes known as employee resource groups, which bring employees together across businesses and locations around the world. With executive and company sponsorship, these groups play an important role in building internal networks for creating a community, advising Amazon business units, leading in service projects, and reaching out to communities where Amazonians live and work.\nWant to know more about our opportunities? Visit our EMEA Student Programs Team Events page to register for one of our upcoming events: https:\/\/amazonstudentevents.splashthat.com\/careers\nBasic Qualifications\n\nCurrently enrolled in a Bachelor\u2019s or Master\u2019s degree program in computer engineering, computer science, or a similar technical field\nAvailability to complete ideally a 6 months + internship working full time week\nAdvanced knowledge and\/or experience using SQL\nExperience with data querying or modelling with SQL, Excel\nExperience with scripting language (e.g., Python, Java, or R)\nKnowledge of BI analytics\/reporting\/visualization tools (e.g., Tableau, AWS QuickSight, COGNOS, or other third-party tools)\n\n\nPreferred Qualifications\nMaster\u2019s or advanced technical degree\nExperience with BI analytics\/ reporting\/visualization tools (e.g., Tableau, AWS QuickSight, COGNOS, or other third-party tools)\nExperience in data mining, data warehouse solutions, and ETL, and using databases in a business environment with large-scale, complex datasets\nKnowledge of algorithm design and complexity analysis\nAbility to deal with ambiguity in a fast-paced environment\nExcellent verbal\/written communication skills and data presentation skills\n\n\n\n\n\nAmazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https:\/\/www.amazon.jobs\/en\/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.","126":"Company Description\n\u00bfApasionad@ de lo digital, los datos, el IoT o la IA y con ganas de ayudar a un equipo din\u00e1mico y ambicioso a escala humana?\u202f \nLlevamos m\u00e1s de 15 a\u00f1os asesorando a empresas y administraciones y acompa\u00f1\u00e1ndolas en la puesta en marcha de sus proyectos de transformaci\u00f3n en Francia y en el extranjero.\u202f\u202f\u202f \nPara ello, nos apoyamos tanto en el apalancamiento tecnol\u00f3gico como en la fuerza de nuestro ADN basado en la inteligencia colectiva, la agilidad y el esp\u00edritu emprendedor.\u202f\u202f\u202f \nPresentes en los cinco continentes y con m\u00e1s de 5.000 empleados, nuestro objetivo es superar los 1.000 millones de euros de ingresos en 2024. La innovaci\u00f3n est\u00e1 en el centro de nuestro desarrollo y participamos en \u00e1reas vinculadas a los cambios tecnol\u00f3gicos de los grandes grupos, como Big Data, IoT, Blockchain e Inteligencia Artificial.\u202f\u202f \nNuestros valores:\nInteligencia colectiva\u202f \nAgilidad\u202f \nEmprendimiento \/ Intrapreneurship\u202f \nPromoci\u00f3n de la diversidad\nCompromiso (empleados, socios, escuelas, asociaciones...)\u202f\u202f \nRespeto del ser humano y calidad de vida en el trabajo\u202f\u202f \nApertura de esp\u00edritu e inclusi\u00f3n\nJob Description\nComo Junior Big Data Developer, tu misi\u00f3n ser\u00e1 contribuir a la transformaci\u00f3n y evoluci\u00f3n continua de plataformas\nNecesitamos a alguien como t\u00fa para ayudarnos en diferentes frentes:\nTrabajar activamente en la optimizaci\u00f3n del software y la eficiencia de los procesos.\nTrabajar en el dise\u00f1o t\u00e9cnico para que las soluciones puedan cumplir con la arquitectura de referencia\nProponer dise\u00f1os de software para aplicaciones o componentes aplicando est\u00e1ndares, patrones y herramientas acordadas.\nContribuye a los requisitos t\u00e9cnicos de todos los productos\/funciones.\nQualifications\n2 a\u00f1os de experiencia en el Desarrollo de Software\nS\u00f3lida experiencia en el desarrollo de tecnolog\u00edas Big Data, especialmente Spark y Scala.\nConocimientos en entornos Cloud Computing. \nConocimientos tecnol\u00f3gicos a tener en cuenta: Python, API JSON, RDBMS (postgresql, MySQL o MairaDB), Docker, Kafka, Jenkins, ElasticSearch.\nGarantizar la calidad del software: integraci\u00f3n continua y automatizaci\u00f3n de pruebas.\n Metodolog\u00edas y herramientas \u00e1giles: Jira, Confluence, GIT\nAdditional Information\nSi has le\u00eddo hasta aqu\u00ed y tienes ganas de sumarte a este reto, no dudes en aplicar... estaremos encantados de conocerte!!!","127":"Company Description\nPublicis Media harnesses the power of modern media through global agency brands Performics, Spark Foundry, Starcom and Zenith. A key business solution of Publicis Groupe ([Euronext Paris FR0000130577, CAC 40], Publicis Media\u2019s digital-first, data-driven global practices deliver client value and drive growth in a platform-powered world. It is present in more than sixty countries with over 23,000 employees worldwide.\nJob Description\nWe are seeking a driven individual with a proven track record of scalable and innovative business intelligence solutions. He\/she shines when serving as a consultant to the business and is genuinely interested in understanding the objectives of complex and evolving projects. In this role, you will champion and advocate the use of Alteryx and Tableau to create an environment of self-service analytics. The candidate must be a self-starter with a sense of urgency and a commitment to quality and professionalism.\n Responsibilities:\nAnalyze business needs and partner with stakeholders to provide a strategic solution\nWork independently on end to end solutions, from data analysis to ETL design and development through to the final visual dashboard\nCollaborate across the organization to build solutions that achieve business objectives\nGuide stakeholders with operational decisions that impact data structures and connectivity\nBring best practices in data architecture and data visualization to the table\nBuild tools in a generic fashion for reuse across other solutions\nDevelop technical documentation for each solution\nManage projects in an agile environment\nQualifications\nMinimum Bachelor\u2019s Degree in Computer Sciences, Information Technology, or its equivalent\n3+ years\u2019 experience with Tableau\n1+ years\u2019 experience with AWS core+ services (EC2, S3, Lambda, Redshift, Glue)\n1+ years\u2019 experience with Python\n3+ years\u2019 experience with data visualization\nComfortable with data warehousing concepts, preparing data, and configuring automated workflows\nExcellent communication and presentation skills as well as an analytical mindset\nExperience with complex logic\nStrong data analysis skills\nExperience connecting and merging disparate datasets\nStrong organizational skills & attention to detail\nPossess a desire to work for a fast-paced, results-based company\nExperience managing multiple projects simultaneously\n Desired Skills\/Experience:\nExperience with media and ad tech platforms (Ad Servers, Media Planning and Buying systems, DSP\u2019s, Programmatic, etc)\nSQL\nAdobe Site Catalyst\nGoogle Analytics\nBasic knowledge of ETL, data modeling, data warehouse, extracting and manipulating large record of data\n Additional Information\nAll your information will be kept confidential according to EEO guidelines.\n ","128":"Company Description\nOur culture is defined by our values and our deep commitment to help our clients succeed. We are a division of the 38th largest company in the world and bring to bear the strength of a very large network of interconnected Hitachi companies. At the same time we remain absolutely committed to the nimble agility that helped us grow Hitachi Solutions from three founding partners to nearly 2,000 consultants, developers and support personnel all around the globe.\nHitachi Solutions is a leader in providing industry solutions based on Microsoft Dynamics AX and Microsoft Dynamics CRM. Hitachi Solutions provides its customers with industry focus, software industry domain expertise, and proven tier-1 people. Hitachi Solutions works with its customers to understand their unique formula for success and develops solutions that improve their business and attain measurable results.2011, 2009, 2006 & 2005 Microsoft Dynamics Partner of the Year (Finalist 2008, 2007). Microsoft Global Dynamics Award (Global Dynamics Partner of the year) 2014. \nHitachi Solutions is a core IT company of the Hitachi Group, which employs some 400,000 people worldwide. Through systems integration, we provide ideal solutions and products for customers. Headquartered in Tokyo, Japan, Hitachi Solutions' reach extends to group companies in Japan and abroad, working with a worldwide network of alliance partners. We bring solutions and products to diverse countries and regions including Asia, the United States and Europe. The flagship company in the Hitachi Group's information and communication system solutions business, Hitachi Solutions also offers solutions for social innovation such as smart cities.  \nFor more information on Hitachi Solutions, please visit: https:\/\/web.hitachi-solutions.com\nJob Description\nRequirements:\nA minimum of 5+ years full-time experience using VertiPaq\nAble to quickly provide both M and DAX solutions\nHands-on experience working in Business Intelligence, Data Engineering or Data Science\nUnwavering ability to quickly propose solutions by recalling the latest best practices learned from MVP & Product Team articles, MSFT documentation, whitepapers, and community publications\nA passion for understanding and integrating business semantics into technology solutions\nExcellent communication, presentation, influencing, and reasoning skills\nAbility to lead projects\nFamiliarity with the Azure data platform, e.g., ADLS, SQL Server, ADF, Databricks etc.\n We would like to see a blend of the following technical skills:\nInformation Design\nDAX, M, PowerShell, and T-SQL\nVertiPaq and MashUp engine knowledge\nPower BI Desktop, Power BI Dataflows, Tabular Editor, DAX Studio, and VertiPaq Analyzer\nPower BI Service architecture design and administration\nData modelling using the Kimball methodology","129":"Description de l'entreprise\nDans un monde o\u00f9 savoir se transformer est la cl\u00e9 du succ\u00e8s, Wavestone s\u2019est donn\u00e9 pour mission d\u2019\u00e9clairer et guider les grandes organisations dans leurs transformations les plus critiques. Des transformations qui visent \u00e0 r\u00e9pondre aux grands enjeux strat\u00e9giques auxquels elles vont faire face dans les ann\u00e9es \u00e0 venir : l\u2019acc\u00e9l\u00e9ration de la r\u00e9volution num\u00e9rique, l\u2019intensification de la concurrence, ou encore la prise en consid\u00e9ration de l\u2019urgence climatique. \nLe cabinet poss\u00e8de des comp\u00e9tences sectorielles centr\u00e9es sur le c\u0153ur de m\u00e9tier de ses clients, des comp\u00e9tences technologiques parmi les plus pointues tant sur le digital, les syst\u00e8mes d\u2019information qu\u2019en mati\u00e8re de cybers\u00e9curit\u00e9, et des comp\u00e9tences en d\u00e9veloppement durable. Wavestone se distingue dans sa capacit\u00e9 \u00e0 conjuguer \u00e9troitement toutes ces comp\u00e9tences, sans couture, au sein d\u2019\u00e9quipes pluridisciplinaires afin d\u2019apporter une r\u00e9ponse \u00e0 360\u00b0, en phase avec les grands enjeux auxquels sont confront\u00e9s ses clients. \nLe cabinet r\u00e9alise un chiffre d\u2019affaires de l\u2019ordre de 470 M\u20ac et rassemble pr\u00e8s de 4 000 collaborateurs en Europe \u2013 o\u00f9 il figure parmi les leaders ind\u00e9pendants du conseil \u2013 aux Etats-Unis et en Asie. \nWavestone est cot\u00e9 sur Euronext \u00e0 Paris et labellis\u00e9 Great Place To Work.\nPour plus d'informations, consulter www.wavestone.com\nDescription du poste\nContexte \nForte de plus de 400 consultants, la Practice Digital Customer a pour vocation d\u2019accompagner nos clients \u00e0 basculer dans le digital en designant et d\u00e9veloppant de nouvelles offres (produits, services...) afin de cr\u00e9er l\u2019exp\u00e9rience du consommateur digital de demain. DC combine une profonde connaissance de l\u2019industrialisation des produits digitaux avec une grande expertise sur la cha\u00eene de valeur de bout en bout. Nous embarquons les parties prenantes cl\u00e9 autour de grands programmes de transformation, afin de cr\u00e9er l\u2019organisation agile de demain et d\u2019encourager l\u2019\u00e9mergence de nouvelles offres.  \nObjectif du stage \nDans le cadre de votre stage, vous serez int\u00e9gr\u00e9.e activement \u00e0 la communaut\u00e9 \u00ab Data, Analytics & IA \u00bb de la practice Digital Customer afin de participer \u00e0 la formalisation de ses convictions, \u00e9toffer sa force de veille technologique, dynamiser son activit\u00e9 commerciale aupr\u00e8s des clients du cabinet, et d\u2019aboutir \u00e0 la production de supports commerciaux ou de livrables de missions. \nAu sein de cette communaut\u00e9, notre \u00e9quipe BI & Dataviz regroupe les savoir-faire cl\u00e9s permettant d\u2019accompagner les entreprises \u00e0 valoriser leurs donn\u00e9es : strat\u00e9gie de valorisation de la donn\u00e9e, r\u00e9alisation de rapports et tableaux de bord BI, transformation des usages data des collaborateurs (acculturation \u00e0 la donn\u00e9e, formation...).  \nTravaux \u00e0 r\u00e9aliser \nLes th\u00e9matiques abord\u00e9es lors du sujet de stage sont les suivantes\u202f:  \nCr\u00e9ation de rapports d\u2019analyse de donn\u00e9es : cadrage et r\u00e9alisation de rapports et tableaux de bord, d\u00e9finition des bonnes pratiques de data storytelling, d\u00e9finition de bonnes pratiques UX et\/ou techniques pour utiliser les outils phares du march\u00e9...  \nFormation & knowledge management : r\u00e9alisation et dispensation de formations li\u00e9es \u00e0 la DataViz, benchmark des bonnes pratiques associ\u00e9es aux principaux outils du march\u00e9, r\u00e9alisation de webinars... \nStrat\u00e9gie BI : d\u00e9finition des bonnes pratiques pour tirer profit de la BI, benchmark des solutions phares du march\u00e9... \nVous aurez \u00e9galement l\u2019opportunit\u00e9 de d\u00e9velopper votre expertise en suivant des formations, dispens\u00e9es par nos consultants ou des partenaires, mais aussi en auto-formation via l'acc\u00e8s \u00e0 de nombreuses plateformes de e-learning & Moocs. \nNous vous donnons la possibilit\u00e9 de participer activement \u00e0 la vie interne du cabinet \u00e0 travers : \nDes contributions au sein du cercle d'expertise BI&Dataviz \nLa publication d'articles sur nos blogs et r\u00e9seaux sociaux \nL'appuis \u00e0 la capitalisation des savoirs \nLa veille sur les sujets BI&dataviz \nLa r\u00e9daction de convictions et la cr\u00e9ation d'acc\u00e9l\u00e9rateurs missions \nLa participation commerciale \u00e0 la r\u00e9ponse aux appels d'offre \nL'animation du r\u00e9seau Wavestone international BI&Dataviz \nMais aussi des contributions plus large \u00e0 envergure practice ou Cabinet : \nLe d\u00e9veloppement de nos Assets : Shake 'up, Cr\u00e9aDesk, Machine Learning & Data Lab, Research & Knowledge Center \nLa contribution au recrutement, relations \u00e9coles, formations internes, \u00e9v\u00e9nements internes \nLa participation \u00e0 la strat\u00e9gie RSE de Wavestone \nEn parall\u00e8le, vous participerez \u00e0 une ou plusieurs missions de conseil aupr\u00e8s de nos clients, en \u00e9tant int\u00e9gr\u00e9 dans une \u00e9quipe de consultants plac\u00e9e sous la responsabilit\u00e9 d\u2019un directeur de mission. \nInformations suppl\u00e9mentaires\nWavestone est un employeur inclusif qui s'engage pour l'\u00e9galit\u00e9 des chances. Dans le cadre de cette politique de diversit\u00e9 et inclusion, Wavestone accompagne les personnes en situation de handicap et\/ou n\u00e9cessitant un am\u00e9nagement durant leur process de recrutement et tout au long de leur prise de poste.","130":"About Us\nRiskified empowers merchants and shoppers to realize the full potential of eCommerce by making it safe, accessible, and frictionless. Our global team helps the world\u2019s most-innovative eCommerce merchants eliminate risk and uncertainty from their business. Merchants integrate Riskified\u2019s machine learning platform to create trusted customer relationships, driving higher sales while reducing costs. Riskified has reviewed hundreds of millions of transactions and approved billions of dollars of revenue for global brands and fast-growing businesses across industries, including Wayfair, Wish, Peloton, Gucci, and many more. As of July 29th, 2021, Riskified has begun trading on NYSE under the ticker RSKD.\nAbout the Role\nAs a BI Developer, you will be responsible for providing analytical support across the organization to enable data-driven decision making and promote strategic planning. You will also deliver an improved understanding of the company\u2019s various metrics to allow for better short and long term forecasting and planning. You will develop close working relationships with various teams including Analytics & Research, Finance, Sales, Marketing, and more.\nWhat You'll Be Doing\nWork with various teams to define key metrics (KPIs) and provide the methodologies to accurately measure Riskified\u2019s performance\nCreate new ETL processes and optimize existing ones\nCreate smart, innovative and effective visualization methods, and promote engagement and implementation of them\nBe the main point of contact for technical support related to BI activity for various teams within Riskified\nQualifications\nMinimum 2 years experience in a BI position - must \nKnowledge in DWH design - must\nExperience in developing ETL processes - must\nExperience with BI tools such as Tableau, Looker or similar - must\nExperience with databases - must\nExperience with scripting languages - an advantage\nExperience with BI system analysis - an advantage\nBachelor\u2019s Degree in Science\/Data Systems Management\/Industrial Engineering and Management\nGood comprehension of data, and how to tell the story behind it\nLife at Riskified\nWe are a fast-growing and dynamic tech company with 750+ team members globally. We value collaboration and innovative thinking. We\u2019re looking for bright, driven, and passionate people to grow with us.\nCOVID-19 Update: \nOur Tel-Aviv team is currently working in a hybrid of remote and in-office work for all our team members. We have recently moved to our new space in Tel Aviv - check it out here! \nSome of our Tel Aviv Benefits & Perks:\nEquity for all employees, Keren Hishtalmut, pension\nPrivate medical insurance, extra time off for parents and caregivers\nCommuter and parking benefits\nTeam events, fully-stocked kitchen,lunch stipend, happy hours, yoga, pilates, functional training, basketball, soccer\nWide-ranging opportunities to volunteer and make an impact\nCommitment to your professional development with global onboarding, skills-based courses, full access to Udemy, lunch & learns\nAwesome Riskified gifts and swag! \nIn the News\nGeektime: Riskified Goes Public\nWalla!: Happy Hour at the Riskified Offices\nGeektime Insider: A look at Riskified Tel Aviv\nGlobes: Riskified to contribute the highest amount up to date to Tmura\nGlobes: Riskified is among Israel\u2019s fastest growing companies \nTechCrunch: Riskified Prevents Fraud on Your Favorite E-commerce Site\nRiskified is deeply committed to the principle of equal opportunity for all individuals. We do not discriminate based on race, color, religion, sex, sexual orientation, national origin, age, disability, veteran status, or any other status protected by law.","131":"Opis oferty pracy\nWide\u0142ki wynagrodzenia przewidziane przy tym stanowisku na umowie o prac\u0119 to: 16 100 - 23 200 PLN brutto.\nModel pracy hybrydowej wed\u0142ug ustale\u0144 lidera i zespo\u0142u.\nW ramach obszaru Data & AI realizujemy projekty oparte o praktyczn\u0105 aplikacj\u0119 \"data science\" i \"artificial intelligence\" o niespotykanej w Polsce skali. Data & AI to grupa ponad 100 do\u015bwiadczonych in\u017cynier\u00f3w BigData zorganizowanych w kilkana\u015bcie zespo\u0142\u00f3w o r\u00f3\u017cnych specjalizacjach. Cz\u0119\u015b\u0107 z nich buduje dedykowane narz\u0119dzia do tworzenia i uruchamiania przetwarza\u0144 BigData czy wdra\u017cania modeli ML dla ca\u0142ej organizacji. Inni pracuj\u0105 bli\u017cej klienta i odpowiadaj\u0105 za realizacj\u0119 silnika wyszukiwarki, tworzenie rekomendacji, budowania profilu kupuj\u0105cych czy rozw\u00f3j platformy eksperymentacyjnej. W obszarze s\u0105 te\u017c zespo\u0142y badawcze, kt\u00f3rych celem jest szukanie rozwi\u0105za\u0144 dla nietrywialnych problem\u00f3w wymagaj\u0105cych stosowania uczenia maszynowego.\nDo\u0142\u0105cz do nas!\nSzukamy programistek i programist\u00f3w Scala i Python, interesuj\u0105cych si\u0119 systemami rozproszonymi i przetwarzaniem danych, kt\u00f3re\/kt\u00f3rzy chc\u0105 poszerza\u0107 swoje kompetencje w tym obszarze. \nZupe\u0142nie si\u0119 nie przejmuj, je\u017celi nie masz do\u015bwiadczenia w technologiach Big Data. Gwarantujemy Ci, \u017ce szybko si\u0119 ich nauczysz od najlepszych in\u017cynier\u00f3w w Polsce pracuj\u0105c m.in. nad:\nSystemem zapewniaj\u0105cym mo\u017cliwo\u015b\u0107 materializacji event\u00f3w (kr\u0105\u017c\u0105cych pomi\u0119dzy mikroserwisami) do postaci umo\u017cliwiaj\u0105cej budowanie analiz za pomoc\u0105 narz\u0119dzi Big Data. Nasze codzienne wyzwania to skala ruchu, strukturyzacja informacji oraz streamowa synchronizacja zbior\u00f3w pomi\u0119dzy rozwi\u0105zaniami lokalnymi oraz \u015brodowiskiem public cloud\nRozproszonym systemem do zbierania informacji i analizy zachowa\u0144 klient\u00f3w Allegro. Przetwarzania batch: Spark + Airflow + BigQuery.\nProcesami agregacji metadanych, zintegrowanymi z platform\u0105 danych Allegro, kt\u00f3re maj\u0105 wspiera\u0107 narz\u0119dzia oraz procesy z zakresu: Data Quality, Data Lineage oraz Data Governance\nSzukamy os\u00f3b, kt\u00f3re:\nPotrafi\u0105 i lubi\u0105 programowa\u0107 w j\u0119zykach: Scala i Python\nMaj\u0105 do\u015bwiadczenie w ekosystemie Big Data (Hadoop, Spark, Kafka, Airflow, Druid, Terraform)\nDodatkowym atutem b\u0119dzie znajomo\u015b\u0107 GCP (Dataproc, Dataflow, BigQuery, Pubsub)\nStosuj\u0105 dobre praktyki (clean code, code review, TDD, CI\/CD)\nSprawnie poruszaj\u0105 si\u0119 w systemach z rodziny Unix\/Linux\nInteresuj\u0105 si\u0119 zastosowaniem ML\/AI\nChc\u0105 si\u0119 rozwija\u0107 i aktualizowa\u0107 swoj\u0105 wiedz\u0119\nZnaj\u0105 j\u0119zyk angielski na poziomie min. B2\nZe swojej strony oferujemy:\nModel pracy hybrydowej, kt\u00f3ry ustalisz z liderem i zespo\u0142em. Mamy \u015bwietnie zlokalizowane biura ( z w pe\u0142ni wyposa\u017conymi kuchniami i parkingami dla rower\u00f3w) i znakomite narz\u0119dzia pracy (podnoszone biurka, interaktywne sale konferencyjne)\nBonus roczny do 10% wynagrodzenia rocznego (zale\u017cny od Twojej oceny roczny oraz wynik\u00f3w firmy)\nBogaty pakiet \u015bwiadcze\u0144 pozap\u0142acowych w systemie kafeteryjnym \u2013 Ty decydujesz z czego korzystasz (do wyboru mamy m.in. pakiety medyczne, sportowe, lunchowe, ubezpieczenia, bony na zakupy)\nZaj\u0119cia angielskiego op\u0142acane przez nas i skoncentrowane na specyfice Twojej pracy\nLaptop z m1, 32GB RAM, SSD - MacBook Pro 16\u2019\u2019 lub 14\u2019\u2019 albo analogiczny Dell z Windows (je\u015bli nie lubisz Mac\u00f3w), do tego dwa zewn\u0119trzne monitory i wszystkie gad\u017cety, kt\u00f3rych potrzebujesz\nPrac\u0119 w zespole, na kt\u00f3rego wsparcie zawsze mo\u017cesz liczy\u0107 -  na pok\u0142adzie mamy najlepszych specjalist\u00f3w i ekspert\u00f3w w swojej dziedzinie\nDu\u017c\u0105 autonomi\u0119 w organizacji pracy zespo\u0142u, zach\u0119camy do ci\u0105g\u0142ego rozwoju i pr\u00f3bowania nowych rzeczy\nHackathony, turystyk\u0119 zespo\u0142ow\u0105, bud\u017cet szkoleniowy oraz wewn\u0119trzna platforma MindUp (m.in. szkolenia z zakresu organizacji pracy, sposobu komunikacji, motywacji do pracy oraz r\u00f3\u017cnych technologii i zagadnie\u0144 merytorycznych)\nJe\u015bli chcesz wiedzie\u0107 wi\u0119cej - sprawd\u017a sam\/a.\nDlaczego mia\u0142(a)by\u015b z nami pracowa\u0107?\n W Allegro zajmiesz si\u0119 przetwarzaniem petabajt\u00f3w danych i miliard\u00f3w zdarze\u0144 dziennie \nStaniesz si\u0119 uczestnikiem jednego z najwi\u0119kszych projekt\u00f3w budowania platformy danych w GCP\nTw\u00f3j rozw\u00f3j b\u0119dzie pod\u0105\u017ca\u0142 za najnowszymi trendami technologicznymi opartymi o open source \nPoza tym, zesp\u00f3\u0142 IT liczy ponad 1700+ os\u00f3b, kt\u00f3re dziel\u0105 si\u0119 wiedz\u0105 na wielu konferencjach, takich jak Big Data Technology Warsaw Summit, Warszawskie Dni Informatyki, Agile By Example, DevOps Days, Code Europe oraz wsp\u00f3\u0142tworz\u0105 bloga allegro.tech\nStosujemy Code Review, Continuous Integration, Scrum\/Kanban, Domain Driven Design, Test Driven Development, Pair Programming w zale\u017cno\u015bci od zespo\u0142u\nAutonomia technologiczna - wybierasz technologi\u0119, kt\u00f3ra pasuje do problemu (nie trzeba zgody wszystkich \u015bwi\u0119tych). Ty za ni\u0105 potem odpowiadasz\nPonad 100 autorskich projekt\u00f3w open source, kilka tysi\u0119cy gwiazdek na github\nOrganizujemy Allegro Tech Live, w 100% zdaln\u0105 ods\u0142on\u0119 naszych stacjonarnych meetup\u00f3w Allegro Tech Talks i wyst\u0119pujemy go\u015bcinnie na zaproszenie takich spo\u0142eczno\u015bci jak Warsaw AI, JUG (Pozna\u0144, \u0141\u00f3d\u017a, Lublin, Wroc\u0142aw), WG .Net, Dare IT, Women in Tech Summit\nSami r\u00f3wnie\u017c stawiamy na rozw\u00f3j. Organizujemy hackathony i wewn\u0119trzne konferencje (np. coroczny Allegro Tech Meeting), regularnie wyje\u017cd\u017camy na wydarzenia w Polsce i za granic\u0105 (Europa i USA), a ka\u017cdy zesp\u00f3\u0142 ma bud\u017cet na szkolenia i ksi\u0105\u017cki. Je\u015bli chcesz si\u0119 rozwija\u0107 lub dzieli\u0107 swoj\u0105 wiedz\u0105 z innymi, to zawsze Ci pomo\u017cemy.\nTo te\u017c mo\u017ce Ci\u0119 zainteresowa\u0107:  \nAllegro Tech Podcast \u2192 https:\/\/podcast.allegro.tech\/\nBooklet \u2192 https:\/\/allegro.tech\/booklet.pdf\nWy\u015blij nam swoje CV i sprawd\u017a dlaczego #dobrzetuby\u0107","132":"Big Data Graduate Program 2022\nFounded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 7 years, 12 locations and 600+ employees later we still believe that today. We connect the dots within our Customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data.\nDue to the continuous success and high demand from our Customers, we are looking for Graduates to kick start their career by joining our Quantexa family. \ud83d\ude80\nWhat does the Graduate Program at Quantexa look like?\nOur Big Data Graduate Program is designed for you to develop your technical skill set, think creatively and be a real problem solver of major issues our clients are facing today. If you are someone who likes to think outside the box, holds a real passion for data and is open to new ideas, you\u2019ll find a Qmmunity that recognizes your needs to be a creative innovator and embrace it.\nYou will work on big data projects where you will have exposure to data science, data engineering and DevOps methods, whilst learning to engage with both internal and external stakeholders. In a typical Quantexa project, you\u2019ll work with high volume data, helping our top clients solve business problems in financial crime, fraud and money laundering along with playing a huge part in helping our others solve complex terrorism cases, human trafficking, and even modern-day slavery. You\u2019ll be working closely with Data Scientists, Data Engineers, Business Analysts, Technical Leads, Project Managers and Solutions Architects, using entity resolution to generate networks and apply a scoring framework to identify risks. At Quantexa everyone is following the same goal of meeting our client\u2019s expectations and delivering a first-class service.\nWhat training is provided, and technology will you use?\nWe want our graduates to learn the latest Big Data technologies and being the huge fans of functional programming that we are, your first 3 months will consist of going through our dedicated training academy. You\u2019ll have exposure to learning Scala, which is our primary language here at Quantexa, so you are confident and comfortable using our platform. Part of this exciting journey will also have you exposed to other tools such as Spark, Hadoop, Hive, Kubernetes,\u202fwith our platform being hosted on Google cloud (GCP). You will learn how to create entities and networks and loading data using Elasticsearch in the Quantexa interface. You\u2019ll be required to generate a solution using our explorer in a world leading big data tool set. This training is heavily self-paced learning giving you the flexibility to add to the task and complete with set timings.\nFollowing completion of the academy you will be working on multiple projects. You can expect to work with different lead experts who share their love of big data to deliver the best for our clients.\nCheck out our graduate brochure here to find out more and here from current graduates \ud83d\ude4c\nRequirements\nWhat do I need to have?\nWe are looking for enthusiastic individuals who share a love of \u2018big data\u2019 and have a numerate degree ie. Mathematics, Physics, Computer Science, IT\/Technology. \ud83d\udc69\u200d\ud83d\udcbb\nMust be a graduate already or expecting to graduate in a STEM subject.\nA passion and the desire to learn and code in Scala using multiple big data tool sets.\nHold problem solving skills and enthusiasm to pick up a broad set of tasks.\nClient facing and Consulting skills such as communication, adaptability, critical thinking etc.\nExperience in Python, Java, Scala, R or similar technologies is desirable.\nPassion and drive to grow within one of the UK\u2019s fastest scale ups.\nBenefits\nWhy join Quantexa?\nWe know that just having an excellent glass door rating isn\u2019t enough, so we\u2019ve put together a competitive package as a way of saying thank you for all your hard work and dedication.\nWe offer:\nCompetitive salary\nCompany bonus\nCompetitive holiday allowance + public holidays + birthday off!\nAccess to our unlimited technical library\nPrivate Healthcare\nRRSP Plan with Q match up to 5%\nShort term & long-term disability\nLife Insurance & Accidental health\nOngoing personal development\nGreat WeWork Office Space & Company wide socials","133":"Company Description\nNatixis in Portugal is fully integrated in the global organization of Natixis, a French multinational financial services firm specialized in Asset & Wealth Management, Corporate & Investment Banking, Insurance and Payments. A subsidiary of Groupe BPCE, Natixis counts nearly 16.000 employees across 38 countries.\nBased in Porto, Natixis Centre of Expertise mission is to transform traditional banking by developing innovative solutions for the bank\u2019s business, operations and work culture worldwide, as a key driver of the company\u2019s culture of agility and innovation. Teams of IT and Banking Support Activities work in an integrated, inclusive and transversal way, supporting all the business lines and country platforms.\nNatixis in Portugal is the best combination of a \u201cstart-up mindset\u201d with a large, solid structure. Its unique culture gives true meaning to a \u201cbeyond banking\u201d personality: to be a real entrepreneur, self-challenging, ever striving to excel and go that extra mile.\nJob Description\nWe are looking for a Data Analyst with a background in Business Intelligence to work in Regulatory reporting across the globe. This position will be integrated in the IT Financing department within the CIB business unit. The candidate will be working with REGBOX, an Oracle datawarehouse built to centralize all the data (Accounting, Inventory, Repository, Risk, etc.) necessary for the regulatory reporting for Natixis branches in APAC and EMEA. REGBOX stores and processes the data in accordance with the requirements of the different downstream tools (from external providers), responsible of the regulatory reporting submission to each Central Bank. Cognos tool is also plugged to Regbox and used to build directly some regulatory reports or for internal reporting.\nIn this role, the DA will have to respond to the data requirements submitted by the regulators and the providers, working in close communication with business users, local vendors in each country, other REGBOX DA and IT developers.\n Roles and responsibilities:\nDiscuss requirements with business users and local vendors in each country;\nSpecify and lead the implementation of changes in the REGBOX data model in order to meet regulatory needs;\nInvestigate data issues and lead the steps towards their resolution;\nCreate or modify SQL extractions;\nCreate or modify Cognos reports (only for one location, so it is a small component of the role)\nQualifications\nPrevious experience as IT Data Analyst or Business Analyst, Product Owner or similar role;\nKnowledge of business intelligence methodologies, in particular data modeling (mandatory);\nExperience with report building;\nExperience in SQL;\nVery good communication (written and oral) and interpersonal skills;\nGood level of English (at least B2) ;\n Previous experience in Banking IT, Accounting and Regulatory topics would also be a plus.\n Additional Information\nEarly morning. Campo 24 de Agosto. In 4 minutes, you are clocking in at the office. After grabbing a cup of coffee and fresh fruit, pick up your laptop and choose your spot for the day. It's going to be a busy one: French class before lunch and, just after, quick medical appointment at Natixis doctor's office.\n \nLunch break. Outside in the big terrace (look at your crops at the Urban Garden; ready to harvest!) or, if you feel like stretching your legs, walk downtown to grab lunch.\n \nBack inside. Quick sprint review (working together anywhere means virtual happy birthday to that colleague in Paris that just turned 35). The afternoon went flying (tasks, reports, calls, some jokes with your teammates). End it on a high note: just one PlayStation game or the final match for that ping-pong tournament.\n \nTomorrow, you complete that certified technical training and the day after, you will work from home, taking advantage to finally do that online course on Udemy. Once you are done with your tasks for the day, you can visit the office for a board games session or show up at the rehearsal of one of Natixis bands. If that is too steady for you, meet your colleagues to surf some waves or join them in a football match.","134":"Company Description\nHitachi Solutions is a global Microsoft solutions integrator passionate about developing and delivering industry-focused solutions that support our clients to deliver on their business transformation goals. Our industry focus, expertise, and intellectual property is what truly sets us apart. We have earned, and continue to maintain, a strategic relationship with Microsoft. Recognized for our achievements - teaming with our clients to deliver innovative digital solutions and services - is how we have achieved year after year recognition.\nAs their trusted advisor, we support our clients to deliver on their strategic business initiatives as they unify, automate, and modernize their data and operations to increase efficiency, reduce costs, and enhance their customer\u2019s experience. Our over 3,000 team members across 14 countries, and our 18 years of 100% focus on Microsoft technologies and business applications, is how we deliver excellence through expert services and industry-focused cloud solutions. \nA part of Hitachi, Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world\u2019s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies.\nJob Description\nThis is a full-time position for a consulting role to be a member of our customer-facing project delivery teams for POC\u2019s, Technical Assessments, and Production Project Delivery. \nQualifications\nBachelor\u2019s Degree  \n7+ years relevant experience in consulting on large scale Data Warehouse\/Big Data projects in team environments.  \nExperience with Power BI, (Power Query, PerformancePoint, PowerView a plus), Power Platform, Analytics (Synapse, backend data modeling in support of Analytics), SSRS, SSAS, Excel Services \nKnowledge of Agile processes (Scrum preferred)  \nExperience with Power BI Dashboard\/Report, Data Warehouse, Data Modeling and Data Integration  \nProficiency in extracting and manipulating large data sets with SQL in MS SQL.  \n Some experience (not all mandatory) using mapping Software and Programming Languages: SQL, R, DAX, Microsoft Power BI, SSRS, Excel, and Tableau \nExperience designing and building large-scale, distributed systems  \nAble to work with the customer\u2019s stakeholders to understand business and technical requirements. \nExperience with complex data modeling  \nAble to identify and communicate issues\/risks applying technical and root cause analysis skills  \nStrong decision making, problem solving, and analytical skills  \nExcellent communication, presentation, influencing, and reasoning skills (there will be client and pre-sales exposure) \nCreativity and ability to think outside-the-box while defining sound and practical solutions  \nExperience with the following Technologies\/Methodologies is a plus:  \nAzure and\/or AWS \nTableau \nSQL Server 2014\/2016  \nOracle, DB2, NoSQL \nC#\/.NET \nAzure Data Services\/Azure SQL Data Warehouse (PLUS) \nAdditional Information\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\nAll your information will be kept confidential according to EEO guidelines.\n #LI-CC1","135":"Veeva [NYSE: VEEV] is the leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, our customers range from the world\u2019s largest pharmaceutical companies to emerging biotechs. Veeva\u2019s software helps our customers bring medicines and therapies to patients faster.\nWe are the first public company to become a Public Benefit Corporation. As a PBC, we are committed to making the industries we serve more productive, and we are committed to creating high-quality employment opportunities.\nVeeva is a Work Anywhere company which means that you can choose to work in the environment that works best for you - on any given day. Whether you choose to work remotely from home or work in an office - it\u2019s up to you.\nThe Role\nVeeva is looking for a Sales BI Analyst with analytics experience in support of our Global Sales and Operations teams. If you are a \u201cData Person,\u201d who knows Tableau, loves to get hands-on, enjoys data modeling, and is good at bringing data to life, we\u2019d love to talk with you.\nWhat You'll Do\nServe as the business expert in support of our Global Sales and Sales Operations Team regarding sales analytics and data visualization\nParticipates in planning processes including technical design, development, testing, and delivery of solutions\nAnalyzes business and functional requirements and translates these requirements into robust, scalable, operable solutions\nServe as the point person for all things Tableau for Sales\/Operations\nImplements data structures using best practices in data modeling, processes, and technologies\nPerforms data conversions, imports, and exports of data within and between internal and external software systems\nAssists in vendor evaluations\nAssist with the upkeep of our data warehouse and semantic layers\nRequirements\nBachelor's degree in Computer Science, Information Systems, Business Management, Mathematics, or specialized training\/certification\n1+ years of professional experience in business intelligence and\/or analytics\nStrong visualization skills with Tableau\nProven ability to model data efficiently to support data requirements\nAbility to work with large data sets, obtain information, identify trends, and solve complex problems\nStrong verbal, written & presentation skills with the ability to effectively communicate complex technical information to personnel at all levels of the organization\nNice to Have\nSQL experience for building complex joins and analytical queries\nData Warehouse experience best practices (Databricks (preferred), Snowflake, etc.)\nUnderstanding of data governance best practices and implementation\nSoftware industry and\/or Life Sciences experience is a plus\nPerks & Benefits\nFlexible PTO\nAllocations for continuous learning & development\nHealth & wellness programs\n#LI-RemoteUS#BI-Remote\nVeeva\u2019s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.\nVeeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances. If you need assistance or accommodation due to a disability or special need when applying for a role or in our recruitment process, please contact us at talent_accommodations@veeva.com. Position may not be eligible for remote work in Colorado.","136":"Geomagical Labs is a 3D research & development lab, fusing 3D computer vision, deep neural networks, graphics, and computational photography into magical experiences for hundreds of millions of users, in partnership with IKEA.\nOur best-in-industry applications allow customers to scan photorealistic models of their indoor spaces, then reimagine them with new furniture in life-like 3D, from anywhere --- changing home commerce along the way.\nWe are looking for a computer vision technologist, with hands-on experience implementing computer vision algorithms on modern smartphones, to push the state of the art in mobile phone scene capture technologies. This could be a dream job for highly-motivated technologists and applied researchers, with strong 3D vision foundations and entrepreneurial drive.\nRequirements\nPh.D. or Master's degree focused on computer vision preferred.\nHighly productive and ambitious software engineer with a track record of success.\nBroad theoretical & practical foundations in 3D computer vision.\nHands-on experience developing 2D & 3D vision algorithms on mobile devices.\nHands-on expertise deploying and using neural networks on mobile phones for live processing of photographic imagery.\nHands-on experience developing cool AR apps.\nStrong applied math skills in optimization, linear algebra, 3D perspective geometry.\nExcellent written & verbal communication skills.\nAppreciation for visual aesthetics and customer success.\nMust be adventurous, ambitious and excited about R&D innovation.\nBenefits\nJoin a mission-driven R&D lab, strategically backed by an influential global brand.\nWork in a dynamic team of computer vision, AI, computational photography, AR, graphics, and design professionals, and successful serial entrepreneurs.\nOpportunity to publish novel and relevant research.\nExcellent health & retirement benefits.\nFully remote work available to people living in the USA or Canada.\nHeadquartered in Mountain View, California, in the heart of the Castro Street downtown --- an easy walk from restaurants, coffee shops, the Stevens Creek Trail, and Caltrain commuter rail.\nThe USA base salary for this full-time position ranges from $150,000 to $340,000 determined by location, role, skill, and experience level.\nGeomagical Labs offers a comprehensive set of benefits, and for qualifying roles, substantial incentive grants, vesting annually.","137":"Unternehmensbeschreibung\nWir bei rheindata beraten unsere Kunden in den Bereichen Big Data, Business Intelligence und Data Science. Wir sind ein buntes Team aus den unterschiedlichsten Fachbereichen wie z.B. Mathematik, VWL, Informatik oder Physik. Uns ist wichtig, dass wir uns weiterbilden k\u00f6nnen und offen sind, unser Wissen zu teilen. Bei uns gibt es wenig B\u00fcrokratie, stattdessen kurze und flache Entscheidungswege und gro\u00dfes Mitspracherecht. Wenn du also Lust hast, uns kennenzulernen\u2026 los geht\u00b4s!\nStellenbeschreibung\nAls BI Berater ETL\/ELT (m\/w\/d)\narbeitest du in unterschiedlichen BI Projekten bei unseren Kunden und entwickelst kreative und innovative BI L\u00f6sungen,\nentwickelst du ETL\/ELT Strecken und zudem orchestrierst und parallelisierst du Ladestrecken,\nerstellst du SQL-basierte Datenbank-Abfragen,\narbeitest du mit strukturierten und unstrukturierten Daten\nund bist du offen f\u00fcr neue Technologien und gibst dein Wissen auch gerne weiter.\nQualifikationen\nDas bringst du mit:\nEinige Jahre praktische Erfahrung im BI Bereich,\nein abgeschlossenes Studium in einem MINT (Mathematik, Informatik, Wirtschaftsinformatik, -mathematik, Physik o.\u00e4.)- oder wirtschaftswissenschaftlichen (BWL, VWL, o.\u00e4.) Fach,\nKommunikationsst\u00e4rke,\nDeutschkenntnisse auf muttersprachlichem Niveau (C2),\nEnglisch flie\u00dfend in Wort und Schrift.\nZudem verf\u00fcgst du \u00fcber Kenntnisse z.B. in:\nSSIS, Talend oder Informatica\nSQL\nErfahrung in Cloud-Plattformen wie Azure, AWS oder GCP\nZus\u00e4tzliche Informationen\nDas bieten wir dir:\n6 Wochen Urlaub im Jahr und in jedem f\u00fcnften Jahr sogar 10 Wochen\neine deinen Bed\u00fcrfnissen entsprechende Einarbeitungsphase mit Begleitung deines Mentors,\ndie M\u00f6glichkeit zu individuell gestaltbaren Sabbaticals,\ndie Teilnahme an unserem Mitarbeiter-Beteiligungsprogramm,\neine kostenlose M-Mitgliedschaft bei Urban Sports Club und verg\u00fcnstigte Konditionen bei L- und XL-Tarifen\nneben einem attraktiven Verg\u00fctungspaket erh\u00e4ltst du nat\u00fcrlich ein Notebook und ein Smartphone sowie weitere Zusatzleistungen wie z.B. Jobticket, JobRad oder betriebliche Altersvorsorge\nje nach Projektgegebenheiten, die M\u00f6glichkeit im Homeoffice zu arbeiten \u2013 wobei du in unserem B\u00fcro im belgischen Viertel nat\u00fcrlich auch immer willkommen bist.","138":"About At-Bay\nThe Data & Research department oversees\u202fall of\u202f At-Bay\u2019s data-related requirements. Our\u202fultimate goal\u202fis to enable and increase the use of data in the company through creative approaches and the implementation of powerful resources such as analytical databases, advanced data pipelines, BI tools, and data science technology. We hire the brightest minds to take on this challenge and equip them with the knowledge and tools that contribute to their personal growth and success while supporting our company\u2019s culture of diversity and experimentation. The role the Data team plays at At-Bay is critical as business users, product managers, engineers, and many others rely on us to empower their decision-making. This is what drives up the challenge as part of the Data department, but also the reward.\nAt-Bay is seeking an experienced and data-driven BI Engineer to join our BI team. Our BI team is a core business & data-oriented team that leads BI solutions to various products and departments around the organization.\nAs a BI engineer, you will work directly with cross-functional teams, internal and external customers to understand the business needs, you will provide reliable and creative BI solutions for complex data challenges and take part in POCs and migrations of new technologies.\nIf you are sharp with technical skills & analytical thinking, passionate about data, and want to be a focal point of analytical & technical aspects of our team activity, come and help us turn our growing amount of events into critical information, business insights that will help to make impactful decisions on our business.\n  Responsibilities:\nEnd to end modeling the core Data warehouse of the company, providing BI Infrastructure to the Product, Cyber , RnD, Sales, Finance, Claims teams.\nGather requirements and business needs from internal and external customers and turn them into technical specifications.\nWork closely with BI engineers, analysts, RnD, product, data teams to improve our data flow & internal processes.\nCreate new ETL processes and optimize existing ones (DBT, Airflow, Python).\n  Qualifications:\n2+ years experience working as a Data\/BI Backend engineer (DWH, ETL) - Must.\nExperience with dimensional data modeling & schema design in DWH - Must.\nAdvanced knowledge in SQL - Must. \nExperience working with ETL tools (dbt, Informatica, SSIS) - Must.\nExperience with Snowflake - Advantage.\nExperience with workflow managers such as Airflow\/Luigi - Advantage.\nExperience with source control systems (Github) \u2013 advantage\nProgramming skills (Python or other) - Advantage.\nBA\/B.Sc. in a technical discipline such as Industrial and Management Engineer\/ Information Systems Engineer \u2013 Advantage.\n  Location: Tel Aviv, Israel\n  What you'll get\nA competitive salary, and equity in a super fast-growing company, taking over commercial insurance.\nA strong emphasis on work-life balance.\nBeautiful offices in the heart of Tel Aviv, near the train station and main bus stops.\nPassionate, smart, and fun people to work with.\nYou will never lack a challenge, we are a unique blend of a fast-growing tech startup, an international firm, and an insurance company.\nLearn more at at-bay.com","139":"Schr\u00f6dinger is seeking a Computational Biology Intern to work on new and exciting drug discovery and development programs.\nOur company aims to revolutionize drug design through the use of breakthrough computational methods. Our powerful platform is transforming the discovery of novel therapeutics, and we\u2019re developing a strong preclinical pipeline and portfolio in multiple therapeutic areas, including oncology, immunology and neurology.\nWho will love this job:\nA capable collaborator and scientist who\u2019s eager to learn and adopt novel methodologies to answer biological questions, while applying their experience with large data consortia and genomic data \nA proficient R and\/or Python programmer who\u2019s familiar with machine learning and AI methodology applied to biological data\nAn excellent verbal and written communicator\nWhat you\u2019ll do:\nWork on programs in early drug discovery and translational research with a group of energetic scientists and developers\nApply modern machine learning, deep learning and AI methods to novel biological discovery and biomarker development\nInterpret and visualize analysis results in a way that facilitates biological or disease discovery \nFacilitate translational biology research by finding and applying new genomic data sources\nWhat you should have:\nA graduate major in computational biology, bioinformatics, statistics, computer science or a related field\nBroad background in computational biology and exposure to machine learning\nExperience analyzing genomics and multi-omics data, especially with large public data sets\nExperience with cell line drug sensitivity and CRISPR screen data is a plus \nExperience with drug combination modeling and prediction is a plus\n  Pay and perks:\nSchr\u00f6dinger understands it\u2019s people that make a company great. Because of this, we\u2019re prepared to offer a competitive salary, stock options, and a wide range of benefits that include healthcare (with dental and vision), a 401k, pre-tax commuter benefits, a flexible work schedule, and a parental leave program. We have catered meals in the office every day, a company culture that is relaxed but engaged, and over a month of paid vacation time.  Our Administrative and Human Resources departments also plan a myriad of fun company-wide events. New York is home to our largest office, but we have teams all over the world. Schr\u00f6dinger is honored to have been selected as one of Crain's New York Best Places to Work for the past three years running.\nEstimated base salary (NYC only): $7,500\/mo. Actual compensation package is dependent on a number of factors, including, for example, experience, education, degrees held, market data, and business needs. If you have any questions regarding the compensation for this role, do not hesitate to reach out to a member of our Strategic Growth team. \nSound exciting? Apply today and join us!\nAs an equal opportunity employer, Schr\u00f6dinger hires outstanding individuals into every position in the company. People who work with us have a high degree of engagement, a commitment to working effectively in teams, and a passion for the company's mission. We place the highest value on creating a safe environment where our employees can grow and contribute, and refuse to discriminate on the basis of race, color, religious belief, sex, age, disability, national origin, alienage or citizenship status, marital status, partnership status, caregiver status, sexual and reproductive health decisions, gender identity or expression, sexual orientation, or any other protected characteristic. To us, \"diversity\" isn't just a buzzword, but an important element of our core principles and key business practices. We believe that diverse companies innovate better and think more creatively than homogenous ones because they take into account a wide range of viewpoints. For us, greater diversity doesn't mean better headlines or public images - it means increased adaptability and profitability.","140":"Do you want the opportunity to leverage your skills to make a direct impact on the world\u2019s leading life sciences, consumer products, and retail companies? Join Clarkston Consulting as a Power BI Developer to help deliver creative business solutions to our market-leading clients as a part of our team of experienced professionals.\nWe are looking for motivated, self-driven leaders who are energized by team results and interested in joining a firm that values its culture and people as its biggest strengths. Together, we can help find the answers to our clients most challenging business problems.\nWhat You\u2019ll Do\nClarkston gives you the opportunity to deliver great solutions, become recognized as an industry expert, and help build a great practice.\nAs a Power BI Developer at Clarkston, you will:\nTurn data into stories by visualizing complex data in an intuitive and user-friendly way\nGather requirements, prototype design, iterate based on client feedback, and develop final visual solutions\nHow You\u2019ll Grow\nAt Clarkston, we feel that we provide the greatest value to our clients through a combination of our industry expertise, business process knowledge, and consulting excellence.\nBeyond your day-to-day responsibilities, throughout your career at Clarkston you will:\nHave the support and mentorship of your Clarkston colleagues and leaders\nOwn your career \u2013 you'll be able to take charge of your career journey with diverse opportunities to lead and expand your skillset both at the client site and within the firm\nHave the opportunity to make a real and positive impact not only the clients you work with, but on the firm as well\n\nTravel Requirement\nTravel is an integral part of this role and is estimated to average 20-30%. This may vary based upon client and project needs. While travel is a requirement of the role, due to COVID-19 restrictions, all non-essential travel has been limited and any on-site requests are subject to review. When not traveling, consultants work from their home office. Relocation is not required.\nRequirements\nWhat We\u2019re Looking For:\nAn ideal candidate as a Power BI Developer would have the following qualifications and experience:\nAbility to use complex expressions to calculate, group, filter, and format custom dashboards\/reports\nKnowledge of best practices for visual flow, interactivity, and drilldown between graphics\nBackground in design principles for UI\nExperience utilizing visualization tools like Power BI and Tableau\nUnderstand the various audiences for consuming the visualizations and tailor design and UI approach to those groups (executive, analyst, information consumer)\nUnderstanding of steps to productionizing a solution, including testing, administration, and security\nSolid understanding of the underlying data models driving visualization, including relational databases and joins\nMinimum degree required: bachelor's degree from an accredited college or university\nBenefits\nOur benefits include:\nComprehensive Health and Wellness Benefits (Medical, Dental, Vision, and more)\n401k with company contributions\nPaid vacation, personal days, holidays, and sick leave\nPaid Parental Leave and Family Building Benefits (Adoption, Surrogacy, and Infertility Support)\nLife and Disability Insurance\nTraining and Professional Development investments, Tuition Assistance, and more\nVisit Careers at Clarkston to learn more about our culture, benefits, and opportunities. We hope you\u2019ll join us!\nCOVID-19 Vaccination Statement\nWhile Clarkston Consulting has not mandated vaccination at this time, COVID-19 vaccinations are required in order to access Clarkston Consulting facilities and those of many of our clients. With this in mind, all prospective hires will be required to provide their vaccination status.","141":"Company Description\nAt Experian Health, our employees have the opportunity to shape more than products \u2013 they shape the future of U.S. healthcare. Experian Health is a pioneer for innovations leading the way in revenue cycle management, identity management, patient engagement, and care management for hospitals, physician groups, labs, pharmacies and other risk-bearing entities. Our success relies on people who are given the freedom to imagine new frontiers in the rapidly changing healthcare space and push the boundaries of innovation. Help us realize our vision of applying data for good and changing the healthcare landscape for the better \u2013 for all of us.\nOur mission is to use data driven insights to simplify healthcare for all. Simply put, we want to make the healthcare system work better for us as consumers and for those who work in healthcare. Our ONE Experian Health culture is the centerpiece of making this happen. Our aspiration is to bring people together who are driven by purpose and want to make a difference.  We strive to have a diverse group of people and minds who are:\nOPEN: Have a growth mindset and collaborate often with others to make things happen\nNIMBLE:  Always embracing change and pushing the envelope on innovative ways to solve problems\nEFFECTIVE:  Accountable to themselves and to others\nJob Description\n100% REMOTE (NOT HYBRID) - WORK ANYWHERE IN THE US\nThe primary responsibility of the Data Analyst will be to support application development leveraging strong SQL skills, knowledge of relational databases, and the skills to ensure custom coordination of benefit software, containing over 400 million rows of data, only allows accurate data to be loaded, and data integrity is maintained after bug fixes and enhancements.\n\nThis position will ensure this software is thoroughly tested from all angles focusing primarily on the backend by developing custom test plans and executing them using SQL, analyzing production data, and writing custom reports.\n\nJob duties:\nFully understand custom built Healthcare Medical Eligibility\/Coordination of Benefits software solution. Understand the technical design and be able to traverse through and fully test the system using custom developed test plans using SQL\nWork collaboratively at ground level with senior level development staff to fully understand product requirements. Be willing to ask questions, push back as necessary, and ultimately ensure the new code meets stringent customer expectations\nIdentify software defects, conduct research, develop plan for resolution, and engage appropriate internal resources as necessary\nPerform data analysis as needed on production data (400+ million rows of data)\nCollaborate with team members on, and provide peer review of, test plans, test cases, test data, and automation\/tool enhancements.\nWork collaboratively with development team to make technical judgments based upon understanding of the business process and customer\/user needs whereby a design change or modification should (or needs to be) changed.\nSupport inquiries from client, operations, and customer support on content related questions and monitor areas for improvement.\nDesign and document test cases to ensure optimal system performance with new code releases\nUtilize QA best practices\nTests will be executed at the database level, using SQL\nBuild automated tests using tools such as Selenium\nOperate load testing on Web Based Portal\nRun smoke tests and regression tests\nPrepare appropriate test data\nCommunicate and document testing results in appropriate tool\nMaintain defect reporting and tracking\nMaintain current test plans, test cases, test scripts, and test data.\nAvailability for planned after hours deployments and unplanned issue resolution\nPlanned deployments typically occur once a month on Thursday nights\nQualifications\nBachelor\u2019s degree in Information Systems, Computer Science, or other related field OR equivalent experience required\nAt least 3 years combined prior business analyst, SQL programming, software QA, SQL data analysis\nMinimum 3 years of SQL usage in a professional setting\nExperience working as an analyst with large datasets (1+ million records) highly desired\nExperience with SDLC and iterative development processes, specifically Agile work processes highly desired\nExperience in working in a highly competitive team environment\nStrong SQL skills required (Data Analyst SQL skill set, not necessarily SQL programming)\nFocus on relational databases\nBusiness analyst knowledge is highly preferred\nQA knowledge is preferred. Willingness to be trained on QA fundamentals is required\nCoordination of Benefits, and\/or Healthcare Revenue Cycle knowledge a plus\nEffective communication and relationship building skills\nSelf-motivated, team player, but who can work independently\nAbility to adapt to an Agile\/Scrum environment\nStrong written and verbal communication skills\nProblem-solving as part of a distributed team\nTime management and organizational skills\nKnowledge of the HIPAA transaction sets and requirements is desirable\nBecome an expert on highly complex custom software - willingness to self-study and learn through trial and error required.  \nAdditional Information\nExperian is an Equal Opportunity Employer. Anyone needing accommodation to complete the interview process should notify the talent acquisition partner. The word \"Experian\" is a registered trademark in the EU and other countries and is owned by Experian Ltd. and\/or its associated companies.\nEOE including Disability\/Veterans.\nExperian is proud to be an Equal Opportunity and Affirmative Action employer. Our goal is to create a thriving, inclusive and diverse team where people love their work and love working together. We believe that diversity, equity and inclusion is essential to our purpose of creating a better tomorrow. We value the uniqueness of every individual and want you to bring your whole, authentic self to work. For us, this is The Power of YOU and and it reflects what we believe.  See our DEI work in action!\nPlease contact us at JobPostingInquiry@experian.com to request the salary range of this position (please include the exact Job Title as it reads above in your email). In addition to a competitive base salary and variable pay opportunity, Experian offers a comprehensive benefits package including health, life and disability insurance, generous paid time off including 12 company paid holidays and parental and family care leave, an employee stock purchase plan and a 401(k) plan with a company match.\nExperian Careers - Creating a better tomorrow together\nFind out what its like to work for Experian by clicking here","142":"Company Description\nAt Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people\u2019s lives. Our promise to our associates is rock-solid: we grow together, we enjoy our work, and we inspire each other. Join in and feel the difference!\nJob Description\nTasks:\nAs Operations Specialist you will handle day-to-day operations of our Big Data Cloud Platform Services and ensure stability, security, and scalability.\nYou drive industrialization of different manufacturing and logistic cloud based platforms through further automation of deployment, configuration, upgrade and maintenance processes. \nPart of your work also entails developing new platform features supporting  (cost) monitoring, logging and alerting as well as the implementation of new operations related processes.   \nIn your responsibility lies the development of scripts for automation (deployment, configuration) and monitoring, as well as providing expert product support to Bosch business units (e.g. root-cause analysis of non-standard issues).\nYour tasks also include testing and evaluating new product features in close alignment with project stakeholders, internal customers, and vendors.\nFurthermore, you consult internal customers on technical level regarding tool selection, code quality, connectivity topics and workload performance.\nQualifications\nProfile:\nExperience with the Microsoft Azure ecosystem (e.g. Azure Services, Azure CLI, Azure DevOps).\nExperience in working on larger projects, including multiple customers and international teams.\nHands-on experience with Cloud or infrastructure operation.\nKnowledge of version control tools (e.g. GIT, Bitbucket) and CI\/CD pipeline tools (e.g. Azure DevOps).\nKnowledge of IT monitoring and logging techniques and relevant technology stack (e.g. Grafana).\nIdeally knowledge of one scripting language (e.g. Bash or Python).\nNice to have: knowledge of Cloud Security.\nUniversity degree in Computer Science, Information Technology, Engineering or related fields.\nProficiency in English both written and spoken.\nAdditional Information\nBenefits:\nWe would like to offer you number of amenities for you and your loved ones.\nWork #LikeABosch:\nContract of employment  and a competitive salary (together with annual bonus)\nFlexible working hours with home office after the pandemic as well\nReferral Bonus Program\nCopyright costs for IT employees\nCanteen in the office with co-financed lunches\nGrow #LikeABosch:\nComplex environment of working, professional support and possibility to share knowledge and best practices\nOn-going development opportunities in a multinational environment\nBroad access to professional trainings, conferences and webinars\nLanguage courses\nLive #LikeABosch:\nPrivate medical care and life insurance\nMultisport card and sports teams\nNumber of benefits for families (for instance summer camps for kids)\nNon working days on the 24th and 31st of December\nDiscounts for Bosch products","143":"For more than 20 years, PointClickCare has been the backbone of senior care. We\u2019ve amassed the richest senior care dataset making our market density untouchable and our connections to the healthcare ecosystem exponentially more powerful than those of any other platform. \nWith Collective Medical & Audacious Inquiry, we\u2019ve become the most expansive, full-continuum care collaboration network, offering care teams immediate, point-of-care access to deep, real-time insights at every stage of a patient\u2019s journey.\nFor more information on PointClickCare, please connect with us on Glassdoor and LinkedIn.\nPosition Type: You must be in a co-op program to be considered. 8 month term from May 8 - December 22, 2023\nReporting to the Director of Business Intelligence, the Business Intelligence Developer I plays an important role as a supporting member of the Business Intelligence department and the broader employee base of PointClickCare.  Customer service and a positive, supportive, personality are essential to the success of this role. This role will provide you the opportunity to gain exposure to some of the core systems and tools that help run our business. You will learn various data transformation and analytical tools such as MS SSIS, MS SSMS, SQL Server, Power BI.\nKey Responsibilities:\nEngage technology and business leaders to leverage business tools to solve real world business challenges\nSupporting the existing Business Intelligence environment through job trouble shooting\nDocumenting existing Business Intelligence configurations\nDesigns, prototypes, codes and tests new or enhanced SQL queries\nPerforms customer support processes and activities for the implementation of new or existing applications\nMonitors the efficiency and effectiveness of application operations and troubleshoots problems, as necessary\nLearn and be involved in different phases of project plan (Business Requirements to Solution Delivery)\nEvaluating new products and services to judge their suitability for use\nPreliminary research and investigation of software and evaluating new products and services to judge their suitability for use\nDesired Skills & Experience:\nEnrolled in a Business, Computers, Engineering, or IT related co-op program\nMotivated learner with the eagerness to work with data\nExposure in ETL and Data Integration, Data Profiling, Data Modeling\nKnowledge of SQL\nExperience with SQL Server, SSIS, SSMS, Visual Studio or ETL tools\nMS Office Applications (Excel), Strong Excel experience (macros)\nWorkflow design and implementation\nScripting experience\nDemonstrating strong written and verbal communication\nCritical thinker, problem solver, with the ability to pursue help when required\nExperience composing project documentation (e.g., high level use cases, detailed business specifications)\nIt is the policy of PointClickCare to ensure equal employment opportunity without discrimination or harassment on the basis of race, religion, national origin, status, age, sex, sexual orientation, gender identity or expression, marital or domestic\/civil partnership status, disability, veteran status, genetic information, or any other basis protected by law. PointClickCare welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process. Please contact recruitment@pointclickcare.com should you require any accommodations.\nWhen you apply for a position, your information is processed and stored with Lever, in accordance with Lever\u2019s Privacy Policy. We use this information to evaluate your candidacy for the posted position. We also store this information, and may use it in relation to future positions to which you apply, or which we believe may be relevant to you given your background. When we have no ongoing legitimate business need to process your information, we will either delete or anonymize it.  If you have any questions about how PointClickCare uses or processes your information, or if you would like to ask to access, correct, or delete your information, please contact PointClickCare\u2019s human resources team: recruitment@pointclickcare.com \nPointClickCare is committed to Information Security. By applying to this position, if hired, you commit to following our information security policies and procedures and making every effort to secure confidential and\/or sensitive information.","144":"Company Description\nNatixis in Portugal is fully integrated in the global organization of Natixis, a French multinational financial services firm specialized in Asset & Wealth Management, Corporate & Investment Banking, Insurance and Payments. A subsidiary of Groupe BPCE, Natixis counts nearly 16.000 employees across 38 countries.\nBased in Porto, Natixis Centre of Expertise mission is to transform traditional banking by developing innovative solutions for the bank\u2019s business, operations and work culture worldwide, as a key driver of the company\u2019s culture of agility and innovation. Teams of IT and Banking Support Activities work in an integrated, inclusive and transversal way, supporting all the business lines and country platforms.\nNatixis in Portugal is the best combination of a \u201cstart-up mindset\u201d with a large, solid structure. Its unique culture gives true meaning to a \u201cbeyond banking\u201d personality: to be a real entrepreneur, self-challenging, ever striving to excel and go that extra mile.\nJob Description\nWe are looking for a Data Analyst with a background in Business Intelligence to work in Regulatory reporting across the globe. This position will be integrated in the IT Financing department within the CIB business unit. \nIn this role, the DA will have to respond to the data requirements submitted by the regulators and the providers, working in close communication with business users, local vendors in each country.\nRoles and responsibilities:\nDiscuss requirements with business users and local vendors in each country;\nSpecify and lead the implementation of changes in the data model in order to meet regulatory needs;\nInvestigate data issues and lead the steps towards their resolution;\nCreate or modify SQL extractions;\nCreate or modify Cognos reports (only for one location, so it is a small component of the role)\nQualifications\nPrevious experience as IT Data Analyst or Business Intelligence Analyst, Product Owner or similar role;\nKnowledge of business intelligence methodologies, in particular data modeling (mandatory);\nExperience with report building;\nKnowledge on data modeling for Data Warehouses (data modeling on big data context is a plus)\nExperience with Power BI (tableau is a plus)\nKnowledge and experience with SQL\/HiveQL\nExperience with big data environment - Hive (experience with Indexima is a plus)\nGood communication with business users to collect business requirements\nVery good communication (written and oral) and interpersonal skills;\nGood level of English (at least B2) ;\nAdditional Information\nEarly morning. Campo 24 de Agosto. In 4 minutes, you are clocking in at the office. After grabbing a cup of coffee and fresh fruit, pick up your laptop and choose your spot for the day. It's going to be a busy one: French class before lunch and, just after, quick medical appointment at Natixis doctor's office.\n \nLunch break. Outside in the big terrace (look at your crops at the Urban Garden; ready to harvest!) or, if you feel like stretching your legs, walk downtown to grab lunch.\n \nBack inside. Quick sprint review (working together anywhere means virtual happy birthday to that colleague in Paris that just turned 35). The afternoon went flying (tasks, reports, calls, some jokes with your teammates). End it on a high note: just one PlayStation game or the final match for that ping-pong tournament.\n \nTomorrow, you complete that certified technical training and the day after, you will work from home, taking advantage to finally do that online course on Udemy. Once you are done with your tasks for the day, you can visit the office for a board games session or show up at the rehearsal of one of Natixis bands. If that is too steady for you, meet your colleagues to surf some waves or join them in a football match.","145":"Company Description\nGuardant Health is a leading precision oncology company focused on helping conquer cancer globally through use of its proprietary tests, vast data sets and advanced analytics. The Guardant Health oncology platform leverages capabilities to drive commercial adoption, improve patient clinical outcomes and lower healthcare costs across all stages of the cancer care continuum. Guardant Health has commercially launched Guardant360\u00ae, Guardant360 CDx, Guardant360 TissueNext\u2122, Guardant360 Response\u2122, and GuardantOMNI\u00ae tests for advanced stage cancer patients, and Guardant Reveal\u2122 for early-stage cancer patients. The Guardant Health screening portfolio, including the Shield\u2122 test, aims to address the needs of individuals eligible for cancer screening.\nJob Description\nDepartment Summary \u2013 This department works towards (NGS) Assay Workflow Software, Data Infrastructure, Data Research and Systems Integration.\nAbout the Role:\nThis position is part of the Systems Integration team for an early-stage cancer screening NGS Assay and associated automation and bioinformatics software components. We are looking for a motivated scientist\/engineer who is interested in crossing the bridge from academia to industry, in the near future and has either completed a grad program or is currently enrolled. This individual will get the opportunity to work at the forefront of scientific and technological innovation within an interdisciplinary Screening Systems Integration team and will make core contribution to evolving cancer screening products designed to have clinical impact on patients. Come join us! \nEssential Duties and Responsibilities:\nAnalyze large amounts of data on NGS assay performance and generate visualizations for storytelling, monitoring and tracking \nAssess various fundamental calculations in assay and associated software implementation \nGenerate test methods for assessing assay and software calculations in Python \nGenerate data visualization to assess the performance of the assay and various assay Quality Controls (in Python). \nGenerate reports integrated in python notebooks, that include data visualization and Quality Control calculations. \nOnce the project is completed, provide written documentation and requirements related to Assay, Software and Automation. \nPresent findings and results to cross functional highly technical audience in Bioinformatics, Software, Automation and Assay functions.  \nContribute to a highly collaborative work environment among cross functional teams.  \nQualifications\nCompleted or currently enrolled in a MS or PhD program in Biomedical Sciences, Engineering, Software or Bioinformatics. \nSignificant research experience in these areas.  \nProficiency in Python, including visualization packages such as Matplotlib and Plotly \nAbility to work with large amounts of structured or semi-structured data.  \nAbility to build reproducible and well-written Python code for data analytics \nAbility to communicate highly technical findings to a diverse audience, within NGS assays development teams.  \nPreferred Qualifications: \nExperience with analysis of NGS assay data.\nAdditional Information\nHybrid Work Model: At Guardant Health, we have defined days for in-person\/onsite collaboration and work-from-home days for individual-focused time. All U.S. employees who live within 50 miles of a Guardant facility will be required to be onsite on Mondays, Tuesdays, and Thursdays. We have found aligning our scheduled in-office days allows our teams to do the best work and creates the focused thinking time our innovative work requires. At Guardant, our work model has created flexibility for better work-life balance while keeping teams connected to advance our science for our patients.\nCovid Vaccination Policy:  Guardant Health requires all employees to be fully vaccinated. We follow the CDC guidelines for the definition of \u201cfully vaccinated\u201d, meaning an employee is consider fully vaccinated against COVID-19 after receiving the second dose of a two-dose vaccine or one dose of a single-dose vaccination, and necessary booster vaccines. In addition, fully vaccinated employees will be required to maintain their fully vaccinated status under this policy by obtaining, if applicable, any FDA-approved boosters. Candidates may request and obtain an approved exemption from Guardant\u2019s COVID-19 U.S. Vaccination Policy as a reasonable accommodation, as consistent with applicable laws.\u202f\u202fCandidates will not be able to start their employment with Guardant until they show proof of vaccination or have an approved exemption.\nFor positions based in Palo Alto, CA or Redwood City, CA, the hourly range for this full-time position is Undergraduate $27\/hr., Graduate $32\/hr., and Doctorate $40\/hr. The range does not include benefits and, if applicable, overtime, bonus, commission, or equity.\nWithin the range, individual pay is determined by work location and additional factors, including, but not limited to, job-related skills, experience, and relevant education or training. If you are selected to move forward, the recruiting team will provide details specific to the factors above.\nEmployee may be required to lift routine office supplies and use office equipment. Majority of the work is performed in a desk\/office environment; however, there may be exposure to high noise levels, fumes, and biohazard material in the laboratory environment. Ability to sit for extended periods of time.\nGuardant Health is committed to providing reasonable accommodations in our hiring processes for candidates with disabilities, long-term conditions, mental health conditions, or sincerely held religious beliefs. If you need support, please reach out to Peopleteam@guardanthealth.com\nGuardant Health is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.\nAll your information will be kept confidential according to EEO guidelines.\n\nTo learn more about the information collected when you apply for a position at Guardant Health, Inc. and how it is used, please review our Privacy Notice for Job Applicants.\nPlease visit our career page at: http:\/\/www.guardanthealth.com\/jobs\/\n#LI-CS4","146":"At Beyond Finance, we\u2019ve made it our mission to help everyday Americans escape the endless cycle of crippling debt and step into a brighter financial future. Through compassionate, individualized care, supportive user-centric technology, and customized financial solutions, we\u2019ve helped over 200,000 clients on their path to a debt-free life.\nWhile we\u2019re proud of what we\u2019ve already accomplished (over $1 billion in resolved debt), we're searching for new collaborators to help us get to the next level! If you\u2019re looking to join a forward-thinking, rapidly growing organization with helping people as its number one goal, we want to hear from you.\nJob Title: Senior Business Intelligence Engineer\nLocation: 333 W Wacker Drive, Suite 1800, Chicago, IL 60606\nJob Description\nDesign strategies for enterprise databases, data warehouse systems, and multidimensional networks for a financial services company. Model, design, and construct large relational databases or data warehouses. Create and optimize data models for warehouse infrastructure and workflow. Document and map existing data structures from the operational system to the new curated data structures and author ETL scripts. Work with various internal business groups to understand their short and long-term business needs and create a plan to deliver the data using the existing system or new data. Use multidimensional modeling techniques to develop models to help internal business users understand data. Perform dimensional modeling, relational databases, tables, columns, and data types. Supervise others and participate in building the BI layer, ensuring integration of BI access in data and reporting. Supervise team members and participate in building BI reports. Train team members to build BI reports. Supervise others and participate in using advanced SQL and LookML techniques to transform excel-based reports into executive summary Looker dashboards with key performance metrics. Supervise others and participate in using SQL and Snowflake data warehousing concepts to build new data repositories by authoring complex ETL logic and evolve current data structures to render them reporting ready. Refine and curate Salesforce data using dimensional modeling techniques to enable operational statistics measurement and agent compliance tracking. Coach \/ mentor junior members on the team. Telecommuting \/ remote work permitted.\nEducation Requirement: Master\u2019s degree in Computer Science, Management Information Systems, or related.\nExperience Requirement: 1 year of experience as BI Engineer, Data Engineer, Data Architect, or related.\nAlternate Requirements: In lieu of a master's degree plus one year of experience, will accept a bachelor's degree plus five years of experience in the same fields.\nSpecial Skills: Must have work experience with each of the following: (1) Use advanced SQL and LookML techniques to transform excel-based reports into executive summary Looker dashboards with key performance metrics for the financial services industry; (2) Use SQL and Snowflake data warehousing concepts to build new data repositories by authoring complex ETL logic and evolve current data structures to render them reporting-ready; and (3) Refine and curate Salesforce data using dimensional modeling techniques to enable operational statistics measurement and agent compliance tracking.\nThe base salary range represents the anticipated salary range for this position. The actual base salary offered within the range will depend on numerous factors including the individual\u2019s skills, experience, performance, and the location where work is performed. In addition to base salary, this position qualifies for an annual bonus subject to the terms outlined in the company's bonus plan. Full-time employees hired into this position are eligible for health care benefits shown here. Base Salary Range$141,000\u2014$150,000 USD\nWhy Join Us?\nWhile you make a difference for others, we\u2019ll work to make a difference for you, providing an uplifting, collaborative work environment and benefits that reflect your value to us. For eligible full-time employees, we offer:\nConsiderable employer contributions for health, dental, and vision programs\nOptional remote and hybrid work models\nGenerous PTO, paid holidays, and paid parental leave\n401(k) matching program\nMerit advancement opportunities\nCareer development & training\nAnd finally, our team spirit and culture! Even as we\u2019ve shifted to a remote-first model, we continue to cultivate an environment of community, connection, and belonging across our entire organization.","147":"Location: Gurgaon, Noida, Hyderabad, Chennai, Bangalore, Pune, Kolkata, Indore, Jaipur, Ahmedabad,None,None\nAbout Material\nMaterial is a global strategy, insights, design, and technology partner to companies striving for true customer centricity and ongoing relevance in a digital first, customer-led world. By leveraging proprietary, science-based tools that enable human understanding, we inform and create customer-centric business models and experiences + deploy measurement systems \u2013 to build transformational relationships between businesses and the people they serve.\nAbout Srijan\nSrijan is a global engineering firm that builds transformative digital paths to better futures for Fortune 500 enterprises to nonprofits all over the world. Srijan brings advanced engineering capabilities and agile practices to some of the biggest names across FMCG, Aviation, Telecom, Technology, and others. We help businesses embrace the digital future with cloud, data, API and platform centric technologies and adapt to changing business models and market demands. Srijan leads in Drupal with 350+ Drupal engineers, 80+ Acquia certifications. Srijan is also a Drupal Enterprise Partner & Diamond Certified\nSkillls and Requrement :\nExperience:\n5+ years\u2019 professional experience developing reports using enterprise reporting tools\nMinimum 4 years\u2019 experience designing and developing dashboards using Tableau Desktop for various organizational metrics and indicators using best practices and industry standards\n4 + years of experience with Data Visualization tools such as Power BI & Tableau required;\nWell organized, with attention to detail and a strong focus on accuracy;\nHas the ability to work effectively in a fast-paced environment, juggling multiple priorities;\nYou possess demonstrated analytical and critical thinking skills;\nData artisan \u2013 can tell a story with the data in a dashboard.\nHighly Experience with Tableau Server and Tableau Desktop across various versions of Tableau 9.x\/10.x- Good in BI and data warehousing concepts Experience with BI applications comprised of multiple \/ inconsistent data sources\nUnderstanding of ETL process- good database knowledge and experience, should be able to write complex SQL queries against RDBMS (such as Oracle, MySQL etc.) and NoSQL databases (such as MongoDB, Couchbase etc.)\nParticularly good understanding of SDLC and Agile processes.\nExperience in data modelling, data loading, data migration, data analysis (must), along with semantic (business rules) layer implementation\nUnderstanding of the Data warehouse life cycle right from data source to ETL to transformations to multidimensional models like data marts, star schema and Reporting\nExperience with Cloud native BI\/ Analytics implementation and service integration\nPreferred experience with Tableau \/ Looker \/ Power-BI \/ Alteryx\nExcellent communication and inter-personal skills, accustomed to work in a team environment with tight schedules and capable of working efficiently under pressure\nAbility to interact with stakeholders throughout the organization\nSolid understanding of data and database technologies (data analysis, data prep, ETL, ELT, etc.) required;\n Responsibilities:\nRequirement Gathering & Analysis:\nResponsible for participating in business requirements gathering exercise and translating business requirements into functional and technical specifications.\nParticipate and provide inputs during requirements feasibility analysis and provide alternate solutions based on application architecture.\nResponsible for functional requirements interpretation and guiding the team on design and development process.\nTechnology Review:\nResponsible for end-to-end analysis of the application portfolio and provide inputs for transformation opportunities for a given line of business.\nTesting:\nResponsible for creating the test plan and associated functional test cases.\nPerform functional testing as required for a given release.\nProject Support:\nGuide the delivery team during impact analysis of incidents by providing inputs on upstream and downstream dependencies.\nProvide inputs for prioritizing incidents and problems.\nParticipate and provide inputs during change impact analysis and prioritization process.\nAssist the delivery team in complying with regulatory and compliance requirements.\nParticipate in release acceptance exercise and provide inputs for business signoff.\nPeople Management:\nDrive the SME development program to assess and develop domain experts.\nCreate a career road map for Application SME to become domain experts and track the progress periodically.\nBusiness Development:\nWork with pre-sales and practice on business development and existing growth opportunities in terms of discovery, solution options, evaluation, estimation, training and creation of collaterals\nCustomer Relationship Management:\nContribute to continuous service improvement plans (CSI).\nKnowledge Management:\nContribute and participate proactively in knowledge sharing sessions.\nAudits\nParticipate in security and compliance audits.\n What you will get:\nCompetitive Salaries with flexi benefits \nGroup Mediclaim Insurance and Personal Accidental Policy\n30+ Paid Leaves in a year \nLearning and Development of quarterly budgets for certification\n   Apply to this job","148":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value\nJob Description\nAs Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions.\nYou will independently drive design discussions to ensure the necessary health of the overall solution.\nThe role requires a hands-on technologist who has strong programming background like Java \/ Scala \/ Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components.\nYou are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. \nRole & Responsibilities:\nYour role is focused on the Design, Development and delivery of solutions involving:\nData Integration, Processing & Governance\nData Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations\nInfrastructure & Cloud Computing\nData Management Platforms\nImplement scalable architectural models for data processing and storage\nBuild functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode\nBuild functionality for data analytics, search and aggregation\n#LI-REMOTE \nQualifications\nOverall 5+ years of IT experience with 3+ years in Data related technologies\nMinimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS \/ Azure \/ GCP)\nHands-on experience with the Hadoop stack \u2013 HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline.\nStrong experience in at least of the programming language Java, Scala, Python. Java preferable\nHands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc\n Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security \n Competency\n1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience\n2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc\n3. Knowledge on distributed messaging frameworks like ActiveMQ \/ RabbiMQ \/ Solace, search & indexing and Micro services architectures\n4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 \u2013 Data Engineering\n5. CI\/CD \u2013 Infra provisioning on cloud, auto build & deployment pipelines, code quality\n6. Cloud data specialty and other related Big data technology certifications\nPersonal Attributes:\nStrong written and verbal communication skills\nArticulaion skills\nGood team player\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nProcess orientation and the ability to define and set up processe\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements\nEmployee Assistance Programs to help you in wellness and well being","149":"Join the fast growing Global Ads Partner Development team as the Senior Business Intelligence Engineer. In this role you will work with a team of Business Intelligence Engineers aimed at providing data driven business insights to inform our partner development strategy.\nYou will drive impact by helping your team to focus on the right priorities, building mechanisms and dashboards to make data accessible to internal teams, and leading the development of strategic initiatives including marketing attribution models and impact measurement.\n\nYou will be part of the Ads Partner Development and Marketing org and will work closely with stakeholders including marketing, product, finance, and partner development teams.\n\nThis highly visible and strategic role will require you to use SQL, ETL, data warehouse concepts, data modeling, business analysis, reporting, scripting, descriptive & inferential statistics to create business insights. You will need to be savvy about leveraging large data sets, defining BI requirements, and building scalable and automated dashboards to provide self-service BI capability to your stakeholders.\n\n\nKey job responsibilities\nDesign, build, and maintain automated reporting, dashboards, and ongoing analysis to enable data driven decisions across our team and with partner teams.\nIdentify, develop, manage, and execute queries across multiple data sets to uncover areas of opportunity and present written business recommendations.\nLead Agile Sprints and task prioritization to drive impact\nLead infrastructure creation for partner advertiser datasets which will include setting up new redshift cluster, creating new data pipelines and building schema for partner tables\nStrong proficiency at querying and architecting relational databases - e.g. ETL, Data Warehouse, Redshift\nDevelop attribution analysis to measure the impact of marketing activities and engagement with partners\nDevelop a framework to understand the impact that partners drive on our business globally\nCommunicate with internal teams to showcase results and identify best practices\n\n#adptjobs\n#sspajobs\n\nAbout the team\nThis role is within Partner Analytics team within the Global Advertising Partner Development organization. We help advertisers and developers to scale their use of Amazon Advertising and grow their business via software tools and marketing\/engagement programs that enable developers (internal and external) and partners (agencies and tool providers) to better serve advertiser needs.\nBasic Qualifications\n\n6+ years of professional or military experience\n5+ years of SQL experience\nExperience programming to extract, transform and clean large (multi-TB) data sets\nExperience with theory and practice of design of experiments and statistical analysis of results\nExperience with AWS technologies\nExperience in scripting for automation (e.g. Python) and advanced SQL skills.\nExperience with theory and practice of information retrieval, data science, machine learning and data mining\n\nPreferred Qualifications\nMaster\u2019s degree in BI, Finance, Engineering, Statistics, Computer Science, Mathematics, Finance or related field required.\nExperience in designing and delivering cross functional custom reporting solutions.\nExperience with Massively Parallel Processing (MPP) databases - Redshift (preferred), Teradata.\nExperience with R, Python or other statistical\/machine learning software.\nExperience with Tableau.\nAdvanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as required, both verbally and written.\nBe self-driven, and show ability to deliver on ambiguous projects.\n\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https:\/\/www.amazon.jobs\/en\/disability\/us.\n\n\nOur compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $104,300\/year in our lowest geographic market up to $202,800\/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and\/or other benefits. For more information, please visit https:\/\/www.aboutamazon.com\/workplace\/employee-benefits. Applicants should apply via our internal or external career site.","150":"Descripci\u00f3n de la empresa\nCon casi 10K empleados en todo el mundo, apoyamos a las empresas en su transformaci\u00f3n digital. Imaginamos y hacemos realidad sus ambiciones gracias a las infinitas posibilidades de las plataformas digitales, para cambiar su cultura y su forma de trabajar, y crear valor en sus organizaciones.\nPresentes en 18 pa\u00edses de Europa y Oriente Medio y con 25 a\u00f1os de experiencia, ponemos la \"Tecnolog\u00eda al servicio del Hombre\" para construir un mundo m\u00e1s humano y sostenible.\n#CreativeTechForBetterChange\n https:\/\/www.youtube.com\/watch?v=ir-IZHrTS0c\nTrabajar en Devoteam significa:\nTrabajar junto a partners como Google, Microsoft, AWS o Salesforce cuyas soluciones implementamos para nuestros clientes;\nevolucionar en un grupo internacional que te apoya en el desarrollo de tu carrera con cursos de formaci\u00f3n y certificaci\u00f3n adaptados.\nunirse a un equipo especializado, acompa\u00f1ado por un responsable local que podr\u00e1 guiarle en sus elecciones y promover los intercambios con sus compa\u00f1eros, ya sea durante eventos t\u00e9cnicos o de convivencia.\ncrecer en una empresa que desaf\u00eda a sus equipos siendo \u00e1gil y ambiciosa, adapt\u00e1ndose para permitir el \u00e9xito individual y colectivo.\nDescripci\u00f3n del empleo\nBIG DATA ENGINEER (AWS)\nBuscamos un\/a Big Data Engineer para que se incorpore a nuestro equipo de Data. Formar\u00e1s parte del equipo que configura la estrategia, la arquitectura y la infraestructura de datos de importante empresa del sector retail ubicada en Barcelona. \n\u00bfC\u00d3MO ES NUESTRO EQUIPO?\nInspiramos y unimos mediante nuestra pasi\u00f3n por el estilo y la cultura. Estamos en 118 pa\u00edses y nuestra presencia online se extiende a m\u00e1s de 80 pa\u00edses. Nuestro equipo est\u00e1 formado por personas de 112 nacionalidades y en un 80% por mujeres.\nSomos un equipo muy din\u00e1mico, motivado por las nuevas tecnolog\u00edas, con pasi\u00f3n por lo que hacemos y abiertos a afrontar grandes retos que nos permitan seguir creciendo y aportando valor a trav\u00e9s de los datos.\n\u00bfQU\u00c9 HACE UN\/A BIG DATA EGINEER EN UNA EMPRESA RETAIL?\nTu objetivo ser\u00e1 desarrollar soluciones de procesamiento de datos de \u00faltima generaci\u00f3n para permitir casos de uso que sean muy innovadores en el sector retail, como geo-anal\u00edtica, robotizaci\u00f3n, personalizaci\u00f3n omnicanal, la tienda online, experiencia del consumidor 360\u00ba y decisiones en tiempo real.\nEn tu d\u00eda a d\u00eda\u2026\n\u2022            Desarrollar\u00e1s pipelines en batch y tiempo real con Spark, dbt, Spark Structured Streaming y Kafka.\n\u2022            Desarrollar\u00e1s y gestionar\u00e1s el Data Lake, el procesamiento de datos y las plataformas de datos end to end:\n1.           Dise\u00f1ar\u00e1s y gestionar\u00e1s soluciones de arquitectura cloud. Desarrollar\u00e1s integraciones de datos escalables y confiables para alimentar los modelos de Data Science.\n2.           Administrar\u00e1s y orquestar\u00e1s mecanismos adecuados de monitorizaci\u00f3n.\n3.           Dise\u00f1ar\u00e1s pipelines CI \/ CD. Participar\u00e1s en la automatizaci\u00f3n de tests, calidad del c\u00f3digo y despliegue autom\u00e1tico de nuestras aplicaciones.\n4.           Estar\u00e1s conectado con los \u00faltimos avances en Big Data y colaborar\u00e1s en el I+D que aportar\u00e1n nuevos casos de uso y mejoras.\n\u00bfQU\u00c9 ESPERAMOS DE TI?\n\u2022       Que aportes al menos 3 a\u00f1os de experiencia desarrollando en Python, Scala, o cualquier otro lenguaje orientado a objetos.\n\u2022       Que aportes experiencia en el desarrollo de ELT escalable, procesos de integraci\u00f3n de datos con Spark, Spark Structured Streaming o cualquier otra tecnolog\u00eda de procesamiento de datos.\n\u2022       Que est\u00e9s interesado\/a y apliques buenas pr\u00e1cticas: tests, automatizaciones, construyas pipelines en CI, etc.\n\u2022       Que tengas experiencia en la construcci\u00f3n y el mantenimiento de cargas de datos de alto volumen complejas y orquestando dependencias (por ejemplo, Airflow).\n\u2022       Que hayas trabajado con servicios de AWS (por ejemplo, S3, Lambda, DynamoDB, API Gateway, Glue, Athena, ECR\/ECS), y Databricks es muy deseable.\n\u2022       Que seas una persona comprometida, proactiva, que se preocupe por la calidad de sus entregables, y una mentalidad hands-on.\n\u00bfQU\u00c9 NOS HACE ESPECIALES?\n\u2022       Incorporaci\u00f3n inmediata con contrato indefinido\n\u2022       Ofrecemos horario flexible (puedes entrar de 8 a 9.30 y salir de 17 a 18.30) con jornada intensiva todos los viernes (puedes entrar de 8 a 9 y salir de 14 a 15) y la mayor\u00eda de las vigilias de festivos\n\u2022       Posibilidad de teletrabajo del 50%  en nuestra sede central en Palau-Solit\u00e0 i Plegamans\n\u2022       25% de descuento en todas nuestras l\u00edneas\n\u2022       Te podr\u00e1s formar a nivel t\u00e9cnico en plataformas como O'Reilly, Udemy, Codely, entre otras, as\u00ed como en idiomas, y en habilidades para tu desarrollo personal. Te acompa\u00f1amos para que sigas creciendo a nivel profesional y personal!\n\u2022       Pol\u00edtica de referrals, podr\u00e1s participar en la incorporaci\u00f3n de talento a nuestros equipos, \u00a1y te recompensaremos por ello!\n\u2022       Transporte gratuito de empresa desde Barcelona y el Vall\u00e8s para llegar a nuestras oficinas centrales\n\u2022       Servicio de fisioterapia en las oficinas centrales, as\u00ed como sala de fitness y vestuarios por si te gusta hacer deporte en tu tiempo libre\n\u2022       Workshops, meetups, comunidades de pr\u00e1cticas, team buildings y company meetings\n\u2022       Paquete de retribuci\u00f3n flexible con ventajas fiscales: seguro m\u00e9dico, formaci\u00f3n, descuento comedor, guarder\u00edas etc\n\u2022       Servicio de comedor y cocina en las instalaciones de la central. La empresa subvenciona parte del men\u00fa diario as\u00ed como los art\u00edculos de cafeter\u00eda.\n\u2022       Servicio m\u00e9dico propio en las instalaciones de la central.\n\u2022       Formar\u00e1s parte de una empresa l\u00edder en el sector de la moda, din\u00e1mica, en plena innovaci\u00f3n, con gran concienciaci\u00f3n y realizando acciones hacia la sostenibilidad\n\u2022       Ambiente de trabajo cercano, inspirador y ambicioso , trabajar\u00e1s con un gran equipo que va en la misma direcci\u00f3n para conseguir los mejores resultados\n\u2022       Oportunidades constantes de desarrollo con retos muy variados que generan aprendizaje en el puesto de trabajo\nInformaci\u00f3n adicional\n  ","151":"Company Description\nVisa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.\nWhen you join Visa, you join a culture of purpose and belonging \u2013 where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world \u2013 helping unlock financial access to enable the future of money movement.\nJoin Visa: A Network Working for Everyone.\nJob Description\nVisa Consulting and Analytics (VCA), the consulting arm of Visa, is a global team of industry experts in strategy, marketing, operations, risk and economics consulting, with decades of experience in the payments industry.\nOur VCA teams offers:\nConsulting services customized to the needs of Visa client's business objectives and strategy\nBusiness and economic insights and perspectives that impact business and investment decisions\nSelf-service digital solutions Visa clients can leverage to improve performance in product, marketing and operations\nProven data-driven marketing strategies to increase clients' ROI\nVCA team is looking for a passionate individual to join our consulting practice and play a role in the data engineering team. The ideal candidate is adept at using big data sets to understand our client's challenges and deploy targeted solutions to drive meaningful benefits, leveraging our world-class payment knowledge, in combination with our diverse service offerings to address key strategic needs for Visa's clients including issuers, acquirers and merchants.\nHe\/She must have experience using a variety of data mining\/data analysis methods, using a variety of distributed data platforms, and leveraging the latest open-source technologies. He\/She must have a proven ability to drive business results with their data-based insights. Adept at creative and critical thinking, be able to deconstruct problems and transform insights into large scale, state-of-the-art solutions.\nResponsibilities\nAutomate and standardize data processes developed by team members.\nLeverage DevOps to create end-to-end streamline CI\/CD data and ML pipelines.\nReview and manage data pipelines, branching, and deployment process.\nWork with partners on requirements and implementation designs of data solutions.\nImplement data quality framework at scale using open-source technologies.\nCreate data monitoring dashboards with real-time notifications.\nUnderstand VisaNet data and platform ecosystem to deploy fully automatic data applications for internal and external clients.\nUnify data engineering and machine learning engineering pipelines.\nApply spark optimization techniques to production jobs to accelerate data prep.\nDocument process, designs, test results, and analysis.\nAbility to articulate complex architectures to non-technical audiences, management, and leadership.\nContinuously research industry best practices and technologies.\nEvangelize end to end automation and standardization across the organization.\nPartner with functional areas, and regional and global teams to leverage the breadth and depth of Visa\u2019s resources.\nThis is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership\/site), with a general guidepost of being in the office 50% or more of the time based on business needs.\nQualifications\nBasic Qualifications\n\n\u2022 BA\/BS required, MBA or other relevant Master\u2019s degree preferred (e.g. engineering, computer science, computer engineering, applied mathematics, or other related fields)\n\nPreferred Qualifications\n\n\u2022 At least 5 years of experience as data engineer or data scientist with open-source tools.\n\u2022 Experience in retail banking, payments, financial services, and\/or technology industries is a plus. Strong interest in the future of payments is a must.\n\u2022 Strong technical competency and experience with shell-scripting and Linux systems.\n\u2022 Experience with CI\/CD pipeline using Azure DevOps, GitHub actions, Jenkins, or Airflow.\n\u2022 Strong coding skills in Spark, Python and SQL to manipulate big data in distributed platforms.\n\u2022 Good to have experience in navigating in Linux\/Unix\/Container based apps such as Docker, Kubernetes, or Microservices environments.\n\u2022 Knowledge in how to leverage AI assistance tools like chatGPT for creating and debugging code.\n\u2022 Ability to interact with big data clusters using Jupiter Notebooks, terminal, or GUI.\n\u2022 Demonstrate experience leveraging open-source tools, libraries, and platforms.\n\u2022 Experience with data visualization and business intelligence tools like Tableau, PowerBI, Microstrategy, or Excel.\n\u2022 Problem solving ability and process creator with strategic focus on replicability, scalability, innovation, and governance.\n\u2022 Proficient with git for version control and code collaboration using branches and pull requests.\n\u2022 Must be passionate about automation and data and able to deliver high quality work.\n\u2022 Experience developing as part of Agile\/Scrum team.\n\u2022 Fluency in English (spoken\/written). Portuguese or Spanish is a plus.\n\u2022 Experience in developing integrated cloud applications with services like AWS, Azure Cloud, and GCP is a plus.\nAdditional Information\nVisa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.","152":"Company Description\nOcorian is a global leader in corporate and fiduciary services, fund administration and capital markets. Wherever our clients hold financial interests, or however they are structured, we provide compliant, tailored solutions that are individual to their needs.\nWe manage over 17,000 structures for 8000+ clients with a global footprint operating from 18 locations. Our scale offers all our people great opportunities to develop their knowledge and skills and to progress their careers.\nJob Description\nPurpose of the job\nTo assist in the development of business intelligence and management information solutions for Ocorian taking information from the financial, HR, corporate administration systems, and Cloud-based solutions to create a reporting base for the business, the single source of truth\nDelivery of key dashboards and reporting requirements from the BI\/MI solutions with appropriate robust security models\nAssist with data cleansing and data loading exercises, which may extend to jurisdictional and regulatory filing requirements\nDocumentation of solutions, handover to BAU Teams, and supporting solutions\nPrior experience of creating\/supporting ETL, data warehouses and Tabular data models. Ocorian utilises Microsoft SQL Server technologies, including SSIS, SSAS, SSRS and Power BI and the successful candidate should have delivered projects using aspects of this technology stack in recent times\nThe individual will be expected to work across all levels of the Business to liaise with key stakeholders to ensure the design, development and documentation meets the requirements of the Business. The role will work extensively with IT functions and the role may be matrix-managed when required with tasks assigned by the BAU BI Team\nMain Rresponsibilities\nDesign and implement data warehouse solutions and Tabular data models\nDevelop dashboards and reporting to meet business reporting needs\nDeliver approved projects within timeframe\nProvide regular updates to management\nMake recommendations for potential improvement or changes\nPromote the use of core systems for data capture aligned to standards and initiatives\nQualifications\nTechnical Skills\nSQL Server 2016 onwards\nSQL Server BI stack \u2013 SSAS \/ SSIS \/ SSRS\nMicrosoft Power BI\nExperience of data cleansing tools and methodologies\nBusinesss Skills\nDemonstrated ability to apply IT in solving business problems\nGood written, oral, and interpersonal communication skills\nAbility to present ideas in business-friendly and user-friendly language\nHighly self-motivated, proactive and attentive to detail\nAbility to effectively prioritise and execute tasks in a high-pressure environment\nExtensive experience working in a team-oriented, collaborative multi-jurisdictional environment\nExperience of working in project teams with mixed skillsets and levels of technical knowledge\nEnergy and enthusiasm to support the future growth and success of the business\nAdditional Information\nAll staff are expected to embody our core values that underpin everything that we do and that reflect the skills and behaviours we all need to be successful.  These are:\nWe are AMBITIOUS - We think and act globally, seizing every opportunity to support our clients and staff - wherever in the world they may be.\nWe are AGILE - Our independence from any financial institution gives us the flexibility and freedom to keep things simple, efficient and effective.\nWe are COLLABORATIVE - We take the time to understand our clients' needs so that we can deliver personalised solutions every time.","153":"Company Description\nEurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins laboratories work with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic, and labelling is accurate.\nThe Eurofins network of companies is the global leader in food, environment, pharmaceutical and cosmetic product testing and in agro-science Contract Research Organization services. It is one of the market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, advanced material sciences and in the support of clinical studies, as well as having an emerging global presence in Contract Development and Manufacturing Organizations. It also has a rapidly developing presence in highly specialized and molecular clinical diagnostic testing and in-vitro diagnostic products.\nIn over 30 years, Eurofins has grown from one laboratory in Nantes, France to 58,000 staff across a decentralized and entrepreneurial network of 900 laboratories in over 54 countries. Eurofins companies offer a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products.\nIn 2021, Eurofins generated total revenues of EUR 6.72 billion, and has been among the best performing stocks in Europe over the past 20 years.\nJob Description\nJob Summary: \nEurofins is looking for a PowerBI Developer to be take responsibility for developing and maintaining meaningful monthly, quarterly and annual reporting metrics for an Americas IT Infrastructure Support Team. This involves aggregating data from multiple sources, including but not limited to ServiceNow, MS Endpoint Configuration Manager, and Security\/Vulnerability databases, and translating that data it into reports and visuals to drive key operational decisions. \nRoles & Responsibilities: \nUnderstand business requirements and translate them into a Power BI context \nCreate dashboards and interactive visual reports using Power BI \nIdentify, prepare, monitor and analyze KPI\u2019s used to aid business decision-making \nIn lieu of automated PowerBI reporting being available, build reports and KPI\u2019s manually using Excel or other available tools \nDesign, develop, test, and deploy Power BI scripts and perform detailed analytics \nPerform DAX (data analysis expressions) queries and functions in Power BI \nAnalyze current ETL (extract and transform load) process, define and design new systems \nInfluence technical\/strategic changes to enhance existing Business Intelligence systems\u202f \n Qualifications\nTechnical Requirements:\n3+ years of work experience in:\nPowerBI development in an IT Service setting \nMicrosoft SQL queries, database management, modeling, warehousing and business intelligence.\nAggregating and correlating large datasets into actionable reporting\nAdvanced English level\nDesired:\nSSRS, SSIS knowledge.\nITSM\/PM experience\n Soft skills: \nFlexible\nSelf-motivated\nProactive","154":"Company Description\nAt ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can\u2019t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. \nWith more than 7,400+ customers, we serve approximately 80% of the Fortune 500, and we're proud to be one of FORTUNE's 100 Best Companies to Work For\u00ae and World's Most Admired Companies\u00ae 2022.\nLearn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.\nUnsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.\nJob Description\nYou will be part of the ServiceNow Cloud Services Big Data Team.  The Big Data team is building the next-generation platform that collects, stores and provides real-time access to large amounts of data.\nYou will be driving the design and implementation of ServiceNow in-house real-time data visualization and analytics platform to support the growth of ServiceNow.\nWhat you get to do in this role:\nBring your innovation and experience in designing and developing the next generation data analytics platform using cutting-edge technologies. \nLead a global engineering team to drive end to end product design and implementation. \nStandardize processes for complete development cycle including design, implementation, unit testing, code review, testing automation etc. \nResearch and adopt the right technologies to improve the scalability and productivity of the engineering group. \nWork closely with key stakeholders and product owners to drive technical design for requirements of various use cases. \nCoordinate with cross-function teams (DevOps, network, QA, etc.) to ensure a smooth cycle from development to deployment.\nQualifications\nTo be successful in this role you have:\nHands-on experience architecting enterprise data analytics products with high scalability and performance.\n6+ years of software development experience along with strong troubleshooting and debugging skills.\nExpert level skills with JavaScript, NodeJS, Webpack, ReactJS or other modern UI frameworks, Java and REST API developments.\nBackground with data analytics, data visualization, BI tools and Hadoop ecosystem.\nAbility to produce high-quality software that is unit tested, code reviewed, and checked in regularly for continuous integration.\nSolid background in complicated SQL & data analytics.\nZeal for learning and adopting new ideas and patterns.\nStrong Computer Science fundamentals,  data structures, algorithms, and software design.\nFor positions in California (outside of the Bay Area), we offer a base pay of $136,800 - 239,400, plus equity (when applicable), variable\/incentive compensation and benefits. Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. Please note that the base pay shown is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location. We also offer health plans, including flexible spending accounts, a 401(k) Plan with company match, ESPP, matching donations, a flexible time away plan and family leave programs.\u202f Compensation is based on the geographic location in which the role is located, and is subject to change based on work location. For individuals who will be working in the Bay Area, there is a pay enhancement for positions located in that geographical area; please contact your recruiter for additional information.\nAdditional Information\nServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.\nAt ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.\nIf you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.\nFor positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.\nPlease Note: Fraudulent job postings\/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.\n  From Fortune. \u00a9 2022 Fortune Media IP Limited All rights reserved. Used under license.\nFortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","155":"GumGum is a contextual-first, global digital advertising platform that uses advanced AI  technology to serve captivating creative ads that drive consumer attention, without the use of personal data. At GumGum, we don\u2019t need to know who you are to deliver relevant and engaging ads that align with your active frame of mind. We believe that a digital advertising industry based on context rather than personal data builds a more equitable and less invasive future for the internet and is better for consumers, publishers and advertisers alike. Our blueprint for the future, The Mindset Matrix\u2122, combines the power of context and creative in digital advertising to deliver superior attention and drive consumer action without sacrificing personal data. \nTo be a part of this next phase of digital advertising that prioritizes data privacy, please visit www.gumgum.com\/careers\nThe BI Developer is responsible for working on our Looker BI platform to drive near real-time data analytics solutions which then supports our internal stakeholders. This role has a core focus on identifying essential reports in Looker for the advertising business. \nReporting to our Data Engineering Manager, the BI Developer will work as part of a team of engineers in the technology division of our advertising business.\nNote: GumGum currently operates in a \u2018work from home\u2019 virtual environment with sporadic opportunities for in-person business and morale events (health guidelines permitting). There will not be any requirement to go into the office on a daily basis moving forward. \nWhat You'll Achieve\nBuild and maintain our big data BI platform with Snowflake and Looker\nDevelop data products that offer new and emerging business insights\nContribute to our self-serve data products that serve hundreds of global users\nWork with stakeholders in various departments to fully understand the business requirements and translate them into database query models and data analytics.\nCreate and manage BI Access controls for users with row level, column level and report level security\nPerform data analysis, discovery, profiling and work with the Data Engineering team to identify and resolve data related issues.\nEstablish governance processes around metadata to ensure data integration, accuracy, validity, and reusability.\nSkills You'll Bring\nMinimum Bachelor's degree in Computer Science, Engineering, or a related technical field\n1+ year experience building and managing complex BI platforms\n1+ year experience with data modeling\n1+ year experience in data analytics and reporting\n1+ year experience working with product squads\nVery strong with SQL \nDeep technical understanding of at least one BI platform tool (Looker, PowerBI, or Tableau)\nStrong communications skills and a \"customer service attitude\"\nVery strong problem solving skills - they should strive to find the root of the problem rather than designing band-aids\nEnthusiasm for exploring new technologies\nSomeone who enjoys working remotely as part of a geographically dispersed team\nCool, calm and collected attitude\nBenefits & Perks\nMedical, Dental and Vision Coverage including 100% premium coverage for employee + spouse\/family \nLife Insurance, AD&D and TPD\nRetirement contributions\nShort-Term Disability and Short-Term Sickness\nWork From Home and Wellness Stipend\nInitial 12 Days PTO of vacation with 1 additional day per year up to a cap of 15 days + 5 sick day\nEmployee Assistance Program \nGumGum Gives Back volunteering\/social impact opportunities\nVirtual and in-person company events\/celebrations\nAnniversary recognition and awards\nModern Family Support and Resources\nAwards\nBuiltIn #37 Best Places to Work 2023 across the United States\nBuiltinLA #7 Best Places to Work 2022\nBuiltinLA Best Places to Work 2021\nAd Exchanger Programmatic Power Player 2022 and 2021\nDigiday Media Awards Europe finalist 2022 and 2021\nGumGum is proud to be an equal opportunity employer. At GumGum, we believe in cultivating an environment where our team members can bring their authentic, whole selves to work. Encouraging identity and belonging is one of the many aspects of our culture that makes us stronger as an organization and drives innovation. We are committed to building and delivering a diverse, inclusive, and equitable workforce that is representative of the world around us, where all individuals are treated with respect and dignity - and to act swiftly if this value is ever threatened. We are constantly striving to be better, and we continue to take strategic steps to advance representation. - Phil Schraeder, CEO\nLearn more about our DEIB programming at gumgum.com\/deib\nFollow us on our socials...\nInstagram: @gumgum & @dogsofgumgum\nLinkedIn: GumGum\nTweet us: @gumgum\nFacebook: GumGum","156":"Company Description\nAt Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people\u2019s lives. Our promise to our associates is rock-solid: We grow together, we enjoy our work, and we inspire each other. Welcome to Bosch.\nThe Bosch Power Tools GmbH  is looking forward to your application!\nJob Description\nThe team market & competitive intelligence owns the global responsibility for the contents and processes of the business development pillars market,\ncompetition & trends\nYour task mainly evolves around business intelligence in the fields of market & competition, for which you are in close interaction with global internal & external stakeholders\nYour biggest topics within the area of business intelligence:\nYou actively drive our team target to develop our contents and data to intelligence\nResponsibility for all data science & intelligence projects evolving around market & competition\nDevelopment and implementationg of AI & machine-based forecasting models (in close collaboration with your teammates\nThe second pillar of your responsibilities lies within market intelligence:\nResponsibility for certain sub-markets for an even better understanding of the contents behind the data science projects\nCoordination of sub-market estimates in close collaboration with the business units, country responsibilities & further internal stakeholders\nQualifications\nEducation: Master degree in the field of business informatics or similar\nPersonality: Analytical, structured & independent way of working. Team spirit & strong communication skills\nWorking Practice: Relevant experience in data science, business intelligence and data visualization. Ideally: experience in market intelligence & knowledge about the relevant competitive landscape\nExperience and Knowledge: Profound knowledge in business intelligence & data science\/visualization\/modeling. Experienced in handling data analytics tools (i.e. Power BI)\nLanguages: Business fluent in German & English\nAdditional Information\nYou want to work remotely or part-time - we offer great opportunities for mobile working as well as different part-time models or job-sharing. Feel free to contact us.\nDiversity and inclusion are not just trends for us but are firmly anchored in our corporate culture. Therefore, we welcome all applications, regardless of gender, age, disability, religion, ethnic origin or sexual identity.\nNeed support during your application?\nJulia Sch\u00f6ffler (Human Resources)\n+49 711 758 4261\nNeed further information about the job?\nAndreas Leinfelder (Functional Department)\n ","157":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value.\nJob Description\nAs Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects:\nData Ingestion, Transformation & Consumption,\nData Storage and Computation Frameworks,\nPerformance Optimizations,\nInfrastructure, Automation & Cloud Computing,\nData Governance & Security\nThe role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java \/ Scala \/ Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL\/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.\nRole & Responsibilities:\n1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation.\n2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality\n3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality\n4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies\n5. Participate in workshops with clients and align client stakeholders to optimal solutions.\n6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc.\n7. People management, contributing to hiring and capability building\n#LI-REMOTE \nQualifications\nOverall 8+ years of IT experience with 3+ years in Data related technologies \n3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS \/ Azure \/ GCP) and delivered at least 1 project as an architect.\nMandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud. \nExpert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions\nExpert in programming languages like Java\/ Scala and good to have Python\nExpert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub\/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc.\nExpert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc.\nShould have worked on MPP style query engines like Impala , Presto, Athena, etc\nShould have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc.\nShould have a good understanding of how to set up Big data cluster security \u2013 Authorization\/ Authentication, Security for data at rest, and data in Transit.\nShould have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager \u2013 Data Engineering\nShould have worked on any of Orchestration tools \u2013 Oozie, Airflow, Ctr-M, or similar.\nWorked on Performance Tuning, Optimization, and Data security\n  Competency\n1. Excellent understanding of data technologies landscape\/ecosystem.\n2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases\n3. Good Exposure in development with CI \/ CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage.\n4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\n5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage.\n6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions\n7. Thought Leadership \u2013 blogs, keynote sessions, POV\/POC, hackathon\n8. Certification in either one of the cloud platforms or big data technologies\nPersonal Attributes:\nStrong analytical and problem-solving skills\nStrong communication skills in verbal, written and visual presentations\nStrong coordination and negotiation skills\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nMulti geo experience and distributed delivery experience in large programs\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements \nEmployee Assistance Programs to help you in wellness and well being","158":"As a BI Engineer at Lalamove, you will be part of the growing BI & Analytics Team, which supports different functional departments in the functional office, as well as our operation offices across the globe. You will be writing and maintaining our data pipelines, reporting scripts and queries. You will be designing and creating visualisations, reports, metrics dashboards and data sources to empower different teams so that they can make informed decisions with the support of analytics.\nWhat we seek:\nQuick learner: you enjoy working with data and you have the ability to learn new technology and frameworks quickly\nProblem solver: you have strong critical thinking skills, willing to find creative solutions to difficult problems and work smart before hard\nHigh autonomy: self-organized, initiator, passionate with a can-do attitude and own end-to-end projects\nTeam player: you go the extra mile to ensure success and alignment of all parties involved\nCommunicative: you have the ability to elaborate complex technical concepts and collaborate effectively with fellow teammates and stakeholders\nWhat you'll need:\nAt least 3 years of work experience in a business intelligence or data analysis role\nExperience working with complex datasets and ability to write efficient SQL queries against Hive and MySQL is a MUST\nKnowledge of data pipeline, ETL\/ELT, workflow management and data warehousing\nExperience using business intelligence platforms for data visualisation, creating and automating dashboards, reports and data sources. Tableau is preferable\nExperience scripting Python for data manipulation, analysis and automation\nGood command of English for communicating technical ideas both orally and in writing\n\n\nTo all candidates- Lalamove respects your privacy and is committed to protecting your personal data.This Notice will inform you how we will use your personal data, explain your privacy rights and the protection you have by the law when you apply to join us. Please take time to read and understand this Notice. Candidate Privacy Notice: https:\/\/www.lalamove.com\/en-hk\/candidate-privacy-notice","159":"Company Description\nVuori is re-defining what athletic apparel looks like: built to move and sweat in but designed with a casual aesthetic to transition into everyday life. We draw inspiration from an active coastal California lifestyle; an integration of fitness, creative expression and life. Our high energy fast paced office environment is reflected in the clothes we make. We aim to inspire others to take on all aspects of their lives with clarity, enthusiasm and purpose\u2026while having a lot of fun along the way. We are proud to be an outlet for opportunity and for personal growth and success.\nJob Description\nThe Senior BI Analyst will provide timely and professional onsite and remote support to Vuori Staff and partners in both a growing office and retail brick \u2018n\u2019 mortar Omni-Channel eco-system.\nPrimary duties include working with key department stakeholders on validating source and end point data views, defining report\/analytics requirements and specifications, teaming up with the tech Product Managers and business users, building workflow and data profiling exercises to ensure full transparency of data integrity, definitions, cadence, and exceptions. This position will be the hub for analytic\/reports requirements as well as backend data requirements\/needs. They are responsible for answering queries and addressing data and analytic\/reports issues in a timely and professional manner.\nResponsibilities include, but are not limited to:\nWorking alongside the Product Manager, develop report specific details and specifications from high level scope at the reporting level, adjusting course as necessary and communicating changes to requisite audiences.\nBuild reports in PowerBI, DOMO(visualization tool) and other analyst\/reporting tools, using the requirements and specifications derived from the requirements gathering exercises.\nWith a high level of communicative expertise, represent and translate the \u201cstory of the numbers\u201d via visualizations, graphs, dashboards, commentary, etc., appropriate to the audience and nature of the request.\nWorking with systems and data engineers, source existing data to develop reports, or, in the event of nonexistent data, identify root source systems in which necessary data resides.\nWork with Data Governance manager to maintain knowledge base\/foundation of KPI\/Metric\/Report definitions, intentions, and access.\nManage relationships and time between projects and product owners while effectively communicating progress, obstacles, change of course, etc., as dictated by reporting dependencies and needs of business.\nOversee and administer BI & Analytics tool\/platform capabilities.\nMake technological adjustments to BI & Analytics tool\/platforms to improve their performance.\nDevelop algorithms and models to mine large data sets.\nUse statistical analysis to identify patterns, correlations, and actionable results.\nQualifications\nA four-year technical degree or equivalent work experience is preferred.\n7 or more years building and maintaining dashboards, analyses, reports, etc.\nHigh degree of proficiency with Power BI, including administration.\nBackground with other BI tools and systems such as DOMO, Tableau, and Looker.\nFundamental understanding of systems and data architecture.\nStrong SQL programming skills, including the use of SQL analytic functions and stored procedure development and maintenance.\nStrong excel experience (sumif, offset, vlookup, pivot tables).\nExposure to analytics tools (Alteryx, SAS, etc.).\nLove for data and data storytelling.\nProficient and knowledgeable on the systems and processes required to achieve consistently high customer satisfaction.\nComfortable working in a matrixed organization involving cross-functional projects; strong communication and collaboration skills.\nExcellent organizational skills to manage priorities.\nWell organized, adaptable, and a clear thinker.\nAdditional Information\nPay Range: From $135,000 - $160,000 annually\nBenefits:\nHealth Insurance\nPaid Time Off\nEmployee Discount\n401(k)\nAll your information will be kept confidential according to EEO guidelines.","160":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nOverview:\nThe Agoda Content department is currently looking for a curious and questioning self-starter and proactive analyst, who will help drive decision making with insights from content, marketing and partner performance data.\nYou will get the opportunity to own analytical projects to direct our department\u2019s focus, and prioritize our actions. By joining Agoda, you will become part of a truly international team, with leading experts of different backgrounds coming from 50+ countries around the world. This is a genuine opportunity to gain valuable experience in a challenging and cutting-edge tech environment. The ideal candidate would have a passion for high-converting content, great user-experience, data and analysis tools and methods. This position reports to the Associate Director of Content Operations, in Bangkok, Thailand.\n  Main responsibilities:\nUnderstand Content goals and KPIs and be able to align reports and insights based on them. Identify and investigate trends, anomalies and opportunities to improve Agoda\u2019s Content strategy.\nIdentify content opportunities that drive customer value, bookings and conversion\nHelp build business cases around the opportunity and get buy-in from stakeholders\nEnsure appropriate data\/tools\/dashboards to measure execution and enable deeper analysis\nTrack execution and report up in regular updates\nWork with product, data\/BI team and IT to create data resources and build appropriate reporting\nWork with Content team leads to understand their business needs and identify opportunities in terms of team actions prioritization and focus.\nUse multiple data sources to report Content projects insights and impact; support Content tests and experiments.\nEncourage and train the Content team in best practice use of Agoda data, analysis techniques and interpretation.\nCoordinate with other Cross Functional departments like Analytics, Partner Services, and Product Owners\nUse Web-Analytics for Research and Analysis\nRequirements:\nBachelor degree or higher\n2+ years of relevant experience\nExperience \/ knowledge in statistics, SQL, Python\/R, Tableau and advanced Excel \u2013 required\nAbility to demonstrate data manipulation using data warehouse and create meaningful insight and visualization\nExperience \/ knowledge in Vertica and \/ or Impala \u2013 advantage\nExperience in generating data and \/ or preparing experiments for product development \u2013 advantage\nProfessional characteristics:\nAttentive to detail and committed to data integrity\nKeen and curious nature; able and willing to share your opinion\nOrganized; able to manage multiple, competing priorities and deliver results under tight deadlines\nAble to communicate effectively; fluent in English \u2013 both spoken and written\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","161":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to Know our Team: \nPartner Development is a team of creative entrepreneurs that develop solutions for Agoda\u2019s accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.\nIn this role you'll get to\nAs a Data Analyst in the PD Analytics team, you will be using data and modeling techniques to identify opportunities and build models and tools to improve efficiency and effectiveness for Agoda's supply team. \nKey activities involved include but not limit to:\nApply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations\nOwn end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development\nBuild dashboards, identify new and track key metrics to closely monitor team\u2019s performance and identify quick and long term opportunities for improvements\nWork closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified\nSupport global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization\nWhat you'll need to succeed \nBachelor\u2019s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline\n3-6 years experience working in a business analysis, data analysis, reporting or business strategy role\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\nCoding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\nData visualization tool experience such as with Tableau or your weapon of choice.\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","162":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value.\nJob Description\nAs Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects:\nData Ingestion, Transformation & Consumption,\nData Storage and Computation Frameworks,\nPerformance Optimizations,\nInfrastructure, Automation & Cloud Computing,\nData Governance & Security\nThe role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java \/ Scala \/ Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL\/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.\nRole & Responsibilities:\n1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation.\n2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality\n3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality\n4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies\n5. Participate in workshops with clients and align client stakeholders to optimal solutions.\n6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc.\n7. People management, contributing to hiring and capability building\n#LI-REMOTE \nQualifications\nOverall 8+ years of IT experience with 3+ years in Data related technologies \n3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS \/ Azure \/ GCP) and delivered at least 1 project as an architect.\nMandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud. \nExpert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions\nExpert in programming languages like Java\/ Scala and good to have Python\nExpert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub\/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc.\nExpert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc.\nShould have worked on MPP style query engines like Impala , Presto, Athena, etc\nShould have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc.\nShould have a good understanding of how to set up Big data cluster security \u2013 Authorization\/ Authentication, Security for data at rest, and data in Transit.\nShould have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager \u2013 Data Engineering\nShould have worked on any of Orchestration tools \u2013 Oozie, Airflow, Ctr-M, or similar.\nWorked on Performance Tuning, Optimization, and Data security\n  Competency\n1. Excellent understanding of data technologies landscape\/ecosystem.\n2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases\n3. Good Exposure in development with CI \/ CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage.\n4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\n5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage.\n6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions\n7. Thought Leadership \u2013 blogs, keynote sessions, POV\/POC, hackathon\n8. Certification in either one of the cloud platforms or big data technologies\nPersonal Attributes:\nStrong analytical and problem-solving skills\nStrong communication skills in verbal, written and visual presentations\nStrong coordination and negotiation skills\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nMulti geo experience and distributed delivery experience in large programs\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements \nEmployee Assistance Programs to help you in wellness and well being","163":"Company Description\nExperian is the world\u2019s leading global information services company. During life\u2019s big moments \u2014 from buying a home or a car to sending a child to college to growing a business by connecting with new customers \u2014 we empower consumers and our clients to manage their data with confidence. We help individuals to take financial control and access financial services, businesses to make smarter decisions and thrive, lenders to lend more responsibly, and organizations to prevent identity fraud and crime.\nWe have 17,800 people operating across 44 countries, and every day we\u2019re investing in new technologies, talented people and innovation to help all our clients maximize every opportunity. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index.\nLearn more at www.experianplc.com or visit our global content hub at our global news blog for the latest news and insights from the Group\nExperian is the world\u2019s leading global information services company. During life\u2019s big moments \u2014 from buying a home or a car to sending a child to college to growing a business by connecting with new customers \u2014 we empower consumers and our clients to manage their data with confidence. We help individuals to take financial control and access financial services, businesses to make smarter decisions and thrive, lenders to lend more responsibly, and organizations to prevent identity fraud and crime.\nWe have 17,800 people operating across 44 countries, and every day we\u2019re investing in new technologies, talented people and innovation to help all our clients maximize every opportunity. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index.\nLearn more at www.experianplc.com or visit our global content hub at our global news blog for the latest news and insights from the Group\nJob Description\n As a key aide to both the IT Infrastructure and Development teams, you will help support existing systems 24x7 and responsible for administering current Big Data environments.  The candidate will be responsible for managing BigData Cluster environments and will work with teammates to maintain, optimize, develop, and integrate working solutions for our big data tech stack. To support the product development process in line with the product roadmap for product maintenance and enhancement such that the quality of software deliverables maintains excellent customer relationships and increases the customer base. \n  If you have the skills and \u201ccan do\u201d attitude, we would love to talk to you! \n What you\u2019ll be doing  \nResponsible for implementation and ongoing administration of Hadoop infrastructure \nAligning with the systems engineering team to propose and deploy new hardware and software environments required for Hadoop and to expand existing environments \nExpert knowledge with delivering Big Data Cloudera Solutions in the cloud with AWS. \nDeliver innovative CI\/CD solutions using the most cutting-edge technology stack. \nAutomating infrastructure and Big Data technologies deployment, build and configuration using DevOps tools. \nHands-on day-to-day expert experience in administering a Cloudera cluster with Cloudera Manager, Cloudera Director, Cloudera Navigator \nWorking with data delivery teams to setup new Hadoop users. This job includes setting up Linux users, setting up Kerberos principals and testing HDFS, Hive, HBase and Yarn access for the new users \nCluster maintenance as well as creation and removal of nodes using tools like Cloudera Manager Enterprise, etc. \nPerformance tuning of Hadoop clusters and Hadoop MapReduce routines \nScreen Hadoop cluster job performances and capacity planning \nMonitor Hadoop cluster connectivity and security \nManage and review Hadoop log files, File system management and monitoring \nHDFS support and maintenance \nDiligently teaming with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability \nCollaborating with application teams to perform Hadoop updates, patches, version upgrades when required \nGeneral operational expertise such as good troubleshooting skills, understanding of system\u2019s capacity, bottlenecks, basics of memory, CPU, OS, storage, and networks \nThe most essential requirements are: They should be able to deploy Hadoop cluster, add and remove nodes, keep track of jobs, monitor critical parts of the cluster, configure name-node high availability, schedule and configure it and take backups \nSolid Understanding on premise and Cloud network architectures \nAdditional Hadoop skills like Sentry, Spark, Kafka, Oozie, etc \nAdvanced experience with AD\/LDAP security integration with Cloudera, including Sentry and ACL configurations \nAbility to configure and support API and OpenSource integrations \nExperience working with DevOps environment, developing solutions utilizing Ansible, etc. \nWill collaborate and communication with all levels of technical and senior business management \nWill require on-call 24X7 support of production systems on a rotation basis with other team members \nPro-actively evaluate evolving technologies and recommend solutions to business problems. \n Qualifications\nTypically requires a bachelor's degree (in Computer Science or related field) or equivalent. \n3+ years of Linux (Redhat) system administration \n3+ years of Hadoop infrastructure administration \nCloud Platforms IaaS\/PaaS \u2013 Cloud solutions: AWS, Azure, VMWare \nKerberos administration skills \nExperience with Cloudera distribution \nGood have knowledge on open-source configuration management and deployment tools such as Puppet or Chef and Shell scripting \nMust have knowledge on DevOps tools like Ansible and HAProxy. Automating deployments and monitoring\/alerting tasks using Ansible. \nAdvantage if working knowledge on terraform \nWorking Knowledge of YARN, HBase, Hive, Spark, Flume, Kafka etc. \nStrong Problem Solving and creative thinking skills \nEffective oral and written communications \nExperience working with geographically distributed teams \nBachelors or master\u2019s degree in Computer Science or equivalent experience \nKnowledge and understanding of the business strategy and use of back-office applications. \nAbility to adapt to multi-lingual and multicultural environment, additional language skills are a bonus. \nAbility to handle conflicting priorities. \nAbility to learn. \nAdaptability. \nReceptive to change. \nAbility to communicate with business users at all levels \nAnalytical skills \nSelf-motivated and pro \nAdditional Information\nExperian Careers - Creating a better tomorrow together\nFind out what its like to work for Experian by clicking here","164":"As a Solutions Architect (Analytics, AI, Big Data, Public Cloud), you will guide the technical evaluation phase in a hands-on environment throughout the sales process. You will be a technical advisor internally to the sales team, and work with the product team as an advocate of your customers in the field. You will help our customers to achieve tangible data-driven outcomes through the use of our Databricks Lakehouse Platform, helping data teams complete projects and integrate our platform into their enterprise Ecosystem. You'll grow as a leader in your field, while finding solutions to our customers' biggest challenges in big data, analytics, data engineering and data science problems. You will report to the Solutions Architect Manager.\nThe impact you will have:\nYou will be a Big Data Analytics expert on aspects of architecture and design\nLead your clients through evaluating and adopting Databricks including hands-on Spark programming and integration with the wider cloud ecosystem\nSupport your customers by authoring reference architectures, how-tos, and demo applications\nEngage with the technical community by leading workshops, seminars and meet-ups\nTogether with your Account Executive, you will form successful relationships with clients throughout your assigned territory to provide technical and business value\nWhat we look for:\nConsulting, Pre-sales or post-sales experience working with external clients across a variety of industry markets\nUnderstanding of customer-facing pre-sales or consulting role with a core strength in either data engineering or data science advantageous\n5+ years of experience demonstrating technical concepts, including demos, presenting and white-boarding\n5+ years of experience designing architectures within a public cloud (AWS, Azure or GCP)\n5+ years of experience with Big Data technologies, including Spark, AI, Data Science, Data Engineering, Hadoop, Cassandra, and others\nCoding experience in Python, R, Java, Spark or Scala\nBenefits :\nPrivate medical insurance\nAccident coverage\nEmployee's Provident Fund\nEquity awards\nPaid parental leave\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nBusiness travel insurance\nMental wellness resources\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.","165":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to Know our Team: \nThe Supply Analytics team is a team of creative entrepreneurs that develop solutions for Agoda\u2019s non-accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek.  Utilizing our strong brand and resources, we build new channels to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. \nThe Opportunity:  \nThe role sits within the Supply Analytics team under Central Supply Team, where new business ideas, and partnership types are incubated and scaled. We are looking for a\u202fSenior BI Analyst\u202fwhose main focus areas are providing visibility and insights for people-related issues through Business Intelligence tools like Tableau and SQL, managing data warehouses, building ETL processes, and helping build other tools to optimize the business. This role will be involved in strategic projects and work closely with commercial owners and business stakeholders, using data to identify and translate business needs and opportunities into actionable initiatives.\nIn this Role, you\u2019ll get to:\nTranslate internal briefs into analytical projects (to include refining the initial brief and asking the \u2018right questions\u2019, working through potential hypotheses and storyboarding the output)\nUse and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders.\nProactively identify opportunities for growth within supply and the wider business.\nDrive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply.\nIdentify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence.\nAutomate manual operational processes and present back on time savings gained through modernization of business operations\nWhat you\u2019ll Need to Succeed:\n4+ years of experience in analytics\/data science\/insights\/strategy.\nBachelor\u2019s degree ideally in a business or quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance).\n3+ years of experience with BI & analytics tools (SQL, Tableau, Metabase, Data Studio, or similar technologies)\n2+ years of solid project management\nGood stakeholder management experience. Comfortable presenting to senior leadership and C-suite.\nStrong experience in finding data insights and provide business recommendation to the business\nA hacker\u2019s mindset \u2013 the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping.\nExcellent communicator with superior written, verbal, presentation and interpersonal communication skills.\nData driven in both decision making and performance measurement.\nExtreme comfort in ambiguous, fast-paced environment.\nAbility to multi-task, prioritize and coordinate resources.\nIt\u2019s Great if you Have:  \nTravel industry \/ e-commerce \/ tech \/ consulting experience.\nExperience in conducting A\/B testing experimentation (a plus)\nA good understanding of statistical modelling knowledge or any machine learning technique knowledge is a plus (regression, logistic regression, random forest, etc.)\n  #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","166":"Company Description\nAt Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people\u2019s lives. Our promise to our associates is rock-solid: we grow together, we enjoy our work, and we inspire each other. Join in and feel the difference.\n\nThe Robert Bosch GmbH is looking forward to your application!\nJob Description\nDuring your assignment, you will make Big Data analysis to support fleet validation for Fuel Cell and Vehicles using Azure Databricks as well as Hadoop\/PySpark.\nYou will visualize the results with Tableau and work with Version Control.\nYou always keep an eye on the documentation \/ knowledge management with Docupedia.\nTake an active role and work in an agile team with international colleagues.\nQualifications\nEducation: studies in the field of Engineering\nExperience and Knowledge: experience in programming (e.g.Python or MATLAB) and data wrangling with PySpark\nPersonality and Working Practice: goal-oriented, reliable personality who can solve tasks independently and enjoys collaborating with different departments at multiple locations\nLanguages: very good in English, German is a plus\nAdditional Information\nStart: according to prior agreement\nDuration: 6 months\nWe offer you\n35 hours\/week with flextime\na permanent contact person who will accompany you during your internship\na modern working environment, as well as mobile working by arrangement\nthe opportunity to become part of our student network students@bosch Stuttgart\ndiscounts in our company restaurants\nRequirement for this internship is the enrollment at university. Please attach a motivation letter, your CV, transcript of records, enrollment certificate, examination regulations and if indicated a valid work and residence permit.\nDiversity and inclusion are not just trends for us but are firmly anchored in our corporate culture. Therefore, we welcome all applications, regardless of gender, age, disability, religion, ethnic origin or sexual identity.\nNeed further information about the job?\nPhilipp Reiner (Business Department)\n+49 711 811 23926","167":"About Rezo TherapeuticsRezo is a different kind of biopharma company.  Our mission is to dramatically increase the success rate of drug development by building a disease-agnostic, fully-integrated, network biology platform that will redefine our understanding of human disease and ability to treat it.   Our Founders and members of the Board are a group of esteemed, world-class scientists from the University of California, San Francisco: Nevan Krogan, Kevan Shokat, Sourav Bandyopadhyay, Natalia Jura, as well as renowned biotech executives George Scangos and Norbert Bischofberger. These leaders bring with them a strong track record of amazing discoveries and scientific breakthroughs, leading to very successful companies and many FDA approved drugs. \nCapitalizing on our Series A of $78M from top-tier investors, we are leveraging a unique integrated approach, combining capabilities in genetics, proteomics, structural biology and AI to generate deep biological insights and novel therapeutic approaches. A list of seminal studies leading to our company's formation, published in the journal Science, can be found here.\nLocated in San Francisco\u2019s vibrant Mission Bay neighborhood, Rezo is in close proximity to UCSF, numerous urban amenities, and outdoor recreational opportunities.  We recognize that realizing our mission depends as much on our people as it does on our science and are building a workplace that fosters collaboration, respect, and diversity where contributing to your team\u2019s success is valued as highly as individual achievements.   If you\u2019re passionate about team science and breaking down barriers to progress in drug development, please consider joining us! \nThe Opportunity We are seeking a highly enthusiastic and motivated Staff Machine Learning Engineer to join the Rezo Computational Biology and AI team.  Becoming a member of this team is an excellent opportunity to join Rezo at an early stage and help build the Computational Biology and AI function and the company from the ground up.\nWhat You'll Do:\nAdvise on AI strategy and serve as technical lead for ML-based approaches to integrate large-scale gene and protein interaction datasets to power Rezo\u2019s Sequence to Systems to Drugs (SSD) platform and other core company initiatives (e.g. computational chemistry and protein structure prediction)\nOperate as an individual contributor initially while building a team of ML and software engineers\nDesign, develop, test, deploy, maintain, and enhance large-scale software solutions\nAdopt and develop data engineering methodologies including feature identification and integration, data pipelining, feature engineering, data munging, and analysis using methods that can translate from research to production\nCollaborate across biology and computational biology to develop strategy for platform buildout, systematic platform-driven data generation, data management and mining, and buildout of interfaces and tools\nManage and analyze experimental data, interpret results, and prepare necessary materials for internal and external meetings, regulatory filings, and publications\nContribute to and balance multiple projects\/studies in parallel in a fast-paced environment\nAbout You:\nPh.D. in computer science or a related technical field plus 4+ years work experience OR B.S in computer science or a related technical field plus 8+ years work experience\nDemonstrated industry expertise in implementing deep learning algorithms and using deep learning frameworks (e.g. TensorFlow, PyTorch, JAX)\nProven track record of scientific excellence as evidenced by a strong publication and\/or patent record in the ML field (e.g. NeurIPS, ICML, ICLR, and\/or top journals in the sciences)\nDemonstrated expertise in data analysis including proficiency in programming languages, software best practices, and data structures\/algorithms\nHands-on experience working on computational biology, systems biology, drug discovery, or computational chemistry datasets, highly desirable\nPrevious experience in graph neural networks, a plus\nExcellent communication, organizational, and interpersonal skills\nStrong mentoring skills required, prior management experience is a plus\nDemonstrated ability helping set scientific direction and priorities for projects\nAble to own and solve a problem, even if it\u2019s ambiguous\nAble to partner with peers in different functions and contribute to cross-functional projects with a collaborative attitude\nAble to work with minimal direction\nBenefits at RezoMedical (HMO or PPO), dental, and vision insuranceDiscretionary time off policyCompany holidays (including summer and winter shutdown)401(k) retirement savings programCommuter \/ Mass Transit Benefit ProgramHealthcare Flexible Spending Account (FSA)Dependent care Flexible Spending Account (FSA)Parental leaveCompetitive compensationFlexible work schedule\nEEOCAt Rezo we value a diverse, equitable, inclusive workplace and provide equal employment opportunity to all persons without regard to race, color, sex, gender identity, gender expression, religion, age, national origin, ancestry, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, genetic information, military or veteran status, or any other basis protected by federal, state or local laws.  This statement covers all facets of employment and is especially important when it comes to growing our team.  \nIf you are wondering if you\u2019ll belong at Rezo, or are worried that you don\u2019t meet 100% of the qualifications for this role, take a chance on us and yourself \u2014 please apply!\nSF Fair Chance OrdinancePursuant to the San Francisco Fair Chance Ordinance, Rezo considers qualified applicants with arrest and conviction records for employment.\nCOVID-19All Rezo employees are required to be fully vaccinated against COVID-19 and to provide proof of vaccination prior to their first day, with limited exceptions.  This policy is grounded in scientific and clinical evidence and has been established with the health and safety of our workplace and community in mind.","168":"As a Solutions Architect (Analytics, AI, Big Data, Public Cloud), you will guide the technical evaluation phase in a hands-on environment throughout the sales process. You will be a technical advisor internally to the sales team, and work with the product team as an advocate of your customers in the field. You will help our customers to achieve tangible data-driven outcomes through the use of our Databricks Lakehouse Platform, helping data teams complete projects and integrate our platform into their enterprise Ecosystem. You'll grow as a leader in your field, while finding solutions to our customers' biggest challenges in big data, analytics, data engineering and data science problems.\nThe impact you will have:\nYou will be a Big Data Analytics expert on aspects of architecture and design\nLead your clients through evaluating and adopting Databricks including hands-on Spark programming and integration with the wider cloud ecosystem\nSupport your customers by authoring reference architectures, how-tos, and demo applications\nEngage with the technical community by leading workshops, seminars and meet-ups\nTogether with your Account Executive, you will form successful relationships with clients throughout your assigned territory to provide technical and business value\nWhat we look for:\nConsulting, Pre-sales or post-sales experience working with external clients across a variety of industry markets\nUnderstanding of customer-facing pre-sales or consulting role with a core strength in either data engineering or data science advantageous\n5+ years of experience demonstrating technical concepts, including demos, presenting and white-boarding\n5+ years of experience designing architectures within a public cloud (AWS, Azure or GCP)\n5+ years of experience with Big Data technologies, including Spark, AI, Data Science, Data Engineering, Hadoop, Cassandra, and others\nHands-on experience in Python, R, Java, Spark or Scala\nBenefits :\nPrivate medical insurance\nAccident coverage\nEmployee's Provident Fund\nEquity awards\nPaid parental leave\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nBusiness travel insurance\nMental wellness resources\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.","169":"About Us\nJoining Capco means joining an organisation that is committed to an inclusive working environment where you\u2019re encouraged to #BeYourselfAtWork. We celebrate individuality and recognise that diversity and inclusion, in all forms, is critical to success. It\u2019s important to us that we recruit and develop as diverse a range of talent as we can. We believe that everyone brings something different to the table \u2013 so we\u2019d love to know what makes you different.\n We are\/have:\nExperts in banking and payments, capital markets and wealth and asset management\nDeep knowledge in financial services offering, including e.g. Finance, Risk and Compliance, Financial Crime, Core Banking etc.\nCommitted to growing our business and hiring the best talent to help us get there Focused on maintaining our nimble, agile and entrepreneurial culture\nCapco is looking for hardworking, innovative and creative people to join our Data Analyst Team. We are looking for Data Analyst  to work on all aspects of project delivery engaging a complex stakeholder groups across multiple global regions \/ product lines to execute global change programs in the Investment Banking domain. This includes business analysis, requirements gathering and documentation, driving technical design and specifications in partnership with IT, functional test strategizing and execution, and user acceptance testing coordination. Must possess strong relationship management skills and be able to manage requirements and testing across Ops and IT teams both cross-division and globally. Role is focused on projects to support the development of regulatory\/industry driven changes.\nRole Description\nThis role provides regulatory data analytics using data from different geography. The primary responsibilities would be:\nLead a highly skilled, multi-disciplinary team of consisting of data, analytics, technology and delivery professionals to deliver advanced data and analytics solutions\nAct as Scrum Master to servant-lead teams to deliver business use cases on a global scale and deploying locally\nWorking closely with data, analytics and technology teams across the business, shape solution designs which meets business needs as well as aligning to the broader strategic Data & Analytics objectives\nWork directly with various stakeholders across multiple geographies; such as technical discipline leads, data scientists, data engineers and data analysts to produce accurate delivery estimates and manage the transition from analysis to successful delivery\nDefine Agile project working approach and enforce all team members to follow the same methodology\nEnsure awareness, involvement and support from key stakeholders by building strong pod teams and maintaining robust communications on the project status throughout its lifecycle\nEnsure risks and issues are identified, managed closely and remove project blockers from the team\nMake key decisions to ensure the successful implementation of all initiatives\nSupport the delivery production line such as definition, implementation and testing and ensuring deliverables meet business requirements and are fit for purpose\nDrive all stakeholders to deliver on time and to the required quality standards\nEnsure cross-team delivery plans exist which represent an achievable commitment based on the capacity of available resource and consideration of internal and external dependencies\nLead and work closely with all teams (including virtual teams based in non-UK locations), creating a strong culture of transparency and collaboration\nDemonstrate a continual desire to implement \u201cstrategic\u201d or \u201coptimal\u201d solutions and where possible, avoid workarounds or short term tactical solutions\nWorking with stakeholders to ensure that negative customer and business impacts are avoided\nUnderstand all changes in the wider context of the business lines\/ areas we support and the programme has an impact, including Regulatory and Global Standards projects\nManage stakeholder expectations and ensure that robust communication and escalation mechanisms are in place across the project portfolio\nStrong self-starter with strong change delivery skills who enjoys the challenge of delivering change within tight deadlines\n\"Knowledge of one or more of the following domains (including market data vendors):\no Party\/Client\no Trade\no Settlements\no Payments\no Instrument and pricing\no Market and\/or Credit Risk\"\n\u2022 Structured and organised leader with strong project management, data and business analysis skills\n\u2022 Ability to manage multiple priorities\n\u2022 Good understanding of the control requirement surrounding data handling will be advantageous in this role\n\u2022 Assess the operational risks as part of the analysis and implementation planning and execution in conjunction with business heads\n\u2022 Experience leading multi-disciplined teams of data, analytics, technology and delivery resources to deliver data and analytics solutions\n\u2022 Experience in agile project methodologies and tools such as JIRA and Confluence\n\u2022 Ability to articulate or translate complex information through clear and meaningful written and spoken communication in a structured way\n\u2022 Ability to develop working relationships with a wide variety of stakeholders, from C-suite to technical resources, balancing competing priorities\n\u2022 Proven skills to lead teams and motivate others to achieve objectives\n\u2022 Preferable knowledge and experience in Data Quality & Governance\n\u2022 Ability to communicate effectively in a multi-programme environment across a range of stakeholders\n\u2022 Relevant Agile Certifications such as Certified Scrum Master, SAFe, LeSS, DAD\n\u2022 Understanding of different analyses options and development of implementable solutions\n\u2022 Highly adaptable and ability to approach things differently in order to achieve goals\n\u2022 Experience of big data and\/or cloud programmes preferable\nWHY JOIN CAPCO?\nYou will work on engaging projects with some of the largest banks in the world, on projects that will transform the financial services industry.\nWe offer:\nA work culture focused on innovation and creating lasting value for our clients and employees\nOngoing learning opportunities to help you acquire new skills or deepen existing expertise\nA flat, non-hierarchical structure that will enable you to work with senior partners and directly with clients\nA diverse, inclusive, meritocratic culture\n ","170":"Description de l'entreprise\nVous \u00eates passionn\u00e9 par le digital, la data, l\u2019ioT ou l\u2019IA et souhaitez rejoindre une \u00e9quipe dynamique et ambitieuse \u00e0 taille humaine ?  \nN\u2019attendez plus et rejoignez Talan !\nDepuis plus de 15 ans, nous conseillons les entreprises et les administrations et les accompagnons dans la mise en \u0153uvre leurs projets de transformation en Suisse et \u00e0 l'international.  \nPour ce faire, nous nous appuyons \u00e0 la fois sur le levier technologique et sur la force de notre ADN bas\u00e9 sur l\u2019intelligence collective, l'agilit\u00e9 et le go\u00fbt d\u2019entreprendre.  \nPr\u00e9sent sur cinq continents, avec plus de 3 500 collaborateurs notre objectif est de d\u00e9passer la barre du milliard d\u2019\u20ac de CA \u00e0 horizon 2024. L'innovation est au c\u0153ur de notre d\u00e9veloppement et nous intervenons dans les domaines li\u00e9s aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.\nNos valeurs & terrains de jeu :\nIntelligence collective\nAgilit\u00e9\nEntreprenariat \/Intrapreneuriat\nPromouvoir la diversit\u00e9\/mixit\u00e9 (Soutient \u00e0 la Fondation femmes@Numerique...)\nEngagement (employ\u00e9, partenaires, \u00e9coles, associations...)\nRespect de l\u2019humain et qualit\u00e9 de vie au travail\nOuverture d\u2019esprit et inclusivit\u00e9  \n Ensemble, construisons le futur de Talan !\nDescription du poste\nLe service DAM (Data Management) du d\u00e9partement informatique de notre client recherche un consultant avec le profil d\u2019Architecte Big Data pour nous assister sur divers projets dans l\u2019\u00e9cosyst\u00e8me Hadoop.\nLe consultant int\u00e9grera l\u2019\u00e9quipe DAM Modelisation et Administration (DADM) qui a comme r\u00f4les entre autres :\nLa gestion des bases de donn\u00e9es (DB2, MSSQL, Oracle).\nLa gestion des donn\u00e9es dans l\u2019\u00e9cosyst\u00e8mes Hadoop.\nOptimisation des performances.\nProtection de la donn\u00e9e\nMissions :\nAssistance dans la migration de HDP (HortonWorks data platform) vers CDP et s\u00e9curisation de l\u2019acc\u00e8s aux donn\u00e9es.\nRecueil des besoins fonctionnels aupr\u00e8s de diverses \u00e9quipes. Inventorier la donn\u00e9e brute (source DB2 Z\/os)\nMod\u00e9lisation des donn\u00e9es \u00e0 ing\u00e9rer dans hadoop. Design de la solution et des composants n\u00e9cessaires.\nMise en place de la proc\u00e9dure d\u2019alimentation hadoop avec r\u00e9cup\u00e9ration historique.\nSupport des \u00e9quipes qui vont consommer la donn\u00e9e.\nSous la responsabilit\u00e9 d'un chef de projet interne\nQualifications\nExp\u00e9rience d\u2019au moins 5 ans dans un poste d\u2019Architecte Big Data\nUne connaissance dans le domaine DB2 for Z\/os est un avantage\nMa\u00eetrise des technologies li\u00e9es au Big Data comme Hadoop & Spark id\u00e9alement dans l\u2019\u00e9cosyst\u00e8me CDP (cloudera data platform)\nFacilit\u00e9 d\u2019int\u00e9gration dans une \u00e9quipe de DBA & Data Scientist\nAisance de communication\nAutonomie dans la r\u00e9alisation des travaux demand\u00e9s\nLangues : fran\u00e7ais, anglais. Le luxembourgeois est consid\u00e9r\u00e9 comme un avantage.","171":"As an Analyst for Professional Service Operations, you will be focused on providing data analytics on the full operations and P&L support to our global Services team throughout Databricks Services (Professional Services (PS) and Education) business. The focus will be on revenue-driving and forecasting activities across billable projects which includes closing monthly and quarterly accounting, establishing revenue rules, accurate forecasting and reporting, resource assignments, and revenue recognition. You will develop\/deploy scalable processes and system logic in collaboration with our Services, Operations, and Finance to support the business. As the connective tissue across the Customer Success organization, you will surface important insights to enhance the customer journey and customer experience. You will report to the Global Operations Manager, Professional Services.\nWith a specific focus on technology, data, and reporting, you will work closely with the PS Operations team and the larger business to aggregate data and facilitate reporting that will drive business decisions and predictability. You will enable the business partners to use and understand reports and data sets, and will have a forward looking approach to support growth of the business and deliver at scale.\nThe impact you will have:\nYou will own all aspects of data and reporting for PS Operations\nYou will drive recurring P&L activities to ensure forecasted vs actual metrics are in line\nYou will develop understanding of the metrics that inform Customer Success and manage the business intelligence layer with the goal of driving insights to actions\nYou will ensure data quality across multiple systems of record and flag areas of continuous improvement\nYou will address questions by the Professional Services leadership team with follow up insights and recommended actions\nYou will prioritize and manage high impact projects across Professional Services\nWhat we look for:\n3+ year's experience with P&L activities, strong data analytics mindset, using analytical frameworks, data, and tools to help structure team thinking, facilitate understanding across multiple senior partners, and reach applicable answers to challenging and ambiguous problems\nSalesforce and FinancialForce (Salesforce PSA) experience, specifically in creating reports and report types\nStrong knowledge in Microsoft Excel or Google Sheets (pivot tables, v-lookup, etc.)\nKnowledge in SQL and experience in Tableau\nSalesforce administrator certified is a plus\nComfort diving into large, complex datasets with little or no documentation\nExperience using business systems such as CRM, billing and revenue systems, PS Automation, Order Management and Accounting.\nHands-on experience coordinating projects and working with leaders across the business to identify areas of improvements, propose and implement solutions\nExperience communicating with senior leadership to guide understanding across team members from divergent functions\nCreate and automate operational dashboards to monitor changes in our performance\nKnowledge of SOX Compliance is a plus\nPlease note: This role involves working in 4 p.m.-1 a.m. IST shift.\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.","172":"Mission:\nAt Databricks we are on a mission to empower our customers to solve the world's toughest data problems by utilising the Lakehouse platform. As a Delivery Solutions Architect (DSA), you will play a critical role during this journey. You will collaborate with our sales and field engineering teams to accelerate the adoption and growth of the Databricks platform in your accounts. As a DSA, you will help ensure customer success by driving focus and technical accountability to our most complex customers who need guidance to accelerate consumption on Databricks workloads that they have already selected.\nThis is a hybrid technical and commercial role. It is commercial in the sense that you will be required to own and drive growth in your assigned customers and use cases through leading your customers\u2019 stakeholders, owning executive relationships and creating and driving plans and strategies for Databricks colleagues to execute upon. This is in parallel to being technical, with expectations being that you become at least Level 200 across all Databricks products\/workloads and that you become the Use Case-specific technical lead post-Technical Win. This requires you to utilize relationship management skills and technical credibility to effectively engage and communicate at all levels with an organisation. You will report directly into a DSA manager as part of your Business Unit\u2019s Technical GM organisation. \nYour day-to-day responsibilities:\nEngage with the Solutions Architect to understand the full Use Case Demand Plan for prioritised customers.\nOwn the Post-Technical Win technical account strategy and investment plan for the majority of Databricks Use CTAMases within our most strategic accounts.\nBe the accountable technical leader assigned to specific Use Cases and customer(s) across multiple selling teams and internal stakeholders, creating certainty from uncertainty\/ambiguity and driving onboarding, enablement, success, go-live and healthy consumption of the workloads where the customer has made the decision to consume Databricks. \nBe the first point of contact for any technical issues or questions related to production\/go live status of agreed upon Use Cases within an account, oftentimes services multiple use cases within the largest and most complex organisations. \nLeverage both Shared Services of User Education, Onboarding\/Technical Services and Support resources, along with escalating to Level 400\/500 technical experts (Specialist Solution Architects and Product Specialists) to execute on the right tasks that are beyond your scope of activities or expertise. \nCreate, own and execute a PoV as to how key use cases can be accelerated into production, bringing EM\/PM in to prepare Professional Services proposals.\nNavigate Databricks Product and Engineering teams for New Product Innovations, Private Previews and Upgrade needs (DBR, E2 and Unity Catalog). \nBuild and maintain mutual success plan that covers all activities of Customer, PS, Partner, SSA, Product Specialist, SA to cover the below workstreams:\nKey use cases moving from \u2018win\u2019 to production\nEnablement \/ user growth plan\nProduct adoption (strategy and activities to increase adoption of LH vision)\nOrganic needs for current investment Eg. Cloud Cost control, Tuning & Optimisation\nExecutive and operational governance\nProactively provide internal and external updates - KPI reporting on the status of consumption and customer health, covering investment status, key risks, product adoption and use case progression - to your Technical GM.\n  What we look for (Competencies):\n5+ years in a customer-facing pre-sales, technical architecture, customer success, or consulting role\nExperience understanding architecture-related distributed data systems, specifically within one of the following:\nData Engineering technologies (e.g. Spark, Hadoop, Kafka)\nData Warehousing (e.g. SQL, OLTP\/OLAP\/DSS)\nData Science and Machine Learning technologies (e.g. pandas, scikit-learn, HPO)\nComfortable managing multiple projects at once, and engaging a virtual team of subject matter experts to address any onboarding or technical challenges outside of your remit or bandwidth.\nInfluencing and leading teams - especially without having direct reporting line responsibility for individuals within account and leadership teams, both internally and externally\nStakeholder management - experience in effectively engaging and influencing a variety of audiences (technical, non technical) at all levels of an organization (CxO to developer)\nExecutive escalation management - experience in resolving complex and critical escalation with senior customer and Databricks executives\nStrategic Management Consulting - experience of conducting open-ended discovery workshops,  creating strategic roadmaps, conducting business analysis and managing delivery of complex programmes\/projects\nBuilding and steering to a value case - business value consulting and realisation\nQuota ownership, achievement and track record of great performance against objective target\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.","173":"Company Description\nSSENSE (pronounced [es-uhns]) is a global technology platform operating at the intersection of culture, community, and commerce. Headquartered in Montreal, it features a mix of established and emerging luxury brands across womenswear, menswear, kidswear, and Everything Else.\nSSENSE has garnered critical acclaim as both an e-commerce engine and a producer of cultural content, generating an average of 100 million monthly page views. Approximately 80% of its audience is between the ages of 18 to 40. It is privately held and has achieved high double digit annual growth and profitability since its inception.\nJob Description\nReporting to the Senior Director of Global Operational Excellence & Continuous Improvement, the Manager of Data Visibility, Governance, and Product is responsible for leading the design, development, and successful implementation of current and future data visualisation, reporting standards, and workflow data products for Operations. They will oversee a team of analysts that translate business requirements into technical reporting requirements across all end-to-end processes, define the metrics, and then build the data products and corresponding dashboards that will be a cornerstone of all Operational roles and training programs at SSENSE. The incumbent will ensure data visualisation, metric, and KPI standards are clearly defined ahead of our global network expansion plans over the coming 1-3 years.\nRESPONSIBILITIES\nData visibility, governance, and product design (75%)\nDevelop and lead the Operations Visualization & Data Governance transformation plan that will standardise and operationalize all data points related to physical and systemic movement of products within the SSENSE Network, spanning operational process paths to C-suite executive-level reporting\nTranslate and develop standard metrics for reporting, and collaborate with the Product and Engineering, and Data Platform team to determine the right mechanism for delivering the reports and insights to maximize how they are used and actioned by Operational teams\nDevelop, and implement reporting solutions with AWS tools like Athena, Tableau, and operational reporting capabilities available through operational systems\nWork closely with all Operational teams and executive leadership to ensure clear and consistent metric definitions, comprehensive capture and up-to-date documentation of operational reporting and analytical reporting requirements \nOversee all data, metric, and dashboard development by the direct team; define the internal development process and stakeholder engagement model, establishing quality measures for product delivery; achieve and maintain best-in-class benchmarks for adoption rates\nDevelop prioritised roadmap for scaling visibility, maturity, automation, and real-time capability for all operational process paths in tandem with process maturity assessment; design agile approach for near-term output and ongoing, ad hoc request management\nImplement design principles and templates for data visualisation and governance across Operations that guides all dashboard development in current and future state\nCollaborate with the Product and Data Platform teams to define and demarcate data accessibility and tools for analysis vs. standardised user interface for operational process and reporting\nPartner with Business Process Owners and Operations leadership to implement standard metrics based on industry best practices to integrate with company-wide metric reporting \nImplement continuous improvement processes for refining \/ streamlining data or visualisation standards, as well as change management practices for deployment; inclusive of scalable approach to deprecating and removing legacy reports and dashboards\nPilot workflow tools that support predictive analytics and algorithmic recommendations\nOversee successful migration of reporting, visualisation, and workflow tools with existing system or product changes (e.g., WMS); partner with Product teams to define requirements of new systems or product implementation (e.g., YMS, LMS); ensuring successful integration with data governance and reporting standards\nPartner directly with the Data Platform team and the Product and Engineering teams to develop a design of the future for these collaterals and corresponding data architecture\nPeople leadership and development (25%)\nWork with Senior Leadership to gauge and monitor team engagement and implement solutions to create a transparent, collaborative and productive work environment \nCollaborate with Senior Leadership to establish the department short term objectives for the department and ensure the team's are engaged towards achieving them \nHold weekly one-on-ones, conduct performance reviews, analyze individual KPIs and assess promotion readiness to help each contributor evolve in their roles\nProvide mentorship and development opportunities to team members, catalyzing growth through coaching and team building\nQualifications\nREQUIREMENTS\nBachelors Degree in Computer Science, Information Systems, Mathematics, Statistics, Data Science, Software Engineering, or another relevant field \nA minimum of 5 years of professional, hands-on data management\/Operations and analytics experience, with at least 3 years of formal management experience leading highly developed data management and analytical professionals, ideally in fast-paced Fulfillment industry, Distribution, Logistics or Production\/Manufacturing environment\nExtensive experience with data manipulation and data visualisation tools, such as Tableau for reporting and dashboarding is essential\nExtensive experience with data manipulation using SQL or other means to extract and transform data is a must\nAnalytical mindset and experience working with business and technical teams to define key metrics, KPIs, definitions, and governance standards, along with the process to manage and maintain them over time is a must\nExperience with Operational SAAS systems and their reporting capabilities (pros and cons) is a plus\nExperience leading teams in information design principles and data visualisation methods, best practices, and software packages and APIs such as Tableau or equivalent analytics tools\nStrong written and verbal communication skills in English and French\nSKILLS\nStrong organisational and time management skills \nAdvanced data analysis skills, and an expert in using supporting tools\nStrong collaboration and prioritisation skills\nAbility to identify, prioritise and articulate high impactful initiatives\nThe ability to translate operational issues into workable data solutions\nCreative out-of-the-box thinking with excellent problem-solving abilities\nTeam player with solid leadership and interpersonal skills\nStrong communication skills, with an ability to influence cross-functional teams\nAdditional Information\nWORLD CLASS TECHNOLOGY \nTechnology is at the core of everything we do at SSENSE. Driven by an engineering mindset and a problem-solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the SSENSE offering. \nWORLD CLASS TEAM\nThe SSENSE tech team is responsible for an international headless commerce platform. Working in an agile environment, our squads are made up of experienced innovators in Product Management, QA, Design, DevOps, Software Development, Machine Learning, Data Engineering, and Security. Headquartered in Montreal, our technology organization has been growing at a rate of 2X year-over-year and is doubling once again in 2021 as we expand across Canada, US, and Europe.  \nWORLD CLASS PLATFORM \nThe SSENSE platform runs on Amazon Web Services making use of serverless microservices across web, mobile and app. Our event-source architecture already achieves over 10,000 requests \/ second and growing at an unmatched pace, currently unseen across the industry.  Our data-driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in Machine Learning techniques. Our automated continuous improvement DevOps model (making use of both blue \/ green and canary deployments) results in an average of 50 production releases every day.  \nRead more about us on our SSENSE Tech Blog.","174":"L\u2019entreprise\nagileDSS est une entreprise de service-conseil sp\u00e9cialis\u00e9e en analytique avanc\u00e9. Depuis plus d\u2019une quinzaine d\u2019ann\u00e9es, nous accompagnons les grandes entreprises \u00e0 tirer le meilleur parti de leurs donn\u00e9es par le biais d\u2019une expertise de pointe en analytique avanc\u00e9 \u00e0 travers des projets en Business Intelligence, Cloud Analytique, Big Data et DataOps.\n\nDescription du Poste\nNous sommes \u00e0 la recherche d\u2019une personne passionn\u00e9e qui sera int\u00e9ress\u00e9e pour un stage r\u00e9mun\u00e9r\u00e9 en Data Engineering. Vous interviendrez dans l\u2019une de nos \u00e9quipes projets directement en client\u00e8le entour\u00e9 des meilleurs dans le domaine.\n\nLe contexte de ton stage :\nInt\u00e9gr\u00e9 dans une \u00e9quipe de conseillers de Data Engineers et encadr\u00e9 par un conseiller s\u00e9nior, le stagiaire interviendra sur de v\u00e9ritables projets d\u2019entreprise chez l\u2019un de nos clients.\n\nTes principales missions seront les suivantes :\nSe former aux outils, techniques et normes de transformation de la donn\u00e9e (Azure Data Factory, Databricks, Python\/Spark, SQL)\nSe former aux outils de gestion de code \/ projet (IntelliJ IDEA, Git, Azure DevOps)\nParticiper au d\u00e9veloppement des flux de donn\u00e9es des diff\u00e9rents projets sur lesquels il aura \u00e0 intervenir\nConcevoir un algorithme de transformation de donn\u00e9es en Python\/Spark\/Delta\nAnalyser et r\u00e9soudre des anomalies dans du code \/ donn\u00e9es existant\nParticiper aux diff\u00e9rentes r\u00e9unions d\u2019\u00e9quipe\nRequirements\nLes comp\u00e9tences requises pour ce stage sont :\nBonnes notions dans un langage de programmation (SQL \/ Python \/ Cloud \/ Git \u2026)\nConnaissances de base sur la transformation de donn\u00e9es (S\u00e9lection, Filtres, Jointures, Group By, Agr\u00e9gations)\nCuriosit\u00e9, passion, enthousiasme, esprit d\u2019\u00e9quipe, relative autonomie\nRigoureux, sens du service\nTu as une bonne aisance relationnelle\nTu es bilingue (atout)\n\nagileDSS, c\u2019est aussi\u2026\nUne entreprise regroupant les meilleures personnes dans le domaine de la Data et du Data Engineering en particulier\nUn environnement stimulant et non hi\u00e9rarchique qui pr\u00f4ne l\u2019autogestion, l\u2019\u00e9change d\u2019id\u00e9es et le leadership\nDes horaires flexibles\nUn beau bureau lumineux et inspirant au c\u0153ur du Vieux Montr\u00e9al (rue McGill)\nUn environnement qui encourage la formation et le d\u00e9veloppement de ses employ\u00e9s\nDes personnes extraordinaires qui mettent l\u2019entraide au c\u0153ur de leurs interactions\nDes activit\u00e9s mensuelles de team building pour tous les go\u00fbts\nPlus que des coll\u00e8gues, une famille!\n\nCondition du Stage\nDestin\u00e9 aux \u00e9tudiants r\u00e9sidants au Qu\u00e9bec\nStage de pr\u00e9-embauche r\u00e9mun\u00e9r\u00e9 : Selon le niveau d\u2019\u00e9tude \/ Dipl\u00f4me\nHoraires : 37.5 heures par semaine, du lundi au vendredi\nDur\u00e9e : 4 \u00e0 6 mois\nD\u00e9but : Avril 2023\nPr\u00e9sentiel \/ \u00c0 distance : 2 jrs\/semaine au bureau au minimum","175":"As a Technical GM for India, you will lead a leadership team managing technical field practitioners covering the end-to-end Databricks customer journey from Pre-Sales to Go-Live. Your teams will drive accountability for technical\/business wins for the Databricks platform and accelerate the consumption of Databricks platform, and driving workloads to production for all customers in your segment. Hiring, coaching, and motivating the team to success will be critical. Included in the scope of management and accountability for the Technical GM will be :\nSolution Architects (SA's)\nSpecialist Solution Architects (SSA's), and\nDelivery Solutions Architects (DSA's) , which is a new post-Technical Win role\nTight alignment with Sales segmentation and strategy, coupled with resource prioritization and distribution across these three technical roles is paramount to the success of the Technical GM. You will report to the Leader of Field Engineering, APJ. You can be based either in Mumbai \/ Pune \/ Bengaluru \/ Delhi.\n  The impact you will have :\nRapidly scale the Field Engineering team from scratch while maintaining a high bar for talent\nBuild Databricks' brand in India, in partnership with the Marketing and Sales team.\nDrive a consistent & robust management operating rhythm to review KPI's (pipeline, Use Case progress, POC\/POV status, velocity of Win to Production, etc.)\nIncrease SA, SSA, and DSA efficiency in Sales and Consumption cycles\nBuild a collaborative culture within a rapid-growth team. Manage & mentor leaders , recruit great people focusing on DEI and resiliency.\nServe as a thought leader, consulting with strategic customer and partner contacts to position the strength of Databricks, the comprehensive solutions strategy, and build trust and credibility in the account.\n  What we look for :\n10+ years experience building and scaling Pre-sales \/ Specialists \/ Customer Delivery \/ Customer facing teams\nExperience working with accounts - from Growth\/Net New to Large and Complex accounts generating +$1M ARR.\nExperience in scaling and mentoring field and technical teams managing both in-person and remote working models\nKnowledgeable in AI, and Cloud software models with technical competence in Data Warehousing, Data Engineering, and Analytics\/Machine Learning.\nExperience instituting processes for technical field members to improve operational efficiency\n  Benefits :\nPrivate medical insurance\nAccident coverage\nEmployee's Provident Fund\nEquity awards\nPaid parental leave\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nBusiness travel insurance\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.","176":"Company Description\nOctopus \nOctopus is a group of innovative, entrepreneurial businesses investing in the people, ideas and industries that will help to change the world. We are experts in financial services and energy, and we\u2019re also a certified B Corp, meaning we care as much about the impact of our investments as the returns they generate. Today we manage more than \u00a312.6* billion on behalf of retail and institutional investors. Our energy supply business is one of the fastest growing companies in the UK, reaching 3.1 million customers in just five years, and is the only supplier to be recommended by Which? four years in a row. \nOctopus Energy, Octopus Giving, Octopus Moneycoach, Octopus Investments, Octopus Renewables, Octopus Real Estate, Octopus Ventures, Octopus Wealth and Seccl Technology are all part of Octopus Group. Visit\u202foctopusgroup.com. \n*Funds Under Management data includes undrawn commitments, funds under advisory mandates, funds monitored and the Octopus Cash service as of 31st December 2021 \nJob Description\nWe are looking for a Senior Power BI Developer to join the Data Insights team within Octopus Investments.  This is an opportunity to join a growing team in an exciting period of transformation where you will be at the forefront of shaping how the business uses data & insight.  You will be the \u2018go-to PowerBI person\u2019 in the team, spearheading the development and rollout of PowerBI across the business.\nCore responsibilities will include:\nProviding end-to-end delivery of enterprise-level Power BI solutions for OI.\nGathering, clarifying, and developing requirements with stakeholders.\nLeading the architectural design, governance, and adoption of Power BI.\nUsing a working knowledge of modern data warehousing frameworks to work closely with the Data Engineering team to define data solutions.\nBuilding and delivering Power BI training.\nOwnership of the Power BI development roadmap.\nCreating and maintaining complete and accurate solution design documents.\nQualifications\nEssential experience & characteristics:\nExperience developing end-to-end Power BI reporting and analytics solutions\nExcellent knowledge SQL, DAX, and Power Query (M)\nStrong understanding of data modelling concepts\nProficiency in data visualisation and report design\nExperience working in or alongside data engineering teams to deliver data solutions\nExperience of designing and delivering Power BI training.\nGreat people skills - this role will involve working with lots of internal stakeholders both technical and non-technical.\nDesire to learn new technologies and continuously develop new skills and expertise.\nNice to have:\nWorking knowledge of DBT.\nExperience of coaching more junior team members.\nExperience working for a similar, fast paced Financial Services company.\nAdditional Information\nOur Values \nAt Octopus we don't just focus on what we do but also how we do it. Everyone shares our values of being straightforward, helpful and bold. And while these are the principles that guide us as an organisation. \nWhat we offer\n\ud83d\udcb0  A competitive salary, bonus, pension and share incentive plan\n\u2708\ufe0f Take what you need holiday\n\ud83c\udfe1 Flexible working \n\u2693 Anchor (our wellness hub) which includes Headspace, one to one coaching through Sanctus, Parent Cloud, Digital GP, Shout & more\n\ud83d\udc6a Enhanced family leave policies\n\u2764\ufe0f Life insurance, critical illness cover and income protection\n\ud83c\udfe5 Private medical insurance for you and your family\n\ud83d\ude97 Electric vehicle leasing\n\ud83c\udf0d The option to work overseas up to a month per year","177":"As a Solutions Architect (Analytics, AI, Big Data, Public Cloud), you will guide the technical evaluation phase in a hands-on environment throughout the sales process. You will be a technical advisor internally to the sales team, and work with the product team as an advocate of your customers in the field. You will help our customers to achieve tangible data-driven outcomes through the use of our Databricks Lakehouse Platform, helping data teams complete projects and integrate our platform into their enterprise Ecosystem. You'll grow as a leader in your field, while finding solutions to our customers' biggest challenges in big data, analytics, data engineering and data science problems. You will report to the Solutions Architect Manager.\nThe impact you will have:\nYou will be a Big Data Analytics expert on aspects of architecture and design\nLead your clients through evaluating and adopting Databricks including hands-on Spark programming and integration with the wider cloud ecosystem\nSupport your customers by authoring reference architectures, how-tos, and demo applications\nIntegrate Databricks with 3rd-party applications to support customer architectures\nEngage with the technical community by leading workshops, seminars and meet-ups\nTogether with your Account Executive, you will form successful relationships with clients throughout your assigned territory to provide technical and business value\nWhat we look for:\nConsulting, Pre-sales or post-sales experience working with external clients across a variety of industry markets\nUnderstanding of customer-facing pre-sales or consulting role with a core strength in either data engineering or data science advantageous\n5+ years of experience demonstrating technical concepts, including demos, presenting and white-boarding\n8+ years of experience designing architectures within a public cloud (AWS, Azure or GCP)\n5+ years of experience with Big Data technologies, including Spark, AI, Data Science, Data Engineering, Hadoop, Cassandra, and others\nCoding experience in Python, R, Java, Spark or Scala\nBachelor's degree in Computer Science, Information Systems, Engineering, or equivalent experience through work experience\nBenefits :\nPrivate medical insurance\nAccident coverage\nEmployee's Provident Fund\nEquity awards\nPaid parental leave\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nBusiness travel insurance\nMental wellness resources\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.","178":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to know our team:\nPartner Development is a team of creative entrepreneurs that develop solutions for Agoda\u2019s accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.\nIn this role you'll get to\nThis role is designed to mainly growth opportunity identification among mid to long tail hotels, experiment execution and data tracking within Partner Development team for the global teams. You will get to work directly with the regional team to design and put in place global experimentation and initiatives to drive tangible impact in each market.\nKey activities involved include but not limit to:\nApply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations\nOwn end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development\nBuild dashboards, identify new and track key metrics to closely monitor team\u2019s performance and identify quick and long term opportunities for improvements\nWork closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified\nSupport global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization\nWhat you'll need to succeed \nBachelor\u2019s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline\n4-8 years experience working in a business analysis, data analysis, reporting or business strategy role\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\nCoding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\nData visualization tool experience such as with Tableau or your weapon of choice.\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","179":"Ginkgo Introduction\nOur mission is to make biology easier to engineer. Ginkgo is constructing, editing, and redesigning the living world in order to answer the globe\u2019s growing challenges in health, energy, food, materials, and more. Our bioengineers make use of an in-house automated foundry for designing and building new organisms.\n\nSpecific Role Description\n\u25cf Ensure effective and high-quality development and support of Ginkgo Ag platform and programs\u25cf Drive digital research strategy definition and operationalization, effective storage and analysis of data for all studies supporting a smooth transition of projects through phases, including experimental design\u25cf Drive optimal externalization strategy and use of Ginkgo-wide capabilities.\n#LI-JH1\nResponsibilities\nManage, develop and lead two core functions: Decision Science, Genomics as well as outsourced functions\nAs member of Ag Dept., partner with other senior team members and Ginkgo teams across the organization to facilitate data management, storage and analysis as well as training of users and promotion of biostatistics culture across Ag Dpt.\nWork closely with IT functions to leverage skills and resources of this function particularly around Project Management and IT systems implementation.  Participate in all necessary integration functions as organization matures.\nEnsure DSA excellence within Ag Dept. as well as across Ag Dept. functions.\nFormulate technical and strategic objectives that involve a high degree of planning and coordination so that numerous activities converge successfully at local and global levels, such as Data Management strategy\nRepresent Ag Dept. at 3rd party and internal collaboration meetings, international conferences and commercial partnerships\nAs a member of Ag Dept. Leadership Team, effectively plan and manage departmental budget (esp. capital and operational expenditure and training budget allocated to direct reports) and develop Ag Dept. innovation strategy.\nMinimum Requirements\nPhD with minimum of 8 years experience in Computational Biology, Bioinformatics, Genomics or related field\nManagement experience supervising PhD level scientists with 5 years of demonstrated leadership skills\nScientific, technical and social skills for the development of internal and external network contacts of global expert teams.\nPreferred Capabilities and Experience\nExpert domain knowledge of data science and bioinformatics incl. all actual developments like deep neural nets and machine learning. \nComprehensive technical understanding of relational databases, network design and systems, servers, and web-based software development. \nStrong communication skills to translate technical and scientific information and to communicate departmental vision\nTo learn more about Ginkgo, visit www.ginkgobioworks.com\/press\/ or check out some curated press below:What is it really like to take your company public via a SPAC? One Boston biotech shares its journey (Fortune)Ginkgo Bioworks resizes the definition of going big in biotech, raising $2.5B in a record SPAC deal that weighs in with a whopping $15B-plus valuation (Endpoints News)Ginkgo Bioworks CEO on scaling up Covid-19 testing: \u2018If we try, we can win\u2019 (CNBC)Ginkgo raises $70 million to ramp up COVID-19 testing for employers, universities (Boston Globe)Ginkgo Bioworks Redirects Its Biotech Platform to Coronavirus (Wall Street Journal)Ginkgo Bioworks Provides Support on Process Optimization to Moderna for COVID-19 Response (PRNewswire)The Life Factory: Synthetic Organisms From This $1.4 Billion Startup Will Revolutionize Manufacturing (Forbes)Synthetic Bio Pioneer Ginkgo Raises $290 Million in New Funding (Bloomberg)Ginkgo Bioworks raises $350 million fund for biotech spinouts (Reuters)Can This Company Convince You to Love GMOs? (The Atlantic)\nWe also feel that it\u2019s important to point out the obvious here \u2013 there\u2019s a serious lack of diversity in our industry, and that needs to change. Our goal is to help drive that change. Ginkgo is deeply committed to diversity, equity, and inclusion in all of its practices, especially when it comes to growing our team. Our culture promotes inclusion and embraces how rewarding it is to work with people from all walks of life.  \nWe\u2019re developing a powerful biological engineering platform, so we must remain mindful of the many ways our technology can \u2013 and will \u2013 impact people around the world. We care about how our platform is used, and having a diverse team to build it gives us the best chance that it\u2019s something we\u2019ll be proud of as it continues to grow. Therefore, it\u2019s critical that we incorporate the diverse voices and visions of all those who play a role in the future of biology.\nIt is the policy of Ginkgo Bioworks to provide equal employment opportunities to all employees and employment applicants.","180":"Binance is the global blockchain company behind the world\u2019s largest digital asset exchange by trading volume and users, serving a greater mission to accelerate cryptocurrency adoption and increase the freedom of money.\nAre you looking to be a part of the most influential company in the blockchain industry and contribute to the crypto-currency revolution that is changing the world?\nResponsibilities\nWork across all aspects of data from engineering to building sophisticated visualizations, machine learning models and experiments\nAnalyze and interpret large (PB-scale) volumes of transactional, operational and customer data using proprietary and open source data tools, platforms and analytical tool kits\nTranslate complex findings into simple visualizations and recommendations for execution by operational teams and executives\nProcessing confidential data and information according to guidelines\nManaging and designing the reporting environment, including data sources, security, and metadata\nTroubleshooting the reporting database environment and reports\nRequirements\nBachelor\u2019s degree from an accredited university or college in Computer Science or Math or Statistics\nProficient in data engineering, modeling and ETL - preferred experience with data sourcing and working with APIs\nExperience with data querying using languages such as SQL, GraphQL, Python \nAble to commit minimum 3 days per week for at least 6 months\nUnderstands project tokenomics and has good knowledge of the DeFi and Web 3.0 infrastructure landscape\nExperience in using tools such as Dune analytics, Nansen etc\nUnderstanding of addressing and metadata standards\nHigh-level written and verbal communication skills","181":"Company Description\nVisa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.\nWhen you join Visa, you join a culture of purpose and belonging \u2013 where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world \u2013 helping unlock financial access to enable the future of money movement.\nJoin Visa: A Network Working for Everyone.\nJob Description\nThis position is ideal for an engineer who is passionate about solving challenging business problems and building applications that provide an excellent user experience. You will be an integral part of the Payment Products Development team focusing on design and development of software solutions that leverage data to solve business problems. The candidate will be extensively involved in hands-on activities including POCs, design, documentation, development, and testing of new functionality. Candidate must be flexible and willing to switch tasks based on team's needs. \nResponsible for the design, development, and implementation.\nWork on development of new products iteratively by building quick POCs and converting ideas into real products.\nDesign and develop mission-critical systems, delivering high-availability and performance.\nInteract with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology.\nDevelop code to ensure deliverables are on time, within budget, and with good code quality.\nHave a passion for delivering zero defect code and be responsible for ensuring the team's deliverables meet or exceed the prescribed defect SLA.\nCoordinate Continuous Integration activities, testing automation frameworks, and other related items in addition to contributing core product code.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nPerform other tasks on R&D, data governance, system infrastructure, and other cross team functions, on an as-needed basis\nThis is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs.\nQualifications\nWe are seeking team members that are passionate, visionary and insatiably inquisitive. Successful candidates frequently have a mix of the following qualifications:\n\n\u2022 2 or more years of work experience in building large-scale applications using open source technologies\n\u2022 Bachelor\u2019s Degree or an Advanced Degree (e.g. Masters) in Computer Science\/ Engineering, Information Science or a related discipline\n\u2022 Extensive experience with SQL and Big Data technologies (Hadoop, Java, Spark, Kafka, Hive etc.) tools for large scale data processing and data transformation\n\u2022 Experience with data visualization and business intelligence tools like Tableau, or other programs highly desired\n\u2022 Familiar with software design patterns\n\u2022 Experience working in an Agile and Test-Driven Development environment\n\u2022 Strong knowledge of API development is highly desired\n\u2022 Strategic thinker and good business acumen to orient data engineering to the business needs of internal and external clients\n\u2022 Demonstrated intellectual and analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style\n\u2022 Previous exposure to financial services is a plus, but not required\n\nPlease Note: Due to the COVID-19 pandemic and the evolving visa\/travel restrictions in place, we are currently only able to extend offers to candidates with the right to work in Singapore. We are keeping the situation under close review and will adjust accordingly should the restrictive measures be lifted.\nAdditional Information\nVisa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.","182":"Company Description\nVisa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.\nWhen you join Visa, you join a culture of purpose and belonging \u2013 where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world \u2013 helping unlock financial access to enable the future of money movement.\nJoin Visa: A Network Working for Everyone.\nJob Description\nThis position is ideal for an experienced Software engineer who is passionate about solving challenging business problems and building applications that provide an excellent user experience. You will be an integral part of Loyalty & Marketing Services team focusing on design and build of software solutions that leverage data to solve business problems.\nResponsibilities\nResponsible for the architecture, design, development, and implementation.\nWork on development of new products iteratively by building quick POCs and converting ideas into real products.\nDesign and develop mission-critical systems, delivering high-availability and performance.\nInteract with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology.\nDevelop code and mentor junior developers to ensure delivery on time, within budget, and with good code quality.\nHave a passion for delivering zero defect code and be responsible for ensuring the team's deliverables meet or exceed the prescribed defect SLA.\nHelp developer efficiencies by utilizing Continuous Integration\/Development tools, test automation frameworks and other related items.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nIdentify opportunities for future enhancements and refinements to products, standards, best practices, and development methodologies\nCollaborate with global and virtual teams on software development.\nThis is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs.\nQualifications\n\u2022 Master\u2019s Degree in Computer Science or related field with 6 years of relevant experience or Bachelor\u2019s degree with 8 years of relevant experience.\n\u2022 Previous exposure to financial services is a plus, but not required.\n\u2022 Strong knowledge on Hadoop framework components (HDFS, Map Reduce, Spark, HBase, Kafka).\n\u2022 Strong knowledge in Java or Scala or Python.\n\u2022 Strong knowledge of database concepts, systems architecture, and data structures is a must.\n\u2022 Experience with one or more of the following database technologies: DB2, Postgres, MySQL, and NoSQL such as Hadoop, Hbase, MongoDB.\n\u2022 Proficient in GIT\/Stash, Maven, Jenkins etc.\n\u2022 Java\/J2EE\/Angular, Spring Cloud, Microservices and strong knowledge on API development is a big plus.\n\u2022 Experience working in an Agile and Test-Driven Development environment.\n\u2022 Process oriented with strong analytical and problem-solving skills.\n\u2022 Work independently and mentor others in the team and with minimal supervision.\n\u2022 Ability to juggle multiple projects and change direction mid-course based on business drivers.\n\u2022 Demonstrated ability to work in a complex organization to determine business and customer needs, providing the best solution to meet those needs.\n\u2022 Ability to work independently in a high throughput environment.\n\u2022 Demonstrated intellectual and analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style.\n\u2022 Excellent presentation and communication skills required.\nAdditional Information\nVisa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.","183":"Definitive Logic has a unique opportunity for a Mid-Level Business Intelligence (BI) Solution Developer to join our tightly knit team supporting the implementation and deployment of a Cloud software solution. We are an\u202faward-winning\u202fcompany that cares about its customers and its employees, and we are a recognized consulting leader in Corporate Performance Management services. \u202fWe offer great benefits, a casual work environment, volunteer hours to help the community, and training. \u202fIf you want to work with a great team that provides growth and training opportunities, we want to talk with you.  We are only looking for people who want to join our team as regular, full-time employees. \u202fWe want to continue building our corporate knowledge and invest in making our employees the best in the business.\nResponsibilities\nApply standard industry practices and methodologies to develop, deploy, and maintain BI interfaces, those include query tools, data visualization and interactive dashboards, ad hoc reporting, and data warehousing tools\nBackground development data solutions and can operate in a fast paced, highly collaborative environment\nAssist in the development of dashboards and other data visualizations\nAssist in all conversion, design, and training activities throughout program planning and execution\nRequired Qualifications\nBachelor's degree or higher in Computer Science, Engineering, Information Systems, Mathematics, Business, Accounting or related degree\nExperience consulting or delivering solutions to federal clients\nMinimum of 8 years of work experience in a technical field with at least 2 years of hands-on experience with BI platforms to include Tableau, Microsoft Power BI, Qlik, etc\nThe ability to obtain a DoD Secret Security Clearance\nDesired Qualifications\nGeneral knowledge of federal financial management processes and requirements\nSQL experience with Oracle databases or SQL Server, or other industry standard DB platforms\nTableau development experience\nExperience working with Redshift, AWS or other Cloud Platforms\nActive DoD Secret Clearance\nAbout Definitive Logic Definitive Logic (DL) is a management and technology consulting firm known for delivering outcomes and ROI for agencies\u2019 most complex business challenges.\u202f DL delivers performance-based and outcome-driven technology consulting solutions that directly support the strategic intent of our Defense, Homeland Security, Emergency Management, Federal Civilian and Commercial clients. We\u2019re the preferred technology integration partner for Federal agencies to apply the best of data science, app dev, DevSecOps, cyber and cloud solutions to improve decision support, empower front-line employees and enhance back-office operations. We serve as trusted advisors providing objective, fact-based, vendor & technology-neutral consulting services.  Definitive Logic is ultimately a team of problem solvers \u2014 thought leaders, domain experts, coders, data enthusiasts, and technophiles.\u202f Our exciting projects and learning and sharing culture has consistently resulted in validation as a Great Place to Work: 2021 Washington Post Top Work Places\u202f(7-time winner) | 2022 Virginia Best Places To Work\u202f(9 years running, #1 midsize in 2019). \nDefinitive Logic is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity\/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class.\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable, or limited in your ability, to use or access our Careers page: https:\/\/www.definitivelogic.com\/careers\/open-opportunities\/ as a result of your disability. You can request a reasonable accommodation by sending an e-mail to Recruiting@DefinitiveLogic.com or via phone: 703-955-4186. In order to quickly respond to your request, please use the words \"Accommodation Request\" as your e-mail subject line.\nDL BenefitsHealthDentalVisionLife\/AD&D: Company paid STD\/LTD:Company paidSupplemental Plans: TriCare Supplement, Pet Insurance through Nationwide, Legal Resources and hospital\/accidental indemnity plans and Wellness initiatives. Compensation Benefits:Competitive Base SalaryAnnual performance based bonus401(k) & Roth option: You are fully (100%) vested on day 1 and DL matches up to 5%Spot Bonuses Referral Bonuses Additional Benefits:Flexible Time Off (FTO): Under our FTO plan, there is no cap in the amount of leave you choose to take, with proper coordination and prior approval.Volunteer Hours: DL allocates up to 8 hours for you to use every year to volunteer for a 501c3 organization of your choice and DL will donate to that charity based on how many hours you volunteer.Cell Phone Reimbursement: $80\/monthLocation Specific Metro\/Parking Tuition Reimbursement Training & Certifications","184":"Our mission is to connect and optimize the world\u2019s commerce. That means the whole world. So we\u2019re determined to nurture our culture of meritocracy where everyone can thrive, no matter what we look like, where we\u2019re from, how we grew up, whom we love, the nature of our faith, or how our bodies or minds work. We\u2019re committed to achieving equity in treatment and opportunity for everyone, where people are judged on the merits and quality of their work.\nIt all starts with people. Inside every company, behind every brand\u00ad - while business success is often measured in profit, it has always been powered by people. We firmly believe people are the heart of any organization - including our own. That\u2019s why a career here provides much more than simple pay and perks. We\u2019re dedicated to empowering people, solving tough problems, and helping careers flourish inside and out. \n  Position Summary:\nThe Business Intelligence Engineer will be a critical contributor to enabling the Business Intelligence Team to identify opportunities for CommerceHub to use its own data, as well as data provided by third parties, to generate additional company revenue and derive valuable industry insights.\n  Responsibilities:\nDesign and build dashboards for internal stakeholders and externally facing products\nDevelop new and maintain existing reports using Looker, Tableau and PowerBI\nWork with stakeholders including Product, Marketing, Finance and Customer Support to design dashboards and reports\nParticipate in full development life cycle including requirements development, implementation, peer review, source control, automated testing, deployment, and operations\nEnforce corporate policies around the evolution and enforcement of industry data standards, data governance and best practices\n  Requirements:\nBachelor\u2019s degree or higher and\/or equivalent work experience\nStrong analytical skills related to working with both structured and non-structured datasets\nStrong data modeling skills and experience working with Star Schemas\nStrong working knowledge of highly scalable data warehouse products such as Amazon Redshift, Snowflake\n2+ years\u2019 experience with data visualization tools such as Looker, Tableau, PowerBI\nExperience working in Retail and Looker BI visualization tool is a plus\n2+ years\u2019 experience with SQL coding languages such as TSQL, LookML, PostgreSQL, Athena\n2+ years\u2019 experience with scripting languages such as Python and R\nExceptional written and verbal communication skills\nComfortable communicating across all levels of management\nAbility to prioritize tasks and work independently\nExcellent analytical, decision-making, and problem-solving skills\nProven ability to work in a rapidly changing environment with keen attention to detail\n  What it\u2019s like to work at ChannelAdvisor, a CommerceHub Company\nWe take a whole-person approach to engage and support our global team. We believe the diversity of our global team is an advantage. If you\u2019re curious, innovative, determined, and customer-focused, then you\u2019ll love the challenge and rewards of collaborating as a team to help our customers win. We offer competitive compensation programs that recognize your hard work and results. Because when our customers win, we win.  And when we win, you win.\nWe work to create an environment where everyone who is committed, works hard, and delivers results can thrive and grow. You can connect with one of our employee resource groups and support our diversity, equity and inclusion task force, network with like-minded team members, and showcase your leadership skills. \n  Benefits: \nEnhanced Private Medical Insurance and a Health Cash Back Plan \nCompetitive time off package with 25 Days of PTO, 9 Holidays, 2 Wellness days and 1 Give Back Day\nFlexibility to choose where you work - at home, in the office, or both!\nAccess to tools to support your wellbeing such as the Calm App, MoveSpring and an Employee Assistance Program\nProfessional development stipend and learning and development offerings to help you build the skills and connections you need to move forward in your career\nCharitable contribution match per team member\n  ChannelAdvisor, a CommerceHub Company, is an Equal Employment Opportunity Employer. We celebrate diversity and are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need.","185":"Netflix is the world\u2019s leading streaming entertainment service with 220 million paid memberships in over 190 countries, enjoying TV series, documentaries, and feature films across a wide variety of genres and languages. Members can watch as much as they want, anytime, anywhere, on any internet-connected screen. About the Engineering Support OrganizationThe aim of the Engineering Support Organization is to enable Platform Engineering to effectively and sustainably scale the support they provide to their customers. The team  is the frontline resource for the engineering support needs of our customers (i.e., our workforce) - handling, troubleshooting, and resolving customer requests and issues. In addition, the team will focus on ways of working, customer advocacy, support tooling, platform product offerings, documentation, and developer education. \n\nOur Mission Deliver an excellent support experience to Netflix\u2019s developer community. To advocate for our customers, follow through on issues and resolve them in a reasonable time. If blockers prevent immediate resolution, we communicate status and ensure there is visibility into why there is a delay. \nProvide insights, feedback and champion customer sentiment about the tools we support to our partners across Productivity and Data Platform Engineering. Partner with Product Management, Developer Education and Engineering to track and maintain visibility into ongoing issues and communicate customer needs to ensure improving in these areas is prioritized.\nDrive collaboration efforts to reduce product friction and increase usability so that Platform Engineering can build, deploy and deliver highly functional solutions for the Developer Community.\n\nThe Role We are looking for a Technical Support Engineer with a passion for data platform infrastructure and tooling, customer service, and automation. You will be responsible for monitoring and handling our customers\u2019 requests, troubleshooting, solving issues, automating support needs, developing support documentation and runbooks, improving and maintaining support tools and automation, understanding our product offerings, and continuously looking for ways to improve the engineering support experience.\n\nOur ideal team member has first-hand experience working in customer-facing, engineering support roles, writing and building a comprehensive self-service knowledge base and has knowledge of infrastructure, internal tooling, platforms, and cloud computing. You are excellent at understanding and solving complex and ambiguous problems and constantly seek improvement. As an Engineer in this role, we need a candidate who can understand our complex offerings on a technical level, be hands-on in the development of our support automation tooling, and recommend product and operational improvements based on customer interactions.\nLocation\nOur offices are located in Los Gatos.\nWhat you\u2019ll need to be successful:\nYou are skilled in providing superior customer support across a complex organization, ideally as part of a central team \nYou are passionate about customer experience\nYou are a data-driven decision-maker\nYou have excellent written and verbal communications skills and appreciate the importance of comprehensive documentation\nYou are comfortable with at least one programming language; preferably Python and\/or Java\nAbility to read and comprehend log files and Unix processes to identify and troubleshoot root causes of issues\nPrior experience supporting platforms built using open source technologies such as, Jupyter, Hadoop, Apache Airflow (or other workflow orchestration platform), Presto\/Trino\nYou  have worked with big data warehouse storage systems (e.g. Iceberg or Hive)\nYou have experience working with data pipelines using Apache Spark framework or  technologies such as Flink, Kafka, Druid or Presto\nAbility to read and write SQL queries to pull required complex data to support any reported issues\/product defects\nExperience with cloud infrastructure and\/or container orchestration platform is a plus\nYou have the desire and aptitude to learn how the pieces of big data platform work together\nOur culture is unique, and we tend to live by our values, allowing you to do your best work and grow. To learn more about Platform Engineering, feel free to listen to this podcast.\n\nWe are an equal-opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.\n\nAt Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location. \n\nThe overall market range for roles in this area of Netflix is typically $90,000 - $900,000\n\nThis market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here.","186":"Company Description\nREF25129J\nJob Description\nciValue is the leading provider of AI-powered customer analytics, personalization, and brand collaboration platform. Serving dozens of retailers and brands across the world using cutting edge big-data, real-time analytics, and data-science automation. \nRecently acquired by NielsenIQ, ciValue\u2019s solution is disrupting existing data & media monetization model by enabling retailers to remain in control of their revenue. \nWe believe that building a great product and teams starts with amazing, diverse minded and bright people who make an impact, generate creative & innovative ideas and take on new perspectives.\u202f \nThe Big Data Software Engineer is responsible for building new data solutions for our rapidly expanding customer base and working with the top data ingestion technologies in an open, collaborative and innovative environment. \nResponsibilities\nBe responsible for Data flow stages from definition to architecture, including Data acquisition, Data set acceptance criteria and Data Science integration \nArchitecture designing and customizing technological solutions for large scale data processing \nDevelop and deploy real-time and batch data processing infrastructures and pipelines \nTake responsibility to explore technologies to scale up Data ecosystem to handle rapidly big Data growth \nWork closely with Data science team to embed ML \/ AI algorithms into the product \nWork with cloud, DevOps, application, and client teams to make sure your solution is solving significant business problems in a robust, scalable manner. \nUse cutting edge technologies: Python, Airflow, Java, Kubernetes, Spark, Scala, Kafka \nQualifiications\nBachelor's or Master\u2019s degree in Computer Science, Computer Engineering or related field \n4+ years of backend engineering work experience in production environments (Data environments, Big Data processing, Database techniques) \nProven experience with Java\/Scala (Python\/Go \u2013 advantage) \nExperience in design and development of scalable big data solutions \nExperience in Big Data \u2013 Spark \/ Kafka \/ Flink \nExperience in Kubernetes, containers & Helm \nExperience working with SQL & NO-SQL Databases \u2013 PostgreSQL, DataLake, Columnar DB \nAbility to learn new technologies and work in a dynamic fast paced environment \nResult-driven, pragmatic, and innovative \nExperience with Cloud technology is an advantage \nExcellent English communication skills spoken and written \n Full-time position in our office in Yokneam (Hybrid) \nAdditional Information\nAbout NielsenIQ\nNielsenIQ is a global measurement and data analytics company providing the most complete and trusted view of consumers and markets in 90 countries covering 90% of the world\u2019s population. Focusing on consumer-packaged goods manufacturers and FMCG and retailers, we enable customers to defy what\u2019s possible. How? We combine unparalleled datasets, pioneering technology, and the industry\u2019s top talent to create insights that unlock innovation. Join us and change the landscape.\nLearn more at: www.niq.com\nWant to keep up with our latest updates? Follow us on: LinkedIn | Instagram | Twitter | Facebook\nOur commitment to Diversity, Equity, and Inclusion\nNielsenIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us.\nWe are proud to be an Equal Opportunity\/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide.\nLearn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https:\/\/nielseniq.com\/global\/en\/news-center\/diversity-inclusion\/\nNielsenIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process.","187":"Company Description\nSSENSE (pronounced [es-uhns]) is a global technology platform operating at the intersection of culture, community, and commerce. Headquartered in Montreal, it features a mix of established and emerging luxury brands across womenswear, menswear, kidswear, and Everything Else.\nSSENSE has garnered critical acclaim as both an e-commerce engine and a producer of cultural content, generating an average of 100 million monthly page views. Approximately 80% of its audience is between the ages of 18 to 40. It is privately held and has achieved high double digit annual growth and profitability since its inception.\nJob Description\nReporting to the Senior Director of Global Operational Excellence & Continuous Improvement, the Manager of Data Visibility, Governance, and Product is responsible for leading the design, development, and successful implementation of current and future data visualisation, reporting standards, and workflow data products for Operations. They will oversee a team of analysts that translate business requirements into technical reporting requirements across all end-to-end processes, define the metrics, and then build the data products and corresponding dashboards that will be a cornerstone of all Operational roles and training programs at SSENSE. The incumbent will ensure data visualisation, metric, and KPI standards are clearly defined ahead of our global network expansion plans over the coming 1-3 years.\nRESPONSIBILITIES\nData visibility, governance, and product design (75%)\nDevelop and lead the Operations Visualization & Data Governance transformation plan that will standardise and operationalize all data points related to physical and systemic movement of products within the SSENSE Network, spanning operational process paths to C-suite executive-level reporting\nTranslate and develop standard metrics for reporting, and collaborate with the Product and Engineering, and Data Platform team to determine the right mechanism for delivering the reports and insights to maximize how they are used and actioned by Operational teams\nDevelop, and implement reporting solutions with AWS tools like Athena, Tableau, and operational reporting capabilities available through operational systems\nWork closely with all Operational teams and executive leadership to ensure clear and consistent metric definitions, comprehensive capture and up-to-date documentation of operational reporting and analytical reporting requirements \nOversee all data, metric, and dashboard development by the direct team; define the internal development process and stakeholder engagement model, establishing quality measures for product delivery; achieve and maintain best-in-class benchmarks for adoption rates\nDevelop prioritised roadmap for scaling visibility, maturity, automation, and real-time capability for all operational process paths in tandem with process maturity assessment; design agile approach for near-term output and ongoing, ad hoc request management\nImplement design principles and templates for data visualisation and governance across Operations that guides all dashboard development in current and future state\nCollaborate with the Product and Data Platform teams to define and demarcate data accessibility and tools for analysis vs. standardised user interface for operational process and reporting\nPartner with Business Process Owners and Operations leadership to implement standard metrics based on industry best practices to integrate with company-wide metric reporting \nImplement continuous improvement processes for refining \/ streamlining data or visualisation standards, as well as change management practices for deployment; inclusive of scalable approach to deprecating and removing legacy reports and dashboards\nPilot workflow tools that support predictive analytics and algorithmic recommendations\nOversee successful migration of reporting, visualisation, and workflow tools with existing system or product changes (e.g., WMS); partner with Product teams to define requirements of new systems or product implementation (e.g., YMS, LMS); ensuring successful integration with data governance and reporting standards\nPartner directly with the Data Platform team and the Product and Engineering teams to develop a design of the future for these collaterals and corresponding data architecture\nPeople leadership and development (25%)\nWork with Senior Leadership to gauge and monitor team engagement and implement solutions to create a transparent, collaborative and productive work environment \nCollaborate with Senior Leadership to establish the department short term objectives for the department and ensure the team's are engaged towards achieving them \nHold weekly one-on-ones, conduct performance reviews, analyze individual KPIs and assess promotion readiness to help each contributor evolve in their roles\nProvide mentorship and development opportunities to team members, catalyzing growth through coaching and team building\nQualifications\nREQUIREMENTS\nBachelors Degree in Computer Science, Information Systems, Mathematics, Statistics, Data Science, Software Engineering, or another relevant field \nA minimum of 5 years of professional, hands-on data management\/Operations and analytics experience, with at least 3 years of formal management experience leading highly developed data management and analytical professionals, ideally in fast-paced Fulfillment industry, Distribution, Logistics or Production\/Manufacturing environment\nExtensive experience with data manipulation and data visualisation tools, such as Tableau for reporting and dashboarding is essential\nExtensive experience with data manipulation using SQL or other means to extract and transform data is a must\nAnalytical mindset and experience working with business and technical teams to define key metrics, KPIs, definitions, and governance standards, along with the process to manage and maintain them over time is a must\nExperience with Operational SAAS systems and their reporting capabilities (pros and cons) is a plus\nExperience leading teams in information design principles and data visualisation methods, best practices, and software packages and APIs such as Tableau or equivalent analytics tools\nStrong written and verbal communication skills in English and French\nSKILLS\nStrong organisational and time management skills \nAdvanced data analysis skills, and an expert in using supporting tools\nStrong collaboration and prioritisation skills\nAbility to identify, prioritise and articulate high impactful initiatives\nThe ability to translate operational issues into workable data solutions\nCreative out-of-the-box thinking with excellent problem-solving abilities\nTeam player with solid leadership and interpersonal skills\nStrong communication skills, with an ability to influence cross-functional teams\nAdditional Information\nWORLD CLASS TECHNOLOGY \nTechnology is at the core of everything we do at SSENSE. Driven by an engineering mindset and a problem-solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the SSENSE offering. \nWORLD CLASS TEAM\nThe SSENSE tech team is responsible for an international headless commerce platform. Working in an agile environment, our squads are made up of experienced innovators in Product Management, QA, Design, DevOps, Software Development, Machine Learning, Data Engineering, and Security. Headquartered in Montreal, our technology organization has been growing at a rate of 2X year-over-year and is doubling once again in 2021 as we expand across Canada, US, and Europe.  \nWORLD CLASS PLATFORM \nThe SSENSE platform runs on Amazon Web Services making use of serverless microservices across web, mobile and app. Our event-source architecture already achieves over 10,000 requests \/ second and growing at an unmatched pace, currently unseen across the industry.  Our data-driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in Machine Learning techniques. Our automated continuous improvement DevOps model (making use of both blue \/ green and canary deployments) results in an average of 50 production releases every day.  \nRead more about us on our SSENSE Tech Blog.","188":"Marco is a one-stop shop for all things business tech. Our employees are \u201cmovers and shakers\u201d and our company is always striving to do what\u2019s right. Does this sound like a culture you want to be a part of? We\u2019re hiring a new team member to help take Marco\u2019s technology further \u2013 working full-time, Monday - Friday, 8am-5pm. More about us. We do it all \u2013 from copy and print solutions to IT and managed services. We are an organization led by salespeople with 650+ engineers ready to fix any and all issues. We have offices in 12 states and service nationally. Join our growing team. You won\u2019t regret it.\nThe Senior Manager of BI and Data Analytics is responsible for gathering, analyzing, interpreting, and presenting information in ways that will help Marco make better decisions, solve business problems, improve business performance, support team decisions\/ideas, challenge the status quo, and improve the customer journey. The Senior Manager of BI and Data Analytics, under the direction of the Chief Service and Automation Officer, will define the roadmap and priorities for the enterprise-wide Business Intelligence & Analytics function.The Senior Manager of BI and Data Analytics will leverage industry best practices to design and implement secure and scalable solutions to meet the evolving needs of Marco. This role leads a group of Data Analysts in support of all business intelligence requests (new requests, break-fix requests, and maintenance support requests) and is responsible for their growth, upskilling and ongoing development. The Senior Manager of BI and Data Analytics will work closely with business function and IS peers to align to a vision for BI and analytic services across all performance-based metrics and reporting at an enterprise-wide level. \nEssential Functions\nGuide and develop assigned Data Analyst staff under the right agile analytic operating model (people, process and tools)\nManage the assigned department team members as follows:\n      Lead, coach and train team members.\n      Develop and implement strategic initiatives for team.\n      Be an escalation point of contact to handle issues and involve direct leadership as needed.\n      Monitor team coverage, oversee personal time off approval, make sure back-ups are in place and redistribute work to cover when others are out.\nMonitor staffing and equipment needs.\n     Conduct performance reviews and make compensation decisions.\nUtilize the landscape of technology (both existing and emerging) to provide the optimal user experience for business leaders to interact with data and analytic insights\nEnsure data integrity across all performance-based metrics and reporting\nWork with a diverse group of C-level and cross-pillar stakeholders to understand business problems and surface digital solutions to address those problems\nDevelop executable plans to achieve business needs on time and to internal business user expectations\nStay informed on industry business intelligence & analytics innovations and best-in-class practices\nProvide thought-leadership with all matters related to business intelligence & analytics as a business partner\nBuild strong cross-pillar relationships with business and IS stakeholders and teams\nRequired Skills\nExpert knowledge of business intelligence platforms (i.e., Tableau, Power-BI)\nExpertise in industry-leading enterprise data practices\/principles, platforms, and technologies (CI\/CD, Automation \u2013 RPA, build-release engineering, advanced monitoring and data configuration management) from the customer value dimension (functionality, reliability, and convenience)\nContinuous expectation management around data & analytics program value through metrics that identify goals and progress being made organizationally\nStrong relationship management skills with the ability to influence technology vision\/decisions at senior stakeholder level and across a global organization\nDemonstrated ability to work\/manage both data analysts\/engineers and broader IS teams across a global IS organization \nBenefits: We\u2019re not just competitive when it comes to business tech \u2013 we\u2019re also pretty proud of what we offer our employees. Our benefits include medical, dental, and vision insurance. We also have paid holidays and vacation, 401k with generous company match, flexible spending accounts, employee purchase program, employer-paid life insurance, voluntary-term life insurance, short and long-term disability, critical illness and accident benefits, and pet insurance. Yes, we care about your furry family too.\n*all benefits are dependent on employment status    Equal Opportunity Employer \/AA Employer\/Minorities\/Women\/Protected Veterans\/Individuals with Disabilities Applicant Labor Law Posters","189":"We are Assembly \u2013 and we\u2019re not like the rest. We\u2019re the modern alternative agency, bringing together industry-leading data, talent, and tech to\u202fFind the Change That Fuels Growth\u202ffor the best brands on the planet, including LG, Adobe, Ralph Lauren, Moncler, Aesop, and more. Our diverse, global community of over 1,600 passionate experts combines global thinking with unmatched local expertise in more than 20 markets worldwide \u2013 enabling brands to engage and move consumers anywhere. We use STAGE, Assembly\u2019s proprietary, privacy-centric data solutions platform, to surface powerful insights that transform into actionable brand opportunities. We\u2019re at the cutting edge of new media, technology, and platforms embedded in the lives of today\u2019s consumers, and we\u2019re tapped into how culture and communities\u2019 needs change. We do this while staying steadfast in our commitment to\u202fLeave the World Better Than We Found It\u202fthrough measurable social and environmental impact work.\nAssembly was named The Drum\u2019s APAC Media Agency of the Year in 2021\nThis role is a central position for the Hong Kong office as that person supports all the existing team on data and analytics topics. The role is also part of a larger regional data team that includes Analytics, BI and Data Science. The role is focused on analytics but not limited to it, the person will have the opportunity to work with SQL servers and cloud platforms.\nRequirements\nWHAT YOU\u2019LL BE DOING ON ANY GIVEN DAY\n\nThe BI Analyst will be responsible for;\nSupport and coordinate with the web analytics team and BI team on day to day challenges encountered on datasets and perform different data analytics tasks on different platforms.\nAssist senior team members to troubleshoot data discrepancy issues and solve ad-hoc requests from the clients.\nWith data managers\u2019 guidance, manage reports and datasets from various channels and platforms, including (but not limited to) various mainstream media platforms such as Google and Bing, and analytics platform such as GA and AA.\nThis includes setting up processes to pull data from platforms and channels, managing data sources, processing and manipulating the data and consolidating data across multiple data sources in SQL databases\nWork with the team to manage, modify, QA, and incorporate any additional data sources upon clients\u2019 data requirements.\nBuild, manage, modify and maintain dashboards.\nSupport regular reports and presentations with key findings, observations, data insights and recommendation\nCreate, manage and improve new or existing datasets where needed.\nAddressing challenges or opportunities presented by clients or teams and creating bespoke solutions using technology\n\nThe role will have the potential to span all existing channels (including but not limited to display, paid social, organic performance, affiliates, content creation and localisation) as well as working on standalone propositions and new services centred around the use of structured data.\nDOES THIS SOUND LIKE YOU?\nMust have good understanding of SQL and able to write queries\nStrong analytical individual who enjoys lateral thinking and problem solving\nAttention to detail with the ability to effectively troubleshoot issues across various data sources and platforms\nData driven approach to optimisation and testing to show full value of changes\nProactive individual who is confident taking the initiative and working with colleagues across teams and departments\nExperience working with and consolidating multiple data sources (direct from engines, google sheets, FTP, HTTP etc.)\nProactive, motivated, self starter and willing to learn\nFluent in English, any other language is a plus\nBenefits\nWHY ASSEMBLY?\nWe\u2019re part of Stagwell, the challenger network built to transform marketing. We\u2019re nimble, smart, and digital-first, and we\u2019re quickly growing to take on the biggest legacy hold cos.\nWe care about your growth \u2013 we offer competitive salaries, annual compensation reviews, and keep detailed personal development plans to ensure you\u2019re hitting your personal and company goals.\nWe recognize and celebrate your success\u2026all the time! Whether it\u2019s through company meetups, employee recognition programs, or just a regular day, we make sure our people\u2019s achievements are known and appreciated!\nWe\u2019re truly a people-first organization. That\u2019s why we offer a Flexible Time Off policy that puts you in control of your work-life balance, as well as market-leading primary and secondary caregiver and parental leave policies.\nWe care about social and environmental Impact \u2013 we have dedicated Impact Champions that collaborate globally to make sure we\u2019re leaving the world better than we found it.\nWe have an amazing group of employee resource groups committed to guiding the agency to become more inclusive, diverse, and representative of the world around us.\nSound like the right role for you? Click to apply now!","190":"Who we are\nAbout Stripe\nStripe is a financial infrastructure platform for businesses. Millions of companies\u2014from the world\u2019s largest enterprises to the most ambitious startups\u2014use Stripe to accept payments, grow their revenue, and accelerate new business opportunities. Our mission is to increase the GDP of the internet, and we have a staggering amount of work ahead. That means you have an unprecedented opportunity to put the global economy within everyone\u2019s reach while doing the most important work of your career.\nAbout the team\nOur mission is to deliver insightful analyses and durable data products to anticipate and inform the right decisions at the right time about Stripe's cloud, security and tech enablement infrastructures.\nWhat you\u2019ll do\nYou will work with our Security Analytics and Detection team, which is committed to promoting data security and protecting Stripe from internal and external threats to its assets and infrastructure.  We\u2019re looking for talented candidates who can leverage data science to build out security capabilities with an emphasis on application security and vulnerability management. Your work will be critical to reducing risks and promoting trust and integrity within Stripe.\nResponsibilities \nResearch, develop, design, and build models for threat detection, guiding processes for signal ingestion, data analytics, and automation to improve detection and investigation of potentially malicious activity;\nWork cross-functionally with data science, software development, and security engineering teams to architect solutions for analyzing security events data at scale and protecting Stripe networks, systems, and data from external threats;\nBuild statistical, machine learning, and simulation models on large datasets, including unstructured data from disparate sources;\nDrive the creation, collection and processing of new data and the enrichment of existing data sources (e.g., log data, network, host-based telemetry, etc.);\nDevelop technical and functional requirements to deploy novel detection and vulnerability identification capabilities that mitigate emergent and current threats;\nProvide actionable insights to stakeholders to help identify, prevent, and detect anomalous usage of Stripe\u2019s endpoints;\nAct as a force multiplier for quantitative methods in our Security organization and help train and mentor engineers on statistical techniques.\nWho you are\nWe\u2019re looking for a data scientist with security experience who is excited about applying their analytical skills to develop methods, systems and processes to protect Stripe from external threats and vulnerabilities. If you are naturally data curious, enjoy deriving insights from data, and motivated by the opportunity to build engineering solutions from the ground up that significantly impact the business, we want to hear from you!\nMinimum requirements\n5+ years experience working with security-related information and analyzing large data sets to solve problems.\nA PhD or MS in a quantitative field (e.g., Applied Mathematics, Computer Science, Statistics, Engineering, Natural Sciences).\nA proven track record of translating large and ambiguous business problems in mathematical models and developing data scientific solutions.\nExisting experience with network security, digital forensics, and incident response.\nExpert knowledge of Python and SQL, and familiarity with other programming languages (R, Go, Scala).\nProficiency with popular open-source machine learning frameworks (scikit-learn, MLlib, pytorch, tensorflow, xgboost, etc.).\nStrong knowledge of statistics and machine learning.\nAbility to communicate results clearly and focus on impact.\nAbility to think creatively and holistically about reducing risk in a complex environment.\nExperience developing foundational and diverse data sources, and generating metrics to measure service and program effectiveness.\nPassion for mentoring others and building a data science and security community.\nPreferred qualifications\nExperience influencing high-impact decisions.\nStrong project management and organizational skills.\nProficiency in taking data-driven approaches to detection, building and automating solutions rather than relying on third party off-the-shelf products.\nExperience with data-distributed tools (Scalding, Spark, Hadoop, DataBricks, dbt, etc.).\nAn adversarial mindset, understanding the goals, behaviors, and TTPs of threat actors.\nFamiliarity with network observability or security software (Uptycs, Icebrg, Splunk, etc.).\nKnowledge of network protocols (DNS or HTTPS) and understanding of cloud computing services\/deployment architecture.\nWorking knowledge of complex distributed machine learning systems deployed at scale in a cloud computing environment.\nExperience in one or more of the following areas: security information event management (SIEM), enterprise risk management (ERM), common weakness enumeration (CWE), and\/or fraud detection.","191":"Who We Are\nFounded in 2005, 2K Games is a global video game company, publishing titles developed by some of the most influential game development studios in the world. Our studios responsible for developing 2K\u2019s portfolio of world-class games across multiple platforms, include Visual Concepts, Firaxis, Hangar 13, CatDaddy, Cloud Chamber, and HB Studios. Our portfolio of titles is expanding due to our global strategic plan, building and acquiring exciting studios whose content continues to inspire all of us! 2K publishes titles in today\u2019s most popular gaming genres, including sports, shooters, action, role-playing, strategy, casual, and family entertainment.\nOur team of engineers, marketers, artists, writers, data scientists, producers, thinkers and doers, are the professional publishing stewards of our growing library of critically-acclaimed franchises such as NBA 2K, Battleborn, BioShock, Borderlands, The Darkness, Mafia, Sid Meier\u2019s Civilization, WWE 2K, and XCOM.\nAt 2K, we pride ourselves on creating an inclusive work environment, which means encouraging our teams to Come as You Are and do your best work! We are dedicated to diversity and inclusion, and want our community of candidates to reflect this commitment. We encourage all qualified applicants to explore our global positions.\n2K is headquartered in Novato, California and is a wholly owned label of Take-Two Interactive Software, Inc. (NASDAQ: TTWO).\nWhat We Need\nAs we grow our slate of mobile titles, we are growing our marketing data science group and looking for an experienced data scientist. This person will be focused on mobile marketing analytics and will be working on crunching data, building predictive models, extracting insights & sharing findings with broad audiences.  This role will be a 12-month contract with potential to go perm, but absolutely no guarantees. \nWhat You Will Do\nReporting into the Senior Manager of Mobile Analytics, you will\nBusiness Insight: Work closely with marketing teams, recognize the real problem our marketing teams want to solve for, and then define the right data, metrics, analysis and interpretation to lead to the right recommendations and decisions.\nReporting: Develop and improve our marketing performance reporting platform; enabling teams across the company to make data informed decisions.\nInnovate: Define requirements for, create, continuously monitor and improve key statistical models needed for making marketing spend decisions.\nCommunication: Design clear and unambiguous narratives, visualizations to report analyses, models and reports developed by the team. These solutions should be easy to understand and use for making decisions.\nWhat Will Make You (a Phenomenal Fit)\nThe ideal candidate will be able to see the underlying story in the data, build sophisticated or simple models depending on the situation, and develop a compelling communication to the business. Someone who is hypothesis driven and has experience using data-driven techniques to test the hypotheses rigorously. Being a solution oriented, creative problem solver; a self-starter with the passion and enthusiasm to get results for substantial change is critical for this role.\nBSc, MSc or PhD in Mathematics, Statistics, Economics, Computer Science, Data Science, Engineering, Sciences (or in another quantitative field).\n4+ years of experience in data mining & analytics, building models with sophisticated and multi-dimensional data sets using R or Python.\nExperience in relational databases, SQL data carpentry. We use Snowflake for our data warehouse.\nExcellent communication skills, with a proven track record of working across all levels of the organization.\nDemonstrated ability to work independently, rapidly prototyping and testing new insights with little mentorship.\nDrive to solve problems, meet expectations, and build whatever is vital along the way.\nExperience understanding the strengths and weaknesses of different modeling approaches and can effectively reason about when to apply different combinations and iterate.\nBonus Points\nExperience with data visualization tools a plus, Tableau preferred.\nMobile games industry experience and\/or gaming familiarity.\nExperience working with paid and unpaid marketing channels is desirable.\nAs an equal opportunity employer, we are committed to ensuring that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform their essential job functions, and to receive other benefits and privileges of employment. Please contact us if you need reasonable accommodation.\nPlease note that 2K Games and its studios never uses instant messaging apps or personal email accounts to contact prospective employees or conduct interviews and when emailing, only use 2K.com accounts.\n    Please note that 2K Games and its studios never uses instant messaging apps or personal email accounts to contact prospective employees or conduct interviews and when emailing, only use 2K.com accounts.\n   \n#LI-Hybrid","192":"Descripci\u00f3n de la empresa\nPassionate about\u202fdigital, data,\u202fIoT or AI and willing to join a dynamic and ambitious team\u202fon a\u202fhuman\u202fscale?\nFor more than 15 years, we have been advising companies and administrations and supporting them in the implementation of their transformation projects in Spain and abroad., around Europe and overseas, with operations around the world with nearly 6,000 consultants so far.\nTo do so, we rely both on technological leverage and on the strength of our DNA based on collective intelligence, agility and entrepreneurial spirit.\nWith a presence on five continents and more than 3,500 employees, our goal is to reach more than\u202fa\u202f\u20ac1 billion\u202frevenue\u202fby 2024. Innovation is at the heart of our development, and we are involved in areas linked to the technological changes of major groups, such as Big Data, IoT, Blockchain and Artificial Intelligence.\nTalan is looking for a candidate willing to work in the banking field as a Solution Architect\nWe are looking for a person with the commitment to stay long term with us, with a previous experience in the sector of +5 years of experience, aiming to start a new international challenge based in Malaga, southern Spain.\nDescripci\u00f3n del empleo\nDevelop and implement pipelines that extract, transform, and load data into an information product that helps the organization reach its strategic goals\nFocus on ingesting, storing, processing, and analyzing large datasets\nCreate scalable, high-performance web services for tracking data\nTranslate complex technical and functional requirements into detailed designs \nInvestigate alternatives for data storing and processing to ensure implementation of the most streamlined solutions\nServe as a mentor for junior staff members by conducting technical training sessions and reviewing project outputs\nRequisitos\nRequired skills and qualifications\nExperience with Python, Spark, and Hive\nUnderstanding of data-warehousing and data-modeling techniques\nKnowledge of industry-wide visualization and analytics tools (ex: Tableau, R)\nStrong data engineering skills with Azure cloud platform\nExperience with streaming frameworks such as Kafka\nKnowledge of Core Java, Linux, SQL, and any scripting language \nGood interpersonal skills and positive attitude\nPreferred skills and qualifications\nDegree in computer science, mathematics, or engineering\nExpertise in ETL methodology for corporate-wide solution design using DataStage\nInformaci\u00f3n adicional\nResponsibilities\nDevelop and maintain data pipelines using ETL processes\nTake responsibility for Apache Hadoop development and implementation\nWork closely with data science team to implement data analytics pipelines\nHelp define data governance policies and support data-versioning processes\nMaintain security and data privacy, working closely with data protection officer\nAnalyze vast number of data stores to uncover insights","193":"We are looking for a Spark developer who knows how to fully exploit the potential of our Spark cluster. You will clean, transform, and analyze vast amounts of raw data from various systems using Spark to provide ready-to-use data to our feature developers and business analysts. This involves both ad-hoc requests as well as data pipelines that are embedded in our production environment.\nRequirements\nRoles and Responsibilities\nResponsible for systems analysis - Design, Coding, Unit Testing and other SDLC activities\nRequirement gathering and understanding, Analyze and convert functional requirements into concrete technical tasks and able to provide reasonable effort estimates\nCreate Scala\/Spark jobs for data transformation and aggregation\nProduce unit tests for Spark transformations and helper methods\nDesign data processing pipelines\nWork proactively, independently and with global teams to address project requirements, and articulate issues\/challenges with enough lead time to address project delivery risks\n\nRequirements\n10 - 12 Years hands on experience.\nExperience with Apache Spark streaming and batch framework\nScala (with a focus on the functional programming paradigm)\nExperience in Azure cloud platform and Data Bricks\nExperience with Pyspark\nScalatest, JUnit, Mockito\nSpark query tuning and performance optimization\nExperience with Mongoldb database\nExperience with Kafka, Storm, Zookeeper\nDeep understanding of distributed systems (e.g. CAP theorem, partitioning, replication, consistency, and consensus)\nConsistently demonstrates clear and concise written and verbal communication\nAbility to work in a fast-paced environment both as an individual contributor and a tech lead\nExperience in Git","194":"Company Description\nGuardant Health is a leading precision oncology company focused on helping conquer cancer globally through use of its proprietary tests, vast data sets and advanced analytics. The Guardant Health oncology platform leverages capabilities to drive commercial adoption, improve patient clinical outcomes and lower healthcare costs across all stages of the cancer care continuum. Guardant Health has commercially launched Guardant360\u00ae, Guardant360 CDx, Guardant360 TissueNext\u2122, Guardant360 Response\u2122, and GuardantOMNI\u00ae tests for advanced stage cancer patients, and Guardant Reveal\u2122 for early-stage cancer patients. The Guardant Health screening portfolio, including the Shield\u2122 test, aims to address the needs of individuals eligible for cancer screening.\nJob Description\nThe Screening Bioinformatics team at Guardant Health is focused on the development of products for the early detection of cancer in average-risk populations. This team works in close collaboration with assay scientists. We develop bioinformatics frameworks and apply statistical and machine learning methods to process raw multi-omic biological signals, identify relevant biomarkers and build predictive models for the detection of early-stage cancer.\nAbout the Role:\nWe are looking for a bioinformatics intern to join the algorithm development team within Screening Bioinformatics this summer. The successful candidate will work at the forefront of research and technological development within the interdisciplinary Screening Bioinformatics team and will make core contributions to evolving products designed to have a clinical impact on patients.\nEssential Duties and Responsibilities:\nThe intern position is with the bioinformatics group and will work on developing computational models for the early cancer screening product. The major responsibilities include:\nDevelop and analyze performance of novel statistical models\nProvide written documentation and specifications for transparency and reproducibility\nQualifications\nMust be currently enrolled in a PhD program in computational biology\/bioinformatics, biostatistics, statistical genetics, machine learning, or related fields\nExperience working with statistical models for genomic, epigenomic, or proteomic data\nProficiency with a high-level scripting language (Python\/R; Python preferred)\nProficiency with Linux command-line and version control tools (git and GitHub)\nFamiliar with high-performance computing infrastructures (e.g., SGE, SLURM, AWS, Spark)\nEffective at communicating findings to cross-functional teams\nPreferred Qualifications:\nGraduating within 1-2 years\nExperience in analyzing public genomic\/epigenomic datasets (e.g. TCGA, ENCODE)\nCancer biology background\nAbility to build reproducible and well-written code (or packages) for data analysis\nExperience working with single-cell data\nAdditional Information\nHybrid Work Model: At Guardant Health, we have defined days for in-person\/onsite collaboration and work-from-home days for individual-focused time. All U.S. employees who live within 50 miles of a Guardant facility will be required to be onsite on Mondays, Tuesdays, and Thursdays. We have found aligning our scheduled in-office days allows our teams to do the best work and creates the focused thinking time our innovative work requires. At Guardant, our work model has created flexibility for better work-life balance while keeping teams connected to advance our science for our patients.\nCovid Vaccination Policy:  Guardant Health requires all employees to be fully vaccinated. We follow the CDC guidelines for the definition of \u201cfully vaccinated\u201d, meaning an employee is consider fully vaccinated against COVID-19 after receiving the second dose of a two-dose vaccine or one dose of a single-dose vaccination, and necessary booster vaccines. In addition, fully vaccinated employees will be required to maintain their fully vaccinated status under this policy by obtaining, if applicable, any FDA-approved boosters. Candidates may request and obtain an approved exemption from Guardant\u2019s COVID-19 U.S. Vaccination Policy as a reasonable accommodation, as consistent with applicable laws.\u202f\u202fCandidates will not be able to start their employment with Guardant until they show proof of vaccination or have an approved exemption.\nFor positions based in Palo Alto, CA or Redwood City, CA, the hourly range for this full-time position is Undergraduate $27\/hr., Graduate $32\/hr., and Doctorate $40\/hr. The range does not include benefits and, if applicable, overtime, bonus, commission, or equity.\nWithin the range, individual pay is determined by work location and additional factors, including, but not limited to, job-related skills, experience, and relevant education or training. If you are selected to move forward, the recruiting team will provide details specific to the factors above.\nEmployee may be required to lift routine office supplies and use office equipment. Majority of the work is performed in a desk\/office environment; however, there may be exposure to high noise levels, fumes, and biohazard material in the laboratory environment. Ability to sit for extended periods of time.\nGuardant Health is committed to providing reasonable accommodations in our hiring processes for candidates with disabilities, long-term conditions, mental health conditions, or sincerely held religious beliefs. If you need support, please reach out to Peopleteam@guardanthealth.com\nGuardant Health is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability.\nAll your information will be kept confidential according to EEO guidelines.\n\nTo learn more about the information collected when you apply for a position at Guardant Health, Inc. and how it is used, please review our Privacy Notice for Job Applicants.\nPlease visit our career page at: http:\/\/www.guardanthealth.com\/jobs\/\n#LI-CS4","195":"Unternehmensbeschreibung\nFashion und Lifestyle, 6.500 Mitarbeiter:innen, 13 Department Stores, Online-Shops in Deutschland, Polen, \u00d6sterreich, Belgien, Luxemburg, Spanien, den Niederlanden und der Schweiz, \u00fcber 2000 Marken, 25 Restaurants & Confiserien, 15 erstklassige Services, drei Friseur-Salons und stets ein besonderes Einkaufserlebnis \u2013 das ist Breuninger. Ein Traditionsunternehmen, das internationale Wege geht, seine Ziele klar definiert und innovative M\u00f6glichkeiten schafft.\nStellenbeschreibung\nAls BI Data Analyst:in verantwortest Du ein wachsendes Portfolio an Datensichten im E-Commerce. Du erm\u00f6glichst f\u00fcr die Fachbereiche (u. a. Onlinemarketing, Web- und Marketing-Analytics, Category Merchandising) den effektiven und sinnvollen Zugang zu unseren Datenwelten\nDu stellst zentrale Daten nicht nur in Form von Dashboards und Reports zur Verf\u00fcgung, sondern findest konsequent aus dem breiten K\u00f6cher an M\u00f6glichkeiten das richtige Mittel, um die individuellen Daten-Needs der Stakeholder zu beliefern\nDabei ber\u00e4tst Du die Fachbereiche im Anforderungsmanagement und verbesserst kontinuierlich die Self-Service-F\u00e4higkeiten der Stakeholder:innen\nMit Deiner Expertise im Bereich Datenmodellierung bist Du gleichzeitig im Sattel, was den Unterbau deiner Datensichten betrifft und treibst die angeforderten Projekte selbstst\u00e4ndig voran\nDar\u00fcber hinaus unterst\u00fctzt Du mit Deinem Weitblick und Gesp\u00fcr f\u00fcr aktuelle Entwicklungen und f\u00fcr den Business Need bei der Verfeinerung und Operationalisierung unserer Daten-Strategie\nQualifikationen\nDu verf\u00fcgst \u00fcber ein erfolgreich abgeschlossenes Studium der Wirtschaftswissenschaften, Wirtschafts-\/ Medieninformatik, BWL, Mathematik, Statistik oder eine vergleichbare Qualifikation\nDu bringst einschl\u00e4gige Berufserfahrung im Bereich Data Management oder Business Intelligence mit\nDu besitzt exzellente F\u00e4higkeiten in der Analyse und Interpretation von komplexen Datenstrukturen\nDich zeichnen eine hohe Expertise in SQL sowie g\u00e4ngigen Datenbank- und Visualisierungstools (PowerBI, Tableau, Sisense) aus\nDu bist ein:e Teamplayer:in, arbeitest eigenverantwortlich, ergebnisorientiert und \u00fcbernimmst gerne Verantwortung f\u00fcr Ver\u00e4nderung\nZus\u00e4tzliche Informationen\nBei uns erh\u00e4ltst Du die M\u00f6glichkeit, in einem modernen, agilen sowie wertsch\u00e4tzenden Umfeld zu arbeiten. F\u00fchlst Du Dich angesprochen? Dann findest Du bei Breuninger ein Team, in dem Du Dich wohlf\u00fchlen und nachhaltig wirken kannst.\nEine spannende Herausforderung in einem innovativen und gleichzeitig traditionsreichen Unternehmen\nAttraktives Gehaltspaket mit freiwilligen Sozialleistungen wie Urlaubs- und Weihnachtsgeld sowie 30 Tage Urlaub\nEine gro\u00dfe Verantwortung und Raum f\u00fcr eigenen Ideen\n30% Mitarbeiterrabatt auf das gesamte Sortiment gem\u00e4\u00df den aktuellen betrieblichen Bestimmungen\nHochmotivierte Kolleg:innen in einem tollen Team\nPers\u00f6nliche und fachliche Entwicklungsm\u00f6glichkeiten\nHaben wir Dein Interesse geweckt? \nDann sollten wir uns schnell kennenlernen!\nWir freuen uns auf Deine aussagekr\u00e4ftige Online Bewerbung mit Angabe Deiner Verf\u00fcgbarkeit sowie Gehaltsvorstellung.\nImpressum","196":"Want to be part of an amazing team, hell-bent on crafting a better future? We\u2019re always looking for creative people who care!\nWe are analysts. Creators. Designers. Doers. Dreamers. Explorers. Geeks. Hipsters. Leaders. Learners. Renegades. Seekers. Strategists. Visionaries. And we fundamentally believe that we\u2019re better together.\nWe are looking for an Power BI Developer to join our tech client\u2019s reliability and quality team. \nWould you like to\u2026\n Experience with Power Platform (specifically power apps and power automate).\n Experience integrating multiple Power Apps. Experience with relational databases such as SQL and Dataverse.\n Some Power BI experience. \n Ability to work with multiple stakeholders as part of a Developer team and as an individual with our partner team process, technical and business managers.\n working in workshops to be able influence the code and bridge the gap btwn requirement and technical solution\nWe would like you to have\u2026\nPower Automate and Power Apps Power Platform, integrating with Power Apps 3-5 years\nRelational Databases SQL, different data sources\nPower BI \nWould you like to work for an organization that\u2026\nEmbraces work-life balance \u2013 our employees\u2019 well-being remains a top priority for us\nPromotes a culture of learning and advocacy across the globe - diversity will enable us to strengthen our impact\nOffers a comprehensive benefits package effective Day 1. Options include health, vision, & dental insurance, FSAs, discounts on pet insurance, PTO, paid holidays, and more\nEncourages innovation and experimentation\nEmphasizes and rewards collaboration\nWorks remotely. We continue to safeguard the health of our employees so our interviewing and on-boarding process will remain virtual until further notice\nWant to know more?\nCheck us out at https:\/\/www.designit.com\/. Just so you know, we don\u2019t have a dress code, but we do have a strict no jerk policy.\nDesignit is committed to ensuring that all candidates have an equal opportunity to be considered for employment. Please let us know if you need any reasonable accommodation to participate in the job application or interview process.","197":"","198":"Company Description\nWood Mackenzie is the global leader in data, analysis and consulting across the energy, chemicals, metals, mining, power and renewables sectors.  \nFounded in 1973, our success has always been underpinned by the simple principle of providing trusted research and advice that makes a difference to our customers. Today we have over 2,000 customers ranging from the largest global energy companies and financial institutions to governments as well as smaller market specialists.  \nOur teams are located around the world. This enables us to stay closely connected with customers and the markets and sectors we cover. Collectively this allows us to offer a compelling combination of global commodity analysis with detailed local market knowledge.  \nWe are committed to supporting our people to grow and thrive. We value different perspectives and aspire to create an inclusive environment that encourages diversity and fosters a sense of belonging. We are committed to creating a workplace that works for you and encourage everyone to get involved in our Wellness, Diversity and Inclusion, and Community Engagement initiatives. We actively support flexible working and are happy to consider alternative work patterns, taking into account your needs and the needs of the team or division that you are looking to join.\u202f  \nHear what our team has to say about working with us:  \nhttps:\/\/www.woodmac.com\/careers\/our-people\/ \nWe are proud to be a part of the Verisk family of companies!\u202f \nAt the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.\u202f\u202f\u202f \nOur global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.\u202f\u202f \nBut why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.\u202f\u202f \nIt\u2019s the reason Verisk is part of the UN Global Compact sustainability initiative. It\u2019s why we made a commitment to balancing 100 percent of our carbon emissions. It\u2019s the aim of our \u201creturnship\u201d program for experienced professionals rejoining the workforce after time away. And, it\u2019s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers\u2019 problems.\u202f\u202f\u202f \nAt its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.\u202f \nAt Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career.\u202f We\u2019ve been recognized by Forbes as a World\u2019s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.\u202f \nJob Description\nYou will be a valuable member of the Wood Mackenzie\u2019s Chemicals Global Analyst Team. This team sits within the Research function and helps produce detailed market supply-demand, cost and price forecasts at the regional and global levels. It is also a key enabler in Wood Mackenzie\u2019s purpose to transform the way we power our planet.\nAs a Research Analyst in the Chemicals Global Analyst Team, you will contribute to high-quality research in the form of thought-provoking reports,  presentations, and articles. You will be a valuable member of Wood Mackenzie\u2019s Chemicals Global Analyst Team. You will also help build new products and services as we embark into the new wave of growth for the Chemicals business and Wood Mackenzie in general.\nThrough your research and responding to client queries, you will expand your network of contacts at key companies and industry associations. You will develop a unique perspective and understanding of the chemicals industry, including the challenges and opportunities it is facing in facilitating the global energy transition. Your contribution to our industry-leading written reports, supply-demand models and presentations will be valued.\n#LI-GW1\nQualifications\nAbout you and how you can excel in this role\nYou have a keen interest in commodity market dynamics and you want to develop further your understanding of the Plastics and Sustainability industry and related sectors.\nYou have an analytical mindset and an eye for detail, which have been proven in your academic and\/or work experience to date. You are comfortable collecting and interpreting data, articulating your findings in a clear and insightful manner. You are curious and seek to clarify and enhance your knowledge. You also have a flair for writing and communication and confidence in presenting to an audience.\nYou are a highly adaptive team player and embrace fast-paced environments with frequent change. You are excited to be part of a team that gives you opportunities to work cross-functionally on a variety of tasks. The way in which you work is productive and driven, striving to be best in class.\nUltimately, you are looking for an opportunity to develop the skills to become an industry-recognised subject matter expert.\nYou have an excellent command of English, both written and spoken. Knowledge of at least one other language would be an advantage. You also have a good working knowledge of the Microsoft Office suite, particularly Excel and PowerPoint.\n Additional Information\nVerisk Analytics is an equal opportunity employer.\nAll members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and\/or expression, sexual orientation, veteran's status, age or disability.\nhttp:\/\/www.verisk.com\/careers.html\nUnsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.","199":"Unternehmensbeschreibung\nM\u00f6chten Sie Ihre Ideen in nutzbringende und sinnvolle Technologien verwandeln? Ob im Bereich Mobility Solutions, Consumer Goods, Industrial Technology oder Energy and Building Technology \u2013 mit uns verbessern Sie die Lebensqualit\u00e4t der Menschen auf der ganzen Welt. Willkommen bei Bosch.\n                                            \nDie Robert Bosch GmbH freut sich auf Ihre Bewerbung!\nStellenbeschreibung\nDu verf\u00fcgst \u00fcber tiefgehendes Wissen in Technologie, Architektur und Betrieb von Big Data Plattformen in der Enterprise IT und in Public Clouds.\nDu steuerst den gesamten Produktlebenszyklus unserer Big Data Plattform und koordinierst ein globales Team.\nDie Industrialisierung neuer Big Data Technologien, -Funktionen und -Module, sowie die Evaluierung zuk\u00fcnftiger Big-Data-Plattformen liegt in Deiner Verantwortung.\nIn enger Zusammenarbeit mit Product Service Ownern, Architekten, Kunden und Herstellern definierst Du die Big Data Strategie und entwickelst die bestehenden Big Data Services f\u00fcr Bosch weiter.\nDu begleitest die Projekte von der Konzeption \u00fcber die Pilotphase bis hin zum Produktiveinsatz.\nDu ber\u00e4tst die Bosch-Stakeholder, das IT-Management sowie die Produkt- und Solution-Teams bei der Entwicklung von Big Data Technologien und -Architekturen.\nQualifikationen\nAusbildung: Abgeschlossenes Hochschulstudium (Master\/Diplom\/Promotion) in Informatik, Informationstechnologie, Ingenieurwesen oder vergleichbarer Fachrichtung\nPers\u00f6nlichkeit: Kommunikativ, teamf\u00e4hig, zielorientiert und interkulturell offen\nArbeitsweise: Strukturiert, selbst\u00e4ndig und analytisch\nErfahrungen: Mehrj\u00e4hrige praktische Berufserfahrung als Big Data Experte, vorzugsweise im Hadoop \u00d6kosystem, sowie mehrj\u00e4hrige Erfahrung in der Durchf\u00fchrung gr\u00f6\u00dferer internationaler Projekte oder F\u00fchrung internationaler Team\nKnow-How: Tiefgehende Erfahrung in Big Data Betrieb, -Design und -Architekturen, sowie in Cloud-basierten Big Data Anwendungen\nSprachen: Sehr gute Deutsch- und Englischkenntnisse\nZus\u00e4tzliche Informationen\nIn diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente.\nBewirb Dich jetzt in nur 3 Minuten! Du willst Remote oder in Teilzeit t\u00e4tig sein - wir bieten tolle M\u00f6glichkeiten des mobilen Arbeitens sowie unterschiedliche Teilzeitmodelle.\nSie haben Fragen zum Bewerbungsprozess?\nAnna Haas (Personalabteilung)\n+49 711 811 52750\nSie haben fachliche Fragen zum Job?\nHannes Hannak (Fachabteilung)\n+49 711 811 19094","200":"Kuda is a full service, app-based digital bank. Our mission is to be the go-to bank not just for those living on the African continent, but also for the African diaspora wherever they might live, anywhere in the world. Kuda is free of ridiculous banking charges and great at helping customers budget, spend smartly and save more. We raised the largest seed round ever seen in Africa, and completed a Series A funding round in February 2021, led by some of the world's smartest venture capital investors.\nWith offices in London (our HQ), Lagos and Cape Town, and further offices opening across Africa during 2021, Kuda is fast becoming recognised as the leading 'Neobank' for Africans.\nTo help us grow into the company that can bring meaningful change to the way people across Africa get access to great financial products and services in order to take control of their personal finances, we are actively looking for bright, talented, driven people who are excited by our mission. If this sounds like a great way to spend your valuable time, then please get in touch with us.\n\nRole overview:\nWe\u2019re looking for a passionate BI Analyst that can apply their data Illustrative and reporting skills to translate complex information into meaningful insights. Excelling in critical thinking, ensuring all data problems are solved.\nYou must be able to transform data, gain understanding and use that insight to dig deeper and present a straightforward data story. Must be conformable, communicating findings and insight across multiple business levels.\nIf you are passionate about data and applying yourself to business challenges excites you, we would love to hear from you.\nRoles and Responsibilities:\nDesign, build, and maintain business intelligence solutions to elevate and showcase data-to-decision across the entire business\nCollaborate with product and business stakeholders to define how best to measure, monitor and understand customer behavior and product performance\nDevelop compelling information visualizations and dashboards\nDeliver strategic initiatives to improve the quality and timeliness of data insights\nDeliver continuous optimizations strategies that continuously re-invent data products and insights\nAnalyze business processes and analytical requirements that assist with decision-making processes\nRequirements\n3+ Years of experience in a Business Intelligence and\/or Data Analyst role, with a focus on analyzing and understanding business problems\nStrong knowledge and proven experience using SQL\nStrong knowledge of and experience with tools like Looker, QlikView, Tableau or PowerBI\nPrior experience in designing and implementing performance measures to track business or product KPIs\nA fundamental in identifying patterns or regions in products or behaviors that indicate opportunities for business process improvement\nExcellent analytical and forecasting ability\nStrong written and verbal communication skills\nUnderstand current data protection and privacy laws, e.g., GDPR\nA degree in the information technology field (e.g., Statistics, Economics, Math, Science, Engineering)\nAdvantageous:\nExperience working in AWS, Google Cloud or Azure\nUsing dbt Cloud to perform data modelling.\nExperience using BigQuery data capabilities\nGood understanding of the software development process and best practices\nBenefits\nWhy join Kuda?\nBecome a part of one of the trailblazers in the challenger banking arena by joining the exciting and ambitious team at Kuda Bank as we work to become the neobank for \u2018every African on the planet\u2019.\nAn exciting and flexible work environment\nCompetitive pay\nSmart and kind coworkers\nFull pension contribution\nReliable health insurance","201":"Payment Systems BI Data Analyst\nAbout the team:\nAt the Capco Technology Delivery Center, we are dedicated to the financial services industries. Our professionals combine innovative thinking with unrivalled industry and domain expertise to offer our clients consulting expertise, complex technology and package integration, transformation delivery, and managed services, to move their organizations forward. Through our collaborative and efficient approach, we help our clients successfully innovate, increase revenue, manage risk and regulatory change, reduce costs, and enhance controls. Our teams stay at the forefront of industry trends and technologies that are driving innovation. From strategy to launch, we are adept at delivering across the full product lifecycle. \nAbout the Job:\nAs a member of the Capco Technology Delivery Team, you\u2019ll bring practical knowledge of agile development methodologies and engineering best practices. As a Java Backend Developer, you\u2019ll use your experience and skills to contribute to the quality and implementation of our software products for our customers.\nWhat You\u2019ll Get to Do:\nProvide support for data requests from Compliance, Operations, Auditors and other parties.\nFocus will be on data related to payments systems and related ecosystems (e.g. Fed\/Chips\/Swift\/Fircosoft).  \nReview and validate data requests.  Transform them into clear requirement documents.\nGenerate data extractions and reports.\nPerform data analysis as required.\nStreamline the reporting process through the application of BI products.  \nUtilize query tools to confirm data quality and investigate questions.\nWhat You\u2019ll Bring with You:\n4+ plus years of relevant experience in BI Data Analyst role.\nExposure to Payment systems including Swift, US clearing systems (FEDwire and CHIPS ) is preferred but not mandatory.\nExperience in Financial security  : Sanction filtering and AML is preferred but not mandatory.\nShould be well versed with reporting technologies like \u2013 MS SQL, Oracle, BI related tools (MS Power BI, Tableau, etc.)\nExposure to audits on the domain would be a real plus.\nWillingness to work out of the NYC office 3 days per week.\nWhy Capco?\nA career at Capco is a chance to help reshape the competitive landscape in financial services.  We launch new banks, transform existing ones, and help our clients navigate complex change.  As consultants, we work on the front-end business design all the way through to technology implementation.\nWe are the largest Financial Services focused consultancy in the world, serving everyone from global banks to emerging FinTechs, from strategy through digital transformation, design, business consulting, data and analytics, cyber, cloud, technology architecture, and engineering.\nCapco is a young and growing firm. We maintain an entrepreneurial spirit and growth mindset, and have minimal bureaucracy. We have no internal silos that get in the way of your career opportunities or  ability to focus on our clients and make a difference to the business.  We offer the opportunity for everyone to learn rapidly, take on tough challenges, and get promoted quickly. We take pride in our creative, collaborative, diverse, and inclusive culture, where everyone can #BYAW.\nWe offer highly competitive benefits, including medical, dental and vision insurance, a 401(k) plan, tuition reimbursement, and a work culture focused on innovation and creation of lasting value for our clients and employees. \nReady to take the Next Step \nIf this sounds like you, we would love to hear from you.  This is an opportunity to make a difference and contribute to a highly successful company with a significant growth trajectory.\nThe estimated salary range for this position in NY is 87,000 \u2013 105,000 plus bonus potential and benefits.","202":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value.\nJob Description\nAs Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects:\nData Ingestion, Transformation & Consumption,\nData Storage and Computation Frameworks,\nPerformance Optimizations,\nInfrastructure, Automation & Cloud Computing,\nData Governance & Security\nThe role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java \/ Scala \/ Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL\/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.\nRole & Responsibilities:\n1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation.\n2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality\n3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality\n4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies\n5. Participate in workshops with clients and align client stakeholders to optimal solutions.\n6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc.\n7. People management, contributing to hiring and capability building\n#LI-REMOTE \nQualifications\nOverall 8+ years of IT experience with 3+ years in Data related technologies \n3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS \/ Azure \/ GCP) and delivered at least 1 project as an architect.\nMandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud. \nExpert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions\nExpert in programming languages like Java\/ Scala and good to have Python\nExpert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub\/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc.\nExpert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc.\nShould have worked on MPP style query engines like Impala , Presto, Athena, etc\nShould have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc.\nShould have a good understanding of how to set up Big data cluster security \u2013 Authorization\/ Authentication, Security for data at rest, and data in Transit.\nShould have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager \u2013 Data Engineering\nShould have worked on any of Orchestration tools \u2013 Oozie, Airflow, Ctr-M, or similar.\nWorked on Performance Tuning, Optimization, and Data security\n  Competency\n1. Excellent understanding of data technologies landscape\/ecosystem.\n2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases\n3. Good Exposure in development with CI \/ CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage.\n4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\n5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage.\n6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions\n7. Thought Leadership \u2013 blogs, keynote sessions, POV\/POC, hackathon\n8. Certification in either one of the cloud platforms or big data technologies\nPersonal Attributes:\nStrong analytical and problem-solving skills\nStrong communication skills in verbal, written and visual presentations\nStrong coordination and negotiation skills\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nMulti geo experience and distributed delivery experience in large programs\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements \nEmployee Assistance Programs to help you in wellness and well being","203":"Company Description\nAt Experian Health, our employees have the opportunity to shape more than products \u2013 they shape the future of U.S. healthcare. Experian Health is a pioneer for innovations leading the way in revenue cycle management, identity management, patient engagement, and care management for hospitals, physician groups, labs, pharmacies and other risk-bearing entities. Our success relies on people who are given the freedom to imagine new frontiers in the rapidly changing healthcare space and push the boundaries of innovation. Help us realize our vision of applying data for good and changing the healthcare landscape for the better \u2013 for all of us.\nOur mission is to use data driven insights to simplify healthcare for all. Simply put, we want to make the healthcare system work better for us as consumers and for those who work in healthcare. Our ONE Experian Health culture is the centerpiece of making this happen. Our aspiration is to bring people together who are driven by purpose and want to make a difference.  We strive to have a diverse group of people and minds who are:\nOPEN: Have a growth mindset and collaborate often with others to make things happen\nNIMBLE:  Always embracing change and pushing the envelope on innovative ways to solve problems\nEFFECTIVE:  Accountable to themselves and to others\nJob Description\n100% REMOTE (NOT HYBRID) - WORK ANYWHERE IN THE US\nThe primary responsibility of the Data Analyst will be to support application development leveraging strong SQL skills, knowledge of relational databases, and the skills to ensure custom coordination of benefit software, containing over 400 million rows of data, only allows accurate data to be loaded, and data integrity is maintained after bug fixes and enhancements.\n\nThis position will ensure this software is thoroughly tested from all angles focusing primarily on the backend by developing custom test plans and executing them using SQL, analyzing production data, and writing custom reports.\n\nJob duties:\nFully understand custom built Healthcare Medical Eligibility\/Coordination of Benefits software solution. Understand the technical design and be able to traverse through and fully test the system using custom developed test plans using SQL\nWork collaboratively at ground level with senior level development staff to fully understand product requirements. Be willing to ask questions, push back as necessary, and ultimately ensure the new code meets stringent customer expectations\nIdentify software defects, conduct research, develop plan for resolution, and engage appropriate internal resources as necessary\nPerform data analysis as needed on production data (400+ million rows of data)\nCollaborate with team members on, and provide peer review of, test plans, test cases, test data, and automation\/tool enhancements.\nWork collaboratively with development team to make technical judgments based upon understanding of the business process and customer\/user needs whereby a design change or modification should (or needs to be) changed.\nSupport inquiries from client, operations, and customer support on content related questions and monitor areas for improvement.\nDesign and document test cases to ensure optimal system performance with new code releases\nUtilize QA best practices\nTests will be executed at the database level, using SQL\nBuild automated tests using tools such as Selenium\nOperate load testing on Web Based Portal\nRun smoke tests and regression tests\nPrepare appropriate test data\nCommunicate and document testing results in appropriate tool\nMaintain defect reporting and tracking\nMaintain current test plans, test cases, test scripts, and test data.\nAvailability for planned after hours deployments and unplanned issue resolution\nPlanned deployments typically occur once a month on Thursday nights\nQualifications\nBachelor\u2019s degree in Information Systems, Computer Science, or other related field OR equivalent experience required\nAt least 3 years combined prior business analyst, SQL programming, software QA, SQL data analysis\nMinimum 3 years of SQL usage in a professional setting\nExperience working as an analyst with large datasets (1+ million records) highly desired\nExperience with SDLC and iterative development processes, specifically Agile work processes highly desired\nExperience in working in a highly competitive team environment\nStrong SQL skills required (Data Analyst SQL skill set, not necessarily SQL programming)\nFocus on relational databases\nBusiness analyst knowledge is highly preferred\nQA knowledge is preferred. Willingness to be trained on QA fundamentals is required\nCoordination of Benefits, and\/or Healthcare Revenue Cycle knowledge a plus\nEffective communication and relationship building skills\nSelf-motivated, team player, but who can work independently\nAbility to adapt to an Agile\/Scrum environment\nStrong written and verbal communication skills\nProblem-solving as part of a distributed team\nTime management and organizational skills\nKnowledge of the HIPAA transaction sets and requirements is desirable\nBecome an expert on highly complex custom software - willingness to self-study and learn through trial and error required.  \nAdditional Information\nExperian is an Equal Opportunity Employer. Anyone needing accommodation to complete the interview process should notify the talent acquisition partner. The word \"Experian\" is a registered trademark in the EU and other countries and is owned by Experian Ltd. and\/or its associated companies.\nEOE including Disability\/Veterans.\nExperian is proud to be an Equal Opportunity and Affirmative Action employer. Our goal is to create a thriving, inclusive and diverse team where people love their work and love working together. We believe that diversity, equity and inclusion is essential to our purpose of creating a better tomorrow. We value the uniqueness of every individual and want you to bring your whole, authentic self to work. For us, this is The Power of YOU and and it reflects what we believe.  See our DEI work in action!\nPlease contact us at JobPostingInquiry@experian.com to request the salary range of this position (please include the exact Job Title as it reads above in your email). In addition to a competitive base salary and variable pay opportunity, Experian offers a comprehensive benefits package including health, life and disability insurance, generous paid time off including 12 company paid holidays and parental and family care leave, an employee stock purchase plan and a 401(k) plan with a company match.\nExperian Careers - Creating a better tomorrow together\nFind out what its like to work for Experian by clicking here","204":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value\nJob Description\nAs Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions.\nYou will independently drive design discussions to ensure the necessary health of the overall solution.\nThe role requires a hands-on technologist who has strong programming background like Java \/ Scala \/ Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components.\nYou are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. \nRole & Responsibilities:\nYour role is focused on the Design, Development and delivery of solutions involving:\nData Integration, Processing & Governance\nData Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations\nInfrastructure & Cloud Computing\nData Management Platforms\nImplement scalable architectural models for data processing and storage\nBuild functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode\nBuild functionality for data analytics, search and aggregation\n#LI-REMOTE \nQualifications\nOverall 5+ years of IT experience with 3+ years in Data related technologies\nMinimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS \/ Azure \/ GCP)\nHands-on experience with the Hadoop stack \u2013 HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline.\nStrong experience in at least of the programming language Java, Scala, Python. Java preferable\nHands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc\n Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security \n Competency\n1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience\n2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc\n3. Knowledge on distributed messaging frameworks like ActiveMQ \/ RabbiMQ \/ Solace, search & indexing and Micro services architectures\n4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 \u2013 Data Engineering\n5. CI\/CD \u2013 Infra provisioning on cloud, auto build & deployment pipelines, code quality\n6. Cloud data specialty and other related Big data technology certifications\nPersonal Attributes:\nStrong written and verbal communication skills\nArticulaion skills\nGood team player\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nProcess orientation and the ability to define and set up processe\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements\nEmployee Assistance Programs to help you in wellness and well being","205":"Unternehmensbeschreibung\nBei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch.\nDie Robert Bosch GmbH freut sich auf Deine Bewerbung!\nStellenbeschreibung\nF\u00fcr unser PreMaster Programm suchen wir engagierte Bachelorabsolvierende, die die Theorie eines Masterstudiums mit Unternehmenspraxis vereinen wollen. Dar\u00fcber hinaus besteht die M\u00f6glichkeit, sich im Gesch\u00e4ftsbereich Bosch eBike Systems breit zu vernetzen und spannende Einblicke in die Bosch-Firmenkultur \u201eLike A Bosch\" zu erhalten.\nDas erwartet Dich:\nZweistufiges Qualifizierungsprogramm\nDauer der Unternehmensphase: Bis zu zw\u00f6lf Monate\nBetreuung durch ein pers\u00f6nliches Mentoring\nFolgende T\u00e4tigkeitsfelder warten auf Dich:\nDu arbeitest in einem innovativen und zukunftstr\u00e4chtigen Datenprojekt f\u00fcr eBikes.\nDu unterst\u00fctzt die Projektleitung sowie das -management koordinativ als auch die Projektteams hands-on im operativen Tagesgesch\u00e4ft.\nDu wirst ein Teil der Bosch eBike Erfolgsgeschichte und setzt erlerntes Wissen aus deinem Studium direkt in die Praxis um.\nVisuelle Aufbereitung von Ergebnissen inklusive managementgerechter Darstellung machen Dir Spa\u00df.\nImplementierung, Umsetzung und Verfolgung von datengetriebenen Fragestellungen (Big Data, Analytics, KI, IoT) haben Dich schon immer interessiert.\nDu hast Lust, den Transformationsprozess hin zu einer datengetriebenen Organisation aktiv zu unterst\u00fctzen.\nWerde ein aktiver Teil der \"eBike Familie\", vernetze Dich, \u00fcbernehme Verantwortung, treibe und verfolge Deine Ergebnisse, lerne \u00fcber unsere eBike Kultur und \u201eshape future cycling\" - Wir freuen uns auf Deine Bewerbung!\nBeginn: ab 01.04.2023.\nQualifikationen\nAusbildung: abgeschlossenes Bachelor-Studium in der Fachrichtung Wirtschaftsinformatik, Informatik, IT-Marketing, Digital-Marketing, Wirtschaftsingenieurwesen, Ingenieurwissenschaften, Naturwissenschaften oder eines \u00e4hnlichen Studienganges\nPers\u00f6nlichkeit und Arbeitsweise: begeisterungsf\u00e4hig, verantwortungsbewusst, eigenverantwortlich, zielorientiert, gute Auffassungsgabe, starke Hands-On Mentalit\u00e4t, strukturiert, selbstst\u00e4ndig, kommunikativ und analytisch\nErfahrungen und Know-how: Data Analytics, Visualisierung, Cloud Affinit\u00e4t, Programmierung, Backend-Services, managementgerechtes PowerPoint, Projektmanagement, strategisches Denken\nSprachen: sehr gute Deutsch- und Englischkenntnisse in Wort und Schrift \nZus\u00e4tzliche Informationen\nIn diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente.\n\nVielfalt und Inklusion sind f\u00fcr uns keine Trends, sondern fest verankert in unserer Unternehmenskultur. Daher freuen wir uns \u00fcber alle Bewerbungen:\u202funabh\u00e4ngig von Geschlecht, Alter, Behinderung, Religion, ethnischer Herkunft oder sexueller Identit\u00e4t.\nNeugierig geworden? Dann finde weitere Informationen zum PreMaster Programm unter www.bosch-career.de. Wir freuen uns auf Deine Bewerbung. Dauer: ca. 1 Jahr\n\nDu hast Fragen zum Bewerbungsprozess?\nMeike Weiland (Personalabteilung)\n+49 7121 35 6909\nDu hast fachliche Fragen zum Job?\nTim Dackermann (Fachabteilung)\n+49 7121 35 39478","206":"Unternehmensbeschreibung\nBei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch.\nDie Robert Bosch GmbH freut sich auf Deine Bewerbung!\nStellenbeschreibung\nIm Gesch\u00e4ftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen \u2013 von hocheffizienten Antrieben \u00fcber das erste serienreife ABS f\u00fcrs Pedelec bis hin zu smarten Connectivity-L\u00f6sungen. F\u00fcr eine nachhaltige Mobilit\u00e4t, die Spa\u00df macht.\nAls Data Analyst und Scientist bist Du der Experte, der aus Big Data Smart Data f\u00fcr den Bosch eBike Service macht und dabei sowohl eigene komplexe Projekte als auch Teilprojekte verantwortet. Deine Ergebnisse stellen eine wertvolle Zuarbeit f\u00fcr andere Projekte und Services dar.\nDu analysierst die uns vorliegenden Datenmengen mit dem Ziel, unsere Prozesse sowie unsere Angebote an den Fachhandel und Endkunden zu verbessern, damit wir unseren Wettbewerbsvorsprung ausbauen.\nDu bist intrinsisch motiviert, aus unstrukturierten Daten unterschiedlicher Quellen und Systemen Muster zu erkennen. Durch die Verbindung von weiteren und der Erschlie\u00dfung neuer Datenquellen definierst Du Anwendungsf\u00e4lle f\u00fcr den Bosch eBike Service. Gemeinsam mit den verschiedenen agilen Teams setzt Du diese Anwendungsf\u00e4lle um und begeisterst unsere Kunden.\nDas Technology Scouting und Benchmarking bzgl. neuer Analysemethoden f\u00fchrst Du selbst\u00e4ndig aktiv durch und leitest daraus m\u00f6gliche Anwendungen f\u00fcr Bosch eBike Systems ab.\nDu stellst die Anforderungen zur Etablierung neuer Datenpipelines und die Realisierung sicher. Dabei agierst Du sowohl bereichs\u00fcbergreifend als auch international und mit Zentralstellen von Bosch. Basierend auf Deinen Analysen f\u00fchrst Du datengetriebene Entscheidungen auf Leitungs- und Bereichsvorstandsebene herbei.\nEin Berichtswesen u. a. mittels einpr\u00e4gsamer Visualisierungen geh\u00f6rt zu Deinem Methodenbaukasten. Zudem sind advanced und predictive Analytics oder KI f\u00fcr Dich keine kryptischen K\u00fcrzel.\nDu bef\u00e4higst die eBike Kollegen in der Nutzung und Wiederverwendung Deiner Analysen und bereitgestellter Dashboards.\nQualifikationen\nAusbildung: abgeschlossenes Hochschulstudium (Master\/Diplom\/Promotion) der Informatik, der Wirtschaftsinformatik oder eines vergleichbaren Studienganges; idealerweise Master in Data Analytics\nErfahrungen und Know-how: mehrj\u00e4hrige Berufserfahrung im IT-Bereich wie Software-, Datenbankentwicklung, Big Data und Analytics-Technologien sowohl on-Premise als auch in der Cloud; Erfahrung mit Machine Learning und von k\u00fcnstlicher Intelligenz getriebenen Anwendungen; KPI-Wissen im Web und App Kontext; Grundkenntnisse des Datenschutzes und den gesetzlichen Regularien im Umgang mit Data und Customer Analytics von Vorteil; Erfahrung in der abteilungs- und gesch\u00e4ftsbereichs\u00fcbergreifenden Koordination in einem internationalen Umfeld\nPers\u00f6nlichkeit und Arbeitsweise: Deine Arbeitsweise zeichnet sich durch Selbstst\u00e4ndigkeit und Struktur aus; Du bist zielgerichtet, kommunikationsstark und \u00fcberzeugend; Du arbeitest gerne im Team; Dein Handeln ist von unternehmerischem Denken getrieben\nSprachen: verhandlungssicheres Deutsch und Englisch in Wort und Schrift\nBewerbungsfrist bis einschlie\u00dflich 08.03.2023.\nZus\u00e4tzliche Informationen\nIn diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente. Wir bieten tolle M\u00f6glichkeiten des remoten Arbeitens sowie unterschiedliche Teilzeitmodelle bis hin zum Jobsharing. Sprich uns gerne dazu an.\n\nVielfalt und Inklusion sind f\u00fcr uns keine Trends, sondern fest verankert in unserer Unternehmenskultur. Daher freuen wir uns \u00fcber alle Bewerbungen:\u202funabh\u00e4ngig von Geschlecht, Alter, Behinderung, Religion, ethnischer Herkunft oder sexueller Identit\u00e4t.\n\nDu hast Fragen zum Bewerbungsprozess?\nNina Sier (Personalabteilung)\n+49 711 811 27525\nDu hast fachliche Fragen zum Job?\nPatrick Millen (Fachabteilung)\n+49 7121 35 39465\nInteressierst Du Dich f\u00fcr diese oder weitere Stellen? Dann bewerbe auf die Virtual JobFair@BOSCH und verschaffe Dir einen \u00dcberblick \u00fcber die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de\/events\/                                        ","207":"Company Description\nAbout Eurofins\nEurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and the environment safer, healthier and more sustainable. From the food you eat to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. Eurofins is a global leader in food, environmental, pharmaceutical and cosmetic product testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies.\nIn over just 30 years, Eurofins has grown from one laboratory in Nantes, France to 58,000 staff across a network of over 1,000 independent companies in 54 countries, operating 900 laboratories. Performing over 450 million tests every year, Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing.\nEurofins is one of the fastest growing listed European companies with a listing on the French stock exchange since 1997. In FY 2021, Eurofins achieved a record revenue of over EUR 6.7 billion.\nEurofins IT Solutions India Pvt Ltd (EITSI) is a fully owned subsidiary of Eurofins and functions as a Global Software Delivery Center exclusively catering to Eurofins Global IT business needs. The code shipped out of EITSI impacts the global network of Eurofins labs and services.\nThe primary focus at EITSI is to develop the next generation LIMS (Lab Information Management system), Customer portals, e-commerce solutions, ERP\/CRM system, Mobile Apps & other B2B platforms for various Eurofins Laboratories and businesses. Young and dynamic, we have a rich culture and we offer fulfilling careers.\nJob Description\nTITLE:  BI Analyst\nREPORTING To: GSC IT Reporting Lead\nWORKING LOCATION: India (Bangalore or Chennai)\nOVERALL OBJECTIVES:\nEurofins today is strengthening the IT Reporting team. The IT Reporting team is controlling governance and operational data and produces and maintains reports that are used by several IT departments (IT Quality Assurance, IT Service Management, IT Compliance, Information Security, IT Infrastructure). The data in scope is the performance of IT Services, compliance of IT Assets, and security posture of the IT environment as a whole.\nThe role of the BI Analyst is to analyse the requirements, solution them, and then develop, maintain and support (level 3) the BI dashboards, in close collaboration with the Data Engineers in the same team.\nSPECIFIC ASSIGNMENTS:\nThe BI analyst:\nAnalyses approved requirements from stakeholders (across IT and business functions)\nLiaises with stakeholders and product owners in clarifying and detailing out requirements\nWorks with the data engineers and the domain experts to extract and transform the data\nDesigns, creates, and maintains the dashboards in the BI platform (Power BI Cloud)\nDemonstrates the accuracy of figures\nDeploys the dashboards to production\nDocuments reporting user guides and data dictionary\nImplements BI ACLs\nParticipates in the Agile SCRUM development process.\nProvides L2\/L3 support for investigating & resolving incidents on the dashboards.\nKeeps the end users and stakeholders engaged by communicating new releases and maintenance windows\nProvide end user trainings\/demonstrations\nREQUIRED PROFILE:\nPersonal Skills:\nData design, modelling, management and visualization\nExcellent graphical design skills (important)\nExcellent communication skills (in English, both orally and in the writing, including moderating meetings)\nAt ease with distant & international communications through several technologies  (ticketing  tool,  documents  and forums, phone, instant messaging, e-mail), Microsoft End User computing tools\nInitial Education Background:\nBachelor's degree or diploma\nLanguage skills and level expected:\nEnglish (fluent) required\nType and duration of previous experience\n3+ year experience as BI engineer\/expert\nData design, modelling, management and visualization\nPower BI experience in creating data-rich dashboards, writing DAX expressions and implementing Row Level Security, Paginated Reports and other BI tools\nExperience in DataOps and\/or Agile\/SCRUM is a plus\nTechnical knowledge:\nMS SQL\nMS Azure DevOps\n ","208":"Company Description\nTransforming businesses, driving success: SmarTek21\nSmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev\/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients\nJob Description\nSmarTek21 is looking for a hands-on Big Data Solution Architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.  \nQualifications\n\u2022 Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python.\n\u2022 Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks.\n\u2022 Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP).\n\u2022 Solid understanding of enterprise strategies for data security and data governance.\n\u2022 Experience in practice development, architecture, and consulting or product development.\n\u2022 Experience delivering data analytics projects and architecture guidelines.\n\u2022 Experience in engaging with enterprise architects. Non-technical Skills:\n\u2022 Excellent oral and written communication and presentation skills.\n\u2022 Ability to handle ambiguous situations and take trade-off decisions.\n\u2022 Strong problem solving and analytical skills to break down complex problems into smaller components.\n\u2022 Ability and willingness to perform in a team environment.\nRequirements:\n\u2022 Understand prospect\/customer\/partner technology landscape.\n\u2022 Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation.\n\u2022 Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers\/partners.\n\u2022 Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints.\n\u2022 Collaborate with the engineering team to create proof-of-concepts (POCs).\n\u2022 Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices.\n\u2022 Demonstrate business value of proposed solutions or current products to prospects and customers.\nSalary Range: $200,000-$215,000 (may be subject to change outside of WA State)\nAdditional Information\nWhat Is in It for You:\nPaid Time off \u2013 start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service.\nPaid Holidays - 8 paid holiday a year in addition to your PTO.\nHealth Insurance for FT employees \u2013 we pay 100 % premium of medical, dental and vision.\nHealth Insurance for FT employee\u2019s family \u2013 we pay 50% of premium for medical, dental and vision for dependents.\n401(k) \u2013 we administer 401(K) retirement contribution for FT employees.\nLife Insurance\/Short Term and Long-Term Disability \u2013 at no cost to you\nOpportunities for internal promotions\/career advancement\nFamily friendly work hours (closed on weekends and paid holidays)\nSmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and\/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class.","209":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value\nJob Description\nAs Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions.\nYou will independently drive design discussions to ensure the necessary health of the overall solution.\nThe role requires a hands-on technologist who has strong programming background like Java \/ Scala \/ Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components.\nYou are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. \nRole & Responsibilities:\nYour role is focused on the Design, Development and delivery of solutions involving:\nData Integration, Processing & Governance\nData Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations\nInfrastructure & Cloud Computing\nData Management Platforms\nImplement scalable architectural models for data processing and storage\nBuild functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode\nBuild functionality for data analytics, search and aggregation\n#LI-REMOTE \nQualifications\nOverall 5+ years of IT experience with 3+ years in Data related technologies\nMinimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS \/ Azure \/ GCP)\nHands-on experience with the Hadoop stack \u2013 HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline.\nStrong experience in at least of the programming language Java, Scala, Python. Java preferable\nHands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc\n Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security \n Competency\n1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience\n2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc\n3. Knowledge on distributed messaging frameworks like ActiveMQ \/ RabbiMQ \/ Solace, search & indexing and Micro services architectures\n4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 \u2013 Data Engineering\n5. CI\/CD \u2013 Infra provisioning on cloud, auto build & deployment pipelines, code quality\n6. Cloud data specialty and other related Big data technology certifications\nPersonal Attributes:\nStrong written and verbal communication skills\nArticulaion skills\nGood team player\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nProcess orientation and the ability to define and set up processe\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements\nEmployee Assistance Programs to help you in wellness and well being","210":"Company Description\nHandling billions of transactions annually, Nexi Group is among the top payment processors in Europe. We keep a tight focus on making it even easier and more intuitive for our customers to handle digital payments and related services. This has made us a trusted partner to more than 700,000 merchant outlets, including 140,000 online merchant outlets, more than 260,000 enterprises and over 250 banks across Europe.\nChanging the future of payments takes strong personalities\nAt Nexi, you\u2019ll develop in a fast-growing tech company in a high-paced, high-impact market. Working to change the future of payments, it\u2019s not just skills and ambition that gets the job done, it\u2019s the full package that makes the difference. Together, we impact the lives of everyone around us by powering an easier tomorrow for every citizen, bank, business and colleague. What powers you at work?\nJob Description\nData Engineering team is focused on improving the process of identifying valuable data,collecting, structuring, and utilizing data to create comprehensive analytics to support different aspects of business streams.\nMain Responsibilities:\nTo Build DWH\/BI and Data analytics solutions and ensure continue growth of Data products\nImplementation of data mappings and design of data flows as well as ETL processes in an agile environment for different kind of Business intelligence solutions\nCreation of  secure and reliable ETL pipelines ingesting data sources\nTo Implement batch and transactional ingestion patterns\nCollaboration with customer business teams to understand business problems and to implement scalable and sustainable data solutions\nDesign data models for consumption by data scientists and business analysts.\nConduct complex data analysis and report on results.\nFurther development of the data and analytics platforms and conduct complex data analysis and report on results\nProactively share know-how, insights and experiences across the organization\nTo be able to provide a delivery and present its business value in an understandable way to all levels of stakeholders\nCreate data quality flows as a part of Data Governance \nQualifications\nUniversity degree in electrical engineering and computer science, mathematics, economics or other related discipline\nMinimum 3 years of experience with Data Engineering\nIt will be considered as advantage if you have experience with card business or Financial Industry\nCoding using different program languages\nKnowledge of building Data warehousing\nKnowledge of BI tools( e.g.Cognos), Data analytics knowledge\nCritical thinking skills\nWilling to promote data culture not only in technical teams but across the organization\nCommunication skills\nImprovement of BI customers processes including  the Machine learning principles\nWilling to understand  company's business processes and the industry at large\nAbility to understand technology-based business intelligence tools focused on improving the process of identifying valuable data\n Additional Information\nPlease apply with your CV latest until 28th of February\nIf you are curious\u2026\n\u2026and you want to know more, you're welcome to contact our Recruitment Business partner, Marija Babi\u0107, on marija.babic@nexigroup.com ","211":"","212":"Company Description\nPublicis Media is one of Publicis Groupe\u2019s four solution hubs, aligning all of Publicis Groupe\u2019s media agencies and operations.  Publicis Groupe (Euronext Paris Exchange: FR0000130577; CAC 40 index), is the world\u2019s third largest communications group.  The Data, Technology and Innovation Global Practice was created to deliver best-in-class programmatic solutions as well as to consolidate Publicis Media\u2019s data and technology to transform our business from a service business to a platform business. \nJob Description\nWe are seeking a driven individual with a proven track record of scalable and innovative business intelligence solutions. He\/she shines when serving as a consultant to the business and is genuinely interested in understanding the objectives of complex and evolving projects. In this role, you will champion and advocate the use of Alteryx and Tableau to create an environment of self-service analytics. The candidate must be a self-starter with a sense of urgency and a commitment to quality and professionalism.\n Responsibilities:\nAnalyze business needs and partner with stakeholders to provide a strategic solution\nWork independently on end to end solutions, from data analysis to ETL design and development through to the final visual dashboard\nCollaborate across the organization to build solutions that achieve business objectives\nGuide stakeholders with operational decisions that impact data structures and connectivity\nBring best practices in data architecture and data visualization to the table\nBuild tools in a generic fashion for reuse across other solutions\nDevelop technical documentation for each solution\nManage projects in an agile environment\nQualifications\nMinimum Bachelor\u2019s Degree in Computer Sciences, Information Technology, or its equivalent\n3+ years\u2019 experience with Tableau\n1+ years\u2019 experience with AWS core+ services (EC2, S3, Lambda, Redshift, Glue)\n1+ years\u2019 experience with Python\n3+ years\u2019 experience with data visualization\nComfortable with data warehousing concepts, preparing data, and configuring automated workflows\nExcellent communication and presentation skills as well as an analytical mindset\nExperience with complex logic\nStrong data analysis skills\nExperience connecting and merging disparate datasets\nStrong organizational skills & attention to detail\nPossess a desire to work for a fast-paced, results-based company\nExperience managing multiple projects simultaneously\n Desired Skills\/Experience:\nExperience with media and ad tech platforms (Ad Servers, Media Planning and Buying systems, DSP\u2019s, Programmatic, etc)\nSQL\nAdobe Site Catalyst\nGoogle Analytics\nBasic knowledge of ETL, data modeling, data warehouse, extracting and manipulating large record of data\nAdditional Information\nCompensation Range: $106,500 - $167,500 annually. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. For this role, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off.\nAll your information will be kept confidential according to EEO guidelines.","213":"Databases are the beating heart of every business in the world.\nWe are looking for a Business Intelligence Engineer to join the Data & Analytics team at Cockroach Labs. As a member of the data organization, you will work closely with our Product and Engineering teams to uncover insights about how customers use CockroachDB, helping to inform the Product\u2019s decision-making and focus Engineering efforts. You will also be responsible for long-running analytical initiatives marked by greater complexity and less structure that will yield substantial product enhancements. We\u2019re looking for someone comfortable working on interesting growth, engagement, and retention-related problems in the SaaS space using cutting-edge and proven techniques. This is a strategic, high-impact role that will help shape the future of CockroachDB products and services.\nYou Will\nBring hands-on experience in creating curated data models, analytical approaches, and metrics strategies to deliver actionable insights\nPerform high-level ad-hoc analyses, quantitative and qualitative, to guide business improvement hypotheses and drive decisions\nCollaborate with senior management to develop goals, objectives, and strategies for improving business performance using BI tools\nOwn the design, development, and support of the data models and visualization dashboard, extracting data from the data warehouse (Snowflake, Big Query \/ Oracle data warehouse) or other sources.\nAdvocate for business intelligence solutions that will help the organization meet its goals\nRecommend changes to existing business intelligence processes or policies to improve efficiency\nBuild a scalable data infrastructure that meets the needs of the business as it enters a period of rapid growth\nEstablishing a robust and efficient business reporting process and building key management and workflow reports with input from management and executive leadership team\nProactively identify trends in market trends and business performance, surfacing findings on a regular basis\nBe a hands-on leader that will leverage enterprise data to enable Cockroach Labs' enormous growth potential in a profitable and efficient manner.\nDevelop analytic dashboards that are used to drive business operations across Finance, Sales, Planning, Manufacturing, and more.\nDevelop analytical frameworks to measure and supervise the performance of our GTM efforts across multiple dimensions (product, geo, segment, etc.)\nThe Expectations\nIn your first month, you will go through the Cockroach Labs onboarding process and start to build relationships with stakeholders across the company. You will understand our current data architecture and the internal and external resources we use to maintain it. You will start to prioritize the current backlog of data requests.\nAfter 30 days, you will have a grasp on the major questions the product management team needs to answer, as well as the executive-level questions that require coordination between disparate data sets. You will update the roadmap priority and put in place key processes for building out this function. You will develop a point of view on the direction we need to take our data platform to support our product operations.\nAfter 90 days, you will be fully integrated into the team. You will put in place the major processes for supporting the Product and the broader organization, and make incremental improvements to our data platform that demonstrably improve our ability to make decisions. You will socialize a strategy for data in the Product team and how this will support the needs of other departments in the future.\nYou Have\nBS, MS or Ph.D. in quantitative fields (e.g., Statistics, Math, Computer Science, Physics, Economics, Operations Research)\n5+ years of experience in business intelligence,  building and architecting data solutions roles, SaaS experience is a plus\nPreferred experience  in tools such as Spark, Airflow, Presto\/Hive, Spark, or any other streaming technologies to process incredible volumes of data, Looker, Tableau, or other reporting tools\nExperience working in GCP\/AWS\/Azure cloud platform and knowledge of cloud utilities\/tools\nAdvanced proficiency in data visualization tools (e.g. Tableau, Looker, Metabase) with hands-on experience in data modeling and reporting in data visualization tools such as Looker, or a similar tool\nFamiliarity with sophisticated data architecture and tools (e.g. data warehouses, data pipelines)\n5+ yrs of hands-on experience writing and optimizing advanced SQL queries, with large-scale, complex datasets\nAdvanced proficiency in Python, Scala, Java, or similar scripting language is preferred \nSkills to manage complex BI projects and teams, and work effectively across internal functional areas in ambiguous situations\nThe Team\nReporting to Veera Ilamurugu, Head of Data\nVeera Ilamurugu heads up the Data Analytics team at Cockroach Labs. He is responsible for our Product data strategy and is passionate about building and scaling businesses with data. Before joining Cockroach Labs, Veera was a Head of Analytics at Stitchfix, Leading an analytics team covering internal company strategy  When not at work, he enjoys watching Netflix, trying out new recipes in the kitchen, and listening to music.\nOur Benefits\n100% health insurance coverage (for you and your dependents!)\nPaid parental leave (with baby bucks)\nFlex Fridays\nFlexible time off & flexible hours\nEducation reimbursement\nRelocation support\nCockroach Labs is proud to be an Equal Opportunity Employer building a diverse and inclusive workforce. If you need additional accommodations to feel comfortable during your interview process, please email us at accessibility@cockroachlabs.com.\nThe annual anticipated base salary range for U.S. candidates for this role is USD $135,000 to $205,000, plus commission if a sales role. We set standard ranges for all U.S.-based roles based on function, level, and geographic location, benchmarked against similar stage growth companies. In order to be compliant with local legislation, as well as to provide greater transparency to candidates, we share salary ranges on all job postings regardless of desired hiring location.  Actual salaries may vary and fall outside of this range depending on factors such as a candidate\u2019s qualifications, geographic location, skills, experience, and competencies. In addition, we are often open to a wide variety of profiles, and recognize that the person we hire may be less experienced (or more senior) than this job description as posted. Salary is one component of the Cockroach Labs\u2019 total rewards package, which includes stock options, health insurance, life and disability insurance, funds towards professional development resources, unlimited PTO, paid holidays, and parental leave, to name a few! Salaries for candidates outside the U.S. will vary based on local compensation structures.","214":"Passionate about precision medicine and advancing the healthcare industry?\nRecent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus\u2019 proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.\nOur data accelerates the pace of innovation, empowering researchers to characterize disease, discover new opportunities, maximize clinical trial success, and ensure new therapies reach the right patients. As a Tempus employee you will have access to the world\u2019s largest real-world patient clinical data set linked to transcriptomics and digital pathology.\nWhat you\u2019ll do:\nSupport partnership development between Tempus and the Life Sciences industry by identifying patient cohorts for Tempus\u2019 oncology data licensing business\nPartner with Tempus\u2019 Pharma Business Development and Life Sciences Strategy & Operations teams to generate fit-for-purpose cohorts supporting pharma research\nSupport monitoring of the volume and profiles of inbound requests in order to generate insights into customer needs\nSupport code maintenance and documentation\nQualifications:\n1+ years of relevant work experience, preferably in an analytical or consulting role within or in support of the Life Sciences or Healthcare industry\nExperienced in SQL and Proficient in R and\/or Python\nExperience using Excel, Google Sheets, or equivalent spreadsheet software\nStrong interest in oncology, cancer genomics, molecular biology and\/or clinical trials\nExperience building client-ready deliverables and other outputs\nExperience working with unstructured data and translating raw data into practical insights\nExperience with data manipulation and cleaning\nStrong communication skills\nAbility to take ownership of deliverables, navigate ambiguity and juggle multiple projects simultaneously\nGoal orientated, self motivated, and driven to make a positive impact in healthcare\nThrive in a fast-paced environment and willing to shift priorities seamlessly\n#LI-GL1 #LI-Remote\nWe are an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.","215":"Company Description\nBlock is one company built from many blocks, all united by the same purpose of economic empowerment. The blocks that form our foundational teams \u2014 People, Finance, Counsel, Hardware, Information Security, Platform Infrastructure Engineering, and more \u2014 provide support and guidance at the corporate level. They work across business groups and around the globe, spanning time zones and disciplines to develop inclusive People policies, forecast finances, give legal counsel, safeguard systems, nurture new initiatives, and more. Every challenge creates possibilities, and we need different perspectives to see them all. Bring yours to Block.\nJob Description\nWe're building a bitcoin wallet for the next 100M bitcoin users - importantly for people around the world who likely haven't yet used bitcoin as a savings tool or for its payments capabilities yet. Our goal is economic empowerment -- starting with bringing easy-to-use, reliable wallet that helps people around the world own and manage their bitcoin, rather than having to rely on several tools and services that don't work well together and are challenging to use for a wide global audience.\nOur goal is to make the future of money intuitive, and safe while helping customers build a better financial future. We're assembling a team experienced in an extremely wide range of disciplines, including business, operations, design, software, hardware, security, and so many other aspects of product delivery.\nWe are hiring our first Product Data Scientist to help our product, marketing, engineering and customer support teams make data-driven decisions about what and how we build for our customers when helping them manage their money. This is a unique opportunity to not only be embedded with an early stage team where you'll have close proximity to strategy and building so you can produce action-oriented analyses, but you'll also influence our data infrastructure and tooling decisions.\nBecause you will work with bitcoin data across different sources (internal systems, blockchain, lightning network, etc.), an understanding of how these technologies function or demonstrated experience or interest working with this data is a big plus.\nYou will report to our Head of Business within Bitcoin Wallet. You can be based anywhere remotely in the United States, as well as in several countries around the world including the UK, Ireland, the Netherlands, Germany, among other countries.\nCome build the future of money with us! Learn more through our newsletter here.\nYou Will:\nEmpower our team to use data to make business decisions as we build a global product from its earliest days- an opportunity to build data analysis into the infrastructure of a team from day 1\nDevelop both backwards-looking analysis on product performance, marketing effectiveness, monetization and pricing and other main product and business decisions, as well as forward-looking predictive models to help us better understand customers and their needs (e.g. cluster analysis that help us map customer segments back to product usage, retention models)\nEmpower the teams with data and help them to make decisions on improving product features and building a meaningful roadmap (e.g. funnel metrics, analysis of churn and CS data, etc), as well as influencing important decisions like pricing based on acquisition and retention insights\nAs a member of the Business team, you'll have the product and business context to be able to proactively spot trends and connect sometimes seemingly disconnected data sets to help the team develop and prove out hypotheses across the end to end lifecycle, forming cohort analysis on things like acquisition channels, etc.\nNavigate external data sets such as publicly available blockchain data insights (eg bitcoin blockchain analysis) to help us understand things like our total addressable market (TAM) as well as SAM and SOM\nDesign and help run statistically-significant experiments across different cohorts of customers and ensure hygienic approach to things like causation vs correlation\nCreate models that help us to analyze risk and security threats as well as optimize key decisions on our approach to money movement (i.e. transaction modeling)\nSupport and guide in our early data infrastructure decisions with product and engineering - as we are a zero to one team, you will get to shape the data infrastructure decisions we make so we have scalable ways of working where data is easily accessible to the right people on our team, all while ensuring that data is secure and aligned with our privacy principles and commitment to customers and partners.\nQualifications\nYou Have:\nBackground in working in product-driven organizations and building and sharing data-driven insights to help make decisions with 8+ years of experience\nExperience with cohort and funnel analyses, an understanding of statistical concepts such as selection bias, probability distributions, and conditional probabilities\nExperience telling stories and making relevant recommendations with data\nYou've set up and run A\/B tests and other types of experimentation designs and can help ensure statistical significance in the right testing environment\nWith technical skills, you can automate complex processes and construct data pipelines\nExperience with data visualization tools (e.g. Looker, PowerBI, Tableau etc.)\nWork in collaborative team environments including Product, Marketing, Engineering, Design and Research\nThrives in earlier stage environments - you're a self-starter who gets excited about complex, sometimes vague, or longer-term problems and can be creative on how to solve those problems with data and insights\nFamiliarity or interest in learning blockchain analytics as we are building in the bitcoin space and external data sets will help you uncover richer trends and recommendations; ability to connect internal and external data sources\nTechnical skills: Python or R, Advanced SQL\n Additional Information\nBlock takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate\u2019s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.\n\nZone A: USD $184,100 - USD $225,000\nZone B: USD $174,900 - USD $213,700\nZone C: USD $165,700 - USD $202,500\nZone D: USD $156,400 - USD $191,200\nTo find a location\u2019s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information. \nBenefits include the following:\nHealthcare coverage\nRetirement Plans including company match \nEmployee Stock Purchase Program\nWellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance \nPaid parental and caregiving leave\nPaid time off\nLearning and Development resources\nPaid Life insurance, AD&D. and disability benefits \nPerks such as WFH reimbursements and free access to caregiving, legal, and discounted resources \nThis role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans.\nWe\u2019re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, veteran status, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. \nWe believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible. Want to learn more about what we\u2019re doing to build a workplace that is fair and square? Check out our I+D page. \nAdditionally, we consider qualified applicants with criminal histories for employment on our team, assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.\nBlock, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.","216":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value\nJob Description\nAs Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions.\nYou will independently drive design discussions to ensure the necessary health of the overall solution.\nThe role requires a hands-on technologist who has strong programming background like Java \/ Scala \/ Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components.\nYou are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. \nRole & Responsibilities:\nYour role is focused on the Design, Development and delivery of solutions involving:\nData Integration, Processing & Governance\nData Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations\nInfrastructure & Cloud Computing\nData Management Platforms\nImplement scalable architectural models for data processing and storage\nBuild functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode\nBuild functionality for data analytics, search and aggregation\n#LI-REMOTE \nQualifications\nOverall 5+ years of IT experience with 3+ years in Data related technologies\nMinimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS \/ Azure \/ GCP)\nHands-on experience with the Hadoop stack \u2013 HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline.\nStrong experience in at least of the programming language Java, Scala, Python. Java preferable\nHands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc\n Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security \n Competency\n1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience\n2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc\n3. Knowledge on distributed messaging frameworks like ActiveMQ \/ RabbiMQ \/ Solace, search & indexing and Micro services architectures\n4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 \u2013 Data Engineering\n5. CI\/CD \u2013 Infra provisioning on cloud, auto build & deployment pipelines, code quality\n6. Cloud data specialty and other related Big data technology certifications\nPersonal Attributes:\nStrong written and verbal communication skills\nArticulaion skills\nGood team player\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nProcess orientation and the ability to define and set up processe\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements\nEmployee Assistance Programs to help you in wellness and well being","217":"Title: Big Data Solution Architect\nType: Full-time\nLocation: Switzerland (Lausanne or Zurich)\n\ud83e\uddec About us\nVisium is a fast-growing Swiss AI technology consultancy company founded in 20218. At Visium, we develop customized AI-powered solutions for our clients in order to help them achieve their business goals.\nWith a team of 55+ Visiumees dedicated to accelerating the adoption of state-of-the-art Artificial Intelligence in traditional industries. We are the strategic AI partner of world-leading companies and we contribute to them with ethical AI solutions that have a massive positive impact on their business, customers and employees.\n\ud83e\udded Role\nYou will be our clients Data Engineering expert, helping them identify their opportunities and designing the projects we will develop for them.\nAs the first point of contact for many of our prospects, you will establish a close, impactful, and long-lasting relationship with our clients and partners. More importantly, you will be the main technical reference when it comes to supporting the growth team in the design of Data Engineering solutions and during client meetings.\n\n\ud83d\udca1 What you will be responsible for\nAs a Big Data Solution Architect you will be:\nOur technical expert to support our Sales team:\nCooperate with our Sales team and senior stakeholders, during pre-sales stage, to construct a total solutioning proposal, including offering and pricing, high level scope of both functional and technical requirements, data and security.\nIdentify potential Data Engineering use-cases and evaluate the value they would bring to our clients.\nPrepare proposal presentations for clients\u2019 projects.\nA trusted technical advisor to clients and project members:\nParticipate in or drive deep architectural discussions to build trust and rapport with clients during the implementation stage.\nProvide technological and architectural consulting to our clients, create strategic roadmaps, and advise on their execution.\nSolve complex technical challenges, and build deep relationships with senior technical individuals within internal and client organizations.\nGuide teams through the end-to-end project lifecycle, covering the initial conception, business requirements, software architecture, implementation, and delivery.\nAct as a technical lead and coach for the more junior team members.\nA resourceful leader to bring our Data Engineering practices to the next level:\nPromote the adoption of new initiatives on client side or internally.\nRun group-wide thought leadership initiatives to advance our architectural practices and sustain our technical excellence.\nDepending on your previous experiences and appetite to grow, you will have the opportunity to gain more responsibilities.\nRequirements\n\ud83d\udd27 What we are looking for\nA trustful expert in Data Engineering with a strong technical knowledge that can be put at the best-use of our clients\u2019 project.\nA client-centric person with strong consultative selling capabilities and commercial awareness to be a winning partner to close deals.\nA resourcefulness and a self-starter leader, always looking for constant self and collective improvements in his\/her areas of expertise and beyond.\nRequired qualifications:\n2-5 years of experience in designing and implementing large scale data engineering projects, preferable from a consulting background.\nStrong expertise on data management and cloud architecture.\nExcellent leadership, stakeholder management and communication skills to speak and present in front of senior executives.\nGood communication skills, fluent in English, French or German is a plus.\nBenefits\n\ud83d\udce6 What we offer\nA yearly education budget to steep your learning curve\nA yearly sport budget because a fit body leads to a fit mind\nA position that enables you to have an impact on 1\u2019000s of people\nA welcoming, international, and diverse team with a fun and dynamic spirit\nOpportunity to join a talented and experienced startup with proven traction in its journey\nOpen and transparent culture\nOur culture\nThe family culture we have built in our company is something we are very proud of. We truly value our people and encourage them to work and express themselves in the best possible way. You can always count on the people around you to help you get back on track. We always strive to do the right thing. Open discussion is welcomed and everyone is encouraged to share new ideas. We believe everyone can make a valuable impact no matter their role. We are united through the passion with which we approach our goals. 'Good-enough' is missing from our vocabulary because we stretch for amazing.\nCheck our LinkedIn and Instagram to learn more about us & don\u2019t hesitate to contact us if you have any questions.","218":"Job Description\nAbout This Role\nYou will build and support the US Data Visualization & Reporting capability as part of the US Data Strategy for the US Commercial Organization at Biogen.  As part of the US Data team, you will enable the US Commercial digital and analytics strategies by developing data solutions that maximize the use of our data assets. As a partner to US Data Team, you will execute and streamline monthly reporting, lead ad hoc analytics use cases, and communicate with all TA\u2019s to build end-to-end data management in close collaboration with stakeholders in CE&O, Finance and IT management. \n What You\u2019ll Do:\nDesign, develop and publish new dashboards and work on enhancements\nTranslate complex data sets into actionable reporting frameworks and models to enable key performance indicator (KPI) visualization that supports high performance for end users\nUse industry standard business intelligence (BI) tools (including Business Objects, QlikView, QlikSense) to formulate metrics and to create data quality management assessments and tools to perform ad hoc data inquiries\nPerform training to other PowerBI users, as needed\nResponsible for design and updating methodology and project documentation\nCollaborate with internal teams to understand business needs, and work to gain in-depth understanding of company processes and procedures\nTranslate business needs to technical specifications\nConduct unit testing and troubleshooting\nCollaborate with teams to integrate systems\nDevelop and execute database queries and conduct analyses\nFollows quality assurance and control processes, and performs routine data management tasks, such as data validation and correction, queries and editing to ensure data accuracy, integrity, and completeness \nPerform other duties as assigned\nQualifications\nWho You Are\nYou are an experienced with Pharmaceutical data assets & vendors professional, with great practical knowledge of BI tools and ability to integrate reporting components from multiple data sources. You know how to optimize dashboards with focus on usability, performance, flexibility and standardization. You have effective analytical, conceptual, and problem-solving skills  and you are passionate about data visualization.\n Required Skills\nMin Bachelor\u2019s degree in business or science related\nProficient in English; \nTechnical capabilities with MS Office, in particular PowerPoint and Excel (including Pivot Tables, Charts, and vLookup).\n1 - 3 years of practical experience working directly with Power BI; experience in developing, publishing and scheduling Power BI reports as per the business requirements\n1-3 years\u2019 practical experience with writing and debugging SQL queries\nAbility to integrate reporting components from multiple data sources\nEffective analytical, conceptual, and problem-solving skills\nExperience in optimizing dashboards with focus on usability, performance, flexibility and standardization\n Analytical thinking for translating data into informative reports and visuals \nExperience with Pharmaceutical data assets & vendors; knowledge of commercial analytics (Sales, Marketing, Managed Markets) in small specialty markets is a plus\nPassionate about data visualization\nAdditional Information\n Why Biogen?\nOur mission to find therapies for neurological and rare diseases is a unique focus within our industry and this shared purpose is what connects us as a team. We work together to overcome obstacles and to follow the science. We are resilient as we strive to make an impact on our patients\u2019 lives and on changing the course of medicine. Together, we pioneer. Together, we thrive. More details: https:\/\/www.biogen.com\/en_us\/careers.html\n Join our Global Business Services Center in Poland!\nThe vision of GBS at Biogen is to be recognized as a world-class Global Business Services organization driven by the desire for excellence in its people, business solutions, execution and partnerships with internal and external customers.\n We offer:\nRole in a dynamic and one of the oldest biotechnology company in the world \nCompany mission you can be really proud of\nWork with diverse and knowledgeable multinational teams\nOpportunities to learn and grow with GBS site in Poland\nStructured onboarding program\nCustomized benefit package, e.g. MyBenefits cafeteria, annual bonus eligibility, medical care, hybrid work\nWhy Biogen?\nOur mission to find therapies for neurological and rare diseases is a unique focus within our industry and this shared purpose is what connects us as a team. We work together to overcome obstacles and to follow the science. We are resilient as we strive to make an impact on our patients\u2019 lives and on changing the course of medicine. Together, we pioneer. Together, we thrive.\nAt Biogen, we are committed to building on our culture of inclusion and belonging that reflects the communities where we operate and the patients we serve. We know that diverse backgrounds, cultures, and perspectives make us a stronger and more innovative company, and we are focused on building teams where every employee feels empowered and inspired. Read on to learn more about our DE&I efforts","219":"Company Description\nVisa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.\nWhen you join Visa, you join a culture of purpose and belonging \u2013 where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world \u2013 helping unlock financial access to enable the future of money movement.\nJoin Visa: A Network Working for Everyone.\nJob Description\nVisa Consulting and Analytics (VCA), the consulting arm of Visa, is a global team of industry experts in strategy, marketing, operations, risk and economics consulting, with decades of experience in the payments industry.\nOur VCA teams offers:\nConsulting services customized to the needs of Visa client's business objectives and strategy\nBusiness and economic insights and perspectives that impact business and investment decisions\nSelf-service digital solutions Visa clients can leverage to improve performance in product, marketing and operations\nProven data-driven marketing strategies to increase clients' ROI\nVCA team is looking for a passionate individual to join our consulting practice and play a role in the data engineering team. The ideal candidate is adept at using big data sets to understand our client's challenges and deploy targeted solutions to drive meaningful benefits, leveraging our world-class payment knowledge, in combination with our diverse service offerings to address key strategic needs for Visa's clients including issuers, acquirers and merchants.\nHe\/She must have experience using a variety of data mining\/data analysis methods, using a variety of distributed data platforms, and leveraging the latest open-source technologies. He\/She must have a proven ability to drive business results with their data-based insights. Adept at creative and critical thinking, be able to deconstruct problems and transform insights into large scale, state-of-the-art solutions.\nResponsibilities\nAutomate and standardize data processes developed by team members.\nLeverage DevOps to create end-to-end streamline CI\/CD data and ML pipelines.\nReview and manage data pipelines, branching, and deployment process.\nWork with partners on requirements and implementation designs of data solutions.\nImplement data quality framework at scale using open-source technologies.\nCreate data monitoring dashboards with real-time notifications.\nUnderstand VisaNet data and platform ecosystem to deploy fully automatic data applications for internal and external clients.\nUnify data engineering and machine learning engineering pipelines.\nApply spark optimization techniques to production jobs to accelerate data prep.\nDocument process, designs, test results, and analysis.\nAbility to articulate complex architectures to non-technical audiences, management, and leadership.\nContinuously research industry best practices and technologies.\nEvangelize end to end automation and standardization across the organization.\nPartner with functional areas, and regional and global teams to leverage the breadth and depth of Visa\u2019s resources.\nThis is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership\/site), with a general guidepost of being in the office 50% or more of the time based on business needs.\nQualifications\nBasic Qualifications\n\n\u2022 BA\/BS required, MBA or other relevant Master\u2019s degree preferred (e.g. engineering, computer science, computer engineering, applied mathematics, or other related fields)\n\nPreferred Qualifications\n\n\u2022 At least 5 years of experience as data engineer or data scientist with open-source tools.\n\u2022 Experience in retail banking, payments, financial services, and\/or technology industries is a plus. Strong interest in the future of payments is a must.\n\u2022 Strong technical competency and experience with shell-scripting and Linux systems.\n\u2022 Experience with CI\/CD pipeline using Azure DevOps, GitHub actions, Jenkins, or Airflow.\n\u2022 Strong coding skills in Spark, Python and SQL to manipulate big data in distributed platforms.\n\u2022 Good to have experience in navigating in Linux\/Unix\/Container based apps such as Docker, Kubernetes, or Microservices environments.\n\u2022 Knowledge in how to leverage AI assistance tools like chatGPT for creating and debugging code.\n\u2022 Ability to interact with big data clusters using Jupiter Notebooks, terminal, or GUI.\n\u2022 Demonstrate experience leveraging open-source tools, libraries, and platforms.\n\u2022 Experience with data visualization and business intelligence tools like Tableau, PowerBI, Microstrategy, or Excel.\n\u2022 Problem solving ability and process creator with strategic focus on replicability, scalability, innovation, and governance.\n\u2022 Proficient with git for version control and code collaboration using branches and pull requests.\n\u2022 Must be passionate about automation and data and able to deliver high quality work.\n\u2022 Experience developing as part of Agile\/Scrum team.\n\u2022 Fluency in English (spoken\/written). Portuguese or Spanish is a plus.\n\u2022 Experience in developing integrated cloud applications with services like AWS, Azure Cloud, and GCP is a plus.\nAdditional Information\nVisa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.","220":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value.\nJob Description\nAs Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects:\nData Ingestion, Transformation & Consumption,\nData Storage and Computation Frameworks,\nPerformance Optimizations,\nInfrastructure, Automation & Cloud Computing,\nData Governance & Security\nThe role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java \/ Scala \/ Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL\/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.\nRole & Responsibilities:\n1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation.\n2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality\n3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality\n4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies\n5. Participate in workshops with clients and align client stakeholders to optimal solutions.\n6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc.\n7. People management, contributing to hiring and capability building\n#LI-REMOTE \nQualifications\nOverall 8+ years of IT experience with 3+ years in Data related technologies \n3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS \/ Azure \/ GCP) and delivered at least 1 project as an architect.\nMandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud. \nExpert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions\nExpert in programming languages like Java\/ Scala and good to have Python\nExpert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub\/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc.\nExpert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc.\nShould have worked on MPP style query engines like Impala , Presto, Athena, etc\nShould have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc.\nShould have a good understanding of how to set up Big data cluster security \u2013 Authorization\/ Authentication, Security for data at rest, and data in Transit.\nShould have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager \u2013 Data Engineering\nShould have worked on any of Orchestration tools \u2013 Oozie, Airflow, Ctr-M, or similar.\nWorked on Performance Tuning, Optimization, and Data security\n  Competency\n1. Excellent understanding of data technologies landscape\/ecosystem.\n2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases\n3. Good Exposure in development with CI \/ CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage.\n4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\n5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage.\n6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions\n7. Thought Leadership \u2013 blogs, keynote sessions, POV\/POC, hackathon\n8. Certification in either one of the cloud platforms or big data technologies\nPersonal Attributes:\nStrong analytical and problem-solving skills\nStrong communication skills in verbal, written and visual presentations\nStrong coordination and negotiation skills\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nMulti geo experience and distributed delivery experience in large programs\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements \nEmployee Assistance Programs to help you in wellness and well being","221":"Company Description\nAt Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people\u2019s lives. Our promise to our associates is rock-solid: We grow together, we enjoy our work, and we inspire each other. Welcome to Bosch.\nThe Bosch Power Tools GmbH  is looking forward to your application!\nJob Description\nThe team market & competitive intelligence owns the global responsibility for the contents and processes of the business development pillars market,\ncompetition & trends\nYour task mainly evolves around business intelligence in the fields of market & competition, for which you are in close interaction with global internal & external stakeholders\nYour biggest topics within the area of business intelligence:\nYou actively drive our team target to develop our contents and data to intelligence\nResponsibility for all data science & intelligence projects evolving around market & competition\nDevelopment and implementationg of AI & machine-based forecasting models (in close collaboration with your teammates\nThe second pillar of your responsibilities lies within market intelligence:\nResponsibility for certain sub-markets for an even better understanding of the contents behind the data science projects\nCoordination of sub-market estimates in close collaboration with the business units, country responsibilities & further internal stakeholders\nQualifications\nEducation: Master degree in the field of business informatics or similar\nPersonality: Analytical, structured & independent way of working. Team spirit & strong communication skills\nWorking Practice: Relevant experience in data science, business intelligence and data visualization. Ideally: experience in market intelligence & knowledge about the relevant competitive landscape\nExperience and Knowledge: Profound knowledge in business intelligence & data science\/visualization\/modeling. Experienced in handling data analytics tools (i.e. Power BI)\nLanguages: Business fluent in German & English\nAdditional Information\nYou want to work remotely or part-time - we offer great opportunities for mobile working as well as different part-time models or job-sharing. Feel free to contact us.\nDiversity and inclusion are not just trends for us but are firmly anchored in our corporate culture. Therefore, we welcome all applications, regardless of gender, age, disability, religion, ethnic origin or sexual identity.\nNeed support during your application?\nJulia Sch\u00f6ffler (Human Resources)\n+49 711 811 4261\nNeed further information about the job?\nAndreas Leinfelder (Functional Department)\n ","222":"Description de l'entreprise\nCabinet d\u2019expertises num\u00e9riques cr\u00e9\u00e9 en 1993, ASI accompagne les ETI et les grandes entreprises dans la concr\u00e9tisation de leur strat\u00e9gie digitale dans les domaines d'expertises suivants :\n  Data & Intelligence Artificielle\nStrat\u00e9gie digitale & Exp\u00e9rience Client\n  Plateformes & Applications\nProcess & Agilit\u00e9\nImplant\u00e9e dans 7 villes en France (Nantes, Rennes, Paris, Lyon, Brest, Niort et Bordeaux) ASI compte 500 collaborateurs. Labelis\u00e9e \"Happy At Work\" depuis 2016, 64% du capital de l'entreprise sont d\u00e9tenues par les salari\u00e9s cadres (actionnariat salarial).\nL\u2019agence ASI Lyon, fait preuve de cr\u00e9ativit\u00e9 pour sans cesse se r\u00e9inventer et diversifier ses savoir-faire tout en d\u00e9veloppant des expertises techniques et m\u00e9tiers, lui permettant d\u2019adresser les besoins 360 de ses clients.  \ud83e\uddd1\u200d\ud83d\ude80 \nL\u2019\u00e9quipe est aujourd\u2019hui constitu\u00e9e d\u2019environ 60 sp\u00e9cialistes qui interviennent dans les \u00e9v\u00e8nements de l\u2019\u00e9cosyst\u00e8me num\u00e9rique local. En recherche constante de nouveaux talents et de leaders passionn\u00e9(e)s par la concr\u00e9tisation de projets innovants au service de nos clients.\nASI Lyon, ce sont aussi des sourires, de la bonne humeur et des moments pour se retrouver entre nous parce qu\u2019on aime \u00e7a !\n Description du poste\n(Dans un souci d\u2019accessibilit\u00e9 et de clart\u00e9, les termes employ\u00e9s au masculin se r\u00e9f\u00e8rent aussi bien au genre f\u00e9minin que masculin).\n V\u00e9ritable architecte ou expert cloud et de la Big Data, vous contribuez \u00e0 la d\u00e9finition de l\u2019orientation technologique des activit\u00e9s, en alignement direct avec la strat\u00e9gie de l'entreprise.\nLe challenge vous anime, vous mettez en place, d\u00e9veloppez l\u2019offre Cloud\/Big Data et constituez votre \u00e9quipe pour accompagner nos clients dans leurs programmes de transformation IT vers les solutions innovantes et vous \u00e9vang\u00e9lisez les enjeux Cloud en lien avec leurs c\u0153urs de m\u00e9tier. \ud83e\uddb8\ud83c\udffd\u200d\u2640\ufe0f \n Votre r\u00f4le, tr\u00e8s complet, passe par le lead d\u2019\u00e9quipe, la contribution \u00e0 la dynamique de croissance du p\u00f4le, par la ma\u00eetrise du design d\u2019architecture en passant par des probl\u00e9matiques data dans le cadre de vos missions.\nDot\u00e9 d\u2019une vision technique pointue, vous serez acteur incontournable en phases d\u2019avant-vente permettant de proposer des architectures Cloud performantes, fiables, s\u00e9curis\u00e9es et \u00e9volutives aux projets strat\u00e9giques.\nDans le cadre de l\u2019animation du p\u00f4le Data, vous \u00eates vecteur de communication de l\u2019empreinte technologique au travers de s\u00e9minaires, conf\u00e9rences et de webinars.\nQualifications\nVous \u00eates dipl\u00f4m\u00e9 d\u2019une \u00e9cole d\u2019ing\u00e9nieur ou d\u2019un parcours universitaire technique. Vous justifiez d\u2019au minimum de 5 ans d\u2019exp\u00e9rience professionnelle en tant qu\u2019expert ou architecte cloud.\nVous avez une exp\u00e9rience en pilotage op\u00e9rationnel r\u00e9ussie et vous souhaitez poursuivre ou \u00e9voluer dans des environnements Agile & DevOps\nDot\u00e9 de v\u00e9ritables qualit\u00e9s relationnelles et d\u2019un leadership naturel, vous savez insuffler une v\u00e9ritable dynamique d\u2019\u00e9quipe et savez accompagner dans la mise en place des bonnes pratiques\nToujours en qu\u00eate de savoir, vous assurez une veille prospective et concurrentielle.\nComp\u00e9tences techniques :\nConnaissances multicloud Azure, AWS et\/ou Google Cloud Platform (GCP)\nSyst\u00e8mes de gestion des bases de donn\u00e9es : SQL, Synapse, Snowflake\nLangages de programmation : java, python, Spark\/scala\n Outils de construction et de virtualisation : Jenkins, Docker, Kubernetes, Ansible\n Repository de code : Git, GitHub, SVN,\nM\u00e9thodes Agile et approche DevOps\nInformations suppl\u00e9mentaires\nVous b\u00e9n\u00e9ficierez bien s\u00fbr d\u2019un package avantageux mais rejoindre ASI, c\u2019est surtout int\u00e9grer une entreprise :\nSignataire de la Charte de la diversit\u00e9 : nous faisons en sorte que chacun, quelles que soient ses particularit\u00e9s, se sente appartenir \u00e0 la soci\u00e9t\u00e9 et soit toujours reconnu pour ses comp\u00e9tences.\n A l\u2019\u00e9coute de ses collaborateurs : ASI est triplement labellis\u00e9e HappyAtWork, TechAtWork et Impact RSE. Ces labels sont d\u00e9cern\u00e9s par Choose My Company aux entreprises respectant notamment les principes de traitement \u00e9thique et de respect de l\u2019environnement et o\u00f9 les salari\u00e9s sont le plus motiv\u00e9s et heureux. \ud83d\ude03 \n  A l\u2019offre de formation riche : gr\u00e2ce \u00e0 la \"ASI Academy\", vous aurez la possibilit\u00e9 de participer \u00e0 des formations en pr\u00e9sentiel ou distanciel, par le biais d\u2019un parcours \u00e0 plusieurs niveaux (d\u00e9couverte, approfondissement, \u00e9valuation). 40 Asiens ont \u00e9t\u00e9 certifi\u00e9s l\u2019an dernier.\nAyant \u00e0 c\u0153ur de maintenir constamment la convivialit\u00e9 et la coh\u00e9sion entre ses collaborateurs au travers de s\u00e9minaires annuels, soir\u00e9es d\u2019agence, afterworks ou encore \u00e9v\u00e9nements internes.\n Porteuse d\u2019une d\u00e9marche RSE VRAIMENT active : ASI a fait partie des 30 premi\u00e8res entreprises \u00e0 avoir rejoint la Convention des Entreprises pour le Climat (CEC). Notre Team RSE est compos\u00e9e de 30 collaborateurs volontaires et engag\u00e9s sur les sujets de pr\u00e9servation de l\u2019environnement, le num\u00e9rique responsable, le bien-\u00eatre au travail !","223":"Company Description\nOcorian is a global leader in corporate and fiduciary services, fund administration and capital markets. Wherever our clients hold financial interests, or however they are structured, we provide compliant, tailored solutions that are individual to their needs.\nWe manage over 17,000 structures for 8000+ clients with a global footprint operating from 18 locations. Our scale offers all our people great opportunities to develop their knowledge and skills and to progress their careers.\nJob Description\nPurpose of the job\nTo assist in the development of business intelligence and management information solutions for Ocorian taking information from the financial, HR, corporate administration systems, and Cloud-based solutions to create a reporting base for the business, the single source of truth\nDelivery of key dashboards and reporting requirements from the BI\/MI solutions with appropriate robust security models\nAssist with data cleansing and data loading exercises, which may extend to jurisdictional and regulatory filing requirements\nDocumentation of solutions, handover to BAU Teams, and supporting solutions\nPrior experience of creating\/supporting ETL, data warehouses and Tabular data models. Ocorian utilises Microsoft SQL Server technologies, including SSIS, SSAS, SSRS and Power BI and the successful candidate should have delivered projects using aspects of this technology stack in recent times\nThe individual will be expected to work across all levels of the Business to liaise with key stakeholders to ensure the design, development and documentation meets the requirements of the Business. The role will work extensively with IT functions and the role may be matrix-managed when required with tasks assigned by the BAU BI Team\n Main responsibilities\nDesign and implement data warehouse solutions and Tabular data models\nDevelop dashboards and reporting to meet business reporting needs\nDeliver approved projects within timeframe\nProvide regular updates to management\nMake recommendations for potential improvement or changes\nPromote the use of core systems for data capture aligned to standards and initiatives\nQualifications\nTECHNICAL SKILLS\nSQL Server 2016 onwards\nSQL Server BI stack \u2013 SSAS \/ SSIS \/ SSRS\nMicrosoft Power BI\nExperience of data cleansing tools and methodologies\nBUSINESS SKILLS\nDemonstrated ability to apply IT in solving business problems\nGood written, oral, and interpersonal communication skills\nAbility to present ideas in business-friendly and user-friendly language\nHighly self-motivated, proactive and attentive to detail\nAbility to effectively prioritise and execute tasks in a high-pressure environment\nExtensive experience working in a team-oriented, collaborative multi-jurisdictional environment\nExperience of working in project teams with mixed skillsets and levels of technical knowledge\nEnergy and enthusiasm to support the future growth and success of the business\nAdditional Information\nAll staff are expected to embody our core values that underpin everything that we do and that reflect the skills and behaviours we all need to be successful.  These are:\nWe are AMBITIOUS - We think and act globally, seizing every opportunity to support our clients and staff - wherever in the world they may be.\nWe are AGILE - Our independence from any financial institution gives us the flexibility and freedom to keep things simple, efficient and effective.\nWe are COLLABORATIVE - We take the time to understand our clients' needs so that we can deliver personalised solutions every time.","224":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value.\nJob Description\nAs Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects:\nData Ingestion, Transformation & Consumption,\nData Storage and Computation Frameworks,\nPerformance Optimizations,\nInfrastructure, Automation & Cloud Computing,\nData Governance & Security\nThe role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java \/ Scala \/ Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL\/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.\nRole & Responsibilities:\n1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation.\n2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality\n3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality\n4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies\n5. Participate in workshops with clients and align client stakeholders to optimal solutions.\n6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc.\n7. People management, contributing to hiring and capability building\n#LI-REMOTE \nQualifications\nOverall 8+ years of IT experience with 3+ years in Data related technologies \n3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS \/ Azure \/ GCP) and delivered at least 1 project as an architect.\nMandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud. \nExpert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions\nExpert in programming languages like Java\/ Scala and good to have Python\nExpert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub\/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc.\nExpert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc.\nShould have worked on MPP style query engines like Impala , Presto, Athena, etc\nShould have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc.\nShould have a good understanding of how to set up Big data cluster security \u2013 Authorization\/ Authentication, Security for data at rest, and data in Transit.\nShould have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager \u2013 Data Engineering\nShould have worked on any of Orchestration tools \u2013 Oozie, Airflow, Ctr-M, or similar.\nWorked on Performance Tuning, Optimization, and Data security\n  Competency\n1. Excellent understanding of data technologies landscape\/ecosystem.\n2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases\n3. Good Exposure in development with CI \/ CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage.\n4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\n5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage.\n6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions\n7. Thought Leadership \u2013 blogs, keynote sessions, POV\/POC, hackathon\n8. Certification in either one of the cloud platforms or big data technologies\nPersonal Attributes:\nStrong analytical and problem-solving skills\nStrong communication skills in verbal, written and visual presentations\nStrong coordination and negotiation skills\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nMulti geo experience and distributed delivery experience in large programs\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements \nEmployee Assistance Programs to help you in wellness and well being","225":"About Us:\nSentinelOne is defining the future of cybersecurity through our XDR platform that automatically prevents, detects, and responds to threats in real-time. Singularity XDR ingests data and leverages our patented AI models to deliver autonomous protection. With SentinelOne, organizations gain full transparency into everything happening across the network at machine speed \u2013 to defeat every attack, at every stage of the threat lifecycle. \nWe are a values-driven team where names are known, results are rewarded, and friendships are formed. Trust, accountability, relentlessness, ingenuity, and OneSentinel define the pillars of our collaborative and unified global culture. We're looking for people that will drive team success and collaboration across SentinelOne. If you\u2019re enthusiastic about innovative approaches to problem-solving, we would love to speak with you about joining our team!\nWhat our team does:\nThe Ingestion team is responsible for SentinelOne's highly scalable ingest of data from all kinds of endpoints into our Data Platform. Ingesting billions of events every day, handling billions of objects and enabling customers to search and gain insight into their data. All with the ability to scale up and down as needed, minimising costs, maximising efficiency, maintaining high availability at petabyte scale.\nOur team solves non-trivial scale and data problems with a unique blending of cloud, distributed systems, and software optimisation techniques and services.\nYour duties :\nSoftware Development (70-80% of time)\nLead implementations of new specifications; Write tests to cover new code or newly found issues;\nImplement with consistent coding patterns with a focus on stability and security\nReview Code\nRaise the quality, stability and security of the code for entire team codebase\nProvide guidance and meaningful feedback, understanding broader patterns and downstream and upstream dependencies\nBuild and Review Technical Specifications\nDocument trade-offs in solutions\/implementations; Document critical implementation details\/pipelines; Review and provide feedback on other specs\nDeeply understands architecture of Ingestion pipelines and connected features\nArchitect end-to-end solution for a complex feature with loose problem definition\nSupport\/On-Call Rotation\nRespond\/troubleshoot to outage incidents; Fix newly found issues\nTeamwork\nHelp team members solve problems; Provide feedback; Attend weekly team sync; Provide Daily Standup in Slack\nYour tools:\nPrimarily modern Java, Go, Python, Scala, Rust;\nAWS, GCP, FedRAMP\nKafka, Splunk, S3, Kubernetes, Terraform, Docker, Jenkins, GitHub; Flink;\nYou enjoy and your passion:\nYou\u2019re passionate about building high-scale elegant and simple distributed systems - and during the past several years you\u2019ve successfully designed & implemented them (using Java or similar), to solve complex problems\nYou enjoy a collaborative development process using design discussions and code review\nYou\u2019re looking for the technical challenges of ingesting and processing petabytes of data daily\nWe\u2019d appreciate \/ You\u2019d learn & gain:\nYou possess solid foundation on building ingestion pipelines, experience with solving high volume streaming challenges and scaling\nYou can identify relevant improvements\/solutions in the literature & bring them into production when they fit\nYou enjoy writing modern Java, Scala, Go and you want to learn Rust\nDeep understanding of technology trade-offs and costs of different options, to keep the system stable and scalable\nHands-on experience with Kafka\nWhat we offer you\nSalary from 5000 EUR\/month.\nYearly % bonus depending on the performance of the company, paid out in 2 installments.\n*The final base salary component can be increased accordingly to individual skills and experience of the selected candidate.\nOn top of that you may look forward to:\nFlexible working hours & Full remote within Slovakia; optional membership in Regus co-working spaces; in Czechia we also have offices in Prague or Brno\nGenerous employee stock plan in the form of RSUs (restricted stock units)\nFlexible Time Off (on top of the standard 5 weeks of vacation)\nFlexible Paid Sick Days\nFully Paid Short Term Sick\/Short Term Nursing Leave\nGlobal gender-neutral Parental Leave (16 weeks, beyond the leave provided by the local laws) & Grandparent Leave\nVolunteering paid day off & Additional paid Company holidays and Wellness days off (e.g. 6 days in 2022)\nPension insurance contribution\nPremium Life Insurance covered by S1\nCafeteria points (5.000 CZK\/month), which you can spend on leisure & sports, kindergarten\/school fees, travel etc. \nPrivate medical care membership\nGlobal Employee Assistance Program (confidential counseling related to both personal and work life matters)\nHigh-end MacBook or Windows laptop, Home-office-setup gear & on top of that additional WFH Allowance\nUdemy Business platform for Hard\/Soft skills Training & Support for your further educational activities\/trainings\nAbove-standard referral bonus\nYearly bonus depending on the performance of the company\nOn top of RSUs, you can benefit also from our attractive ESPP (employee stock purchase plan)\nRefreshments & snacks at the offices (+weekly massages & yoga at Prague office)\nOptional company events for those who like to meet outside of work too (sport, BBQ, charity, offsite etc.)\nSentinelOne is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.\nSentinelOne participates in the E-Verify Program for all U.S. based roles. ","226":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nOverview:\nThe Agoda Content department is currently looking for a curious and questioning self-starter and proactive analyst, who will help drive decision making with insights from content, marketing and partner performance data.\nYou will get the opportunity to own analytical projects to direct our department\u2019s focus, and prioritize our actions. By joining Agoda, you will become part of a truly international team, with leading experts of different backgrounds coming from 50+ countries around the world. This is a genuine opportunity to gain valuable experience in a challenging and cutting-edge tech environment. The ideal candidate would have a passion for high-converting content, great user-experience, data and analysis tools and methods. This position reports to the Associate Director of Content Operations, in Bangkok, Thailand.\n  Main responsibilities:\nUnderstand Content goals and KPIs and be able to align reports and insights based on them. Identify and investigate trends, anomalies and opportunities to improve Agoda\u2019s Content strategy.\nIdentify content opportunities that drive customer value, bookings and conversion\nHelp build business cases around the opportunity and get buy-in from stakeholders\nEnsure appropriate data\/tools\/dashboards to measure execution and enable deeper analysis\nTrack execution and report up in regular updates\nWork with product, data\/BI team and IT to create data resources and build appropriate reporting\nWork with Content team leads to understand their business needs and identify opportunities in terms of team actions prioritization and focus.\nUse multiple data sources to report Content projects insights and impact; support Content tests and experiments.\nEncourage and train the Content team in best practice use of Agoda data, analysis techniques and interpretation.\nCoordinate with other Cross Functional departments like Analytics, Partner Services, and Product Owners\nUse Web-Analytics for Research and Analysis\nRequirements:\nBachelor degree or higher\n2+ years of relevant experience\nExperience \/ knowledge in statistics, SQL, Python\/R, Tableau and advanced Excel \u2013 required\nAbility to demonstrate data manipulation using data warehouse and create meaningful insight and visualization\nExperience \/ knowledge in Vertica and \/ or Impala \u2013 advantage\nExperience in generating data and \/ or preparing experiments for product development \u2013 advantage\nProfessional characteristics:\nAttentive to detail and committed to data integrity\nKeen and curious nature; able and willing to share your opinion\nOrganized; able to manage multiple, competing priorities and deliver results under tight deadlines\nAble to communicate effectively; fluent in English \u2013 both spoken and written\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","227":"Our Engineering community is growing, and we\u2019re now looking for a (Senior) Big Data Engineer to join our team supporting our global growth.\n\nAs Big Data Engineer, you design and optimize data processing algorithms on a talented, cross-functional team. You are familiar with the Apache open-source suite of technologies and want to contribute to the advancement of data engineering.\n\nWHAT WE OFFER\nA chance to accelerate your career and work with outstanding colleagues in a supportive learning community split across 3 continents\nContribute your ideas to our unique projects and make an impact by turning them into reality\nBalance your work and personal life through our workflow organization and decide yourself if you work\u202fat home, in the office, or on a hybrid setup\nAnnual performance review, and regular feedback cycles, generating distinct value by connecting colleagues through networks rather than hierarchies\nIndividual development plan, professional development opportunities\nEducational resources such as paid certifications, unlimited access to Udemy Business, etc.\nLocal, virtual, and global team events, in which UT colleagues become acquainted with one another\nRequirements\nWHAT YOU\u2019LL DO\nYou make data useful. You build program code in Java or similar languages, test and deploy to various environments, design and optimize data processing algorithms for clients\nYou work on feature implementation, and you automate testing of data-driven applications, using open-source and cloud-native technologies\nYou organize your workflow independently in an agile setting and contribute to your team with high quality code in alignment with the project vision\nYou communicate primarily in English with your team members\n\nWHAT YOU\u2019LL BRING\n2+ years of hands-on experience in the development of software using Java or a comparable language\nExperience with data ingestion, analysis, integration, and design of big data applications using Apache open-source technologies, such as Hadoop, Spark, or Flink. Experience with Kafka, Docker, Kubernetes also good\nSolid computer science fundamentals (algorithms, data structures, and programming skills in distributed systems) and work experience in agile environments\nProfessional communications skills in English \n\nDid we pique your interest, or do you have any questions?\nWe want to hear from you: contact us at recruit@ultratendency.com\n\nABOUT US\nUltra Tendency is an international premier Data Engineering consultancy for Big Data, Cloud, Streaming, IIoT and Microservices. We design, build, and operate large-scale data-driven applications for major enterprises such as the European Central Bank, HUK-Coburg, Deutsche Telekom, and Europe\u2019s largest car manufacturer. Founded in Germany in 2010, UT has developed a reliable client base and now runs 8 branches in 7 countries across 3 continents.\nWe do more than just leverage tech, we build it. At Ultra Tendency we contribute source code to +20 open-source projects including Ansible, Terraform, NiFi, and Kafka. Our impact on tech and business is there for anyone to see. Enterprises seek out Ultra Tendency because we solve the problems others cannot.\nWe love the challenge: together, we tackle diverse and unique projects you will find nowhere else. In our knowledge community, you will be a part of a supportive network, not a hierarchy. Constant learning and feedback are our drivers for stable development. With us you can develop your individual career through work-life balance.\nWe evaluate your application based on your skills and corresponding business requirements. Ultra Tendency welcomes applications from qualified candidates regardless of race, ethnicity, national or social origin, disability, sex, sexual orientation, or age.\nData privacy statement: Datenschutzerkl\u00e4rung f\u00fcr Bewerber \u2013 Ultra Tendency","228":"Unternehmensbeschreibung\nBei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch.\nDie Robert Bosch GmbH freut sich auf Deine Bewerbung!\nStellenbeschreibung\nIm Gesch\u00e4ftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen \u2013 von hocheffizienten Antrieben \u00fcber das erste serienreife ABS f\u00fcrs Pedelec bis hin zu smarten Connectivity-L\u00f6sungen. F\u00fcr eine nachhaltige Mobilit\u00e4t, die Spa\u00df macht.\nDu bist Expert:in f\u00fcr den Bereich Data Engineering bei Bosch eBike Systems und stellst die relevanten Daten den Nutzern unserer Cloud-basierten Datenplattform zur Verf\u00fcgung.\nDu programmierst gerne und beherrschst Python und SQL. Zu Deinem Repertoire z\u00e4hlen au\u00dferdem ausgepr\u00e4gte Kenntnisse \u00fcber die performante Verarbeitung und Speicherung gro\u00dfer Datenmengen sowohl in Data Lakes als auch in Data Warehouse Systemen.\nIm Rahmen Deiner T\u00e4tigkeit f\u00fchrst Du Code-Reviews durch und definierst Best Practices und Leitplanken f\u00fcr die Entwicklung von Data Pipelines. \nWir unterst\u00fctzen Dich, damit Du Deine Kreativit\u00e4t in dem Bereich entfalten kannst und bieten Design Reviews mit anderen erfahrenen Kolleg:innen und Interessengruppen an.\nDu baust Deine Data Pipelines robust und mit einem hohen Fokus auf Observability, um eine einfache Fehleranalyse zu erm\u00f6glichen.\nZudem \u00fcbernimmst Du Verantwortung f\u00fcr deine entwickelten Daten Pipelines auch w\u00e4hrend des Betriebs und entwickelst diese kontinuierlich weiter, um eine optimale Qualit\u00e4t und Zuverl\u00e4ssigkeit sicherzustellen.\nDu hast Spa\u00df daran, dein Wissen weiterzugeben und agierst als Mentor:in f\u00fcr Junior Kolleg:innen im Team. Es macht Dir Spa\u00df mit dem Daten-Team, den Fachbereichen, der IT und den Kolleg:innen im fachlichen Diskurs die beste L\u00f6sung zu identifizieren.\nQualifikationen\nAusbildung: abgeschlossenes Hochschulstudium (Master\/Diplom\/Promotion) der Wirtschaftsinformatik oder eines vergleichbaren Studienganges\nPers\u00f6nlichkeit und Arbeitsweise: kommunikativ, selbstreflektiert, getting-things-done-Mindset, stetig lernbereit, Interesse f\u00fcr Innovationen im Arbeitsgebiet, eigenverantwortlich, l\u00f6sungs- und kundenorientiert, pragmatisch und problembewusst\nErfahrungen und Know-how: 5 Jahre Berufserfahrung als Data Engineer sowie Erfahrung im Aufbau von zuverl\u00e4ssigen Data Pipelines; Erfahrung in der agilen Softwareentwicklung (SCRUM, Kanban) und Erfahrung in der Datenmodellierung sowie in unterschiedlichen Ans\u00e4tzen f\u00fcr Daten Architekturen; Erfahrung im\nArbeiten in multinationalen Teams\nKnow-How: Breites Wissen \u00fcber unterschiedliche Technologien im Bereich Big Data Engineering (z.B. Databricks \/Spark, Snowflake, Apache Airflow, dbt, Kafka) sowie fundierte Kenntnisse in relevanten Programmiersprachen (Python, SQL, Scala) und CI\/CD (Gitlab CI\/CD, Jenkins); Au\u00dferdem Kenntnisse der Daten-Analyse, des Daten-Managements und der Softwareentwicklung\nBegeisterung: Spa\u00df daran, Wissen an andere zu vermitteln\nSprachen: sehr gute Deutsch- und Englischkenntnisse in Wort und Schrift\nZus\u00e4tzliche Informationen\nIn diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente.\n\nBewirb Dich jetzt in nur 3 Minuten!\nDu m\u00f6chtest Remote oder in Teilzeit t\u00e4tig sein - wir bieten tolle M\u00f6glichkeiten des mobilen Arbeitens sowie unterschiedliche Teilzeitmodelle. Sprich uns gerne dazu an.\nDu hast Fragen zum Bewerbungsprozess?\nNelly Ehrmann (Personalabteilung)\n+49 711 811 27525\nDu hast fachliche Fragen zum Job?\nDaniel Grimm (Fachabteilung)\n+49 7121 35 18668\nInteressierst Du Dich f\u00fcr diese oder weitere Stellen?\nDann bewerbe Dich auf die Virtual JobFair@BOSCH und verschaffe Dir einen \u00dcberblick \u00fcber die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de\/events\/                                        ","229":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to Know our Team: \nPartner Development is a team of creative entrepreneurs that develop solutions for Agoda\u2019s accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.\nIn this role you'll get to\nAs a Data Analyst in the PD Analytics team, you will be using data and modeling techniques to identify opportunities and build models and tools to improve efficiency and effectiveness for Agoda's supply team. \nKey activities involved include but not limit to:\nApply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations\nOwn end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development\nBuild dashboards, identify new and track key metrics to closely monitor team\u2019s performance and identify quick and long term opportunities for improvements\nWork closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified\nSupport global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization\nWhat you'll need to succeed \nBachelor\u2019s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline\n3-6 years experience working in a business analysis, data analysis, reporting or business strategy role\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\nCoding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\nData visualization tool experience such as with Tableau or your weapon of choice.\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","230":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to Know our Team: \nThe Supply Analytics team is a team of creative entrepreneurs that develop solutions for Agoda\u2019s non-accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek.  Utilizing our strong brand and resources, we build new channels to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. \nThe Opportunity:  \nThe role sits within the Supply Analytics team under Central Supply Team, where new business ideas, and partnership types are incubated and scaled. We are looking for a\u202fSenior BI Analyst\u202fwhose main focus areas are providing visibility and insights for people-related issues through Business Intelligence tools like Tableau and SQL, managing data warehouses, building ETL processes, and helping build other tools to optimize the business. This role will be involved in strategic projects and work closely with commercial owners and business stakeholders, using data to identify and translate business needs and opportunities into actionable initiatives.\nIn this Role, you\u2019ll get to:\nTranslate internal briefs into analytical projects (to include refining the initial brief and asking the \u2018right questions\u2019, working through potential hypotheses and storyboarding the output)\nUse and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders.\nProactively identify opportunities for growth within supply and the wider business.\nDrive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply.\nIdentify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence.\nAutomate manual operational processes and present back on time savings gained through modernization of business operations\nWhat you\u2019ll Need to Succeed:\n4+ years of experience in analytics\/data science\/insights\/strategy.\nBachelor\u2019s degree ideally in a business or quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance).\n3+ years of experience with BI & analytics tools (SQL, Tableau, Metabase, Data Studio, or similar technologies)\n2+ years of solid project management\nGood stakeholder management experience. Comfortable presenting to senior leadership and C-suite.\nStrong experience in finding data insights and provide business recommendation to the business\nA hacker\u2019s mindset \u2013 the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping.\nExcellent communicator with superior written, verbal, presentation and interpersonal communication skills.\nData driven in both decision making and performance measurement.\nExtreme comfort in ambiguous, fast-paced environment.\nAbility to multi-task, prioritize and coordinate resources.\nIt\u2019s Great if you Have:  \nTravel industry \/ e-commerce \/ tech \/ consulting experience.\nExperience in conducting A\/B testing experimentation (a plus)\nA good understanding of statistical modelling knowledge or any machine learning technique knowledge is a plus (regression, logistic regression, random forest, etc.)\n  #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","231":"Job Description\nGlobeMed Group, the largest Healthcare Benefits Management company in the MENA region is looking for a (Senior) BI Developer to develop and test Business Intelligence applications integrated with the enterprise data warehouse and the source databases. In addition, he\/she will be coordinating with the Business Intelligence Team Leader and his team to ensure timely completion of projects\u2019 deliverables to the end user. \nDuties & Responsibilities:\nDevelops and maintains business intelligence applications based on technical requirements and designs following Business intelligence development standards and guidelines.\nPerforms testing of all components of BI applications.\nCoordinates with other ICT teams.\nDetermines requirements feasibility by evaluating analysis, problem definition, solution development, and proposed solutions.\nDemonstrates solutions by creating or updating documentations, Guidelines, flowcharts, layouts, code comments and clear code.\nWork closely with the Team Leader for understanding of the functional and technical requirements\nDevelop the atomic\/semantic layers, metadata, reports and analytic dashboards\nAssist the team leader in the design of databases and data warehouses to ensure interoperability with business intelligence applications.\nConduct job duties and responsibilities according to the organization\u2019s business intelligence development methodology\nTroubleshoot BI tools and applications.\nConduct research related to Business Intelligence projects.\nQualifications\nExperience in BI tools development (Qlik) or experience in ETL (Talend or Informatica) development\nExperience in Data Warehouse fundamentals.\nSQL experience is a must (PL\/SQL development experience is a plus)\nBachelor Degree in computer science or related fields.\nAnalytical thinking and strong troubleshooting skills\nFluent in English and Arabic","232":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to know our team:\nPartner Development is a team of creative entrepreneurs that develop solutions for Agoda\u2019s accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.\nIn this role you'll get to\nThis role is designed to mainly growth opportunity identification among mid to long tail hotels, experiment execution and data tracking within Partner Development team for the global teams. You will get to work directly with the regional team to design and put in place global experimentation and initiatives to drive tangible impact in each market.\nKey activities involved include but not limit to:\nApply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations\nOwn end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development\nBuild dashboards, identify new and track key metrics to closely monitor team\u2019s performance and identify quick and long term opportunities for improvements\nWork closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified\nSupport global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization\nWhat you'll need to succeed \nBachelor\u2019s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline\n4-8 years experience working in a business analysis, data analysis, reporting or business strategy role\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\nCoding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\nData visualization tool experience such as with Tableau or your weapon of choice.\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi\nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","233":"Company Description\nVisa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.\nWhen you join Visa, you join a culture of purpose and belonging \u2013 where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world \u2013 helping unlock financial access to enable the future of money movement.\nJoin Visa: A Network Working for Everyone.\nJob Description\nThis position is ideal for an engineer who is passionate about solving challenging business problems and building applications that provide an excellent user experience. You will be an integral part of the Payment Products Development team focusing on design and development of software solutions that leverage data to solve business problems. The candidate will be extensively involved in hands-on activities including POCs, design, documentation, development, and testing of new functionality. Candidate must be flexible and willing to switch tasks based on team's needs. \nResponsible for the design, development, and implementation.\nWork on development of new products iteratively by building quick POCs and converting ideas into real products.\nDesign and develop mission-critical systems, delivering high-availability and performance.\nInteract with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology.\nDevelop code to ensure deliverables are on time, within budget, and with good code quality.\nHave a passion for delivering zero defect code and be responsible for ensuring the team's deliverables meet or exceed the prescribed defect SLA.\nCoordinate Continuous Integration activities, testing automation frameworks, and other related items in addition to contributing core product code.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nPerform other tasks on R&D, data governance, system infrastructure, and other cross team functions, on an as-needed basis\nThis is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs.\nQualifications\nWe are seeking team members that are passionate, visionary and insatiably inquisitive. Successful candidates frequently have a mix of the following qualifications:\n\n\u2022 2 or more years of work experience in building large-scale applications using open source technologies\n\u2022 Bachelor\u2019s Degree or an Advanced Degree (e.g. Masters) in Computer Science\/ Engineering, Information Science or a related discipline\n\u2022 Extensive experience with SQL and Big Data technologies (Hadoop, Java, Spark, Kafka, Hive etc.) tools for large scale data processing and data transformation\n\u2022 Experience with data visualization and business intelligence tools like Tableau, or other programs highly desired\n\u2022 Familiar with software design patterns\n\u2022 Experience working in an Agile and Test-Driven Development environment\n\u2022 Strong knowledge of API development is highly desired\n\u2022 Strategic thinker and good business acumen to orient data engineering to the business needs of internal and external clients\n\u2022 Demonstrated intellectual and analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style\n\u2022 Previous exposure to financial services is a plus, but not required\n\nPlease Note: Due to the COVID-19 pandemic and the evolving visa\/travel restrictions in place, we are currently only able to extend offers to candidates with the right to work in Singapore. We are keeping the situation under close review and will adjust accordingly should the restrictive measures be lifted.\nAdditional Information\nVisa has adopted a COVID-19 vaccination policy. As a condition of employment, all employees based in Singapore are required to be fully vaccinated for COVID-19, unless a reasonable accommodation is approved or as otherwise required by law.","234":"Company Description\nAt Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people\u2019s lives. Our promise to our associates is rock-solid: We grow together, we enjoy our work, and we inspire each other. Welcome to Bosch.\nThe Robert Bosch GmbH is looking forward to your application!\nJob Description\nAs DevOps Engineer for Cloud Data Platform services you act as IT Operation\/Infrastructure Specialist.\nYou drive industrialization of the cloud based Manufacturing Data Platform through further automation of deployment, configuration, upgrade, and maintenance processes.\nPart of your work also entails developing new Manufacturing Data Platform features supporting workload automation, monitoring, and enhanced usability.\nIn your responsibility lies the development of scripts for automation (deployment, configuration) and monitoring, as well as providing expert product support to Bosch business units (e.g. root-cause analysis of non-standard issues).\nYour tasks also include testing and evaluating new product features in close alignment with project stakeholders, internal customers, and vendors.\nFurthermore, you consult internal customers on technical level regarding tool selection, code quality, connectivity topics and workload performance.\nQualifications\nEducation: completed university degree in Computer Science, Information Technology, Engineering, Natural Science or related fields\nPersonality: resilient, team-oriented\nWorking Practice: initiative, goal-oriented\nExperience: experience (hands-on) as Software or DevOps engineer in cloud based Data Lake and Analytics environments; experience in Big Data designs, architectural blueprints, in the cloud concept IaC (infrastructure as code e.g. Terraform); experience working in larger projects, including multiple customers and international teams\nKnowledge: knowledge in data processing with Big Data frameworks (e.g. Spark), in version control tools (GIT, Bitbucket) and in CI\/CD Pipeline tools (e.g. Jenkins, Azure DevOps), in in scripting languages (e.g. Python, C, Scala) and in Microsoft Azure Analytics ecosystem (ADLS, Functions, EventHub); ability to move easily between conceptual and implementation level\nLanguages: good English and German\nAdditional Information\nYou want to work remotely or part-time - we offer great opportunities for mobile working as well as different part-time models or job-sharing. Feel free to contact us.\nDiversity and inclusion are not just trends for us but are firmly anchored in our corporate culture. Therefore, we welcome all applications, regardless of gender, age, disability, religion, ethnic origin or sexual identity.\nNeed support during your application?\nAnna Haas (Human Resources)\n+49 711 811 27525\nNeed further information about the job?\nJohannes Epple (Functional Department)\n+49 711 811 14417","235":"Company Description\nVisa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.\nWhen you join Visa, you join a culture of purpose and belonging \u2013 where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world \u2013 helping unlock financial access to enable the future of money movement.\nJoin Visa: A Network Working for Everyone.\nJob Description\nThis position is ideal for an experienced Software engineer who is passionate about solving challenging business problems and building applications that provide an excellent user experience. You will be an integral part of Loyalty & Marketing Services team focusing on design and build of software solutions that leverage data to solve business problems.\nResponsibilities\nResponsible for the architecture, design, development, and implementation.\nWork on development of new products iteratively by building quick POCs and converting ideas into real products.\nDesign and develop mission-critical systems, delivering high-availability and performance.\nInteract with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology.\nDevelop code and mentor junior developers to ensure delivery on time, within budget, and with good code quality.\nHave a passion for delivering zero defect code and be responsible for ensuring the team's deliverables meet or exceed the prescribed defect SLA.\nHelp developer efficiencies by utilizing Continuous Integration\/Development tools, test automation frameworks and other related items.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nIdentify opportunities for future enhancements and refinements to products, standards, best practices, and development methodologies\nCollaborate with global and virtual teams on software development.\nThis is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs.\nQualifications\n\u2022 Master\u2019s Degree in Computer Science or related field with 6 years of relevant experience or Bachelor\u2019s degree with 8 years of relevant experience.\n\u2022 Previous exposure to financial services is a plus, but not required.\n\u2022 Strong knowledge on Hadoop framework components (HDFS, Map Reduce, Spark, HBase, Kafka).\n\u2022 Strong knowledge in Java or Scala or Python.\n\u2022 Strong knowledge of database concepts, systems architecture, and data structures is a must.\n\u2022 Experience with one or more of the following database technologies: DB2, Postgres, MySQL, and NoSQL such as Hadoop, Hbase, MongoDB.\n\u2022 Proficient in GIT\/Stash, Maven, Jenkins etc.\n\u2022 Java\/J2EE\/Angular, Spring Cloud, Microservices and strong knowledge on API development is a big plus.\n\u2022 Experience working in an Agile and Test-Driven Development environment.\n\u2022 Process oriented with strong analytical and problem-solving skills.\n\u2022 Work independently and mentor others in the team and with minimal supervision.\n\u2022 Ability to juggle multiple projects and change direction mid-course based on business drivers.\n\u2022 Demonstrated ability to work in a complex organization to determine business and customer needs, providing the best solution to meet those needs.\n\u2022 Ability to work independently in a high throughput environment.\n\u2022 Demonstrated intellectual and analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style.\n\u2022 Excellent presentation and communication skills required.\nAdditional Information\nVisa has adopted a COVID-19 vaccination policy. As a condition of employment, all employees based in the country where this job is located are required to be fully vaccinated for COVID-19, unless a reasonable accommodation is approved or as otherwise required by law.","236":"Company Description\nAt ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can\u2019t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you. \nWith more than 7,400+ customers, we serve approximately 80% of the Fortune 500, and we're proud to be one of FORTUNE's 100 Best Companies to Work For\u00ae and World's Most Admired Companies\u00ae 2022.\nLearn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.\nUnsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.\nJob Description\nJob Description\nThe Big Data team plays a critical and strategic role in ensuring that ServiceNow can exceed the availability and performance SLAs of the ServiceNow Platform powered Customer instances deployed across the ServiceNow cloud and Azure cloud.  Our mission is to:\nDeliver state of the art Monitoring, Analytics and Business Insights by employing new tools, Big Data systems, AI and Machine Learning methodologies that improve efficiencies across a variety of functions in the company: Cloud Operations, Customer Support, Product Usage Analytics, Product Upsell Opportunities enabling to have an significant impact both on the topline and bottomline growth   The Big Data team is responsible for:\nCollecting, storing and providing real-time access to large amount of data\nProvide real-time analytics tools and reporting capabilities for various functions including:\nMachine Learning and Anomaly detection\nMonitoring, alerting and troubleshooting\nCapacity planning\nData analytics and deriving Business Insights\nRole Responsibilities\nResponsible for Building, Maintaining and Supporting BigData infrastructure on ServiceNow Private Cloud and Azure.\nAutomate deployment, maintenance, and monitoring of BigData components.\nImplement security for our Hadoop clusters.\nCapacity planning for BigData clusters.\nPerformance tuning for various Hadoop components.\nResponsible for enforcing data governance policies.\nHelp with various Big Data and cloud automation projects.\nApplication code deployment, maintenance and troubleshooting Spark, Hbase, Kudu applications, API\u2019s, Python, and shell scripts.\nPerform On-Call production monitoring and support for Big Data infrastructure and Big Data applications in ServiceNow private cloud and Azure cloud.  \nQualifications\nTechnical Skills\nExpert level experience in a Hadoop administration (preferably Cloudera CDP) role.\nExpert level experience working on Azure or AWS.\nExperience with performing Hadoop and Azure\/AWS performance tuning.\nExperience with Ansible, Terraform, Puppet and similar technologies.\nCI\/CD automation leveraging Docker\/Kubernetes orchestration.\nIn-depth knowledge of Hadoop components such as Spark Streaming, HDFS, HBase, YARN, Hive, Impala, Atlas, and Kudu.\nExperience securing Hadoop stack with Sentry, Ranger, LDAP, Kerberos KDC.\nIn-depth knowledge of Centos 7.x and shell scripts.\nWorking knowledge of Java, Python, Shell.\nAbility to learn quickly in a fast-paced, dynamic team environment.\nHighly effective communication and collaboration skill.\nRequired Bachelors or master\u2019s degree in computer science or equivalent.\n7+ years of overall experience with at least 2 in Big Data related positions.\n JV20\nAdditional Information\nServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.\nAt ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.\nIf you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.\nFor positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.\nPlease Note: Fraudulent job postings\/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.\n  From Fortune. \u00a9 2022 Fortune Media IP Limited All rights reserved. Used under license.\nFortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","237":"Company Description\nOur brand Deutsche Telekom IT Solutions Slovakia entered the life of Ko\u0161ice region in 2006 under the name of T-Systems Slovakia and ever since has been inextricably linked with the region when became one of the founding members of Ko\u0161ice IT Valley. We have managed to grow from scratch to the second largest employer in the eastern part of the country with more than 3900 employees. Our goal is to proactively find new ways to improve and continuously transform into the type of company providing innovative information and communication technology services.\nJob Description\nPurpose\nThe senior data engineer develops, constructs, tests and maintains architectures, such as databases and large-scale processing systems, and ensures that architecture fully supports requirements of the business. Plays a collaborative role where he\/she works closely with the business\u2019s Data and Analytics teams, gathering technical requirements for exceptional data governance.\nKey accountabilities\nAs a Senior Software Engineer in the field of Data & Analytics, you will develop complex software solutions for the IT landscape of tomorrow's telecommunications in agile teams. You will take over the further development of software for complex products and services along the entire development process (lifecycle). We use the following technologies: Cloudera, Kafka, NiFi, Flink, Spark, Informatica, Unix\/Linux, Java, REST, SOAP, PL SQL, DB2 (Unix), Perl, Scala, Python.\nTogether as a team, you will implement customer requirements, develop prioritized user stories and ensure the quality of your solutions\n1.    As an experienced Big Data Software Engineer, you will give guidance to less experienced colleagues, keep an eye on the big picture and thus ensure the implementation of the vision with the team\n2.    You will program, take over the installation and configuration of the software as well as the creation and maintenance of the software documentation\n3.    You will design and define system tests and test automation and support team members during error analysis up to error elimination\n4.    You will also take over the technical last level support for other teams for the supervised systems and service\nTeam Description\nAs a Senior Data Engineer in the field of data analytics, data engineering technologies and the development of data analytics solutions are your passion. You feel at home when it comes to developing data pipelines, implementing microservices, and building databases\/data lakes. You quickly understand complex data analytics architectures and are eager to contribute your experience in modern data analytics technologies and cloud technologies (AWS, Snowflake) to transform DT into a data-driven company. Then we, the Chapter Software Engineer Data & Analytics of Deutsche Telekom IT, are exactly the right workplace for you.\nQualifications\nYou have a university degree or a comparable qualification and already have several years of professional experience in the field of big data. Furthermore, you are characterized by the following knowledge and skills:\n \n\u2022    Expertise in technology and methodologies: streaming processing, ideally with Cloudera, and hands-on experience with Kafka, NiFi, and REST\n\u2022    Expert knowledge in relevant description languages and (object-oriented) programming languages, Java, Python, Perl\n\u2022    Knowledge and experience in the classic BI\/DWH environment: SQL, DB2 (Unix) as well as with data integration tools such as Informatica\n\u2022    Knowledge in hardware sizing and in the solution of security requirements as well as software engineering know-how in agile methods in design, architecture, development, testing\n\u2022    Practical experience in the use of appropriate tools for development change management and configuration management, GIT, JIRA\n\u2022    Intercultural experience in offshore projects\n\u2022    Experience in agile methods Scrum and SAFE\nLanguages\nEnglish - advanced (C1)\nGerman - advantage\nAdditional Information\nBenefits\nWe believe in balance between work and personal life. An attractive and extensive work-life balance portfolio guarantees lasting motivation for employees and thus a better quality of life, promotes physical and mental well-being and contributes to a positive work environment. All this with the aim of providing more freedom in reconciling work, career growth, private life and individual lifestyle. Therefore we offer to our employees over 25 different benefits to improve their personal and professional life in these areas:\nFinancial benefits\nBenefits with focus on learning and development\nBenefits with focus on health and sport\nBenefits with focus on family and work \u2013 life balance\nOther benefits\nFor more information about our benefits click to Benefits\nSalary\nFinal salary is negotiable.\nWe are offering base salary depending on seniority level and previous experience of candidate. In addition to base salary we provide variable part and other financial benefits. Base salary will not be lower than 2000 \u20ac \/brutto.\nAdditional information\n* Please be informed that our remote working possibility is only available within Slovakia due to European taxation regulation.","238":"Company Description\nWe organise over 500 large-scale branded and transaction-oriented events in 14 specialist markets. These are typically not-to-be-missed annual events where buyers and sellers build relationships, see and show products and do business.\nWe also provide year-round online platforms where companies showcase their businesses and products and buyers conduct research, generating valuable leads, and we provide data and digital content that supports the flow of knowledge and transactions in markets.\nJob Description\n6-month fixed term contract with a likely extension based on project work. The role is almost 100% working remotely.\nInforma Markets are looking to bring on a technically minded individual, who is interested in combining the analytical intelligence from data and developing technical solutions to problems in data systems. The key applications are PowerBI and SQL Server Analysis Services.\nWith a background in project work, they will be able to demonstrate the ability to meeting tight deadlines with system familiarity. They will be comfortable in both running their own projects and working alongside other developers on larger projects.\nWhat you\u2019ll be doing:\nThe PowerBI Developer is responsible for developing and supporting the Reporting Hub. This is new project currently in the development stage. The team is currently using IBM Planning Analytics for financial, FTE and KPI planning and reporting and would like to use PowerBI as the reporting front end for internal customers. This role is going to be the team expert on PowerBI and will help upskilling other members of the team. \nWhat we\u2019re looking for:\nTasks are likely to include:\nUsing best practice, develop the Product Tracker PowerBI reporting used by hundreds of people\nHelp develop the Finance standard reporting suite in PowerBI, which will service finance and business users across multiple Portfolios and Divisions.\nDevelop a series of prioritised dashboards based on prioritisation \nOptimise the data flow from the source systems to PowerBI\nChallenges current processes and ways of working, striving for an optimal level of output which delivers on requirements in a timely fashion\nQualifications\nStrong experience in a PowerBI development role\nBS Degree or equivalent professional qualifications\nHas a good knowledge of a wide area of information systems concepts and practice, both within and beyond own organization. Including all stages of systems development.\nFamiliarity with TM1 would be beneficial but not essential.\nCan demonstrate a rational and organized approach to the tasks undertaken and an awareness of the need to achieve quality","239":"Our Engineering community is growing, and we\u2019re now looking for a (Senior) Big Data Engineer to join our team supporting our global growth.\n\nAs (Senior) Big Data Engineer, you design and optimize data processing algorithms on a talented, cross-functional team. You are familiar with the Apache open-source suite of technologies and want to contribute to the advancement of data engineering.\n\nWHAT WE OFFER\nA chance to accelerate your career and work with outstanding colleagues in a supportive learning community split across 3 continents\nContribute your ideas to our unique projects and make an impact by turning them into reality\nBalance your work and personal life through our workflow organization and decide yourself if you work\u202fat home, in the office, or on a hybrid setup\nAnnual performance review, and regular feedback cycles, generating distinct value by connecting colleagues through networks rather than hierarchies\nIndividual development plan, professional development opportunities\nEducational resources such as paid certifications, unlimited access to Udemy Business, etc.\nLocal, virtual, and global team events, in which UT colleagues become acquainted with one another\nRequirements\nWHAT YOU\u2019LL DO\nYou make data useful. You build program code in Java or similar languages, test and deploy to various environments, design and optimize data processing algorithms for clients\nYou work on feature implementation, and you automate testing of data-driven applications, using open-source and cloud-native technologies\nYou organize your workflow independently in an agile setting and contribute to your team with high quality code in alignment with the project vision\nYou communicate primarily in English with your team members\n\nWHAT YOU\u2019LL BRING\n2+ years of hands-on experience in the development of software using Java or a comparable language\nExperience with data ingestion, analysis, integration, and design of big data applications using Apache open-source technologies, such as Hadoop, Spark, or Flink. Experience with Kafka, Docker, Kubernetes also good\nSolid computer science fundamentals (algorithms, data structures, and programming skills in distributed systems) and work experience in agile environments\nProfessional communications skills in English \n\nDid we pique your interest, or do you have any questions?\nWe want to hear from you: contact us at recruit@ultratendency.com\n\nABOUT US\nUltra Tendency is an international premier Data Engineering consultancy for Big Data, Cloud, Streaming, IIoT and Microservices. We design, build, and operate large-scale data-driven applications for major enterprises such as the European Central Bank, HUK-Coburg, Deutsche Telekom, and Europe\u2019s largest car manufacturer. Founded in Germany in 2010, UT has developed a reliable client base and now runs 8 branches in 7 countries across 3 continents.\nWe do more than just leverage tech, we build it. At Ultra Tendency we contribute source code to +20 open-source projects including Ansible, Terraform, NiFi, and Kafka. Our impact on tech and business is there for anyone to see. Enterprises seek out Ultra Tendency because we solve the problems others cannot.\nWe love the challenge: together, we tackle diverse and unique projects you will find nowhere else. In our knowledge community, you will be a part of a supportive network, not a hierarchy. Constant learning and feedback are our drivers for stable development. With us you can develop your individual career through work-life balance.\nWe evaluate your application based on your skills and corresponding business requirements. Ultra Tendency welcomes applications from qualified candidates regardless of race, ethnicity, national or social origin, disability, sex, sexual orientation, or age.\nData privacy statement: Datenschutzerkl\u00e4rung f\u00fcr Bewerber \u2013 Ultra Tendency","240":"Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto \u201cBuilding Success Together\u00ae,\u201d Nisum has grown to over 1,800 professionals across the United States, Chile,Colombia, India, Pakistan and Canada. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today\u2019s world, with immersive and seamless experiences across digital and physical channels.\nWhat You'll Do\nCandidate should be able to design, build and deploy BI Solutions\nExperience with requirements gathering, technical analysis, and writing technical specifications\/documentation\nGood Communication skills & Capability to work in a distributed team environment with minimal supervision are required.\nExposure to Dot Net or equivalent programming languages is a plus\nWhat You Know\nMinimum 8 + years of experience\nMust have strong knowledge of Power BI, SQL, SSIS, ADF, and Cubes\nMust have a strong understanding of Stored procedures, designing data models, and ETL process\nShould have real-time work experience on MSBI (SSIS), and Azure Data Factory Services(ADF) and will be responsible for hands-on design and development on ADF & model creation on SQL server database.\nShould have expert knowledge in writing SQL commands, queries, and stored procedures. Ability to improve SQL performance: analyzing SQL joins and table structures\nAnalyze and benchmark reporting and ETL performance; Evaluate and improve existing BI systems.\nKnowledge of Azure cloud and experience on Azure SQL DB and Azure analysis server is preferred.\nBI development background and coding experience in Azure stack - Migrate to Azure \/ Work with Azure services\nExperience with Azure Data bricks is a plus\nExperience working with programming languages like JS Framework is plus.\n  Education\nBachelor\u2019s \/ Master\u2019s degree in specific technical fields like computer science, math, statistics preferred, or equivalent practical experience.\nBenefits\nIn addition to competitive salaries and benefits packages, Nisum India offers its employees some unique and fun extras:\nContinuous Learning - Year-round training sessions are offered as part of skill enhancement certifications sponsored by the company on an as need basis. We support our team to excel in their field.\nParental Medical Insurance - Nisum believes our team is the heart of our business and we want to make sure to take care of the heart of theirs. We offer opt-in parental medical insurance in addition to our medical benefits.\nActivities -From the Nisum Premier League's cricket tournaments to hosted Hack-a-thon, Nisum employees can participate in a variety of team building activities such as skits, dances performance in addition to festival celebrations.\nFree Meals - Free snacks and dinner is provided on a daily basis, in addition to subsidized lunch.\nNisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace.","241":"Company Description\nOur mission as a company providing IT services is to provide our clients all over the world with the best solutions. We manage to do this by analyzing the needs of our clients and matching them to the skills and aspirations of our employees. Therefore, one of our main motivations is to provide each Employee and Consultant with a satisfying experience. Joining us means being part of a community with diverse personalities. Start your adventure with ALTER SOLUTIONS!\nJob Description\nDevelopment of ETL\/ELT flows on the on-premise - as well as the cloud platform\nDesign data models\nProvide daily support and maintain solutions for our customers\nParticipate in knowledge sharing cross team and domain\nQualifications\nMust have\nData warehouse technologies\nSQL\nELT\/ETL tools\nDatabases\nNice to have\nWherescape\nData Vault 2.0\nMicrosoft Azure tech stack\nAdditional Information\nHybrid model (3 days in Warsaw office)\nType of contract: B2B or employment contract\nAccess to local and international projects - Clients from France, Germany, Portugal, UK and Benelux\nProfessional development support -trainings, technical certificates, conference participation, foreign language classes and soft skills trainings are subsidized up to 2 000 PLN\nFlexibility - You choose form of cooperation: employment or business-to-business contract\nBonus for recommending Candidates up to 6 000 PLN\nFully paid Medicover healthcare card\nMultisport card\nRegular integration events and gifts\nPsychological support program WellBee\nMobility Program\nLong term cooperation\nIf You applied for this position the Controller of your personal will be  ALTER SOLUTIONS POLSKA Sp. z o.o., with its registered office at ul. Emilii Plater 10\/47, Warsaw. The personal data provided by you will be processed for the purpose of the recruitment process and for future recruitment processes. You will have the right too choose one or both options on next page.\nYou have the right to access the content of your data, request their rectification, erasure, restriction of processing, the right to data portability, the right to object to the processing of your data and the right to lodge a complaint to the President of the Personal Data Protection Office.","242":"Netcetera Spring Internship Program is now open!\nDeciding on how you work is totally up to you.\nYou will get to build your skills with the support of our experts and dedicated mentor, either in our Netcetera office or from the comfort of your home.\nYou will have the opportunity to work on real client projects and use the latest technology and tools, guided by our team of dedicated experts. Apart from expanding your knowledge and skills, you will also get the chance to be part of every Netcetera event and enjoy our fringe benefits.\nOur onboarding program will provide all the information to get you started. You will be supported with all the necessary equipment, engaging and fun activities, learning, and remote training. Take the initiative and bring your knowledge and skills to the next level.\nWe invite you to experience our culture, which fosters innovation, personal development, recreation, and respect for individuality.\nApply and experience Netcetera!\nYour tasks:\nLearn all about a selected specialization:\nBuild, implement, evaluate, and optimize data driven models (involving various machine learning approaches)\nDo detailed research in an area of interest, keep up to date on trends, tools and emerging technologies\nPerform ad-hoc analysis and present results in a clear manner\nGet familiar with the assigned project eco-system and mission\nParticipate in the team coordination meetings and events\nRequirements\nYou are a student in computer science, like to work in a team, have good communication skills, and are familiar with or interested in some of the following areas:\nMachine learning, reinforcement learning, computer vision, deep learning, natural language processing\nProbability and statistics (e.g., hypothesis testing, regressions)\nPython and relevant packages (Scikit-Learn, Pandas, Pytorch, NumPy)\nGeneral computer science and software development skills are considered as an advantage\nThis internship round will last for 3 months (combination of half and full time based on your obligations). Within legal and company policies, Netceterians\/you can choose whether to work remotely or from a Netcetera office and enjoy flexible working hours. This hybrid working model demonstrates our commitment to achieving the best suitable private and professional life balance.\nThis will be, of course, based on the interns\u2019 preferences, and agreed with their mentors.\nExpected start: beginning of April\nValid until 05.03.2023\nBenefits\nFlexibility: Adjust your time to work efficiently, be it working hours, part-time options, home office, or unpaid leave\nExtra vacation days: Need to take some extra time off? With us, you have the possibility to activate 5 additional paid days per year on top of your vacation plan\nPrivate health & Family Insurance: The company policy covers a private health insurance plan for you and your family\nYearly Education Fund: We strongly believe in continuous development and would love to see you enrich your knowledge. Ever Netceterian has a dedicated yearly fund to invest in their professional and personal development through conferences, courses, lectures or long-term education\nMeals & Snacks: Enjoy a lunch allowance each working day, free fruit and drinks in the office","243":"Codete is not just a software company, it\u2019s a place where tech-enthusiasts can grow by doing what they love and feel valued for what they are. We\u2019re experienced, agile and versatile: we work with a wide range of technologies in projects from many different industries, and the majority of our team are senior-level specialists.\nAt Codete, there\u2019s always something new to learn!\nOur client is a leader in consulting services with excellence competences in the areas of Digital Transformation and Data Strategy, focusing on Analytics, Big Data, Data Science, Artificial Intelligence, Data Visualizations, CPM and Software Engineering. Through a unique experience and extensive knowledge of the various business sectors and functions, they help organizations of all sizes thrive and improve the way their business operates.\nWe are looking for Data Engineer Professionals!\n\nLocation: Remote from Poland\nTech stack: PySpark, Apache Airflow, Kafka, Grafana, AWS, Azure\nSalary: PLN 23,000.00 - PLN 30,000.00 per month for B2B\nRequirements\nWhat we are looking for\n3 years+ of proven experience for Mid level Engineers and 5 years+ for Senior Engineers\nBachelor\u2019s or Master\u2019s degree in information systems\/engineering, computer science and management or related\nProficiency in modelling and maintaining Data Lakes with PySpark \u2013 preferred basis\nExperience with Big Data technologies (e.g. Databricks)\nAbility to model and optimize workflows (e.g. Azure Data Factory, Apache Airflow)\nExperience with Streaming Analytics services (e.g. Kafka, Grafana)\nAnalytical, innovative and solution-oriented mindset\nTeamwork, strong communication and interpersonal skills\nRigor and organizational skills\nFluency in English (spoken and written) - B2\nNice to have\nAbility to implement custom APIs and connectors\nKnowledge of automation services (e.g. Terraform, Azure DevOps, AWS CodeBuild, Jenkins)\nKnowledge of visualization technologies (e.g. Microsoft PowerBI, Looker) \u2013 Cloud certifications\nExperience in AGILE methodologies\nBenefits\nValues & Atmosphere\n\u2022 flexible attitude (including working hours) \u2022 international business trips \u2022 social events & awaydays \u2022 support for your ideas\nPersonal development\n\u2022 external conferences \u2022 technical & soft skills training \u2022 switching between projects\/technology \u2022 English classes \u2022 internal library\nHealth & Relax\n\u2022 Employee Wellbeing Platform \u2022 private health care \u2022 multisport card \u2022 sports events \u2022 chill-out room \u2022 fresh fruits & juicer\nKnowledge & Culture\n\u2022 open source initiatives \u2022 Codete Mentorship Program \u2022 R&D department\n\nThe data controller of your personal data is Codete Global Sp. z o.o. with its seat in Krak\u00f3w (30-527), Poland, ul. Na Zje\u017adzie 11. The data will be processed for recruitment purposes. To learn more please read an appropriate section of our Privacy Policy (Personal data provided for recruitment purposes).","244":"Have you ever ordered a product on Amazon and when that box with the smile arrived you wondered how it got to you so fast? Have you wondered where it came from and how much it cost Amazon to deliver it to you? If so, the WW Amazon Logistics, Last Mile team is for you. We manage the delivery of tens of millions of products every week to Amazon\u2019s customers, achieving on-time delivery in a cost-effective manner to deliver a smile for our customers.\n\nThis position will be responsible for building out analysis and visualization tools and processes\u2019 to support our growing Amazon Logistics business in Japan and Worldwide. We are is looking for a customer focused, innovative and technically skilled Sr. Business Intelligence Engineer to drive effective performance measurement and management, innovation and execution in last mile delivery.\n\nThe successful candidate will be able to effectively retrieve, integrate, visualize and present critical data to improve the efficiency of the package delivery network, and enable efficient management of a large global logistics system. They will work with technical and business teams to optimize planning, execution, process improvement and track progress against goals. This role requires excellent analytical abilities as well as excellent business acumen and comfort with technical teams and systems.\n\nCore Job Responsibilities include:\nLead and develop a team of Business Intelligence Engineers and Business Analysts.\nPartner with internal stakeholders across multiple teams, gathering requirements and delivering end to end solutions.\nPartner with Data Engineering and Software Development Engineers to prioritize and define AMZL data and BI development needs.\nWork with in-house scientists, global supply chain, transportation and logistics teams to identify new BI capabilities and projects.\nConduct deep dive investigations into operations execution and business problems, identify opportunities, and lead or support implementation.\nAnalyze and visualize large scale geo-spatial logistics and transaction data to articulate user behavior or delivery process problems, and output solid analysis report with recommendation\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, visit https:\/\/www.amazon.jobs\/disability\/jp\nBasic Qualifications\n\n5+ yrs of experience in analytic skills to integrate data into operational planning\nAdvanced level of SQL and ETL; ability to write and tune complex SQL scripts and ETL development\n5+ yrs of experience in Operational Excellence initiatives, working with data warehousing and data quality (MySQL and Redshift)\/\n5+ yrs of experience in visualization tools such as GIS visualization, Tableau, QlikView, QuickSight\nBusiness Level of English (written & verbal).\nBachelor's degree in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field.\n\nPreferred Qualifications\n3+ years of relevant work experience building end to end solutions to performance measurement and process improvement in a transportation, logistics or supply chain setting.\n3+ yrs of experience implementing basic software solutions to automate data source, visualization and\/or data modeling application.\nProject Management experience and\/or Tech product management experience.\nAbility to understand operations at a detailed, practical level and also to think big \/ strategically.\nMBA\/MS in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field.\n\n\nPlease check the website below for measures to eliminate unwanted second-hand smoking in each facility:\nhttps:\/\/www.amazon.jobs\/en\/landing_pages\/passivesmoking\n\u5c31\u696d\u306e\u5834\u6240\u306b\u304a\u3051\u308b\u53d7\u52d5\u55ab\u7159\u3092\u9632\u6b62\u3059\u308b\u305f\u3081\u306e\u63aa\u7f6e\u306b\u95a2\u3059\u308b\u4e8b\u9805\u306b\u3064\u3044\u3066\u306f\u3001\u4e0b\u8a18\u30ea\u30f3\u30af\u5148\u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002\nhttps:\/\/www.amazon.jobs\/jp\/landing_pages\/passivesmoking\n\nThe salary information can be provided individually prior to the 1st interview\n\u8cc3\u91d1\u306b\u95a2\u3059\u308b\u6761\u4ef6\u306f\u3001\uff11\u6b21\u9762\u63a5\u306e\u524d\u306b\u500b\u5225\u306b\u3054\u6848\u5185\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059","245":"With over 35 nationalities and a range of backgrounds represented in our Benevolent team, we aim to build an inclusive environment where our people can bring their authentic selves to work, be respected for who they are and the exceptional work they do. We welcome and actively encourage applications from all sections of society and are committed to offering equal employment opportunities regardless of sex, race, religion or belief, ethnic or national origin, marital, domestic or civil partnership status, sexual orientation, gender identity, parental status, disability, age, citizenship, or any other basis. We see our diversity as an asset as we tackle challenging problems that bridge the gap between drug discovery and technology.\n\nThe Role\nWe are seeking bioinformatics data scientists to join our London teams and apply advanced bioinformatics methods and data analytics to real-world drug discovery challenges. We have identified 3 projects across our Product Areas at BenevolentAI, which each give successful candidates the opportunity to learn more about leveraging biomedical data, developing targeting identification processes and establishing precision medicine workflows, all within an industry setting.\n\nProduct Area\nWe have one role available in each of the following three product areas:\nAs part of the Target Identification product area, you will work to:\nDevelop programmatic tools and workflows that enable the construction and optimisation of biological questions for target identification\nUse scientific methods to validate new tools\/workflows developed\nIdentify opportunities for further work in current biological question data pipelines using the latest scientific literature to help potential solutions\nCollaborate and communicate with members of the Bioinformatics, Data Science, Drug Discovery, Artificial Intelligence, Engineering, UX and Product teams to deliver BenevolentAI corporate strategic goals\nAs part of the Precision Medicine product area:\nYou will explore and analyse the multi-omics data available in house to evaluate different integration models;\nYou will develop programmatic tools and workflows that enable the integration of bulk or single-cell omics data;\nYou will apply advanced statistical methods to multiple datasets and integrate multi-omics data to generate robust evidence to inform mechanism-specific patient subgroups and personalised drugs recommendations;\nYou will validate new tools\/workflows developed computationally and qualitatively in collaboration with biology experts;\nIdentify opportunities for further work in current multi-omics integration pipelines using the latest scientific literature to help potential solutions.\nAs part of the Knowledge product area, based on FAIR data principles (Findable, Accessible, Interoperable and Reusable), you will:\nGet access to the tissue-specific network data\nInspect the data content to understand the features of the data\nDesign and implement a standardisation pipeline\nDefine the data model based on internal use cases\nIngest the data into the Knowledge Graph\n\nPrimary Responsibilities\nPursue a research project to investigate new approaches in applying tech-driven methods for drug discovery and development.\nWork as a member of a cross-functional team comprising specialists in informatics, engineering, AI, drug discovery and product for applied research.\n\nWe're looking for someone with\nPreference for candidates with a PhD\/MSc\/MSci in bioinformatics\/data science or who are working towards any of those qualifications but will consider candidates with relevant experience without formal higher education qualifications;\nGood programming skills in Python and\/or R;\nComfortable applying common data science concepts, running statistical analysis and training machine-learning models (unsupervised and\/or supervised) or eager to learn;\nGood communication skills who enjoy working in a collaborative team environment;\n\nNice to haves\nFor Target Identification product area:\nBonus points if familiar with the drug discovery process\nFor Precision Medicine product area:\nExperience in working with large-scale genetic datasets.\nExperience in post-GWAS analysis and interpretation, statistical methods for causal inference (e.g. Colocalisation, Mendelian randomisation) and gene prioritisation.\nFor Knowledge product area:\nExperience with databases.\n\nNotes\nApplications close on Wednesday 1st March 2023. Our interview process will commence after applications close and will take place over 3-4 weeks. Internships can commence anytime from Monday, June 5th 2023\nIn addition to your CV, please send us a cover letter.\n\nAbout us\nBenevolentAI (AMS: BAI) is a leading, clinical-stage AI-enabled drug discovery and development company listed on the Euronext Amsterdam stock exchange. Through the combined capabilities of its AI platform, scientific expertise, and wet-lab facilities, BenevolentAI is well-positioned to deliver novel drug candidates with a higher probability of clinical success than those developed using traditional methods. The Benevolent Platform\u2122 powers a growing in-house pipeline of 13 named drug programmes and over 10 exploratory programmes, and it maintains successful collaborations with AstraZeneca, as well as leading research and charitable institutions. BenevolentAI is headquartered in London, with a research facility in Cambridge (UK) and a further office in New York.\n\nWant to do a little more research before you apply?\nHead over to our Glassdoor page to learn about our benefits, culture and to find out what our team think about life at Benevolent. You can also find out more about us on LinkedIn and Twitter.\n\nTerms and Conditions\nSalary: We offer remuneration for the duration of the internships. However, remuneration remains subject to the University regulations & T&C\u2019s - should they not comply with our policy, we reserve the right to review the salary allowance.\nPlease note that by applying for a job you agree that we will collect and process your personal data submitted in your job application in accordance with our Privacy Policy.","246":"Location: Delhi, Gurgaon, Bangalore, Chennai,Indore, Ahmedabad, Jaipur, Kolkata,Pune.,None,None\nAbout Material\nMaterial is a global strategy, insights, design, and technology partner to companies striving for true customer centricity and ongoing relevance in a digital first, customer-led world. By leveraging proprietary, science-based tools that enable human understanding, we inform and create customer-centric business models and experiences + deploy measurement systems \u2013 to build transformational relationships between businesses and the people they serve.\nAbout Srijan\nSrijan is a global engineering firm that builds transformative digital paths to better futures for Fortune 500 enterprises to nonprofits all over the world. Srijan brings advanced engineering capabilities and agile practices to some of the biggest names across FMCG, Aviation, Telecom, Technology, and others. We help businesses embrace the digital future with cloud, data, API and platform centric technologies and adapt to changing business models and market demands. Srijan leads in Drupal with 350+ Drupal engineers, 80+ Acquia certifications. Srijan is also a Drupal Enterprise Partner & Diamond Certified\nJob Description\nAbout the Role\nAs a Senior Data Engineer, you will have the opportunity to work in a dynamic environment with plenty of opportunities to experiment with new technologies and solutions. Our team is highly collaborative and works closely with both the engineering organization and the business. We are agile in our approach to technology and always seek to improve and innovate within our platform and ways of working.\n What you will do\nBuild a large-scale, highly performant self-service data platform using cutting-edge technologies\nMinimize technical debt by continuously revisiting and finding improvements to existing implementations\nMaintain and rethink existing datasets and data pipelines to optimize performance and accessibility\nDrive internal tooling and process development to continuously increase data quality and constantly improve the engineering experience of our users\nImplement effective data governance across the business\nCollaborate with other engineers, data analysts, data scientists, and decision makers to tackle data challenges and gain novel insights\nMentor and coach other engineers on data engineering best practices\nBe technical leader within the team you work with and across Storytel in general\n About You\n3+ years of professional experience as a Data Engineer or Software Engineer, with hands-on coding experience in Python and SQL\nSeveral years of experience in design and architecture of scalable and reliable complex systems\nStrong background in data pipelining, distributed data processing, software engineering components, and data modeling concepts\nExperience with cloud infrastructure (GCP) and cloud data warehousing, preferably BigQuery.\nExperience with designing and developing pipelines and data integration solutions using ELT tool.\nExperience with Infrastructure as Code and remote configuration tools\nExperience in operating, maintaining and ensuring quality of production grade software\nExperience in data privacy and sensitive data management\nYou have strong communication skills to partner with stakeholders effectively\nYou have an innovative mindset and are always striving for improvements, making sure that each workday is value driven, collaborative and rewarding.\nYou embrace knowledge sharing and have an eagerness to continuously learn and develop yourself and team\n  Apply to this job","247":"Our mission is to connect and optimize the world\u2019s commerce. That means the whole world. So we\u2019re determined to nurture our culture of meritocracy where everyone can thrive, no matter what we look like, where we\u2019re from, how we grew up, whom we love, the nature of our faith, or how our bodies or minds work. We\u2019re committed to achieving equity in treatment and opportunity for everyone, where people are judged on the merits and quality of their work.\nIt all starts with people. Inside every company, behind every brand\u00ad - while business success is often measured in profit, it has always been powered by people. We firmly believe people are the heart of any organization - including our own. That\u2019s why a career here provides much more than simple pay and perks. We\u2019re dedicated to empowering people, solving tough problems, and helping careers flourish inside and out. \n  Position Summary:\nThe Business Intelligence Engineer will be a critical contributor to enabling the Business Intelligence Team to identify opportunities for CommerceHub to use its own data, as well as data provided by third parties, to generate additional company revenue and derive valuable industry insights.\n  Responsibilities:\nDesign and build dashboards for internal stakeholders and externally facing products\nDevelop new and maintain existing reports using Looker, Tableau and PowerBI\nWork with stakeholders including Product, Marketing, Finance and Customer Support to design dashboards and reports\nParticipate in full development life cycle including requirements development, implementation, peer review, source control, automated testing, deployment, and operations\nEnforce corporate policies around the evolution and enforcement of industry data standards, data governance and best practices\n  Requirements:\nBachelor\u2019s degree or higher and\/or equivalent work experience\nStrong analytical skills related to working with both structured and non-structured datasets\nStrong data modeling skills and experience working with Star Schemas\nStrong working knowledge of highly scalable data warehouse products such as Amazon Redshift, Snowflake\n2+ years\u2019 experience with data visualization tools such as Looker, Tableau, PowerBI\nExperience working in Retail and Looker BI visualization tool is a plus\n2+ years\u2019 experience with SQL coding languages such as TSQL, LookML, PostgreSQL, Athena\n2+ years\u2019 experience with scripting languages such as Python and R\nExceptional written and verbal communication skills\nComfortable communicating across all levels of management\nAbility to prioritize tasks and work independently\nExcellent analytical, decision-making, and problem-solving skills\nProven ability to work in a rapidly changing environment with keen attention to detail\n  What it\u2019s like to work at ChannelAdvisor, a CommerceHub Company\nWe take a whole-person approach to engage and support our global team. We believe the diversity of our global team is an advantage. If you\u2019re curious, innovative, determined, and customer-focused, then you\u2019ll love the challenge and rewards of collaborating as a team to help our customers win. We offer competitive compensation programs that recognize your hard work and results. Because when our customers win, we win.  And when we win, you win.\nWe work to create an environment where everyone who is committed, works hard, and delivers results can thrive and grow. You can connect with one of our employee resource groups and support our diversity, equity and inclusion task force, network with like-minded team members, and showcase your leadership skills. \n  Benefits: \nEnhanced Private Medical Insurance and a Health Cash Back Plan \nCompetitive time off package with 25 Days of PTO, 9 Holidays, 2 Wellness days and 1 Give Back Day\nFlexibility to choose where you work - at home, in the office, or both!\nAccess to tools to support your wellbeing such as the Calm App, MoveSpring and an Employee Assistance Program\nProfessional development stipend and learning and development offerings to help you build the skills and connections you need to move forward in your career\nCharitable contribution match per team member\n  ChannelAdvisor, a CommerceHub Company, is an Equal Employment Opportunity Employer. We celebrate diversity and are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need.","248":"Have you ever ordered a product on Amazon and when that box with the smile arrived you wondered how it got to you so fast? Have you wondered where it came from and how much it cost Amazon to deliver it to you? If so, the Worldwide (WW) Amazon Logistics, Last Mile team is for you. We manage the delivery of tens of millions of products every week to Amazon\u2019s customers, achieving on-time delivery in a cost-effective manner to deliver a smile for our customers.\n\nAmazon Logistics is looking for a customer focused, innovative and technically skilled Business Intelligence Engineer to drive effective performance measurement and management, innovation and execution in last mile delivery. This position will be responsible for building out analysis and visualization tools and processes\u2019 to support our growing Amazon Logistics business in Japan and Worldwide.\n\nThe successful candidate will be able to effectively retrieve, integrate, visualize and present critical data to improve the efficiency of the package delivery network, and enable efficient management of a large global logistics system. This individual will work with technical and business teams to optimize planning, execution, process improvement and track progress against goals. This role requires an individual with excellent analytical abilities as well as excellent business acumen and comfort with technical teams and systems. The successful candidate will be a self-starter comfortable with ambiguity, with strong attention to detail, and enjoy working with large scale of data.\n\n\n\u3010More Information\u3011\nLast Mile: https:\/\/www.amazon.co.jp\/b?node=5637343051\nBIE Job: https:\/\/www.amazon.co.jp\/b?node=5609906051\nTokyo office: https:\/\/www.amazon.co.jp\/b?node=5589794051\n\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, visit https:\/\/www.amazon.jobs\/disability\/jp\n\nKey job responsibilities\nPartner with internal stakeholders across multiple teams, gathering requirements and delivering end to end solutions.\nPartner with Data Engineering and Software Development Engineers to prioritize and define AMZL data and BI development needs.\nWork with in-house scientists, global supply chain, transportation and logistics teams to identify new BI capabilities and projects.\nConduct deep dive investigations into operations execution and business problems, identify opportunities, and lead or support implementation.\nAnalyze and visualize large scale geo-spatial logistics and transaction data to articulate user behavior or delivery process problems, and output solid analysis report with recommendation.\nLiaise between Planning, Analytics and Operations teams to achieve actionable insights into current performance, and conduct ad hoc investigations into future improvements or innovations.\nDevelop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting.\nBasic Qualifications\n\nBachelor's degree in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field.\n2+ yrs of experience in analytic skills to integrate data into operational planning.\nAdvanced level of SQL and ETL; ability to write and tune complex SQL scripts and ETL development.\n2+ yrs of experience in Operational Excellence initiatives, working with data warehousing and data quality (MySQL and Redshift).\n2+ yrs of experience in visualization tools such as GIS visualization, Tableau, QlikView, QuickSight\nBusiness Level of English (written & verbal).\n\nPreferred Qualifications\nMBA\/MS in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field.\nBusiness level of Japanese.\n3+ years of relevant work experience building end to end solutions to performance measurement and process improvement in a transportation, logistics or supply chain setting.\n3+ yrs of experience implementing basic software solutions to automate data source, visualization and\/or data modeling application.\nProject Management experience and\/or Tech product management experience.\nOrganized, operational mindset with track record of delivering projects within scope, time, budget and quality.\nAbility to understand operations at a detailed, practical level and also to think big \/ strategically.\n\n\nPlease check the website below for measures to eliminate unwanted second-hand smoking in each facility:\nhttps:\/\/www.amazon.jobs\/en\/landing_pages\/passivesmoking\n\u5c31\u696d\u306e\u5834\u6240\u306b\u304a\u3051\u308b\u53d7\u52d5\u55ab\u7159\u3092\u9632\u6b62\u3059\u308b\u305f\u3081\u306e\u63aa\u7f6e\u306b\u95a2\u3059\u308b\u4e8b\u9805\u306b\u3064\u3044\u3066\u306f\u3001\u4e0b\u8a18\u30ea\u30f3\u30af\u5148\u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002\nhttps:\/\/www.amazon.jobs\/jp\/landing_pages\/passivesmoking\n\nThe salary information can be provided individually prior to the 1st interview\n\u8cc3\u91d1\u306b\u95a2\u3059\u308b\u6761\u4ef6\u306f\u3001\uff11\u6b21\u9762\u63a5\u306e\u524d\u306b\u500b\u5225\u306b\u3054\u6848\u5185\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059","249":"Company Description\nTransforming businesses, driving success: SmarTek21\nSmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev\/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients\nJob Description\nSmarTek21 is looking for a hands-on architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.  \nQualifications\n\u2022 Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python.\n\u2022 Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks.\n\u2022 Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP).\n\u2022 Solid understanding of enterprise strategies for data security and data governance.\n\u2022 Experience in practice development, architecture, and consulting or product development.\n\u2022 Experience delivering data analytics projects and architecture guidelines.\n\u2022 Experience in engaging with enterprise architects. Non-technical Skills:\n\u2022 Excellent oral and written communication and presentation skills.\n\u2022 Ability to handle ambiguous situations and take trade-off decisions.\n\u2022 Strong problem solving and analytical skills to break down complex problems into smaller components.\n\u2022 Ability and willingness to perform in a team environment.\nRequirements:\n\u2022 Understand prospect\/customer\/partner technology landscape.\n\u2022 Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation.\n\u2022 Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers\/partners.\n\u2022 Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints.\n\u2022 Collaborate with the engineering team to create proof-of-concepts (POCs).\n\u2022 Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices.\n\u2022 Demonstrate business value of proposed solutions or current products to prospects and customers.\nSalary Range: $200,000-$215,000 (may be subject to change outside of WA State)\nAdditional Information\nWhat Is in It for You:\nPaid Time off \u2013 start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service.\nPaid Holidays - 8 paid holiday a year in addition to your PTO.\nHealth Insurance for FT employees \u2013 we pay 100 % premium of medical, dental and vision.\nHealth Insurance for FT employee\u2019s family \u2013 we pay 50% of premium for medical, dental and vision for dependents.\n401(k) \u2013 we administer 401(K) retirement contribution for FT employees.\nLife Insurance\/Short Term and Long-Term Disability \u2013 at no cost to you\nOpportunities for internal promotions\/career advancement\nFamily friendly work hours (closed on weekends and paid holidays)\nSmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and\/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class.","250":"Company Description\nWriting the future. Together. \n\nAvaloq is a value driven, fast-paced financial technology and services company and we are committed to developing the banking solutions of tomorrow. \n\nBy joining Avaloq, you\u2019ll become a key part of our effort to power the digital transformation of the financial services industry. Our ambition is big and bold \u2013 to provide full end-to-end digital solutions by combining our leading efficiency with a flexible, responsible digital user experience. Headquartered in Zurich, Avaloq has over 2,000 employees globally. More information is available at www.avaloq.com  \nJob Description\nWe are the Analytics domain teams helping financial institutions to easily adopt and use, as well as gather and analyze data from our Avaloq products, within a wide ecosystem. We believe our colleagues comes first, thinking different is an asset and innovation comes by putting customer experience first in our design thinking.\nWe are looking for a strong resource who has both business acumen and technical experience, to become part of these domains, driving the interactions and collaboration with existing and potential clients.\nYour mission\nClosely collaborate with the Product Owner, Business Analysts and other Software Engineers distributed worldwide\nImplement Data Pipelines in Java\nImplement Data Analytics -  Big data exploration, extraction, processing and ingestion to different SQL and NonSQL storage systems\nDesign, develop and maintain new\/existing solutions within the team\u2019s responsibility\nImprove and optimize existing functionalities\nDevelop and maintain automated tests\nTake ownership and responsibility for your area of expertise\nEnsure high quality on the delivery and efficient communication\nQualifications\nWhat you need\nUniversity degree in Computer Science\/Physics\/Engineering\/Mathematics or comparable education\nAt least 2-3 years of work experience in the fintech or financial sector\nPractical experience implementing container platforms, preferably OpenShift \/ Kubernetes\nFamiliarity in streaming technology like Kafka, Kafka Connect\nAnalytical, problem solving and conceptual skills\nCompetent in one or more programming and scripting languages\nFluent in spoken and written English\nExperience in Big Data \/ Data Analytics productive environments, using technologies such as distributed SQL engines \/ file systems\nExperience in Stream Processing, Streaming Data, and Data Pipelines\nYou will get extra points for\nExperience with Distributed SQL engines\nExperience in implementing Microservices\nHands-on experience with Snowflake\nUnderstanding of data visualization using software like Tableau, Qlik, PowerBI, Yellowfin\nPractical experience on Infrastructure as code like Terraform\nBanking know-how or experience working on financial solutions\nKnowledge of JavaScript and Python\nWork Experience in team with Agile Scrum\nExpertise in data warehousing, modelling and data management tools\nKnowledge and experience on Avaloq Banking Suite\nAdditional Information\nWhat you can expect:\n\nIt\u2019s all about getting to know our teams and to e-meet with us. We will use video interviews to give you the opportunity to meet your future colleagues and get a first insight into Avaloq\u2019s unique culture.\n\nWhat we will offer you\n\nWe have a hybrid work week model, giving colleagues flexibility in how they work, as well as ensuring we create our unique Avaloq culture in our office locations. Our base salaries are competitive and you can be recognised for outstanding effort with an extraordinary achievement reward \u2013 the pinnacle of recognition. Avaloq aims to share its success with all its colleagues by paying out \u201cSuccess Share Units\u201d depending on its performance in a given year.\nAt Avaloq we embrace diversity, we embrace difference. We are whole-heartedly committed to equal employment opportunities and we foster an inclusive culture where everyone\u2019s' contributions are valued and their voices are listened to. We hire, compensate and promote regardless of origin, age, sexual orientation, gender identity or any other fascinating characteristics that make us different. Please note that our job descriptions are intended to be written in an inclusive and gender neutral language.\n\nDon\u2019t be shy \u2013 apply!\n\nPlease only apply online, preferably with pdf documents.","251":"Description de l'entreprise\nAvec plus de 30 ans d\u2019histoire, ALTEN accompagne en France et dans le monde entier la strat\u00e9gie de d\u00e9veloppement de ses clients dans les domaines de l\u2019innovation, de la R&D et des syst\u00e8mes d\u2019information. \u00catre la maison des ing\u00e9nieurs, telle est l'ambition d'ALTEN. \nDescription du poste\nRattach\u00e9(e) aux consultants ALTEN, vous serez amen\u00e9(e) \u00e0 travailler chez les clients finaux et \u00e9voluerez au sein d\u2019\u00e9quipes pluridisciplinaires.\n Nous recherchons pour l'un de nos clients Grands Comptes, un(e) Data Analyst qui sera charg\u00e9(e) des missions suivantes :\n Accompagnement et suivi projets m\u00e9tiers :\nCollaborer avec les \u00e9quipes op\u00e9rationnelles m\u00e9tiers pour conna\u00eetre le contexte d\u2019intervention ;\nCollecter et manipuler les donn\u00e9es ;\nR\u00e9aliser des \u00e9tudes statistiques et analytiques ;\nValoriser l\u2019information, la restituer et la pr\u00e9senter aux clients\n D\u00e9ploiement de reportings :\nConstruire des requ\u00eates SQL\nImpl\u00e9menter des dashboards sous Power BI\nMigrer et transformer des reportings existants (Power BI, Dataiku)\n De mani\u00e8re g\u00e9n\u00e9rale, vous \u00eates aussi amen\u00e9 \u00e0 assurer la Data Quality en suivant les anomalies, en validant les corrections...\nQualifications\nDes fondamentaux th\u00e9oriques acquis en cursus \u00e9cole d\u2019ing\u00e9nieurs informatique ou universitaire avec une sp\u00e9cialisation IT, avec une exp\u00e9rience d\u2019au minimum 3 ans post-dipl\u00f4me sur des fonctions Analyse\/Dataviz.\nConnaissance solide d\u2019au moins un outil de visualisation : Power BI\nComp\u00e9tence av\u00e9r\u00e9e en Gestion de Projets\nInformations suppl\u00e9mentaires\nEn plus de vos missions remplis de challenges au quotidien, vous pourrez entreprendre, \u00eatre form\u00e9 et surtout certifi\u00e9. Tracez votre trajectoire de carri\u00e8re avec votre manager de proximit\u00e9 et r\u00e9v\u00e9lez le meilleur de vous-m\u00eame !\n\nR\u00e9mun\u00e9ration attractive : salaire fixe + variable, participation, mutuelle, TR, prestations CE.\nCe projet est une opportunit\u00e9 unique de toucher plusieurs domaines concurrents au sein d\u2019un projet. Vous disposerez de l\u2019appui d\u2019une communaut\u00e9 d\u2019experts pour mener votre mission !\nALTEN entreprise handi-accueillante.\nPoste \u00e0 pourvoir en CDI.","252":"Why you want to join us\nHere at Datacom, we connect people and technology in order to solve challenges, create opportunities and discover new possibilities for the communities we live in. We\u2019ve maintained our local family feel whilst expanding globally, across Australia, ASIA, US and the UK. Working together, we strive to imagine the possible, challenge the status quo and put forward fresh, diverse thinking. We offer our staff a competitive salary package, fantastic perks and benefits like healthcare, life insurance, discounts at local retailers and a supportive, flexible working environment. Are you ready to make a difference in Australasia's largest homegrown technology company? Apply within today!\nAbout the role\nThe Group Data BI Developer is a position with the Group Data & Analytics team within Datacom Group focused on designing and developing reports, dashboards and analytics outcomes on the reporting and analytics platform at Datacom, and providing reliable, coherent information. The role is responsible for the requirements, design, implementation, maintenance and stability of the reports. The role includes close collaboration with other development and support roles in the team using best practice data management life cycles. The role reports into the GM Analytics.\nRole Responsibilities\nDesign, development, test and support of standard analytics and reporting artefacts, including but not limited to Power BI reports, dashboards, paginated reports, Excel pivots, etc.\nFollow best practices as provided by the GM Analytics and CDO to extend, maintain and support the enterprise reporting platform so that it can provide reliable, timely, performant and accurate information to business users.\nProvide assistance and support to all Datacom users with respect to the reporting platform, including internal users who are using and manipulating data\nAdhere to report design and quality best practices as defined, using modern UX standards and conforming to Kimball best practices\nSupport and further a group wide awareness of the benefit of analytics and centralized reporting and see encouraging signs of adoption of business intelligence and analytics.\nIncreasing business confidence in the accuracy, veracity, reliability and value of data to help guide business decision making and exploit commercial opportunities with our data.\nSkills Requirements\nStrong communication skills working in a team environment. Will be interacting with business, corporate users and stakeholders throughout the enterprise across New Zealand and Australasia.\nRequires strong technical skills using the technologies in use (Power BI, Analysis Services, DAX, MDX, Paginated Reporting Services SSRS, etc.).\nDemonstrable experience designing, implementing and managing complex reporting environments in a corporate context\nRequires strong technical skills using the technologies in use (SQL Server, Azure Data Factory, SQL Server Integration Services, BIML, DETL Framework).\nAppropriate tertiary education in Business Information Systems and Computer Science, as well as strong background and knowledge with data transformation and data management concepts. 5 years or more experience in the field.","253":"Company Summary:\nTessera Therapeutics is pioneering Gene Writing\u2122\u2014 a new biotechnology designed to offer scientists and clinicians the ability to write small and large therapeutic messages into the genome, thereby curing diseases at their source. Gene Writing holds the potential to become a new category in genetic medicine, building upon recent breakthroughs in gene therapy and gene editing while eliminating important limitations in their reach, utilization, and efficacy. Tessera Therapeutics was founded by Flagship Pioneering, a life sciences innovation enterprise that conceives, resources, and develops first-in-category companies to transform human health and sustainability.\nPosition Summary:\nTessera is seeking a talented and motivated Computational Biologist to join our expanding Data Sciences team.  You will tackle challenging bioinformatics and computational biology problems to advance our understanding of Gene Writing and help accelerate programs to the clinic.  You will contribute scientific, technical, and leadership expertise to a multidisciplinary team, emphasizing conceptualization, experimentation, data analysis, presentation, and strategic planning. \n  Key Responsibilities:\nWork collaboratively with our platform and Biology teams to enable scientific discovery and progression through data analysis, data visualization and data integration\nBuild and implement data analysis pipelines and storage solutions for various forms of sequencing including Amplicon sequencing, long-read sequencing (Pac Bio) and related methods\nIdentify and acquire relevant public and third-party \u2018omics data and perform integrative data analyses to generate insights that address strategic biological questions critical to Tessera\u2019s core mission.\nDevelop computational methods that provide project support to gene therapy project teams\nOperationalize data analysis aspects of relevant molecular assays to maximize the design, build, test cycle for platform and pipeline candidates\nStructure and store data to enable data reuse, data mining and machine learning\nCreate compelling data visualizations for internal and external presentations\n\n  Basic Qualifications:\nPh.D.\/M.S. in Computational Biology, Bioinformatics, or related quantitative discipline. \n3+ years of industry experience in discovery research.\nProficient with experimental design, data processing, statistical analysis, and bioinformatics analysis\/reporting of next-generation sequencing data.\nExperience analyzing gene therapy, gene editing, in vitro\/vivo assay, genetics, genomics and cell biology data\nExperience using comparative genomics as a tool for gene discovery\nStrong grounding in biology or medicine\nStrong data visualization skills and experience\nFluency in one or more programming languages with bioinformatics applications (R, Python).\nTrack record of success working in a fast-paced, cross-functional, and rapidly growing organization.\nOutstanding written and verbal communication skills, ability to work with colleagues from diverse scientific backgrounds and cultures.\n  Preferred Qualifications:\nExperience with recent advances in gene therapy and development of gene editing platforms as therapeutics.\nStrong competency in sequence analysis methods including gene identification, functional annotation, or comparative genomics.\nFamiliarity with short and long read next-generation sequencing platforms (Illumina, PacBio, Nanopore).\nProficiency in handling large scale sequencing data in a cloud environment (AWS preferred).\nProficiency in statistics and machine learning.\nExperience in virology or mobile genetic elements.\n  More About Flagship Pioneering\nFlagship Pioneering has conceived of and created companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune\u2019s \u201cChange the World\u201d list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies. \nFlagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. \nRecruitment & Staffing Agencies:  Flagship Pioneering and its affiliated Flagship Lab companies (collectively, \u201cFSP\u201d) do not accept unsolicited resumes from any source other than candidates.  The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering\u2019s internal Talent Acquisition team.   Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto. \n ","254":"Company Description\nOur brand Deutsche Telekom IT Solutions Slovakia entered the life of Ko\u0161ice region in 2006 under the name of T-Systems Slovakia and ever since has been inextricably linked with the region when became one of the founding members of Ko\u0161ice IT Valley. We have managed to grow from scratch to the second largest employer in the eastern part of the country with more than 3900 employees. Our goal is to proactively find new ways to improve and continuously transform into the type of company providing innovative information and communication technology services.\nJob Description\nPurpose\nWe are seeking a skilled and experienced Power BI Developer with an innovative mindset to join our Finance International Business Intelligence Team working in a Scrum environment. The ideal candidate will have the opportunity to work remotely from anywhere in Slovakia and will be responsible for designing and implementing data-driven solutions in a Microsoft BI cloud environment to support business intelligence needs across multiple foreign countries, with a focus on automation and implementing predictions, artificial intelligence and self-service BI in the future. If you have a passion for data analysis and visualization, are comfortable working in a Scrum environment, have an innovative mindset, and possess the required skills and experience, we would love to hear from you! Join our Finance International BI Team and work from the comfort of your own home in Slovakia.\nKey accountabilities\nDevelop and maintain Power BI reports, dashboards, and data models within the Microsoft Azure cloud environment, using Power BI Desktop and Power BI Service\nCollaborate with stakeholders to gather requirements and provide insights and recommendations based on data analysis, using SQL, data warehousing concepts, and data modeling techniques\nImplement data visualization techniques to effectively communicate complex data concepts, using DAX language and advanced Power BI visualizations such as tables, matrices, pie charts, bar charts, line charts, scatter plots, maps, and more\nEnsure data accuracy, integrity, and security in all Power BI solutions by implementing data validation and data quality checks\nDevelop and maintain technical documentation and training materials, including user guides, process flows, and training presentations\nStay current on new Power BI features and updates and apply them to ongoing projects in a Scrum environment, while adhering to project timelines, budgets, and quality standards\nSupport automation of processes and contribute to the implementation of predictions and artificial intelligence in future projects, using machine learning algorithms and predictive analytics\nQualifications\nEducation\nBachelor's degree in Computer Science, Information Technology, or related field\nExperience\nAt least 2-3 years of experience in Power BI development and data visualization, with a proven track record of delivering high-quality, data-driven solutions that meet business needs\nIT Technical Skills\nExperience with Power BI Desktop, Power BI Service in a Microsoft Azure environment\nProficient in SQL and data warehousing concepts\nExperience with data modeling and DAX language, with the ability to write complex DAX expressions and implement data transformation techniques\nSoft skills\nStrong problem-solving and analytical skills, with the ability to understand and interpret complex data and identify patterns and trends\nExcellent communication and interpersonal skills, with the ability to effectively communicate with both technical and non-technical stakeholders\nAbility to work independently and as part of a team in a remote and Scrum environment, with the ability to manage multiple tasks and priorities\nInnovative mindset with a passion for exploring and implementing new technologies and solutions, and a strong interest in machine learning and artificial intelligence\nLanguages\nEnglish \u2013 Upper intermediate (B2)\nGerman - Advantage \u2013 Intermediate (B1)\nAdditional Information\nBenefits\nWe believe in balance between work and personal life. An attractive and extensive work-life balance portfolio guarantees lasting motivation for employees and thus a better quality of life, promotes physical and mental well-being and contributes to a positive work environment. All this with the aim of providing more freedom in reconciling work, career growth, private life and individual lifestyle. Therefore we offer to our employees over 25 different benefits to improve their personal and professional life in these areas:\nFinancial benefits\nBenefits with focus on learning and development\nBenefits with focus on health and sport\nBenefits with focus on family and work \u2013 life balance\nOther benefits\nFor more information about our benefits click to Benefits\nSalary\nFinal salary is negotiable.\nWe are offering base salary depending on seniority level and previous experience of candidate. In addition to base salary we provide variable part and other financial benefits. Base salary will not be lower than 2000 - 2650 \u20ac \/brutto.\nAdditional information\n* Please be informed that our remote working possibility is only available within Slovakia due to European taxation regulation.","255":"As part of the development team create and DEVELOP reports that meet agreed specification\/design\nSupports a high performing culture that achieves results by:\nDeveloping reports according to functional and technical design specifications and maintain a \u201ccommon sense\u201d approach that serves to recognise potential technical gaps and provide insight into closing them whilst adhering to Fantastic Furniture IT standards and conventions.\nDeveloping, configuring, and testing Power BI reports\nSupporting and resolving production issues for developed reports.\nCreating and update schema\u2019s, views, stored procedures, T-SQL statements with a \u201cbest practices\u201d approach to keys, indexes and relationships in Microsoft SQL Design documentation must be updated to include any design changes made throughout the development process.\nLearning new technologies and adding valuable suggestions.\nAs part of the IT team DEVELOP & DEPLOY reports & SQL queries using Power BI or ZAP with SQL\nSupports a high performing culture that achieves results by:\nDeveloping reports using Power BI connected to on-prem SQL, Azure SQL, Azure data lake etc to meet business requirements.\nDevelop and configure reports\/paginated reports\/dashboards\/visuals using Power BI.\nSolid working experience in Power BI tool.\nGood understanding Azure services such as Azure SQL, Azure data lake.\nGood understanding of security and governance.\nGood understanding of data modelling and data warehousing concepts\nGood understanding SQL server components such as database\/stored procedures\/indexing\/jobs\/SSIS etc.\n\nRequirements\nEssential\nDegree in Information Technology, expert in SQL, Reporting platform, Data warehousing.\nVery strong and solid working experience on Power BI\nMinimum 5 - 7 years hands-on development experience in designing & configuring reports in Power BI & SQL\nMinimum 5 - 7 years\u2019 experience in writing SLQ queries, transformations for reports, dashboards, visuals in Power BI.\nExperience in SQL (stored procedure, SSAS, Views, trigger, index, SQL Jobs etc)\nWorking experience and good understanding on Cloud environment using Azure services\nSolid understanding of the SDLC & Agile Scrum\nDesirable\nExperience in Retail business\nExperience in Power Apps & Power Automate\nExperience with Azure services & Azure Dev-Ops\nBenefits\nStandard Job Benefits:\n- HMO on Day 1\n- Temporary Work from Home Set Up\n- Paid Time-Off\n- Quarterly Sick-Leave conversion\n- Paid Government-Mandated Benefits (SSS, PHIC, Pag-IBIG)\n- Equipment provided\n\nStandard Job Highlights:\n\u2022 Work-life balance\n\u2022 Career growth and development opportunities\n\u2022 Stable organization and industry leader\n\u2022 Collaborative and fruitful company culture\n\nSALARY RANGE: PHP 100,000 \u2013 160,000","256":"Amazon Music reimagines music listening by enabling customers to unlock millions of songs, podcast episodes, and thousands of curated playlists and stations with their voice. Amazon Music provides unlimited access to new releases and classic hits across iOS and Android mobile devices, PC, Mac, Echo, and Alexa-enabled devices including Fire TV and more. With Amazon Music, Prime members have access to ad-free listening of 2 million songs at no additional cost to their membership. Listeners can also enjoy the premium subscription service, Amazon Music Unlimited, which provides access to more than 75 million songs and the latest new releases. Amazon Music Unlimited customers also now have access to the highest-quality listening experience available, with more than 75 million songs available in High Definition (HD), more than 7 million songs in Ultra HD, and a growing catalog of spatial audio. Customers also have free access to an ad-supported selection of top playlists and stations on Amazon Music. All Amazon Music tiers now offer a wide selection of podcasts at no additional cost, and live streaming in partnership with Twitch. Engaging with music and culture has never been more natural, simple, and fun. For more information, visit amazonmusic.com or download the Amazon Music app.\n\nLove music? The Amazon Music team is looking for a brilliant, creative, and passionate professional to join our Business Intelligence team. Responsibilities include: developing customer insights and segmentation to enhance and drive acquisition and engagement marketing, optimization of Amazon Music signup funnels on all devices and platforms, evaluation and optimization of marketing and content, and developing self-serve analytical tools for use by the Digital Music product and business teams.\n\n\n\nKey job responsibilities\nIn this role, you will work to create and surface critical datasets to the Music org for self-service analysis and reporting in order to facilitate business and product team ability to identify marketing, product and content opportunities. You will help lead the way in defining and optimizing how we measure and value customer acquisition and engagement.\n\nOur ideal candidate has a combination of strong technical skills, superb analytical capabilities, outstanding business insight, and excellent verbal and written communication skills. As a member of our team, you will have the opportunity to work with one of the largest and most complex data warehouses in the world to gather insights using data from across Amazon. You will work closely with the marketing, merchandising, product, and development teams to solve unique problems and find answers to questions that require tenacious problem solving and creativity.\n\nData-driven decision making is at the core of Amazon\u2019s culture, and your work will have a direct impact on decision making and strategy for the Amazon Music Team.\nWorking with product management and engineering to identify and scope analysis of most common customer behavioral questions.\nPartnering with our Data Engineering team to enhance data infrastructure, data availability, and broad access to customer insights made available through .\nJoin large and growing BI\/ Science team to leverage extensive music listening to better understand customers and contribute to product and marketing strategy.\nDefining and developing tests to identify the best way to reach, convert, and retain customers.\nReporting to senior leadership and the team at large, on customer, product and marketing insights and trends.\nProactively developing new metrics and studies to quantify customer behavior.\nPartnering with Alexa teams to unlock insights on our voice platform.\nQuickly build a thorough understanding of the Digital Music industry, its seasonality and global business trends and continually monitor the impact of important industry developments.\n\n** Please note this role can sit either in SFO or SEA\nBasic Qualifications\n\n- Bachelor\u2019s degree in a quantitative area such as math, statistics, computer science, engineering or equivalent experience\n- 5+ years of relevant experience in analytics, business intelligence, data engineering, or related field\n- 2+ years of relevant work experience in a role requiring application of analytic skills\n- Proficient in SQL working with large-scale, complex datasets from multiple sources\n- Experience with data modeling, ETL development, and data warehousing\n- Advanced skills in Excel as well as additional data visualization tools like Tableau, Amazon QuickSight or similar BI tools\n- Advanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as required\n\nPreferred Qualifications\nMBA or Master\u2019s degree in Computer Science, Engineering, Statistics, Mathematics or related field\nExpert in writing and tuning SQL scripts\nExperience working in large data warehouse environments\n5+ years of experience in a BIE or data engineer role with a technology company\nStrong verbal\/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams\nAbility to deliver on ambiguous projects with incomplete or dirty data\n\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https:\/\/www.amazon.jobs\/en\/disability\/us.\n\nPursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\n\n\nOur compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $104,300\/year in our lowest geographic market up to $202,800\/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and\/or other benefits. Applicants should apply via our internal or external career site.","257":"Company Description\nAt Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people\u2019s lives. Our promise to our associates is rock-solid: We grow together, we enjoy our work, and we inspire each other. Welcome to Bosch.\nThe Robert Bosch GmbH is looking forward to your application!\nJob Description\nBe part of our team and develop novel electrically actuated braking systems for future product generations. Together with experts from R&D and from the business divisions you are involved in the predevelopment process from the specification of requirements until the tryout of prototypes.\nYour field of responsibility is the thermal design, modeling and assessment of components as well as the analysis of prototypes regarding their thermal characteristics.\nFurthermore, you are responsible for the identification, creation as well as evaluation of concepts for heat transfer and thermal management in electrified mobility.\nThe modeling and simulation of heat transfer by using common simulation tools (FEM\/CFD\/network models) is part of your responsibility as well.\nAlso, you are working on the conception of application-specific simulation tools and models for electrical mobility including electrically actuated brakes.\nYou plan, execute and evaluate thermal validation experiments on component prototypes including the selection of suitable measurement techniques.\nLast but not least, you cooperate with internal and external research partners, e.g. in publicly funded projects (pfp).\nQualifications\nEducation: Master in Mechanical-, Computational- or Electrical Engineering, Physics or comparable, a PhD is beneficial\nExperience and Knowledge: profound knowledge in thermal management technology, applications and systems, experience in the simulation of heat transfer by using common simulation tools and\/or knowledge of experimental heat transfer testing methods including the validation of simulations, programming and scripting experience (C++, Python etc.) is beneficial\nPersonality and Working Practice: team player, communicative, independent, analytical as well as structured with good organizational skills, cooperative, team-, solution-, and outcome-oriented\nEnthusiasm: open and agile mindset to create as well as drive new ideas and transfer them to innovative products\nLanguages: excellent communication skills in German and English\nAdditional Information\nwww.bosch.com\/research\nhttps:\/\/www.bosch-ai.com\nPlease submit all relevant documents (CV, letter of motivation, certificates, transcript of records).\nDiversity and inclusion are not just trends for us but are firmly anchored in our corporate culture. Therefore, we welcome all applications, regardless of gender, age, disability, religion, ethnic origin or sexual identity.\nNeed support during your application?\nDiana St\u00fcber (Human Resources)\n+49(711)811-10356\nNeed further information about the job?\nChristine Meyer (Functional Department)\n+49(711)811-54929","258":"Description de l'entreprise\nChez TRIGO, nous sommes convaincus que la Qualit\u00e9 est essentielle \u00e0 la performance de l\u2019Industrie et \u00e0 sa durabilit\u00e9. C\u2019est pourquoi nous d\u00e9ployons des solutions qui optimisent les productions industrielles, \u00e0 l'\u00e9chelle mondiale.\nNous sommes 10 000 collaborateurs dans 26 pays, offrant un portefeuille complet de services \u00e0 de nombreuses cha\u00eenes d'approvisionnement et de fabrication. De l'inspection et la retouche au conseil et \u00e0 l\u2019ing\u00e9nierie, nous nous engageons pour la qualit\u00e9 de nos partenaires industriels. Nous nous appuyons sur nos solutions technologiques en d\u00e9veloppement, bas\u00e9es sur l'industrie 4.0, l'analyse de donn\u00e9es et l'intelligence artificielle.\nAu sein d'une entreprise \u00e0 l'esprit start-up et \u00e0 la culture internationale, vous contribuerez et am\u00e9liorerez l'efficacit\u00e9 de nombreuses chaines de montage et d\u2019assemblage. Gr\u00e2ce \u00e0 des missions engageantes et responsabilisantes, vous constaterez l'impact de vos efforts. Rejoignez une \u00e9quipe engag\u00e9e qui vise l'excellence !\nDescription du poste\nAu sein de l\u2019\u00e9quipe digital France en charge de toutes les solutions digitales (terrain, support et client), nous t'offrons la possibilit\u00e9 de participer en autonomie \u00e0 des projets d'innovation monde.\nTu travailleras en collaboration constante avec ton manager, le responsable digital France.\nTes principales missions seront :\n- La gestion de projet :\nD\u00e9finition des besoins des m\u00e9tiers (visite sur sites et ateliers de travail)\nD\u00e9finition d\u2019une solution (d\u00e9veloppement interne, externe, d\u00e9finition d\u2019un nouveau process ou d\u2019une nouvelle m\u00e9thode de travail)\nAnimation des r\u00e9unions de suivi de projet (r\u00e9union de travail avec l\u2019\u00e9quipe op\u00e9rationnelle, et r\u00e9union de suivi avec l\u2019\u00e9quipe projet)\nExemples de projets : mise en place d\u2019une application de contr\u00f4le de pi\u00e8ces via scan, cr\u00e9ation de power BI pour tous m\u00e9tiers, cr\u00e9ation d\u2019une application de suivi d\u2019activit\u00e9 pour le suivi du co\u00fbt de main d\u2019\u0153uvre, d\u00e9finition de outils digitaux aux postes \u00e0 d\u00e9ployer sur la France enti\u00e8re, lancement de projets de RPA, etc.\n- La partie technique : En fonction de tes app\u00e9tences et de besoins, tu seras guid\u00e9 sur l\u2019apprentissage de la suite Power Platform de Microsoft (Power Apps, Automate et Power BI essentiellement) afin de r\u00e9pondre directement aux besoins de nos clients internes via la cr\u00e9ation d\u2019applications et de rapports simples\n- Le support : En soutient de l\u2019\u00e9quipe Digital, tu accompagneras et formera les utilisateurs aux nouveaux rapports et applications cr\u00e9\u00e9es. Tu participeras \u00e9galement \u00e0 la cr\u00e9ation des diff\u00e9rents contenus (guides utilisateurs, processus, etc.) sous PowerPoint ou SharePoint.\nQualifications\nDe formation minimum Bac+5, vous pr\u00e9parez un diplome d'ing\u00e9nieur.\nVous avez une app\u00e9tence pour le digital et la gestion de projet.\nEn plus de savoir maitriser le pack office (word, excel...), vos qualit\u00e9s relationnelles et manag\u00e9riales, ainsi que votre r\u00e9activit\u00e9 vous permettront de r\u00e9ussir \u00e0 ce poste.\nEn nous rejoignant vous aurez l\u2019opportunit\u00e9 de vous voir confier des responsabilit\u00e9s cl\u00e9s et de contribuer aux challenges des acteurs majeurs industriels tout en d\u00e9veloppant vos comp\u00e9tences.\nPr\u00e9-requis:\nBonne maitrise d'excel\nPowerApps et PowerBI serait un plus\nInformations suppl\u00e9mentaires\nLes 3 raisons de rejoindre TRIGO :\n\u2022Vous int\u00e9grez le leader de la Qualit\u00e9 Industrielle en contribuant \u00e0 des projets d\u2019envergures et \u00e0 forte valeur ajout\u00e9e en France et \u00e0 l\u2019International.\n\u2022Vous \u00e9voluez dans un cadre bienveillant. Nous consid\u00e9rons que la qualit\u00e9 des prestations d\u00e9marre par l\u2019\u00e9panouissement de chaque collaborateur, notre management de proximit\u00e9 et le suivi r\u00e9gulier en sont des piliers.\n\u2022Nous rendons votre r\u00e9ussite professionnelle possible en vous donnant les moyens de devenir un v\u00e9ritable expert qualit\u00e9.","259":"Description de l'entreprise\nChez TRIGO, nous sommes convaincus que la Qualit\u00e9 est essentielle \u00e0 la performance de l\u2019Industrie et \u00e0 sa durabilit\u00e9. C\u2019est pourquoi nous d\u00e9ployons des solutions qui optimisent les productions industrielles, \u00e0 l'\u00e9chelle mondiale.\nNous sommes 10 000 collaborateurs dans 26 pays, offrant un portefeuille complet de services \u00e0 de nombreuses cha\u00eenes d'approvisionnement et de fabrication. De l'inspection et la retouche au conseil et \u00e0 l\u2019ing\u00e9nierie, nous nous engageons pour la qualit\u00e9 de nos partenaires industriels. Nous nous appuyons sur nos solutions technologiques en d\u00e9veloppement, bas\u00e9es sur l'industrie 4.0, l'analyse de donn\u00e9es et l'intelligence artificielle.\nAu sein d'une entreprise \u00e0 l'esprit start-up et \u00e0 la culture internationale, vous contribuerez et am\u00e9liorerez l'efficacit\u00e9 de nombreuses chaines de montage et d\u2019assemblage. Gr\u00e2ce \u00e0 des missions engageantes et responsabilisantes, vous constaterez l'impact de vos efforts. Rejoignez une \u00e9quipe engag\u00e9e qui vise l'excellence !\nDescription du poste\nAu sein de l\u2019\u00e9quipe digital France en charge de toutes les solutions digitales (terrain, support et client), nous t'offrons la possibilit\u00e9 de participer \u00e0 des projets d'innovation monde.\nTu travailleras en collaboration constante avec ton manager, le responsable digital France.\nTes principales missions seront :\n- La gestion de projet :\nD\u00e9finition des besoins des m\u00e9tiers (visite sur sites et ateliers de travail)\nD\u00e9finition d\u2019une solution (d\u00e9veloppement interne, externe, d\u00e9finition d\u2019un nouveau process ou d\u2019une nouvelle m\u00e9thode de travail)\nAnimation des r\u00e9unions de suivi de projet (r\u00e9union de travail avec l\u2019\u00e9quipe op\u00e9rationnelle, et r\u00e9union de suivi avec l\u2019\u00e9quipe projet)\nExemples de projets : mise en place d\u2019une application de contr\u00f4le de pi\u00e8ces via scan, cr\u00e9ation de power BI pour tous m\u00e9tiers, cr\u00e9ation d\u2019une application de suivi d\u2019activit\u00e9 pour le suivi du co\u00fbt de main d\u2019\u0153uvre, d\u00e9finition de outils digitaux aux postes \u00e0 d\u00e9ployer sur la France enti\u00e8re, lancement de projets de RPA, etc.\n- La partie technique : En fonction de tes app\u00e9tences et de besoins, tu seras guid\u00e9 sur l\u2019apprentissage de la suite Power Platform de Microsoft (Power Apps, Automate et Power BI essentiellement) afin de r\u00e9pondre directement aux besoins de nos clients internes via la cr\u00e9ation d\u2019applications et de rapports simples\n- Le support : En soutient de l\u2019\u00e9quipe Digital, tu accompagneras et formera les utilisateurs aux nouveaux rapports et applications cr\u00e9\u00e9es. Tu participeras \u00e9galement \u00e0 la cr\u00e9ation des diff\u00e9rents contenus (guides utilisateurs, processus, etc.) sous PowerPoint ou SharePoint.\nQualifications\nDe formation Bac+5, vous pr\u00e9parez un diplome d'ing\u00e9nieur.\nVous avez une app\u00e9tence pour le digital et la gestion de projet.\nEn plus de savoir maitriser le pack office (word, excel...), vos qualit\u00e9s relationnelles et manag\u00e9riales, ainsi que votre r\u00e9activit\u00e9 vous permettront de r\u00e9ussir \u00e0 ce poste.\nEn nous rejoignant vous aurez l\u2019opportunit\u00e9 de vous voir confier des responsabilit\u00e9s cl\u00e9s et de contribuer aux challenges des acteurs majeurs industriels tout en d\u00e9veloppant vos comp\u00e9tences.\nPr\u00e9-requis:\nBonne maitrise d'excel\nPowerApps et PowerBI serait un plus\nInformations suppl\u00e9mentaires\nLes 3 raisons de rejoindre TRIGO :\n\u2022Vous int\u00e9grez le leader de la Qualit\u00e9 Industrielle en contribuant \u00e0 des projets d\u2019envergures et \u00e0 forte valeur ajout\u00e9e en France et \u00e0 l\u2019International.\n\u2022Vous \u00e9voluez dans un cadre bienveillant. Nous consid\u00e9rons que la qualit\u00e9 des prestations d\u00e9marre par l\u2019\u00e9panouissement de chaque collaborateur, notre management de proximit\u00e9 et le suivi r\u00e9gulier en sont des piliers.\n\u2022Nous rendons votre r\u00e9ussite professionnelle possible en vous donnant les moyens de devenir un v\u00e9ritable expert qualit\u00e9.","260":"   Company Summary:\nTessera Therapeutics is pioneering Gene Writing\u2122\u2014 a new biotechnology designed to offer scientists and clinicians the ability to write small and large therapeutic messages into the genome, thereby curing diseases at their source. Gene Writing holds the potential to become a new category in genetic medicine, building upon recent breakthroughs in gene therapy and gene editing while eliminating important limitations in their reach, utilization, and efficacy. Tessera Therapeutics was founded by Flagship Pioneering, a life sciences innovation enterprise that conceives, resources, and develops first-in-category companies to transform human health and sustainability.\nPosition Summary:\nTessera is seeking a talented and motivated Computational Biologist to join our expanding Data Sciences team.  You will tackle challenging bioinformatics and computational biology problems to advance our understanding of Gene Writing and help accelerate programs to the clinic.  You will contribute scientific, technical, and leadership expertise to a multidisciplinary team, emphasizing conceptualization, experimentation, data analysis, presentation, and strategic planning. \n  Key Responsibilities:\nWork collaboratively with our platform and Biology teams to enable scientific discovery and progression through data analysis, data visualization and data integration\nBuild and implement data analysis pipelines and storage solutions for various forms of sequencing including Amplicon sequencing, long-read sequencing (Pac Bio) and related methods\nIdentify and acquire relevant public and third-party \u2018omics data and perform integrative data analyses to generate insights that address strategic biological questions critical to Tessera\u2019s core mission.\nDevelop computational methods that provide project support to gene therapy project teams\nOperationalize data analysis aspects of relevant molecular assays to maximize the design, build, test cycle for platform and pipeline candidates\nStructure and store data to enable data reuse, data mining and machine learning\nCreate compelling data visualizations for internal and external presentations\n\n  Basic Qualifications:\nPh.D.\/M.S. in Computational Biology, Bioinformatics, or related quantitative discipline. \n3+ years of industry experience in discovery research.\nProficient with experimental design, data processing, statistical analysis, and bioinformatics analysis\/reporting of next-generation sequencing data.\nExperience analyzing gene therapy, gene editing, in vitro\/vivo assay, genetics, genomics and cell biology data\nExperience using comparative genomics as a tool for gene discovery\nStrong grounding in biology or medicine\nStrong data visualization skills and experience\nFluency in one or more programming languages with bioinformatics applications (R, Python).\nTrack record of success working in a fast-paced, cross-functional, and rapidly growing organization.\nOutstanding written and verbal communication skills, ability to work with colleagues from diverse scientific backgrounds and cultures.\n  Preferred Qualifications:\nExperience with recent advances in gene therapy and development of gene editing platforms as therapeutics.\nStrong competency in sequence analysis methods including gene identification, functional annotation, or comparative genomics.\nFamiliarity with short and long read next-generation sequencing platforms (Illumina, PacBio, Nanopore).\nProficiency in handling large scale sequencing data in a cloud environment (AWS preferred).\nProficiency in statistics and machine learning.\nExperience in virology or mobile genetic elements.\n  More About Flagship Pioneering\nFlagship Pioneering has conceived of and created companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune\u2019s \u201cChange the World\u201d list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies. \nFlagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. \n  Recruitment & Staffing Agencies:  Flagship Pioneering and its affiliated Flagship Lab companies (collectively, \u201cFSP\u201d) do not accept unsolicited resumes from any source other than candidates.  The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering\u2019s internal Talent Acquisition team.   Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto. \n ","261":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value\nJob Description\nAs Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions.\nYou will independently drive design discussions to ensure the necessary health of the overall solution.\nThe role requires a hands-on technologist who has strong programming background like Java \/ Scala \/ Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components.\nYou are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. \nRole & Responsibilities:\nYour role is focused on the Design, Development and delivery of solutions involving:\nData Integration, Processing & Governance\nData Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations\nInfrastructure & Cloud Computing\nData Management Platforms\nImplement scalable architectural models for data processing and storage\nBuild functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode\nBuild functionality for data analytics, search and aggregation\n#LI-REMOTE \nQualifications\nOverall 5+ years of IT experience with 3+ years in Data related technologies\nMinimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS \/ Azure \/ GCP)\nHands-on experience with the Hadoop stack \u2013 HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline.\nStrong experience in at least of the programming language Java, Scala, Python. Java preferable\nHands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc\n Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security \n Competency\n1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience\n2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc\n3. Knowledge on distributed messaging frameworks like ActiveMQ \/ RabbiMQ \/ Solace, search & indexing and Micro services architectures\n4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 \u2013 Data Engineering\n5. CI\/CD \u2013 Infra provisioning on cloud, auto build & deployment pipelines, code quality\n6. Cloud data specialty and other related Big data technology certifications\nPersonal Attributes:\nStrong written and verbal communication skills\nArticulaion skills\nGood team player\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nProcess orientation and the ability to define and set up processe\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements\nEmployee Assistance Programs to help you in wellness and well being","262":"Farfetch is unlike anything in the world of fashion and technology.Our mission: to revolutionize the way the world shops.To do it, we need innovators. People who challenge convention and dare to dream.We\u2019ve gone from a start-up to a billion-dollar business. But we\u2019re not done yet. Far from it.Be bold.Be brilliant.Together, we can be extraordinary\nWe have rapidly grown into a truly global company since our launch in 2008 and we\u2019re continuing to grow. Our family now includes partner boutiques and brands across Europe, North and South America, and Asia; we demonstrate our \u2018Think Global\u2019 value in everything we do. We are a global team of over 1,500 people and have offices based in London, New York, L.A., Porto, Guimaraes, Lisbon, Sao Paulo, Shanghai, Moscow, Hong Kong & Tokyo.We are a company with an entrepreneurial spirit and innovative culture. We are positive and passionate, and live our values: Be Human, Be Brilliant, Todos Juntos, Be Revolutionary, Think Global, and Amaze Customers day to day.\nThe Team\nFarfetch\u2019s Data Teams are focused on everything related to data. Their main purpose is to harness the power of Farfetch\u2019s data to deliver insights and reports that support business decisions and also analyze and discover new ways to amaze our customers. These teams cover multiple areas related to data, such as  Business Intelligence, Software and Data Engineering, Data Science, and Data Analytics.\nJust like the rest of Farfetch, Data Teams are committed to turning the company into a leading e-commerce platform. As so, they are constantly looking for brilliant people who like the challenges that a fast-growing, data-driven company faces on its path to becoming a market leader.  \nThe RoleYou will be integrated into the Data Engineering team, being responsible for helping maintain and improve the BI architecture and tools.\n\n\nWhat you\u2019ll do\nDesign and build scalable & reliable data pipelines (ETLs) for our data platform\nConstantly evolve data models & schema design of our Data Warehouse to support self-service needs\nWork cross functionally with various teams, creating solutions that deal with large volumes of data.\nWork with the team to set and maintain standards and development practices;\nBe a keen advocate of quality and continuous improvement;\nWho you are\nYou have experience building and maintaining data pipelines in a custom or commercial ETL tool (eg. SSIS, Talend, Informatica, Airflow) (plus);\nYou have worked in a Data Warehouse environment (plus); \nBackground in working with cloud environments (eg. AWS, GCP, Azure) (plus);\nBasic experience in SQL;\nYou have basic knowledge of Hadoop\/BigData ecosystem (HDFS, Hive) (plus);\nYou have basic skills in one of the following programming languages: C#, Java, Python;\nKnowledge in distributed computing (Spark) (plus);\nExperience in working with a BI reporting tool (eg. Tableau, QlikView, PowerBI, Looker) (plus);\nYou are familiar with in continuous delivery principles: version control, unit and automated tests (plus);\nYou have an intermediate level in English, both written and spoken;\nYou have good analytical and problem solving skills, the ability to work in a fast moving operational environment and you are enthusiastic and with a positive attitude;\nWe can\u2019t wait to receive your application. But before you send it to us, here are some helpful tips to make sure your application is as strong as it can be.\nHave you set out why this role is a good match for your career aspirations and that you have the skills and experience required? We want you to be as clear about your future ambitions as we are and whilst we encourage people to learn, develop and grow, you will need to hit the ground running.\nHave you checked spelling and grammar? We have high standards and you don\u2019t want to miss out because of something as easily correctable as a typo.","263":"Company Description\nWelcome to This Australian Life.\u202f \nFrom the millions of Australians we protect, to those that make it happen every day at TAL, people really are what we\u2019re all about.\u202fWe want to grow with you. Achieve with you. And support you to do your best work. That's why we're focused on developing leadership, promoting diversity, rewarding excellence and retaining great talent. \nWe're always looking for people who want to go further with us. People who do what\u2019s right, aim high, and work smart.\u202f\u202fWhy not see where we can go? \nJob Description\nThe BI Developer role is a critical role within the Data and Analytics team ensuring that new and existing ways of producing information products are understood and documented so that operational risks are within TAL\u2019s risk appetite.\nYou will engage with various business analysts within the Data and Analytics team to understand stated \/ unstated customer needs and requirements specific to Group Life\u2019s reporting needs.\nThis position will have a primary focus on the delivery of periodic, ad-hoc and\/or new requests relating to Group Life and Investments data to external industry regulators, fund partners, partnership team and governing bodies.\nQualifications\nMinimum of 2 years' experience in BI space\n Must have experience in translating business requirements to technical\/analytical specifications. \nMust have experience working with and documenting workflow and business processes\nProficiency with SQL, MS BI Stack (SSIS), Azure Data factory and Power BI.\nLife Insurance or Banking experience including knowledge of financial \/ actuarial valuation methods and processes \nDemonstrable ability and attributes such as; assertiveness, resilience, and flexibility in times of change.\nExperience in process improvement and change\nYou\u2019re\u202falways\u202faccountable for your actions. You never give up. You strive to find the best outcomes for customers and partners.\u202fAnd\u202fyou value\u202fworking together to find the best solutions for problems.\u202f \nAdditional Information\nWork is a big part of this Australian life, and we work hard to make it one of the best parts. We don\u2019t just say it; we do it.\u202f\u202fWe offer a workplace that\u2019s inclusive and flexible, supporting our people with options that let them make the most of their careers. \nWe know the value of having different people from all walks of life, with varied points of view and attributes regardless of their age, ethnicity, religion, sexual orientation, gender identity, intersex status or any disabilities they might be living with.\u202fWe strive for a diverse and inclusive workplace where a sense of belonging encourages people to bring their full selves to work.  \n#LI-Hybrid \n#LI-REMOTE \nEveryone at TAL has a responsibility to do the right thing and is accountable for the way they conduct themselves. Our expectations are that you follow the principles set out in our Code of Conduct when you come to work every day. Risk management is everyone\u2019s responsibility.\nIf you are already a TAL employee please apply via the SmartRecruiters button in Workday and navigate to the Employee Portal. This is important to ensure that your application is recorded accurately.","264":"Enroute is about being exceptional. We deliver IT services and solutions by tech-savvy problem solvers, constantly looking for innovative approaches to everyday problems. Enrouters have unique ideologies, principles, and incredible life stories. Everyone is welcome at Enroute.\nWe take pride in our culture. We want every Enrouter to enjoy working with us and become part of a great community of highly driven, responsible, respectful, and happy people. We offer outstanding benefits, compensation, flexible schedules, and policies that balance work and personal life. We strive to be involved and know our people to improve continuously.\nWe seek a talented and experienced BI Developer - Visualizations Expert (Tableau) to join our dynamic and growing team. As a key member of the Business Intelligence team, you will be responsible for designing and developing interactive dashboards, reports, and visualizations to provide insights and support data-driven decision-making across the organization.\nRequirements\nBachelor's degree in Computer Science, Information Technology, or a related field\n5+ years of experience in business intelligence and data visualization, with a strong focus on Tableau\nProficient in Tableau Desktop, Server, and Tableau Public (minimum of Tableau 2021.3 version)\nExperience with data modeling, data warehousing, and ETL processes\nStrong SQL skills\nAbility to work with large datasets and create scalable and efficient dashboards\nExcellent communication and collaboration skills, with the ability to work effectively with both technical and non-technical stakeholders\nA self-starter with the ability to take the initiative and work independently\nExcellent problem-solving skills and the ability to think creatively\n\nResponsibilities\nDesign and develop advanced Tableau dashboards, reports, and visualizations\nWork with stakeholders to gather requirements and translate them into data-driven insights.\nCollaborate with cross-functional teams to ensure the delivered solution meets business requirements.\nStay up-to-date with Tableau technologies and trends to ensure the solution is always current.\nParticipate in code reviews and ensure the code is maintainable and scalable.\nTroubleshoot and resolve issues with existing Tableau dashboards and reports\nParticipate in training and mentoring junior team members.\nBenefits\nMonetary compensation\nYear-end Bonus\nIMSS, AFORE, INFONAVIT\nMajor Medical Expenses Insurance\nMinor Medical Expenses Insurance\nLife Insurance\nFuneral Expenses Insurance\nPreferential rates for car insurance\nTDU Membership\nHolidays and Vacations\nSick days\nBereavement days\nCivil Marriage days\nMaternity & Paternity leave\nEnglish, Japanese, and Spanish classes\nPerformance Management Framework\nCertifications\nTALISIS Agreement: Discounts at ADVENIO, Harmon Hall, U-ERRE, UNID\nTaquitos Rewards\nAmazon Gift Card on your Birthday\nWork-from-home Bonus\nLaptop Policy\nEqual employment\nEnroute is committed to providing equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.","265":"Company Description\nWelcome to This Australian Life.\u202f \nFrom the millions of Australians we protect, to those that make it happen every day at TAL, people really are what we\u2019re all about.\u202fWe want to grow with you. Achieve with you. And support you to do your best work. That's why we're focused on developing leadership, promoting diversity, rewarding excellence and retaining great talent. \nWe're always looking for people who want to go further with us. People who do what\u2019s right, aim high, and work smart.\u202f\u202fWhy not see where we can go? \nJob Description\nThe Senior BI Developer role is a critical role within the Data and Analytics team ensuring that new and existing ways of producing information products are understood and documented so that operational risks are within TAL\u2019s risk appetite.\nYou will engage with various business analysts within the Data and Analytics team to understand stated \/ unstated customer needs and requirements specific to Group Life\u2019s reporting needs.\nThis position will have a primary focus on the delivery of periodic, ad-hoc and\/or new requests relating to Group Life and Investments data to external industry regulators, fund partners, partnership team and governing bodies.\nQualifications\nMinimum of 5 years experience in BI space\nMust have experience in translating business requirements to technical\/analytical specifications. \nMust have experience working with and documenting workflow and business processes.\nProficiency with SQL, MS BI Stack (SSIS), Azure Data factory and Power BI.\nAbility to build strong commercial acumen, problem solving and analytical skills\nAbility to communicate proactively and effectively with stakeholders (written and verbal)\nYou\u2019re\u202falways\u202faccountable for your actions. You never give up. You strive to find the best outcomes for customers and partners.\u202fAnd\u202fyou value\u202fworking together to find the best solutions for problems.\u202f \nAdditional Information\nWork is a big part of this Australian life, and we work hard to make it one of the best parts. We don\u2019t just say it; we do it.\u202f\u202fWe offer a workplace that\u2019s inclusive and flexible, supporting our people with options that let them make the most of their careers. \nWe know the value of having different people from all walks of life, with varied points of view and attributes regardless of their age, ethnicity, religion, sexual orientation, gender identity, intersex status or any disabilities they might be living with.\u202fWe strive for a diverse and inclusive workplace where a sense of belonging encourages people to bring their full selves to work.  \n#LI-Hybrid \n#LI-REMOTE \nEveryone at TAL has a responsibility to do the right thing and is accountable for the way they conduct themselves. Our expectations are that you follow the principles set out in our Code of Conduct when you come to work every day. Risk management is everyone\u2019s responsibility.\nIf you are already a TAL employee please apply via the SmartRecruiters button in Workday and navigate to the Employee Portal. This is important to ensure that your application is recorded accurately.","266":"Company Description\nIt all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app, bringing a better way to send, spend, invest, borrow and save to our millions of monthly active users. With a mission to redefine the world's relationship with money by making it more relatable, available and accessible, at Cash App you'll have the opportunity to make a real-world impact with your career.\nToday, Cash App has thousands of employees around the world with a culture geared toward creativity, collaboration and impact. We\u2019ve been a distributed team since day one, and continue to value working across time zones and continents both remotely and in our Cash App offices.\nOur offices are great, but many of our roles can be done remotely from the countries where Block operates. We tailor our experience to champion our employees\u2019 creativity and productivity wherever they are. \nJob Description\nThe BI Team at Cash App enables our teams to make impactful business decisions. Our BI Engineers handle everything from data architecture and modeling to data pipeline tooling and dashboarding. As a Senior BI Engineer at Cash App, you will report to the BI Manager and work with Analysts, Data Scientists, Software Engineers and Product Managers to lay the foundation for analyzing our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, to informing product development. You will build, curate, document, and manage key datasets and ETLs to increase the impact of the entire team.\n\nYou will:\nCreate brand new and optimize existing data models for the most widely used Cash App events, entities, and processes\nStandardize business and product metric definitions in curated and optimized datasets\nBuild pipelines out of our data warehouse\nTeach (and encourage) others to self-serve while building tools that make it simpler and faster for them to do so\nPromote data, analytics, and data model design best practices\nCreate dashboards that help our teams understand the performance of the business and help them make decisions\nQualifications\nYou have:\nBackground\/knowledge in Computer Science, Applied Math, Engineering, Stats, Physics, or a something comparable\n3+ years of industry experience building complex, scalable ETLs for a variety of different business and product use cases\nAn interest in advancing Cash App's vision of building products for economic empowerment - this should be something that legitimately excites you\nTechnologies we use and teach:\nSQL (MySQL, Snowflake, BigQuery, etc.)\nAirflow, Looker and Tableau\nPython and Java\nAdditional Information\nBlock takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate\u2019s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.\n\nZone A: USD $152,100 - USD $185,900\nZone B: USD $144,500 - USD $176,700\nZone C: USD $136,900 - USD $167,300\nZone D: USD $129,300 - USD $158,100\nTo find a location\u2019s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information. \nBenefits include the following:\nHealthcare coverage\nRetirement Plans including company match \nEmployee Stock Purchase Program\nWellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance \nPaid parental and caregiving leave\nPaid time off\nLearning and Development resources\nPaid Life insurance, AD&D. and disability benefits \nPerks such as WFH reimbursements and free access to caregiving, legal, and discounted resources \nThis role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans.\nWe\u2019re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, veteran status, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. \nWe believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible. Want to learn more about what we\u2019re doing to build a workplace that is fair and square? Check out our I+D page. \nAdditionally, we consider qualified applicants with criminal histories for employment on our team, assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.\nBlock, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.","267":"Company Description\nAt Experian Health, our employees have the opportunity to shape more than products \u2013 they shape the future of U.S. healthcare. Experian Health is a pioneer for innovations leading the way in revenue cycle management, identity management, patient engagement, and care management for hospitals, physician groups, labs, pharmacies and other risk-bearing entities. Our success relies on people who are given the freedom to imagine new frontiers in the rapidly changing healthcare space and push the boundaries of innovation. Help us realize our vision of applying data for good and changing the healthcare landscape for the better \u2013 for all of us.\nJob Description\n100% REMOTE (NOT HYBRID) - WORK ANYWHERE IN THE US\nThe primary responsibility of the Data Analyst will be to support application development leveraging strong SQL skills, knowledge of relational databases, and the skills to ensure custom coordination of benefit software, containing over 400 million rows of data, only allows accurate data to be loaded, and data integrity is maintained after bug fixes and enhancements.\n\nThis position will ensure this software is thoroughly tested from all angles focusing primarily on the backend by developing custom test plans and executing them using SQL, analyzing production data, and writing custom reports.\n\nJob duties:\nFully understand custom built Healthcare Medical Eligibility\/Coordination of Benefits software solution. Understand the technical design and be able to traverse through and fully test the system using custom developed test plans using SQL\nWork collaboratively at ground level with senior level development staff to fully understand product requirements. Be willing to ask questions, push back as necessary, and ultimately ensure the new code meets stringent customer expectations\nIdentify software defects, conduct research, develop plan for resolution, and engage appropriate internal resources as necessary\nPerform data analysis as needed on production data (400+ million rows of data)\nCollaborate with team members on, and provide peer review of, test plans, test cases, test data, and automation\/tool enhancements.\nWork collaboratively with development team to make technical judgments based upon understanding of the business process and customer\/user needs whereby a design change or modification should (or needs to be) changed.\nSupport inquiries from client, operations, and customer support on content related questions and monitor areas for improvement.\nDesign and document test cases to ensure optimal system performance with new code releases\nUtilize QA best practices\nTests will be executed at the database level, using SQL\nBuild automated tests using tools such as Selenium\nOperate load testing on Web Based Portal\nRun smoke tests and regression tests\nPrepare appropriate test data\nCommunicate and document testing results in appropriate tool\nMaintain defect reporting and tracking\nMaintain current test plans, test cases, test scripts, and test data.\nAvailability for planned after hours deployments and unplanned issue resolution\nPlanned deployments typically occur once a month on Thursday nights\nQualifications\nBachelor\u2019s degree in Information Systems, Computer Science, or other related field OR equivalent experience required\nAt least 3 years combined prior business analyst, SQL programming, software QA, SQL data analysis\nMinimum 3 years of SQL usage in a professional setting\nExperience working as an analyst with large datasets (1+ million records) highly desired\nExperience with SDLC and iterative development processes, specifically Agile work processes highly desired\nExperience in working in a highly competitive team environment\nStrong SQL skills required (Data Analyst SQL skill set, not necessarily SQL programming)\nFocus on relational databases\nBusiness analyst knowledge is highly preferred\nQA knowledge is preferred. Willingness to be trained on QA fundamentals is required\nCoordination of Benefits, and\/or Healthcare Revenue Cycle knowledge a plus\nEffective communication and relationship building skills\nSelf-motivated, team player, but who can work independently\nAbility to adapt to an Agile\/Scrum environment\nStrong written and verbal communication skills\nProblem-solving as part of a distributed team\nTime management and organizational skills\nKnowledge of the HIPAA transaction sets and requirements is desirable\nBecome an expert on highly complex custom software - willingness to self-study and learn through trial and error required.  \nAdditional Information\nExperian is an Equal Opportunity Employer. Anyone needing accommodation to complete the interview process should notify the talent acquisition partner. The word \"Experian\" is a registered trademark in the EU and other countries and is owned by Experian Ltd. and\/or its associated companies.\nEOE including Disability\/Veterans.\nExperian is proud to be an Equal Opportunity and Affirmative Action employer. Our goal is to create a thriving, inclusive and diverse team where people love their work and love working together. We believe that diversity, equity and inclusion is essential to our purpose of creating a better tomorrow. We value the uniqueness of every individual and want you to bring your whole, authentic self to work. For us, this is The Power of YOU and and it reflects what we believe.  See our DEI work in action!\nPlease contact us at JobPostingInquiry@experian.com to request the salary range of this position (please include the exact Job Title as it reads above in your email). In addition to a competitive base salary and variable pay opportunity, Experian offers a comprehensive benefits package including health, life and disability insurance, generous paid time off including 12 company paid holidays and parental and family care leave, an employee stock purchase plan and a 401(k) plan with a company match.\nExperian Careers - Creating a better tomorrow together\nFind out what its like to work for Experian by clicking here","268":"Binance is the global blockchain company behind the world\u2019s largest digital asset exchange by trading volume and users, serving a greater mission to accelerate cryptocurrency adoption and increase the freedom of money.\nAre you looking to be a part of the most influential company in the blockchain industry and contribute to the crypto-currency revolution that is changing the world?\nAbout Binance Accelerator Programme Binance Accelerator Programme is a concise 3 - 6 months programme designed to have an immersive experience in the rapidly expanding Web3 space.  You will be given the opportunity to experience life at Binance and understand what goes on behind the scenes of the worlds\u2019 leading blockchain ecosystem. Alongside your job, there will also be a focus on networking and development, which will expand your professional network and build transferable skills to propel you forward in your career. \nWho may applyCurrent students, fresh graduates, and candidates who are mid-career switchers.\nAbout the roleAs a data scientist in Sanctions Compliance team, you will have the opportunity to leverage rich data (PB-level scalability) and state-of-art machine learning infrastructure to provide collation and analysis of data, research and background information to support the day-to-day operations of the Sanctions and AB&C Risk and Compliance Team.\nYou will collaborate with a strong team of compliance experts, engineers, data analysts, to define and build solutions for the compliance department based on our rich data and cutting-edge machine learning technology.\nResponsibilities\nProvide support to the heads of Global Sanctions and AB&C Risk and Compliance Programme in all data related request\nDevelop dashboard in monitoring Sanctions and AB&C Risk and Compliance team in monitoring operational risk, efficiency and productivity\nData quality control: Understand operational process and ensure data quality and correctness for internal controls and compliance analysis\nLeverage our PB-scale data warehouse to perform in-depth analysis and build personalised services for Sanctions and AB&C Risk\nData driven sanctions risk analysis: leverage of machine learning techniques to understand customers\u2019 demographics and sanctions exposure with proven data evidence and analysis\nCoordinate automations and system improvement projects\nPromote data-driven culture within the Sanctions and AB&C Risk and Compliance team in making compliance decisions\nDevelop training and procedures to team members in understanding data, using excel \/ SQL to conduct data analysis\nNavigate and build strong stakeholder relationships across Binance\u2019s global functions and teams\nHorizon scans for regulatory and internal developments, that affect Binance globally\nConfidently raises challenges, providing different perspectives, whilst maintaining and building professional relationships.\nRequirements\nUniversity degree in computer science, statistics or data science related programs\nGood experience in developing dashboards for operations and risk monitoring\nGood project experience with developing machine learning modelsGood experience with processing large size data is preferred\nGood experience with Python, SQL and any data visualization tools is preferred\nDeep understanding of modern machine learning techniques and mathematical underpinning, such as classifications, recommendation systems, optimization etc.\nFluent in English - a second language is preferred \nStrong analytical and writing skills, and sound judgement\nAbility to work across functional and geographic lines\nYou are pragmatic and energetic, with an ability to think \u2018outside the box\u2019 in a fast-paced dynamic environment \nYou have strong learning agility as well as a critical and innovative mindsetYou are people-focused\nYou are a good communicator verbally and in writing, being able to convey complex messages in a simple way to bring an understanding to \u201cwhy\u201d change is required \nYou are confident, result driven and seek to find innovative and new creative solutions\nWorking at Binance\u2022 Do something meaningful; Be a part of the future of finance technology and the no.1 company in the industry\u2022 Fast moving, challenging and unique business problems\u2022 International work environment and flat organisation\u2022 Great career development opportunities in a growing company\u2022 Possibility for relocation and international transfers mid-career\u2022 Competitive salary\u2022 Flexible working hours, Casual work attire\nBy submitting a job application, you confirm that you have read and agree to our Candidate Privacy Notice.","269":"Computational Biologist \nVesalius Therapeutics is seeking a highly motivated and collaborative Computational Biologist driven to leverage single-cell genomics data to reveal biological mechanisms of health and disease.\u202f The candidate will participate in the statistical design and analysis of genomic experiments (e.g. single-cell RNA-seq, ATAC-seq, CRISPR screens, etc.) in collaboration with wet-lab biologists.\u202f The role requires the ability to interpret experiments that deliver testable hypotheses that integrate clinical and biological endpoints using cutting edge methods and technologies.\u202f The candidate should have a solid foundation in applied statistics, deep generative models, computational biology, molecular biology paired with a strong work ethic and the ability to work independently and in highly matrixed teams. The candidate will leverage publicly available data and integrate with internally generated data. This is an exciting and interdisciplinary role that will collaborate with statistical geneticists, biomedical informaticists and wet-lab biologists to support the development of novel therapeutics.\u202f \n  Responsibilities \nComputational analysis of large, complex, single cell genomics datasets from in vitro cellular model systems\u202f \nDeliver testable hypotheses\/insights from complex high-dimensional data to inform target selection\u202f \nLinking results and insights between internal and public data, as well as orthogonal data such as human genetics.\u202f \nIdentify and validate approaches to improve quality and efficiency of hypothesis generation from model systems\u202f \nMaintain awareness of emerging methods in computational biology and applications for novel omics technologies\u202f \nProvide ad-hoc bioinformatics support to cross-disciplinary project teams\u202f \nReporting results to scientific team and management.\u202f \n  Qualifications \nPhD in Bioinformatics, Biostatistics, Computer Science, Computational Biology, Genetics, Mathematics, Physics, Statistics or other related discipline\u202f \n2-3 years post PhD experience applying quantitative approaches to solve biological problems\u202f \nKnowledge and experience of single-cell transcriptomic data and analyses; additional modalities such as histone modification data analysis considered a plus.\u202f \nStrong knowledge of applied statistics and machine learning (in particular deep generative models)\u202f \nStrong statistical and scripting programming skills (Python\/R\/etc.)\u202f \nKnowledge of molecular biology, neuroscience experience a plus\u202f \nDemonstrated experience in design and interpretation of in vivo and\/or in vitro biological experiments.\u202f \nDemonstrated expertise in delivering insights\/hypotheses from complex high-dimensional biological data\u202f \nDemonstrated ability to collaborate with biologists to communicate results and discuss follow-up experiments\u202f \nExceptional communication skills (oral and written) as demonstrated by publications & presentations.\u202f \nDemonstrated ability to work in a dynamic environment as a team player with a strong work ethic. \nDemonstrated ability to work in a dynamic environment with a sense of urgency and creativity and focus on deliverables.\nTeam player with a strong work ethic, able to work both independently and collaboratively \nContinuously learns and adapts quickly to new information\nAuthentic, proactively appreciative of different points of view, backgrounds and perspectives\n  What We\u2019ll Offer You: \nComprehensive, competitive healthcare (PPO) and dental coverage through Blue Cross Blue Shield, vision coverage through VSP, family leave, three weeks\u2019 paid time off with additional holidays, 401k retirement plan, disability and life insurance, and commuter benefits. \nA dynamic early-stage work environment and highly interdisciplinary, talented, and collaborative team. \nParticipate in the development and growth of a company with enormous potential impact on human health\nProfessional growth opportunities through mentoring, training, immersion in cross-functional projects, and opportunities to learn and try new things. \n    Who We Are:  \n  Vesalius Therapeutics is a Flagship Pioneering platform company with a bold and critical mission to revolutionize drug development for the diseases that cause 90% of global morbidity and mortality.   \nThe company was founded in 2019 in Flagship Labs, Flagship Pioneering\u2019s innovation foundry.  Vesalius is led by CEO Christopher Austin, M.D., Flagship Managing Partner, Doug Cole, M.D., and a leadership team with decades of experience working at some of the most renowned pharma and biotech companies in the industry. \nVesalius\u2019s ContinuumDiscovery\u2122 platform harnesses a combination of human clinical data and genetics, artificial intelligence and machine learning, and patient-derived experimental models into a uniquely potent discovery engine.   \nYou can read more about our mission here. ","270":"Company Description\nVisa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging \u2013 where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world \u2013 helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone.\nJob Description\nThe Marketing, Sales, Services Technology Systems (MSST) Team manage the Customer Relationship Manager (CRM) systems, Business process management (BPM) applications and custom applications for Sales, Services, Marketing and Product teams. The Analytics team within this team integrate data from multiple applications like CRM, Contact Center applications, Appian and build executive and operational reports as well as enable self-service reporting and insights from to empower Business to monitor and track KPIs and make data driven decisions. The Sr. Data Engineer (ETL\/Power BI\/SQL) within the Analytics Delivery team will be responsible for solution design, development and implementation of Data integration and Analytics solutions on data platforms (SQL server) and Hadoop. This position requires designing database schemas for reporting, perform data engineering activities using ETL tools like Pentaho and\/or scripts to ingest data from multiple applications on the cloud and on premise, build Power BI data sets and enable self- service reporting on Power BI and Hadoop. This position requires close collaboration with Global Sales Business partners and Product owners to understand Business goals and requirements and implement Data Analytics solutions following agile methodologies. This position requires collaboration with multiple global IT teams including application teams, database teams, Infrastructure and Platform teams and respond to changing Business priorities with agility. This position provides Production support for applications, data analysis and requires investigation and resolution of issues. Responsibilities: Participate in Technology project delivery activities such as gathering Business requirements, conceptual technology approach, design, development, enhance and build scalable solutions and support systems in production in a DevOps model. Work as a member of Sales domain scrum teams and provide solutions for complex reporting requirements. Work as a Subject matter expert on data from Sales and Marketing domain. Architect solutions and build data management systems \u2013 on premise or on cloud. Understand application systems, architect solution, develop the source to target mapping documents and ETL code to load data from Cloud applications (MS Dynamics) other CRM applications to databases on premise. Develop workflows using ETL tools like Pentaho. Develop database components on premise databases (SQL Server) and\/or Hadoop for reporting. Develop Power BI data models and dashboards. Support QA, UAT and performance testing phases of development cycle and implement DevOps principles from development to deployment to production Partner with IT groups such as Engineering, Product, Cybersecurity, and Infrastructure on project delivery activities and security findings remediation. Own Operational support for multiple applications Perform POC and build prototypes based on business and technology requirements. This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership\/site), with a general guidepost of being in the office 50% or more of the time based on business needs.\nQualifications\nBasic Qualifications: \u2022 2 or more years of work experience with a Bachelor\u2019s Degree or an Advanced Degree in Computer Science\/ Engineering, Information Science or a related discipline with strong technical experiences (e.g. Masters, MBA, JD, MD, or PhD). Preferred Qualifications: \u2022 Minimum of 2-3 years\u2019 experience with Master\u2019s degree or 4-5 years' experience with Bachelor\u2019s degree in Computer Science\/ Engineering, Information Science or a related discipline \u2022 Experience of at least four years in building data pipelines and utilizing data engineering techniques like ELT or ETL for building and scaling reporting and Analytical solutions \u2022 Strong expertise in Data analysis, writing SQL scripts and hands on experience working on Relational data bases like SQl Server required \u2022 Experience building Power BI data models and dashboards required \u2022 Extensive experience with ingesting and transforming data using ETL tools like Pentaho, Informatica is required \u2022 Experience using FetchXML, DAX functions, implementing Power BI security features required \u2022 Experience using MS Dynamics Sales and Services modules nice to have \u2022 Experience in provisioning databases and managing application servers (on premise or on cloud) nice to have \u2022 Experience with ensuring data quality for reporting and implementing data observability metrics highly desirable \u2022 Experience using Hadoop (Hive, Presto, Spark) highly desirable \u2022 Experience in Python, PowerShell, job scheduling (Control M) and version control (bitbuket, GitHub), implementing CI\/CD for Reporting components nice to have \u2022 Experience with embedding dashboards in MS Dynamics, Power apps, Power Automate nice to have \u2022 Experience working in Agile methodology owning end to end product solutions \u2022 Experience with cloud infrastructure like Azure data lake, Synapse, Snowflake on Azure nice to have \u2022 Good Presentation skills and communication skills presenting ideas and insights to Business is highly desired \u2022 Experience on Sales and Marketing domain nice to have \u2022 Demonstrated analytical rigor, strong attention to detail, team oriented, collaborative, agile and flexible style\nAdditional Information\nVisa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.","271":"We offer a hybrid work environment. Most US-based positions can also be performed remotely (any exceptions will be noted in the Minimum Qualifications below.)\nFor Israel-based positions, we encourage working from our Saarona, Tel Aviv office a few days a week, meeting your colleagues, and having a flexible work environment.\nOur Mission: \nTo actively connect people to their next great opportunity. \nWho We Are: \nZipRecruiter is a leading online employment marketplace. Powered by AI-driven smart matching technology, the company actively connects job seekers with millions of businesses of all sizes through innovative mobile app, web, and email services, as well as partnerships with the best job sites on the web. ZipRecruiter has the #1 rated job search app on iOS & Android. \nSummary of Job\nZipRecruiter is changing the way job seekers get hired and how small businesses manage their HR. Our R&D center in Tel Aviv offers an empowering, fun and collaborative culture where talented individuals who think like business owners and entrepreneurs are invited to join our growing team.  \nWe use models and algorithms of machine-learning and deep-learning to find candidates for a job, and get the job information to reach the candidate as quickly as possible to allow the employer to reach the best candidates in the least possible time.\nWe are looking for a passionate Big Data Engineer with expertise in cloud technologies, big data, and distributed systems to join our data engineering team. This exciting role requires the experience and skills to design and build key components and infrastructure for our data science and engineering team. \nKey focuses:\nBuild infrastructure to empower fellow engineers and data scientists to build together best-in-class machine-learning based products\nWorking in a high volume production environment that gets bigger and bigger\nMastering scalability and enterprise-grade production services implementation\nSense of ownership - leading design for new products and initiatives as well as integrating with currently implemented best-practices\nWorking with a number of off-the-shelf tools including Spark, Airflow, Kafka, DynamoDb, SQS, S3, RedShift, Mysql, but often push them past their limits\nCollaborating and working as part of a highly skilled team that enjoys doing the impossible together every day\nMinimum Requirements:\nAt least 5+ years of coding experience with at least one of the following: Java, Python, Scala.\nEnd to end experience - owning feature from an idea stage, through design, architecture, coding, integration and deployment stages\nA deep understanding of software engineering with at least 5+ years of hands-on coding experience at a senior level in high-volume production environments\nExperience with one or more of these technologies Spark, MapReduce, Airflow, Kafka, Key\/Value Stores like DynamoDB, SQL DB\u2019s, SQS\nDealing with data on high volume, high availability production systems\nFluent with SQL\nBachelor\u2019s degree or higher in Computer Science or equivalent professional Software Engineering experience\nCloud - AWS, Azure, Google Cloud - an advantage\nExperience in algorithm design and implementation or Machine learning\nAs part of our team you\u2019ll enjoy:\nCompetitive salary\nExceptional benefits package\nZipRecruiter is proud to be an equal opportunity employer and provides equal employment opportunities (EEO) to all employees and applicants without regard to race, color, religion, sex, national origin, age, disability, veteran status, sexual orientation, gender identity or genetics.\nPrivacy Notice: For information about ZipRecruiter's collection and processing of job applicant personal data for this job, please see our Privacy Notice at: https:\/\/www.ziprecruiter.com\/careers\/job-applicant-privacy-notice","272":"Company Description\nPublicis Media is one of Publicis Groupe\u2019s four solution hubs, aligning all of Publicis Groupe\u2019s media agencies and operations.  Publicis Groupe (Euronext Paris Exchange: FR0000130577; CAC 40 index), is the world\u2019s third largest communications group.  The Data, Technology and Innovation Global Practice was created to deliver best-in-class programmatic solutions as well as to consolidate Publicis Media\u2019s data and technology to transform our business from a service business to a platform business. \nJob Description\nWe are seeking a driven individual with a proven track record of scalable and innovative business intelligence solutions. He\/she shines when serving as a consultant to the business and is genuinely interested in understanding the objectives of complex and evolving projects. In this role, you will champion and advocate the use of Alteryx and Tableau to create an environment of self-service analytics. The candidate must be a self-starter with a sense of urgency and a commitment to quality and professionalism.\n Responsibilities:\nAnalyze business needs and partner with stakeholders to provide a strategic solution\nWork independently on end to end solutions, from data analysis to ETL design and development through to the final visual dashboard\nCollaborate across the organization to build solutions that achieve business objectives\nGuide stakeholders with operational decisions that impact data structures and connectivity\nBring best practices in data architecture and data visualization to the table\nBuild tools in a generic fashion for reuse across other solutions\nDevelop technical documentation for each solution\nManage projects in an agile environment\nQualifications\nMinimum Bachelor\u2019s Degree in Computer Sciences, Information Technology, or its equivalent\n3+ years\u2019 experience with Tableau\n1+ years\u2019 experience with AWS core+ services (EC2, S3, Lambda, Redshift, Glue)\n1+ years\u2019 experience with Python\n3+ years\u2019 experience with data visualization\nComfortable with data warehousing concepts, preparing data, and configuring automated workflows\nExcellent communication and presentation skills as well as an analytical mindset\nExperience with complex logic\nStrong data analysis skills\nExperience connecting and merging disparate datasets\nStrong organizational skills & attention to detail\nPossess a desire to work for a fast-paced, results-based company\nExperience managing multiple projects simultaneously\n Desired Skills\/Experience:\nExperience with media and ad tech platforms (Ad Servers, Media Planning and Buying systems, DSP\u2019s, Programmatic, etc)\nSQL\nAdobe Site Catalyst\nGoogle Analytics\nBasic knowledge of ETL, data modeling, data warehouse, extracting and manipulating large record of data\n Additional Information\nAll your information will be kept confidential according to EEO guidelines.\n ","273":"Company Summary:\nEach day, the lives of more than 2 billion people across the globe are impacted by chronic diseases. Moreover, the economic burden on society of treating chronic disease is spinning out of control. Today, this dire situation appears unlikely to change as >95% of global healthcare costs are spent on treating rather than preventing chronic diseases. FL84, Inc. is a privately held early-stage company that is applying advanced biological and computational platforms to discover breakthroughs in detection of and intervention against the etiologies that drive progression from health to disease. Our goal is to leverage our proprietary platforms to disrupt the current approach of treating chronic disease too late. We endeavor to provide true health care rather than sick care to individuals that are at risk of progressing to disease.\nFL84 was founded by Flagship Pioneering, an innovation enterprise dedicated to originating and developing first-in-category life sciences companies. Flagship Pioneering conceives, creates, resources, and develops first-in-category life sciences companies to transform human health and sustainability. Since its launch in 2000, the firm has applied a unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures, resulting in over $30 billion in aggregate value. The current Flagship ecosystem comprises 37 transformative companies, including: Moderna Therapeutics (NASDAQ: MRNA), Rubius Therapeutics (NASDAQ: RUBY), Indigo Agriculture, and Sana Biotechnology.\nPosition Summary:\nWe are seeking a Scientist\/Sr. Scientist of Computational Biology\/Bioinformatics who is enthusiastic about developing, learning and applying computational skills to understand complex biological systems and their relationship to clinical state changes. The candidate will design and implement novel approaches to handling biological data, initially focused on single-cell\/nuclei RNAseq but rapidly expanding to multiple types of biological and clinical data.  The role will focus on two main areas: (1) application of machine-learning to uncover novel targets; and (2) exploration of large, multimodal datasets to develop pipelines for preemptive clinical discovery.  An ideal candidate will pride themselves on their ability to craft scientifically logical and creative stories out of complex data and convert them into executable experiments. The position will provide a unique opportunity to play a foundational role in the development of FL84\u2019s preclinical platform and treat diseases before they become a burden to the patient or the healthcare system.\nKey Responsibilities:\nDevelop and apply bioinformatics, computational biology, and machine learning tools to generate insights and hypotheses from high-dimensional molecular datasets, with an initial focus on time-series snRNA-seq and genomic data\nWork with FL84 team to develop and apply novel ML models on heterogenous biological data\nIdentify and explore internal and external datasets to address questions critical to FL84\u2019s core objectives and generate testable hypotheses\nIdeate on how to align time-series biological data with clinically relevant inflection points identified in electronic health records, clinical trials, or other sources\nEstablish pipelines to prioritize targets for biological validation\nDevelop clear, intuitive visualizations and communicate analysis results via presentations to a multi-disciplinary audience\nCultivate a data-centric company philosophy by helping to maintain best practices for software development, data management, and infrastructure\nMonitor and evaluate new and emerging technologies and models and identify opportunities for collaboration within Flagship Pioneering companies, academia, and third parties\nBasic Requirements:\nPhD with 3+ years of experience or equivalent level of experience in quantitative biology.  Ph.D. may be in Computational Biology, Bioinformatics, Computer Sciences, Applied Mathematics, Applied Physics, or related\nPractical programming and scripting skills, preferably in Python and R\nBreadth of experience applying deep learning (DL) models to biological data\nMotivated and team oriented, with an ability to thrive in an entrepreneurial and multidisciplinary environment\nAbility to independently lead and run research projects, while maintaining close communication with team members\nExcellent communication and presentation skills. Must be able to speak and ideate with multi-disciplinary team including biologists. Must be able to think independently, work collaboratively and contribute to an active intellectual environment\nPreferred Requirements:\nExperience with biological, medical, and chemical data\nExperience with emergent behavior in complex systems, time series analysis, causal inference, domain adaptation, transfer learning, multi-modal deep learning, geometric deep learning (learning on graphs and\/or manifolds)\nExperience working with reference biological databases and datasets (e.g., TCGA, UK Biobank) is a strong plus\nExperience with CMAP, LINCS or other perturbagen (e.g., small molecule, CRISPT, etc.) induced transcriptomic databases\nExperience running genome wide association studies (GWAS)\nFamiliarity with AWS, GCP, or similar cloud-computing services\nAbility to Google error messages and seek resolution from self-investigation\nFlagship Pioneering is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.\nRecruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, \u201cFSP\u201d) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering\u2019s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.\n ","274":"Company Description\nPublicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients\u2019 businesses through creating the products and services their customers expect.\nJob Description\nAs Senior Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.\n\nYour role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.\n\nAs a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration.\nQualifications\n Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS \/ Azure \/ GCP)\nExperience delivering end to end Big Data solutions on premise and\/or on Cloud\nKnowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases\nExpertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions\nProficiency in Java and Scala programming languages (Python a plus)\nExpertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.)\nExperience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub\/Sub etc.)\nExpertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc.\nKnowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding\nKnowledge of performance tuning, optimization and scaling solutions from a storage\/processing standpoint\nExperience building DevOps pipelines for data solutions, including automated testing\nYou\u2019ll Also Likely Have Some Of The Following\n Knowledge of containerization, orchestration and Kubernetes engine\nAn understanding of how to setup Big data cluster security (Authorization\/ Authentication, Security for data at rest, data in transit)\nA basic understanding of how to manage and setup Monitoring and alerting for Big data clusters\nExperience of orchestration tools \u2013 Oozie , Airflow , Ctr-M or similar\nExperience of MPP style query engines like Impala, Presto, Athena etc.\nKnowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\nExposure to data governance, catalog, lineage and associated tools would be an added advantage\nA certification in one or more cloud platforms or big data technologies\nAny active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV\/POC, hackathon)\nAdditional Information\nThere is a superb package of benefits waiting for you at Publicis Sapient.\nWe cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension.\nThe learning opportunities here are endless. Most importantly, of course, there\u2019s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine.\nFlexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services.","275":"Opis oferty pracy\nNa czym b\u0119dzie polega\u0107 Twoja praca? \nB\u0119dziesz odpowiada\u0107 za analityk\u0119 biznesow\u0105 w eBilet w obszarze hurtowni danych, proces\u00f3w przetwarzania danych, proces\u00f3w raportowych, kt\u00f3re  dostarczaj\u0105 danych wspieraj\u0105cych tworzenie strategii i wyznaczanie kierunk\u00f3w dzia\u0142a\u0144\nWe\u017amiesz odpowiedzialno\u015b\u0107 za kszta\u0142towanie strategii BI, wyb\u00f3r narz\u0119dzi analitycznych jak i tworzenie raport\u00f3w niezb\u0119dnych dla organizacji\nWe\u017amiesz odpowiedzialno\u015b\u0107 za pozyskiwanie informacji i przygotowywanie analiz oraz produkt\u00f3w analitycznych\nB\u0119dziesz wsp\u00f3\u0142pracowa\u0107 z w\u0142a\u015bcicielami r\u00f3\u017cnych proces\u00f3w przy opracowywaniu optymalnych rozwi\u0105za\u0144 dla danego obszaru\nPrzygotujesz analizy po wdro\u017ceniu nowych rozwi\u0105za\u0144, zbudujesz wnioski i rekomendacje\nB\u0119dziesz analizowa\u0107 du\u017ce zbiory danych w poszukiwaniu prawid\u0142owo\u015bci i zale\u017cno\u015bci, kt\u00f3re wp\u0142ywaj\u0105 na kluczowe dla firmy obszary\nB\u0119dziesz mia\u0142 okazj\u0119 pracowa\u0107 nad autorskimi rozwi\u0105zaniami z zakresu ML\nZe swojej strony oferujemy:\nStabiln\u0105 prac\u0119 w firmie ze startupow\u0105 kultur\u0105 organizacyjn\u0105, kt\u00f3ra jest cz\u0119\u015bci\u0105 grupy Allegro\nMo\u017cliwo\u015b\u0107 uczestnictwa w wybranych wydarzeniach kulturalnych, rozrywkowych i sportowych z oferty eBilet.pl\nModel pracy hybrydowej\nBogaty pakiet \u015bwiadcze\u0144 pozap\u0142acowych w systemie kafeteryjnym \u2013 Ty decydujesz z czego korzystasz (do wyboru mamy m.in. pakiety medyczne, sportowe, lunchowe, ubezpieczenia, bony na zakupy)\nZaj\u0119cia angielskiego op\u0142acane przez nas i skoncentrowane na specyfice Twojej pracy\nPrac\u0119 w zespole, na kt\u00f3rego wsparcie zawsze mo\u017cesz liczy\u0107 -  na pok\u0142adzie mamy najlepszych specjalist\u00f3w i ekspert\u00f3w w swojej dziedzinie\nTurystyk\u0119 zespo\u0142ow\u0105, bud\u017cet szkoleniowy oraz wewn\u0119trzna platforma MindUp (m.in. szkolenia z zakresu organizacji pracy, sposobu komunikacji, motywacji do pracy oraz r\u00f3\u017cnych technologii i zagadnie\u0144 merytorycznych)\nJe\u015bli chcesz wiedzie\u0107 wi\u0119cej - sprawd\u017a sam\/a\nTa oferta jest dla Ciebie, je\u015bli:\nPosiadasz do\u015bwiadczenie w analizie du\u017cych wolumen\u00f3w danych i potrafisz \u0142\u0105czy\u0107 dane z wielu r\u00f3\u017cnych \u017ar\u00f3de\u0142\nMasz do\u015bwiadczenie z prac\u0105 w hurtowni danych\nWiesz jak dobiera\u0107 techniki statystyczne i metody wizualizacji danych adekwatne do problemu badawczego (must have = Tableau, nice to have = Data Studio)\nBardzo dobrze znasz SQL (Oracle, GCP, Spark) oraz masz do\u015bwiadczenie w pracy z rozproszonymi systemami baz danych (cz\u0119\u015bci\u0105 procesu rekrutacji b\u0119dzie test z SQL)\nPotrafisz jasno komunikowa\u0107 wyniki analiz i rekomendacje z nich p\u0142yn\u0105ce\nPotrafisz wsp\u00f3\u0142pracowa\u0107 z wieloma interesariuszami, wypracowuj\u0105c przy tym efektywne sposoby komunikacji\nPotrafisz zidentyfikowa\u0107 problem i zaproponowa\u0107 skuteczne rozwi\u0105zanie\nZnasz j\u0119zyk angielski na poziomie min. B2 \nMile widziane: znajomo\u015b\u0107 Pythona oraz narz\u0119dzi takich jak: GA4, GTM, AUTO ML.\nWy\u015blij nam swoje CV i sprawd\u017a dlaczego #dobrzetuby\u0107\nChcesz nas lepiej pozna\u0107? Pos\u0142uchaj Allegro Podcast","276":"Company Description\nPublicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients\u2019 businesses through creating the products and services their customers expect.\nJob Description\nAs a  Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.\n\nYour role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.\n\nAs a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration.\nQualifications\n Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS \/ Azure \/ GCP)\nExperience delivering end to end Big Data solutions on premise and\/or on Cloud\nKnowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases\nExpertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions\nProficiency in Java and Scala programming languages (Python a plus)\nExpertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.)\nExperience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub\/Sub etc.)\nExpertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc.\nKnowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding\nKnowledge of performance tuning, optimization and scaling solutions from a storage\/processing standpoint\nExperience building DevOps pipelines for data solutions, including automated testing\nYou\u2019ll Also Likely Have Some Of The Following\nKnowledge of containerization, orchestration and Kubernetes engine\nAn understanding of how to setup Big data cluster security (Authorization\/ Authentication, Security for data at rest, data in transit)\nA basic understanding of how to manage and setup Monitoring and alerting for Big data clusters\nExperience of orchestration tools \u2013 Oozie , Airflow , Ctr-M or similar\nExperience of MPP style query engines like Impala, Presto, Athena etc.\nKnowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\nExposure to data governance, catalog, lineage and associated tools would be an added advantage\nA certification in one or more cloud platforms or big data technologies\nAny active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV\/POC, hackathon)\nAdditional Information\nThere is a superb package of benefits waiting for you at Publicis Sapient.\nWe cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension.\nThe learning opportunities here are endless. Most importantly, of course, there\u2019s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine.\nFlexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services.","277":"Company Description\nPublicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients\u2019 businesses through creating the products and services their customers expect.\nJob Description\nAs a  Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.\n\nYour role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.\n\nAs a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration.\nQualifications\n Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS \/ Azure \/ GCP)\nExperience delivering end to end Big Data solutions on premise and\/or on Cloud\nKnowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases\nExpertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions\nProficiency in Java and Scala programming languages (Python a plus)\nExpertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.)\nExperience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub\/Sub etc.)\nExpertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc.\nKnowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding\nKnowledge of performance tuning, optimization and scaling solutions from a storage\/processing standpoint\nExperience building DevOps pipelines for data solutions, including automated testing\nYou\u2019ll Also Likely Have Some Of The Following\nKnowledge of containerization, orchestration and Kubernetes engine\nAn understanding of how to setup Big data cluster security (Authorization\/ Authentication, Security for data at rest, data in transit)\nA basic understanding of how to manage and setup Monitoring and alerting for Big data clusters\nExperience of orchestration tools \u2013 Oozie , Airflow , Ctr-M or similar\nExperience of MPP style query engines like Impala, Presto, Athena etc.\nKnowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\nExposure to data governance, catalog, lineage and associated tools would be an added advantage\nA certification in one or more cloud platforms or big data technologies\nAny active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV\/POC, hackathon)\nAdditional Information\nThere is a superb package of benefits waiting for you at Publicis Sapient.\nWe cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension.\nThe learning opportunities here are endless. Most importantly, of course, there\u2019s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine.\nFlexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services.","278":"Hello!!\nWe are thrilled to have you here!!!\nWe are growing and we would love to have you in our company but it\u00b4s fair to say we\u00b4ll have great people in the right places as soon as we have an open spot!\nOur open positions on the website are a talent pool vacancies and we\u00b4ll reach out whenever we get an opening that fits better for you!\nSo please, apply for the best opportunity you have for you and in the right moment, we\u00b4ll be in touch!!\n  About us\nWe are part of ABInBev\u2019s ecosystem, the biggest brewer in the world, and we work to help our costumer\u2019s life using a range of BEES Applications.\nAs a tech cell of our organization, we have a simple goal: to grow. Grow as people, as professionals, as a company.\nTo achieve it, we use the technology creating digital solutions that make our costumers lives simpler, their decisions smarter and their business more profitable.\n  What you\u00b4ll do:\nResponsible for creating and producing forecasts, reports, ad hoc requests, dashboards, etc.\nin order to provide insights to determine operational impact, trends, and opportunities.\n\nDesign and create data visualizations (reports and dashboards) that tell a compelling\nnarrative as required to support business needs.\n\nIntegrate data from multiple sources to produce requested or required data elements\n\nCreate and maintain report forms and formats, information dashboards, data generators,\ncanned reports and other end-user information portals or resources\n\nEnsure compliance with deliverable reporting requirements by performing quality data audits\nand analysis\n\nReviewing and improving existing dashboards and collaborating with teams to integrate new\n\nsystems.\n\nWhat you\u00b4ll need:\n5+ years of Tableau Desktop Experience, Tableau dashboards, visualizations, and\nperforming advanced analytics\n\n3- 5 years of experience writing complex SQL queries to build Tableau data sources.\n\nAble to monitor scheduled Tableau extract jobs and proactively fix and rerun failed\nprocesses, notify team, automate notifications, etc\n\nAbility to analyze and interpret data.\n\nAbility to work independently, as well as in a collaborative and dynamic team environment\n\nExcel knowledge is a plus.\n\nBachelor's degree in business or related field\nWhat We Offer:\nPerformance based bonus*\nFourteen annual salaries*\nPrivate pension plan\nMeal Allowance\nCasual office and dress code\nDays off*\nHealth, dental, and life insurance\nMedicines discounts\nGympass partnership\nZenklub partnership\nChildcare subsidies\nDiscounts on Ambev products*\nNewvalue partnership\nScholarship*\nSchool materials assurance\nLanguage and training platforms\nTransport allowance\n*Rules applied\nEqual Opportunity & Affirmative Action:\nBees is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon of race, color, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other applicable legally protected characteristics.\nThe following fields are optional, but anticipate the information for your registration*.\nRemember: your data will never be used as elimination criteria in selection processes. With them, Bees is able to analyze diversity and reduce biases in selection processes. We want to contribute to changing this reality by being an inclusive company.\nFor more information: www.bees.com\n   ","279":"Company Description\nPushing the Edge\nVANTIVA, headquartered in Paris, France and formerly known as Technicolor, is a global technology leader in designing, developing and supplying innovative products and solutions that connect consumers around the world to the content and services they love \u2013 whether at home, at work or in other smart spaces.\nVANTIVA has also earned a solid reputation for optimizing supply chain performance by leveraging its decades-long expertise in high-precision manufacturing, logistics, fulfillment and distribution.\nWith operations throughout the Americas, Asia Pacific and EMEA, VANTIVA is recognized as a strategic partner by leading firms across various vertical industries, including network service providers, software companies and video game creators for over 25 years. Our relationships with the film and entertainment industry goes back over 100 years by providing end-to-end solutions for our clients.\nVANTIVA is committed to the highest standards of corporate social responsibility and sustainability across all aspects of their operations. For more information, please visit www.vantiva.com and follow us on LinkedIn and Twitter.\nJob Description\nWithin Vantiva Broadband & Video, located in Rennes R&D site, and as part of the Operations Global Sourcing team, under the Systems, Processes and Strategy department, the candidate will be responsible for supply chain sustainability data, management, and reporting in support of Product and Component Part Regulatory Compliance.\n Responsibilities:\nMaintain knowledge of European Environmental and Human Rights Regulations and Decrees that may impact the supply chain of our products ;\nCollaborate with Vantiva\u2019s R&D Product Compliance team on other new customer requirements for products which impact the supply chain ;\nUse company tools and 3rd party compliance platforms to manage supplier part Declarations of Compliance (DoCs) and related data: review documents for accuracy, update our part and supplier database, ensure all parts are compliant, and create reports ;\nResolve supplier issues such as incomplete, outdated or missing Declarations, inaccurate reporting of substances, use of banned or restricted substances, etc ;\nManage EU Waste Framework Directive actions to ensure that Vantiva\u2019s European Products are registered in the SCIP Database, in collaboration with Vantiva\u2019s supply chain compliance management partner, ASSENT ;\nCollaborate with internal sourcing managers for supplier management and issue escalations ;\nProvide Ad hoc support of Product Teams, New Product Development groups, Customers, Legal, and others as required, for supply chain compliance data and reports ;\nSupport the Supply Chain Sustainability\u2019s Team KPIs and objectives, to ensure that Vantiva products and BOM parts meet all compliance requirements.\n To do so, you will be asked to use your knowledge of :\nRegulatory agency requirements on banned and restricted substances such as EU Directives on RoHS, REACH, CRM (Critical Raw Materials) and POPs, and Flame Retardants found in plastics and PCBs ;\nManaging project activities independently and collaborating with a variety of internal and external teams (which include suppliers, manufacturing partners, and compliance partner (ASSENT) team members).\nQualifications\nCandidate Profile:\nDegree in Electrical or Mechanical Engineering, Chemistry, Environmental Science, or similar ;\nPrevious relevant experience (+5 years) with environmental \/ sustainability compliance regulations and reporting for electronic products, data management, and reporting ;\nRelevant previous experience in Project Management skills and ability to work independently ;\nKnowledge of tools such as PLM (Agile), Power BI, Sharepoint, Excel, and Microsoft TEAM is desired.  Familiarity with any third party Regulatory Compliance Data Management tool is a plus ;\nGood communications skills, ability to collaborate with global internal and external cross-functional teams, as well as global supplier network ;\nFluent English (verbal and written) is required ;\nKnowledge of Corporate Social Responsibility (CSR) topics such as Conflict Minerals, Human Rights, Forced Labor Prevention and Due Diligence is a plus ;\nTravel may be required during this mission.\nAdditional Information\n  ","280":"Company Description\nVisa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging \u2013 where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world \u2013 helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone.\nJob Description\nVisa Consulting and Analytics (VCA), the consulting arm of Visa, is a global team of industry experts in strategy, marketing, operations, risk and economics consulting, with decades of experience in the payments industry. Our VCA teams offers: Consulting services customized to the needs of Visa client's business objectives and strategy Business and economic insights and perspectives that impact business and investment decisions Self-service digital solutions Visa clients can leverage to improve performance in product, marketing and operations Proven data-driven marketing strategies to increase clients' ROI VCA team is looking for a passionate individual to join our consulting practice and play a role in the data engineering team. The ideal candidate is adept at using big data sets to understand our client's challenges and deploy targeted solutions to drive meaningful benefits, leveraging our world-class payment knowledge, in combination with our diverse service offerings to address key strategic needs for Visa's clients including issuers, acquirers and merchants. He\/She must have experience using a variety of data mining\/data analysis methods, using a variety of distributed data platforms, and leveraging the latest open-source technologies. He\/She must have a proven ability to drive business results with their data-based insights. Adept at creative and critical thinking, be able to deconstruct problems and transform insights into large scale, state-of-the-art solutions. Responsibilities Automate and standardize data processes developed by team members. Leverage DevOps to create end-to-end streamline CI\/CD data and ML pipelines. Review and manage data pipelines, branching, and deployment process. Work with partners on requirements and implementation designs of data solutions. Implement data quality framework at scale using open-source technologies. Create data monitoring dashboards with real-time notifications. Understand VisaNet data and platform ecosystem to deploy fully automatic data applications for internal and external clients. Unify data engineering and machine learning engineering pipelines. Apply spark optimization techniques to production jobs to accelerate data prep. Document process, designs, test results, and analysis. Ability to articulate complex architectures to non-technical audiences, management, and leadership. Continuously research industry best practices and technologies. Evangelize end to end automation and standardization across the organization. Partner with functional areas, and regional and global teams to leverage the breadth and depth of Visa\u2019s resources. This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership\/site), with a general guidepost of being in the office 50% or more of the time based on business needs.\nQualifications\nBasic Qualifications \u2022 BA\/BS required, MBA or other relevant Master\u2019s degree preferred (e.g. engineering, computer science, computer engineering, applied mathematics, or other related fields) Preferred Qualifications \u2022 At least 5 years of experience as data engineer or data scientist with open-source tools. \u2022 Experience in retail banking, payments, financial services, and\/or technology industries is a plus. Strong interest in the future of payments is a must. \u2022 Strong technical competency and experience with shell-scripting and Linux systems. \u2022 Experience with CI\/CD pipeline using Azure DevOps, GitHub actions, Jenkins, or Airflow. \u2022 Strong coding skills in Spark, Python and SQL to manipulate big data in distributed platforms. \u2022 Good to have experience in navigating in Linux\/Unix\/Container based apps such as Docker, Kubernetes, or Microservices environments. \u2022 Knowledge in how to leverage AI assistance tools like chatGPT for creating and debugging code. \u2022 Ability to interact with big data clusters using Jupiter Notebooks, terminal, or GUI. \u2022 Demonstrate experience leveraging open-source tools, libraries, and platforms. \u2022 Experience with data visualization and business intelligence tools like Tableau, PowerBI, Microstrategy, or Excel. \u2022 Problem solving ability and process creator with strategic focus on replicability, scalability, innovation, and governance. \u2022 Proficient with git for version control and code collaboration using branches and pull requests. \u2022 Must be passionate about automation and data and able to deliver high quality work. \u2022 Experience developing as part of Agile\/Scrum team. \u2022 Fluency in English (spoken\/written). Portuguese or Spanish is a plus. \u2022 Experience in developing integrated cloud applications with services like AWS, Azure Cloud, and GCP is a plus.\nAdditional Information\nVisa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.","281":"Unternehmensbeschreibung\nWir bei rheindata beraten unsere Kunden in den Bereichen Big Data, Business Intelligence und Data Science. Wir sind ein buntes Team aus den unterschiedlichsten Fachbereichen wie z.B. Mathematik, VWL, Informatik oder Physik. Uns ist wichtig, dass wir uns weiterbilden k\u00f6nnen und offen sind, unser Wissen zu teilen. Bei uns gibt es wenig B\u00fcrokratie, stattdessen kurze und flache Entscheidungswege und gro\u00dfes Mitspracherecht. Wenn du also Lust hast, uns kennenzulernen\u2026 los geht\u00b4s!\nStellenbeschreibung\nAls BI Berater ETL\/ELT (m\/w\/d)\narbeitest du in unterschiedlichen BI Projekten bei unseren Kunden und entwickelst kreative und innovative BI L\u00f6sungen,\nentwickelst du ETL\/ELT Strecken und zudem orchestrierst und parallelisierst du Ladestrecken,\nerstellst du SQL-basierte Datenbank-Abfragen,\narbeitest du mit strukturierten und unstrukturierten Daten\nund bist du offen f\u00fcr neue Technologien und gibst dein Wissen auch gerne weiter.\nQualifikationen\nDas bringst du mit:\nEinige Jahre praktische Erfahrung im BI Bereich,\nein abgeschlossenes Studium in einem MINT (Mathematik, Informatik, Wirtschaftsinformatik, -mathematik, Physik o.\u00e4.)- oder wirtschaftswissenschaftlichen (BWL, VWL, o.\u00e4.) Fach,\nKommunikationsst\u00e4rke,\nDeutschkenntnisse auf muttersprachlichem Niveau (C2),\nEnglisch flie\u00dfend in Wort und Schrift.\nZudem verf\u00fcgst du \u00fcber Kenntnisse z.B. in:\nSSIS, Talend oder Informatica\nSQL\nErfahrung in Cloud-Plattformen wie Azure, AWS oder GCP\nZus\u00e4tzliche Informationen\nDas bieten wir dir:\n6 Wochen Urlaub im Jahr und in jedem f\u00fcnften Jahr sogar 10 Wochen\neine deinen Bed\u00fcrfnissen entsprechende Einarbeitungsphase mit Begleitung deines Mentors,\ndie M\u00f6glichkeit zu individuell gestaltbaren Sabbaticals,\ndie Teilnahme an unserem Mitarbeiter-Beteiligungsprogramm,\neine kostenlose M-Mitgliedschaft bei Urban Sports Club und verg\u00fcnstigte Konditionen bei L- und XL-Tarifen\nneben einem attraktiven Verg\u00fctungspaket erh\u00e4ltst du nat\u00fcrlich ein Notebook und ein Smartphone sowie weitere Zusatzleistungen wie z.B. Jobticket, JobRad oder betriebliche Altersvorsorge\nje nach Projektgegebenheiten, die M\u00f6glichkeit im Homeoffice zu arbeiten \u2013 wobei du in unserem B\u00fcro im belgischen Viertel nat\u00fcrlich auch immer willkommen bist.","282":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value.\nJob Description\nAs Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects:\nData Ingestion, Transformation & Consumption,\nData Storage and Computation Frameworks,\nPerformance Optimizations,\nInfrastructure, Automation & Cloud Computing,\nData Governance & Security\nThe role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java \/ Scala \/ Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL\/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.\nRole & Responsibilities:\n1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation.\n2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality\n3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality\n4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies\n5. Participate in workshops with clients and align client stakeholders to optimal solutions.\n6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc.\n7. People management, contributing to hiring and capability building\nQualifications\nOverall 8+ years of IT experience with 3+ years in Data related technologies \n3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS \/ Azure \/ GCP) and delivered at least 1 project as an architect.\nMandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud. \nExpert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions\nExpert in programming languages like Java\/ Scala and good to have Python\nExpert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub\/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc.\nExpert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc.\nShould have worked on MPP style query engines like Impala , Presto, Athena, etc\nShould have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc.\nShould have a good understanding of how to set up Big data cluster security \u2013 Authorization\/ Authentication, Security for data at rest, and data in Transit.\nShould have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager \u2013 Data Engineering\nShould have worked on any of Orchestration tools \u2013 Oozie, Airflow, Ctr-M, or similar.\nWorked on Performance Tuning, Optimization, and Data security\n  Competency\n1. Excellent understanding of data technologies landscape\/ecosystem.\n2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases\n3. Good Exposure in development with CI \/ CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage.\n4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\n5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage.\n6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions\n7. Thought Leadership \u2013 blogs, keynote sessions, POV\/POC, hackathon\n8. Certification in either one of the cloud platforms or big data technologies\nPersonal Attributes:\nStrong analytical and problem-solving skills\nStrong communication skills in verbal, written and visual presentations\nStrong coordination and negotiation skills\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nMulti geo experience and distributed delivery experience in large programs\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements \nEmployee Assistance Programs to help you in wellness and well being","283":"Company Description\nWelcome to SMG Swiss Marketplace Group AG\nWe are a pioneering network of online marketplaces and a leading European digital company that simplifies people's lives with forward-looking products.\nJob Description\nAs the new Business Intelligence Developer, you will be part of the Group Data Team (GDT). You will work together with data engineers, data architects, data product owners and diverse business domain stakeholders to make group-wide data more accessible, well-governed and understood.\nAs a contributor to the GDT, you will be responsible for delivering data products for our internal customers. To be effective in this position, you must be comfortable working with various business domains, a bottom-up management approach and be able to get up to speed with new technologies quickly.\n Role Ratio:\n60% Backend - data extraction, loading and transformation (ELT)\n40% Frontend - data visualization (charts and dashboard building)\n\nYour Responsibilities:\nMake use of the cloud infrastructure created by data engineers to extract, load and transform (ELT) data from different sources\/domains into the Group Business Intelligence platform\nDevelop reusable data assets (marts, reports, metrics, metadata) that reflect the business's needs and follow data protection guidelines\nApply data warehousing best practices to the data assets and monitor them to guarantee data completeness, uniqueness, consistency, validity, accuracy and timeliness\nFollow naming standards guidelines and perform technical data documentation in order to have data assets metadata flowing into the group data catalogue and downstream tools\nVersion code, deploy using continuous integration and continuous delivery tools, review code and test changes assuring data quality and business requirements satisfaction.\nImplement business-defined metrics and key performance indicators as a single source of truth\nWork closely with the BI Team Lead, Data Product Owner and Stakeholders to understand their needs\/requirements in order to design data visualizations that bring value, business insights capabilities and help the teams measure the impact of their work\nDevelop charts and dashboards using a cloud data visualization tool incorporating usability best practices and following SMG branding guidelines when designing it\nCollaborate with the remote teams making transparent your activities' progress and keeping Kanban board updated to keep track of tasks and documentation for future support on troubleshooting\nParticipate and collaborate with the data engineering, data product enablement and business intelligence teams in different workshops to define objectives and key results (OKRs) that are achievable in order to promote innovation and learning\nQualifications\n You have a Bachelor\u2019s or Master\u2019s Degree in Information Technology, Data Analytics, Management Information Systems, Computer Science, Artificial Intelligence, Data Science or a related technical\/data field\nYou have at least 2 years of professional experience working with Structured Query Language (SQL ansi)\nYou have at least 2 years of professional experience working with one data warehousing architecture (E.g. Star schema, Snowflake schema, One Big Table, Data Vault, Data Lake, etc)\nYou have at least 1 year of professional experience working with business intelligence or\/and analytics engineering or\/and data engineering or\/and data analysis\nYou have experience with at least one modern cloud data warehousing tool. E.g. BigQuery (preferably), Azure, Redshift, Snowflake, etc. \nYou have experience with at least one data visualization tool. E.g. Looker (preferably), Tableau, Power BI, etc.\nYou have experience with at least one code versioning tool. E.g. git (preferably), svn, etc.\nYou have experience with at least one code repository platform. E.g. Github (preferably), Bitbucket, etc.\nYou have strong interpersonal and collaboration skills, organization and attention to detail\nYou have the ability to take initiative and engage in discussions related to requirements and data products\nGood verbal and written communication skills in English. German is a plus.\n\n Nice to have experience with:\nOnline marketplaces and\/or digital businesses\nGoogle Cloud Platform data warehousing and business intelligence tools (BigQuery sql syntax, Looker as a LookML developer)\nData Build Tool (dbt core) as a data transformation tool\nThe git protocol and Github for code versioning and repository platforms\nAgile methodologies (E.g. Kanban, Scrum, Lean, etc)\nContinuous integration and continuous delivery (CI\/CD)\nAtlan data catalogue tool\nData mesh decentralized data architecture\nPython\nNotion\nJira\n Additional Information\nBenefits you'll love and why you should join us\nYour new team and the people you work with will consist of an international and diverse group of fantastic people.\nWe live a hybrid working model without fixed office days. You are welcome to work in our modern and spacious office in Zurich, or from your home base in Switzerland.\n In addition, SMG offers you:\n6 weeks of holidays (with the possibility to buy up to 10 additional days)\n40-hour week (flexitime) We take work-life balance seriously\n4 months' notice after the probationary period\nSBB Half-Fare Card\nYou travel 1st class by train between SMG sites in Switzerland\n18 weeks maternity and 6 weeks paternity leave (also in case of adoption)\nProfessional accident and supplementary insurance (100% covered by SMG)\nNo fixed office days (teams organize themself regarding onsite presence)\nIndependent counselling centre for personal and psychological problems\nGender-neutral fair pay with clearly defined career profiles\nChoose your hardware (Mac or Windows + 2 monitors for home)\nChoose your mobile phone (iPhone, Samsung or Pixel)\nFree Gym Facilities (Flamatt office only)\n Apply Now! We are looking forward to getting to know you!\n  SMG Swiss Marketplace Group Ltd. is a pioneering network of online marketplaces and an innovative European digital company that simplifies people\u2019s lives with groundbreaking products.\n\nSMG Swiss Marketplace Group Ltd. provides customers with the best tools to meet their life decision needs. The portfolio includes Real Estate (ImmoScout24, Homegate, Immostreet.ch, home.ch, Acheter-Louer.ch), Automotive (AutoScout24, MotoScout24, CAR FOR YOU), General Marketplaces (anibis.ch, tutti.ch, Ricardo) and Finance & Insurance (FinanceScout24). The company is owned by TX Group AG (31%), Ringier AG (29.5%), La Mobili\u00e8re (29.5%), and General Atlantic (10%).","284":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value\nJob Description\nAs Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions.\nYou will independently drive design discussions to ensure the necessary health of the overall solution.\nThe role requires a hands-on technologist who has strong programming background like Java \/ Scala \/ Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components.\nYou are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. \nRole & Responsibilities:\nYour role is focused on the Design, Development and delivery of solutions involving:\nData Integration, Processing & Governance\nData Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations\nInfrastructure & Cloud Computing\nData Management Platforms\nImplement scalable architectural models for data processing and storage\nBuild functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode\nBuild functionality for data analytics, search and aggregation\nQualifications\nOverall 5+ years of IT experience with 3+ years in Data related technologies\nMinimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS \/ Azure \/ GCP)\nHands-on experience with the Hadoop stack \u2013 HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline.\nStrong experience in at least of the programming language Java, Scala, Python. Java preferable\nHands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc\n Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security \n Competency\n1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience\n2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc\n3. Knowledge on distributed messaging frameworks like ActiveMQ \/ RabbiMQ \/ Solace, search & indexing and Micro services architectures\n4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 \u2013 Data Engineering\n5. CI\/CD \u2013 Infra provisioning on cloud, auto build & deployment pipelines, code quality\n6. Cloud data specialty and other related Big data technology certifications\nPersonal Attributes:\nStrong written and verbal communication skills\nArticulaion skills\nGood team player\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nProcess orientation and the ability to define and set up processe\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements\nEmployee Assistance Programs to help you in wellness and well being","285":"Company Description\nPublicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients\u2019 businesses through creating the products and services their customers expect.\nJob Description\nAs Senior Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.\n\nYour role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.\n\nAs a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration.\nQualifications\n Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS \/ Azure \/ GCP)\nExperience delivering end to end Big Data solutions on premise and\/or on Cloud\nKnowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases\nExpertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions\nProficiency in Java and Scala programming languages (Python a plus)\nExpertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.)\nExperience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub\/Sub etc.)\nExpertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc.\nKnowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding\nKnowledge of performance tuning, optimization and scaling solutions from a storage\/processing standpoint\nExperience building DevOps pipelines for data solutions, including automated testing\nYou\u2019ll Also Likely Have Some Of The Following\n Knowledge of containerization, orchestration and Kubernetes engine\nAn understanding of how to setup Big data cluster security (Authorization\/ Authentication, Security for data at rest, data in transit)\nA basic understanding of how to manage and setup Monitoring and alerting for Big data clusters\nExperience of orchestration tools \u2013 Oozie , Airflow , Ctr-M or similar\nExperience of MPP style query engines like Impala, Presto, Athena etc.\nKnowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\nExposure to data governance, catalog, lineage and associated tools would be an added advantage\nA certification in one or more cloud platforms or big data technologies\nAny active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV\/POC, hackathon)\nAdditional Information\nThere is a superb package of benefits waiting for you at Publicis Sapient.\nWe cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension.\nThe learning opportunities here are endless. Most importantly, of course, there\u2019s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine.\nFlexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services.","286":"Project Description\nWe occupy a unique position in the market because we are vertically integrated. We have both a PBM platform (RxAgile) that provides enterprise solutions to B2B players in the healthcare space and a direct to consumer product (SingleCare) with a mission to make prescription medication more affordable.\nResponsibilities\nPrimary Duties and Responsibilities:\nDesign and develop BI dashboards and reports in Qlik Sense\nDevelop and schedule Reports using NPrinting in Qlik Sense\nWork with Analysts and Stakeholders to develop requirements\nCreate Data Models that optimize performance and extensibility\nCreate Visualizations by translating requirements and finding innovative solutions\nWork with developers, BI engineers, business end users, UX designers and IT teams (DBA, Source system Developers, Data Analysts, QA Testers) for data accuracy and performance\nWork with a geographically diverse team. Escalate work progress and bottlenecks (if any) to the Lead Developer\nMinimum of 3 years overall Qlik experience\nMinimum of 4 years overall BI experience\nRequirements\nProficient in building Qlik Sense load Scripts and Qlik Sense Apps\nStrong knowledge of Qlik techniques and complex functions (ex: set analysis, aggregation, date & string functions, formatting, mapping & conditional statements, etc.)\nLoading data in Qlik Sense using Web Connectors\nStrong SQL skills\nData model optimization is a plus\nStrong experience and backend knowledge of Qlik Sense is preferred and is a plus Other Skills\nMust be a critical thinker who can successfully troubleshoot and solve data quality\/performance issues\nAbility to understand business needs and translate into technology solutions\nAbility to manage key project milestones with limited direct supervision.\nWork in a fast-paced, self-managed environment and juggle priorities based on project needs\nAbility to work in an agile environment\nPlanned, tracked, and managed agile development via Software (Ex. JIRA)\nMust have worked with BI tools in a development, and production support capacity Should be able to demonstrate a consistent progression of Qlik-related skill sets\nExperience working in Data Warehouse environments\nRewards\nPayment in USD.\nFree credentials for e-learning platforms.\nRemote workshops & activities.","287":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value.\nJob Description\nAs Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects:\nData Ingestion, Transformation & Consumption,\nData Storage and Computation Frameworks,\nPerformance Optimizations,\nInfrastructure, Automation & Cloud Computing,\nData Governance & Security\nThe role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java \/ Scala \/ Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL\/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.\nRole & Responsibilities:\n1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation.\n2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality\n3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality\n4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies\n5. Participate in workshops with clients and align client stakeholders to optimal solutions.\n6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc.\n7. People management, contributing to hiring and capability building\nQualifications\nOverall 8+ years of IT experience with 3+ years in Data related technologies \n3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS \/ Azure \/ GCP) and delivered at least 1 project as an architect.\nMandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud. \nExpert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions\nExpert in programming languages like Java\/ Scala and good to have Python\nExpert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub\/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc.\nExpert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc.\nShould have worked on MPP style query engines like Impala , Presto, Athena, etc\nShould have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc.\nShould have a good understanding of how to set up Big data cluster security \u2013 Authorization\/ Authentication, Security for data at rest, and data in Transit.\nShould have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager \u2013 Data Engineering\nShould have worked on any of Orchestration tools \u2013 Oozie, Airflow, Ctr-M, or similar.\nWorked on Performance Tuning, Optimization, and Data security\n  Competency\n1. Excellent understanding of data technologies landscape\/ecosystem.\n2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases\n3. Good Exposure in development with CI \/ CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage.\n4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\n5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage.\n6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions\n7. Thought Leadership \u2013 blogs, keynote sessions, POV\/POC, hackathon\n8. Certification in either one of the cloud platforms or big data technologies\nPersonal Attributes:\nStrong analytical and problem-solving skills\nStrong communication skills in verbal, written and visual presentations\nStrong coordination and negotiation skills\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nMulti geo experience and distributed delivery experience in large programs\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements \nEmployee Assistance Programs to help you in wellness and well being","288":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value\nJob Description\nAs Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions.\nYou will independently drive design discussions to ensure the necessary health of the overall solution.\nThe role requires a hands-on technologist who has strong programming background like Java \/ Scala \/ Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components.\nYou are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. \nRole & Responsibilities:\nYour role is focused on the Design, Development and delivery of solutions involving:\nData Integration, Processing & Governance\nData Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations\nInfrastructure & Cloud Computing\nData Management Platforms\nImplement scalable architectural models for data processing and storage\nBuild functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode\nBuild functionality for data analytics, search and aggregation\nQualifications\nOverall 5+ years of IT experience with 3+ years in Data related technologies\nMinimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS \/ Azure \/ GCP)\nHands-on experience with the Hadoop stack \u2013 HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline.\nStrong experience in at least of the programming language Java, Scala, Python. Java preferable\nHands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc\n Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security \n Competency\n1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience\n2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc\n3. Knowledge on distributed messaging frameworks like ActiveMQ \/ RabbiMQ \/ Solace, search & indexing and Micro services architectures\n4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 \u2013 Data Engineering\n5. CI\/CD \u2013 Infra provisioning on cloud, auto build & deployment pipelines, code quality\n6. Cloud data specialty and other related Big data technology certifications\nPersonal Attributes:\nStrong written and verbal communication skills\nArticulaion skills\nGood team player\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nProcess orientation and the ability to define and set up processe\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements\nEmployee Assistance Programs to help you in wellness and well being","289":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value.\nJob Description\nAs Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects:\nData Ingestion, Transformation & Consumption,\nData Storage and Computation Frameworks,\nPerformance Optimizations,\nInfrastructure, Automation & Cloud Computing,\nData Governance & Security\nThe role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java \/ Scala \/ Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL\/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.\nRole & Responsibilities:\n1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation.\n2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality\n3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality\n4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies\n5. Participate in workshops with clients and align client stakeholders to optimal solutions.\n6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc.\n7. People management, contributing to hiring and capability building\nQualifications\nOverall 8+ years of IT experience with 3+ years in Data related technologies \n3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS \/ Azure \/ GCP) and delivered at least 1 project as an architect.\nMandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud. \nExpert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions\nExpert in programming languages like Java\/ Scala and good to have Python\nExpert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub\/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc.\nExpert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc.\nShould have worked on MPP style query engines like Impala , Presto, Athena, etc\nShould have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc.\nShould have a good understanding of how to set up Big data cluster security \u2013 Authorization\/ Authentication, Security for data at rest, and data in Transit.\nShould have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager \u2013 Data Engineering\nShould have worked on any of Orchestration tools \u2013 Oozie, Airflow, Ctr-M, or similar.\nWorked on Performance Tuning, Optimization, and Data security\n  Competency\n1. Excellent understanding of data technologies landscape\/ecosystem.\n2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases\n3. Good Exposure in development with CI \/ CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage.\n4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\n5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage.\n6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions\n7. Thought Leadership \u2013 blogs, keynote sessions, POV\/POC, hackathon\n8. Certification in either one of the cloud platforms or big data technologies\nPersonal Attributes:\nStrong analytical and problem-solving skills\nStrong communication skills in verbal, written and visual presentations\nStrong coordination and negotiation skills\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nMulti geo experience and distributed delivery experience in large programs\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements \nEmployee Assistance Programs to help you in wellness and well being","290":"At Jamf, people are at the core of everything we do. We do what\u2019s right for our customers, our employees, our communities and our world. We take pride in simplifying technology for tens of thousands of customers around the globe and helping organizations succeed with Apple.\n  Jamf operates as a choice-based office model. Choose to work in the office, connect 100% remote from your home, or find the blend that works best for you.\n  What you\u2019ll do at Jamf: \nAt Jamf, we empower people to be their best selves and do their best work.The Business Intelligence Data Analyst collaborates with members of the primary business functions to provide key insights, reports, and visibility to the goals of the organisation. They work with the leaders of the key business functions to understand data visibility needs and create effective ways to share that data on a regular basis. The Business Intelligence Data Analyst works in conjunction with members of the Business Intelligence team to create, adapt, and grow our access and availability of data based on the needs of the organization.\nThis role is remote in the United Kingdom. We are only able to accept applications for those based in the UK or have sponsorship to live and work in the UK.\n\nResponsibilities: \nCollaborates with other Data Analysts and business leaders in multiple business functions to understand visibility\/reporting needs.\nCollaborates with BI team members to create innovative ways to deliver data and insights to internal customers.\nCreates engaging, accurate, and effective reports and dashboards.\nExplains trends across data\/reports, potential opportunities, and caveats when looking at descriptive, diagnostic, predictive and prescriptive data analysis.\nHelps build better understanding of that data leading to wider use and data intelligence across the organisation.\nHelps to drive growth of our data warehouse as well as documenting the lifecycle of data in our Data catalog.\nMonitors and provides solutions to issues submitted through the Business Operations ticketing system.\nPerforms the role of a Data stewards to improve data health, quality, and governance.\nUnderstands and executes within the data quality metrics set by the Data stewards.\nOther duties and special projects as assigned.\n\nSkills & Requirements:\n4 Year \/ Bachelor\u2019s Degree in Science, Engineering, Technology, Mathematics, or related field (Required).\nA combination of relevant experience and education may be considered.\nMinimum of 1 year of data reporting\/analysis experience (Required).\nMinimum of 1 year of experience with business intelligence tools such as DOMO or Tableau (Required).\nAbility to write complex SQL including multi-table joins, grouping, aggregation, common table expressions and conditional filters (Required).\nFluency in English.\nExperience working with a variety of data sources. Such as Salesforce, Marketo, Google suites, APIs, etc (Preferred).\nAble to communicate complex business logic, technical requirements, and design recommendations clearly and concisely.\nExperience cleaning and modelling raw or disorganised data.\nEffective management of tasks and clear communication of status of work.\nComfortable working in an agile environment and taking an iterative approach to solutioning.\nSelf-starter with a passion for solving problems.\nHighly Organised and detail-oriented.\nAbility to build strong relationships with team members across various departments.\nAbility to work in situations with changing priorities and parallel projects.\nAbility to prepare high-level summaries and reports.\nAbility to prioritise and execute on highest priority first.\n\nHow we help you reach your best potential:\nNamed a Fortune Best Workplace in Technology, 2021.\nWe know that big ideas can come from anyone, so we empower everyone to make an impact. Our more than 90% employee retention rate agrees!\nYou will have the opportunity to make a real and meaningful impact for more than 60,000 global customers with the best Apple device management solution in the world.\nWe put people over profits \u2013 which is why our customers keep coming back to us.\nOur volunteer time off allows employees to support and give back to our communities.\nWe encourage you to simply be you. We constantly seek and value different perspectives to ensure Jamf is a place where everyone feels comfortable and can be successful.\n23 of 25 world\u2019s most valuable brands rely on Jamf to do their best work (as ranked by Forbes).\nOver 100,000 Jamf Nation users, the largest online IT community in the world.\nWhat is a Jamf?\nYou go above and beyond for others, are willing to help, and support the team around you. You value and learn from different perspectives. You are curious and resourceful, a problem-solver, self-driven and constantly improving. You are excited by not knowing what may lie ahead. You are willing to take risks, try new things, even fail just to do it better next time. You\u2019re not a jerk. You are someone who cares about doing the right thing.\n\nWhat does Jamf do?\nJamf extends the legendary Apple experience people enjoy in their personal lives to the workplace. We believe the experience of using a device at work or school should feel the same, and be as secure as, using a personal device. With Jamf, IT and security teams are able to confidently manage and protect Mac, iPad, iPhone and Apple TV devices, easing the burden of updating, deploying and securing the data used by their end-users. Jamf\u2019s purpose is to simplify work by helping organizations manage and secure an Apple experience that end-users love and organizations trust.\n  We are free-thinkers, can-doers and problem crushers with a passion for helping customers empower their workforce to focus on their jobs, not the hassles of managing technology \u2013 freeing nurses to care, teachers to teach and businesses to thrive. We have over 2,500 employees worldwide who are encouraged to bring their whole selves to work each and every day.\n  Get social with us and follow the conversation at #OneJamf\n  #LI-REMOTE","291":"Senior Software Engineer, Big Data\nLocation: Remote Romania - This role can be performed anywhere in Romania\nAbout Data Science Engineering (DSE) \nDSE at GoPro is responsible for our in-house data platform infrastructure, data engineering, automated data analytics reporting, and ML Ops platform. We are responsible for enabling and empowering our partners in product engineering, software engineering, product analytics, marketing, and subscription business to make data-driven decisions by providing infrastructure, tools, services, and visualization to access data and business reports. We also prepare data and metrics to support data scientists and business operations.\nAbout the role: \nThe ideal candidate is an experienced software engineer focused on understanding business requirements and designing & developing data solutions in a big-data ecosystem. The candidate with a passion for analyzing the data, understanding its relationship and sharing insights with the combination of building & optimizing data systems and software engineering best practices.\nWhat you will likely do:\nUnderstand business requirements, assess the level of effort, and break down the development solution to the granular task level.\nWork with business and engineering\/solution teams to understand the upstream data sources \/ raw datasets and develop data models to build quality datasets.\nPlan, design, develop, test, deploy, document and support data pipeline solution for ingesting, storing, processing, and querying data at scale.\nCreate and maintain documentation and technical specification.\nCreate metrics and graphs to visualize and validate datasets.\nContribute to successful project completion by participating in the resolution of issues\nSkills We\u2019re excited About:\nWe are looking for a candidate with 5+ years of demonstrable ability in designing & developing highly scalable, and fit-for-purpose data solutions, who has attained a degree in Computer Science, Information Systems, or another quantitative field.\nStrong software development experience with\u202fproficiency\u202fin Scala or Java.\nYou are passionate about the architecture of the Big Data Technology stack consisting of layers: Data Modeling, Data Lakehouse, Data Pipeline, and Data Analytics.\nHave experience in designing and building scalable\/reliable data pipelines using the Big Data ecosystem (Hive\/Spark\/Databricks\/Presto\/Kafka\/Airflow or equivalents).\nExperienced in creating, modifying, and querying database entities (tables, views) using optimized SQL for performance and knowledge in data warehouse data models.\nExperienced in the design\/implementation of scalable and reliable services using AWS or other cloud services.\nKnowledge of Machine Learning Model Operationalization (MLOps) is a plus.\nYou have the capability to synthesize business requirements and construct technical requirements.\nYou are a strong problem solver with meticulous attention to detail and can tackle loosely defined problems.\nSkilled in written and verbal communication skills with an ability to communicate in a clear, collaborative, open-minded, and effective manner with both technical and non-technical peers.\nWhy Work With Us?\nCreate your own destiny. GoPro enables you and trusts you to get your own job done, because we believe that autonomy in role brings out the best in our employees.\nLive your best life. We\u2019ve adopted remote and flexible work arrangements to support work at GoPro alongside our commitment to supporting employee wellbeing, belonging and connection with one another.\nWork with leading edge technologies. We encourage employees to cultivate and use the latest and greatest technology, to provide the best solutions to serve our customers. We celebrate creative solutions that bring innovation to GoPro technology.\nGoPro Highlights\nGet your very own GoPro camera + gear;\nGenerous time off policy\nComprehensive healthcare benefits\nCompetitive salary and discretionary annual performance-related bonus\nGym fee compensation\nDiscounted employee stock purchase plan (ESPP)\nLiveHealthy monthly wellness reimbursement\nInnovative remote-friendly wellness classes and events\nFlexible work arrangements\nWe strive for the day that no group can be described as underrepresented at GoPro \u2013 whether as part of our brand or in our workforce. We are committed to providing a more inclusive, representative, equal, just and happy world. GoPro is proud to be an Equal Opportunity Employer.\n#LI-Remote #flexible #LI-CS1 #Data #Scala #Java #Python #SQL #ETL #BigData","292":"Pattern is a leading eCommerce data and growth company located in the Silicon Slopes tech hub with global offices in Europe, China, Australia, the Middle East and Canada. Named one of the fastest growing companies in the US by Inc. 500, Pattern has made its mark in the industry. Some of the biggest consumer brands like Skullcandy, Nestle, Clorox, Kong, Panasonic, Tumi and Popsockets trust Pattern with their eCommerce management. Pattern has recruited top talent from brands like Amazon, eBay, Adobe, Pepsico, Apple, Google and Oracle. Think you have what it takes to work at Pattern? If you have a whole lot of hustle and a touch of nerd, Pattern is the place for you.\nWe are looking for an experienced Business Intelligence developer to join our analytics team in Pattern\u2019s Pune office. This role will create a data model, develop the data transformation in Fivetran, write efficient SQL and create a stunning visualization in Tableau to tell a story using data.\nEssential Duties and Responsibilities:\nReceive ad-hoc requests for information and promptly respond with accurate information\nTranslate business needs to technical specifications\nWrite efficient SQL queries to interrogate data\nCreate stunning graphs\/reports\/dashboards using Tableau\nProven abilities to take initiative and be innovative\nCoordinate with BI team in US with weekly planning\nForecast, analyze data and trends and create reports that highlight areas in need of performance improvement\nWork with all levels of end users, including executive staff\nDive into data issues when questions arise and offer solutions\nConduct unit testing and troubleshooting.\nQualifications:\n10+ years developing reports\/dashboards using common analytics tools\nA Bachelor's degree in Computer Science, Information Systems, or related analytic field.\nStrong SQL skills\nExpert level with Tableau\nExpertise in data analysis and report design\/development\nExpertise in presentation\/interface creation\nUnderstanding of E-commerce fundamentals including Supply Chain, Advertising, and Sales\nStrong problem solving, analytical and diagnostic skills\nAbility to interact well in a team environment\nExcellent documentation and communication skills\nSnowflake or Fivetran experience is preferred\nStrong attention to detail.\nExperience in data warehouse design\nProven ability to write ETL transformations\nWhat We're About\nData Fanatics: Our edge is always found in the data\nPartner Obsessed: We are obsessed with partner success\nTeam of Doers: We have a bias for action\nGame Changers: We encourage innovation","293":"About us\nHere at GoCardless, we\u2019re building the world\u2019s bank payment network. Bringing simple and secure direct bank payment solutions for people and businesses everywhere, as well as making open banking more accessible. GoCardless is used by 75,000+ organisations and counting, processing more than $30 billion of payments across 30 countries. \nWe\u2019re an award-winning London based fintech, with additional offices in Riga, Paris, Melbourne and New York.\nThe Role\nWe are looking for experienced Business Intelligence Engineers to help support our growing business and build out our data capabilities. You will be working with the BI Engineering team to define and build GoCardless\u2019s core data models which provide the foundations for BI excellence and downstream data-hungry teams and tools. You\u2019ll create the underpinning models that enable deep insight into a fast-growing business and do so with scale and resilience in mind from day one. You\u2019ll help people in all areas of GoCardless make better, faster, more data-driven decisions and develop an expert knowledge of all areas of our operation. \nYou\u2019ll sit in our Product Development division and will work with technical and non-technical people across the whole company. You\u2019ll collaborate closely with our team of talented BI Analysts, designing and implementing the foundations they need to provide first class analysis to the business.\nThe main elements of this role will involve:\nDeveloping coherent and performant data models that transform large, complex and disparate datasets into explorable, understandable and accurate data products\nBuilding end-to-end BI solutions from ETL through to data modelling and on to front end dashboards\nCollaborating with engineers to prototype, design and build pipelines which take raw data from production systems and deliver them in a format suitable for analytic workloads\nSupporting people across the company to enable them to self-serve Business Intelligence through BI tools - we\u2019re using dbt and Looker at GoCardless. \nBuilding BI tooling that fully leverages the capabilities of Google Cloud Platform and BigQuery\nCollaborating with BI Analysts and other data teams to create a data architecture that powers their deep-dive analysis to both test specific hypotheses and generate new business insights\nCollaborating with our team of Data Infrastructure Engineers to design and implement ingestion pipelines for new data sources, leveraging their tooling to expand the breadth of the GoCardless data warehouse\nWhat excites you \nYou can point to a solid track record as a developer of first class data tooling\nYou\u2019re a self-starter - you take initiative in spotting opportunities and finding ways to solve problems with data\nYou\u2019re used to sharing your technical work in a clear way to others around you\nYou can turn complex business requirements into scalable, robust, explorable data products\nYou\u2019re good at quickly getting a grasp of any dataset that you\u2019re working with\nYou\u2019ll be able to demonstrate how you have automated repetitive tasks and built robust ETL pipelines\nWhat excites us  \nYou have excellent SQL skills and experience of scripting languages like Python\nExperience with Big Data technologies (e.g. BigQuery, Snowflake) and working with data at significant scale\nYou have a firm grasp of self-serve data tools like Looker, Tableau or similar. We\u2019re using Looker at GoCardless.\nYou have experience working in an agile environment at pace\nYou can communicate your work clearly to both technical and non-technical audiences\nYou are as comfortable sourcing data from third party APIs as you are with discussing data modelling approaches\nSalary Range: \u20ac3,420 - \u20ac3,780\n(some of) The good stuff\nWellbeing - stay healthy with dedicated support and medical cover\nWork away scheme - gives you the option to work away from your country of residence for up to 90 days in any 12 month period.\nAdaptive Working - allows you to work flexibly, around your lifestyle\nEquity - all permanently employed GCs get equity to help you make a valuable contribution \nParental leave - to suit everyone embarking on life's great adventure\nLearning Budget - lead your own development with an annual learning budget \nTime off - generous holiday allowance, + 3 annual volunteer days, + 4 annual business-wide wellness days (\u2018GC Fridays\u2019)\nLife at GoCardless  \nWe're an organisation defined by our values; We start with why before we begin any project, to ensure it\u2019s aligned with our mission. We act with integrity, always. We care deeply about what we do and we know it's essential that we be humble whilst we do it. Working this way creates the GC magic- the reason we all love showing up to work. \nDiversity & Inclusion\nWe\u2019re building the bank payment network of the future and our ambition is to move money anywhere, for anything, for anyone. If we\u2019re going to achieve this goal, we need to build a team of \u2018GeeCee\u2019s\u2019 that is as wonderfully diverse as the world we live in - with a multitude of perspectives, experiences & backgrounds.\nWe\u2019ve got a long way to go, but here\u2019s how we\u2019re doing as of June 2022;\nFemale Employees - 46%\nEthnic background - 32%\nIdentify as LGBTQIA - 10%\nNeurodivergent - 9%\nWe\u2019re rooting for you during your application and GoCardless aims to provide reasonable adjustments to make our recruitment process as remarkable and accessible as we can. Please speak to your Talent Partner if you need extra support.\nIf you want to learn more, you can read about our Employee Resource Groups and objectives here as well as our latest D&I Report \nSustainability \nWe\u2019re committed to reducing our impact on the environment, leaving a more sustainable world for future generations. In 2021 we became co-founders of the Tech Zero coalition, a group of businesses committed to taking climate action as part of the UNFCCC Race to Zero. We aim to reduce our impact and to create positive change on the natural world. Check out our sustainability action plan here. \nFind out more about Life at GoCardless via Twitter, Instagram and LinkedIn. ","294":"ABOUT THE ROLE\nThe Business Intelligence Engineer will be the lead who can take ownership of projects and provide technical design expertise. They should have strong experience in building data models to support the BI projects. They should also have working experience on more than one BI platforms ( Looker, Sigma, Tableau, Power BI etc). \nHOW YOU'LL SPEND YOUR TIME\nCreate dashboards and reports using data visualization tools such as Looker, sigma\nBuild data models to support the BI projects\nProvide analytics support to cross functional teams with data understanding and insights,  thus helping our clients grow\nCoordinate with data engineering and product team on product and data understanding and creating data models or Dashboards\nUse business intelligence data and tools to analyze product performance, conversion funnels and bring in actionable insights and recommendations for product improvement\nMaintain current knowledge of industry and business trends through communication with professional organizations, suppliers, customers, competitors, and other informed individuals\nSummarize product performance and financial data reports for review by executives, managers, clients, and stakeholders\nWHO YOU ARE\nMinimum 5-8 years of experience in the field of data and business analytics\nExcellent verbal and written communication skills\nBachelor's degree in Engineering\nProficient in SQL, Excel and scripting languages such as Python or R \nStrong working experience with BI tools (Looker, Sigma ,Power BI, Tableau)\nWorking experience in Looker is preferred\nExtremely organized with great attention to detail\nExcellent ability to analyze information and think systematically\nStrong business analysis skills\nWorks well independently and as part of a team\nThorough understanding of the company's business and product\nAbility to handle databases and understand technology-driven business intelligence tools\nWHAT CAN HELP YOU STAND OUT\nExperience in eCommerce and\/or ad-optimization is preferred\nABOUT TEIKAMETRICS \nTeikametrics\u2019 AI-powered Marketplace Optimization Platform helps sellers and brand owners maximize their potential on the world\u2019s most valuable marketplaces. Founded in 2015, Teikametrics uses proprietary AI technology to maximize profitability in a simple SaaS interface. Teikametrics optimizes more than $8 billion in GMV across thousands of sellers around the world, with brands including Munchkin, mDesign, Clarks, Nutribullet, Conair, Nutrafol, and Solo Stove trusting Teikametrics to unlock the full potential of their selling and advertising on Amazon, Walmart, and other marketplaces.\nThe job description is representative of typical duties and responsibilities for the position and is not all-inclusive. Other duties and responsibilities may be assigned in accordance with business needs. We are proud to be an equal opportunity employer. A background check will be conducted after a conditional offer of employment is extended. #LI-Remote","295":"Company Description\nHandling billions of transactions annually, Nexi Group is among the top payment processors in Europe. We keep a tight focus on making it even easier and more intuitive for our customers to handle digital payments and related services. This has made us a trusted partner to more than 700,000 merchant outlets, including 140,000 online merchant outlets, more than 260,000 enterprises and over 250 banks across Europe.\nChanging the future of payments takes strong personalities\nAt Nexi, you\u2019ll develop in a fast-growing tech company in a high-paced, high-impact market. Working to change the future of payments, it\u2019s not just skills and ambition that gets the job done, it\u2019s the full package that makes the difference. Together, we impact the lives of everyone around us by powering an easier tomorrow for every citizen, bank, business and colleague. What powers you at work?\nJob Description\nData Engineering team is focused on improving the process of identifying valuable data,collecting, structuring, and utilizing data to create comprehensive analytics to support different aspects of business streams.\nMain Responsibilities:\nTo Build DWH\/BI and Data analytics solutions and ensure continue growth of Data products\nImplementation of data mappings and design of data flows as well as ETL processes in an agile environment for different kind of Business intelligence solutions\nCreation of  secure and reliable ETL pipelines ingesting data sources\nTo Implement batch and transactional ingestion patterns\nCollaboration with customer business teams to understand business problems and to implement scalable and sustainable data solutions\nDesign data models for consumption by data scientists and business analysts.\nConduct complex data analysis and report on results.\nFurther development of the data and analytics platforms and conduct complex data analysis and report on results\nProactively share know-how, insights and experiences across the organization\nTo be able to provide a delivery and present its business value in an understandable way to all levels of stakeholders\nCreate data quality flows as a part of Data Governance \nQualifications\nUniversity degree in electrical engineering and computer science, mathematics, economics or other related discipline\nMinimum 3 years of experience with Data Engineering\nIt will be considered as advantage if you have experience with card business or Financial Industry\nCoding using different program languages\nKnowledge of building Data warehousing\nKnowledge of BI tools( e.g.Cognos), Data analytics knowledge\nCritical thinking skills\nWilling to promote data culture not only in technical teams but across the organization\nCommunication skills\nImprovement of BI customers processes including  the Machine learning principles\nWilling to understand  company's business processes and the industry at large\nAbility to understand technology-based business intelligence tools focused on improving the process of identifying valuable data\n Additional Information\nPlease apply with your CV latest until 28th of February\nIf you are curious\u2026\n\u2026and you want to know more, you're welcome to contact our Recruitment Business partner, Marija Babi\u0107, on marija.babic@nexigroup.com ","296":"Have you ever ordered a product on Amazon and when that box with the smile arrived you wondered how it got to you so fast?\nHave you wondered where it came from and how much it cost Amazon to deliver it to you?\nIf so, Amazon Logistics (AMZL), Last Mile team is for you. We manage the delivery of tens of millions of products every week to Amazon\u2019s customers, achieving on-time delivery in a cost-effective manner to deliver a smile for our customers.\n\nAmazon Logistics is looking for a customer focused, analytically and technically skilled Business Intelligence Engineer to drive effective performance measurement and management, innovation and execution in last mile delivery. This position will be responsible for playing a key role in our Analytics team building out analysis and visualization tools and processes\u2019 to support our growing Amazon Logistics business in Japan.\n\nThe successful candidate will be able to effectively retrieve, integrate, visualize and present critical data to improve the efficiency of the package delivery network. This individual will work with technical and business teams to optimize planning, execution, process improvement and track progress against goals. This role requires an individual with excellent analytical abilities as well as outstanding business acumen and comfort with technical teams and systems. The successful candidate will be a self-starter comfortable with ambiguity, with strong attention to detail, and enjoy working with large scale of data.\n\n[More Information]\nLast Mile Department\nData Analyst\/BI Engineer\nTokyo Office\n\n*Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, visit https:\/\/www.amazon.jobs\/disability\/jp\n\nKey job responsibilities\nPartner with internal stakeholders across multiple teams, gathering requirements and delivering complete solutions\nPartner with Data Engineering teams to prioritize and define AMZL JP data and BI development needs\nWork with in-house scientists, global supply chain, transportation and logistics teams to identify new BI capabilities and projects\nConduct deep dive investigations into operations execution and business problems, identify opportunities, and lead or support implementation\nAnalyze and visualize large geospatial datasets to uncover trends or issues relevant to last mile logistics, and output solid analysis report with recommendation\nDevelop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting\n\nAbout the team\nLast Mile Execution Analytics (LMEA) team of JP works as an integral part of Amazon Logistics to ensure that its business intelligence, analytics, tools and planning needs are met. By providing information, insight, and decision support, we strive to enable success of all parts of AMZL. Our customer set includes senior management, station operations, external vendors, long-term planning, Ops technology (Voice of the Delivery Station, Voice of the Customer), network planning, and pretty much every BI and Ops teams.\n\nVoice of Employee\n\n[Work Life Harmony]\nWe believe, it is important to spend private time such as spending time with your family or doing anything you like to spur innovation. Amazon promotes a fulfilling and flexible work style according to the work volume and lifestyle of each employee.\nBasic Qualifications\n\nBachelor's degree in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field\n2+ yrs of experience in analytical skills to integrate data\nAdvanced level of SQL and ETL, ability to write and tune complex SQL scripts and ETL development\nExperience using Python\n2+ yrs of experience in visualization tools such as GIS visualization, Tableau, QlikView, Quick Sight\nBusiness Level of English\n\nPreferred Qualifications\nMBA\/MS in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field\nBusiness Level of Japanese\n3+ years of relevant work experience building end - to end solutions to performance measurement and process improvement in a transportation, logistics or supply chain setting\n3+ yrs of experience in Operational Excellence initiatives, working with data warehousing and data quality (MySQL and Redshift)\n3+ yrs of experience implementing basic software solutions to automate data source, visualization and\/or data modeling application\nProject Management experience and\/or Tech product management experience\nOrganized, operational mindset with track record of delivering projects within scope, time, budget and quality\nAbility and interest in working in a fast-paced and rapidly-changing environment\nAbility to understand operations at a detailed, practical level and also to think big \/ strategically\nExperience with analyzing geospatial\/location data in SQL and\/or via a programming language\nExcited about working in a diverse group and contributing to an inclusive culture.\n\n\nPlease check the website below for measures to eliminate unwanted second-hand smoking in each facility:\nhttps:\/\/www.amazon.jobs\/en\/landing_pages\/passivesmoking\n\u5c31\u696d\u306e\u5834\u6240\u306b\u304a\u3051\u308b\u53d7\u52d5\u55ab\u7159\u3092\u9632\u6b62\u3059\u308b\u305f\u3081\u306e\u63aa\u7f6e\u306b\u95a2\u3059\u308b\u4e8b\u9805\u306b\u3064\u3044\u3066\u306f\u3001\u4e0b\u8a18\u30ea\u30f3\u30af\u5148\u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002\nhttps:\/\/www.amazon.jobs\/jp\/landing_pages\/passivesmoking\n\nThe salary information can be provided individually prior to the 1st interview\n\u8cc3\u91d1\u306b\u95a2\u3059\u308b\u6761\u4ef6\u306f\u3001\uff11\u6b21\u9762\u63a5\u306e\u524d\u306b\u500b\u5225\u306b\u3054\u6848\u5185\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059","297":"Job Description\nResponsibilities:\nDesigning, developing, troubleshooting, evaluating, deploying, and documenting data management and business intelligence systems, enabling stakeholders\/PO\u2019s to manage the business and make effective decisions.\nWork with business customers and product managers in understanding the business requirements and implementing\nSolutions to support analytical and reporting needs with highly scalable code repos.\nDesign and implement an analytical environment using third-party and in-house reporting tools, modelling metadata, building reports & dashboards and providing our stakeholders timely, flexible and structured access to their data.\nEnsuring completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements.\nReviewing and participating in testing of the data design, tool design, data extracts\/transforms, networks and consulting data driven solutions.\nImplement training and documentation solutions that enable business stakeholders to get the most out of our self-serve reporting tools.\nQualifications\nRequirements:\nBachelor's Degree in Computer Science or a related technical field, and solid years of relevant experience.\nA strong grasp of SQL\/Presto and at least one scripting (Python, preferable) or programming language.\nExperience with an enterprise class BI tools and it's auditing along with automations using REST API's.\nExperience with reporting tools \u2013 QuickSight (preferred, at least 2 years hands on).\nTableau\/Looker (both or anyone would suffice with at least 5+ years of hands on).\n5+ years of experience with and detailed knowledge of data warehouse technical architectures, data modelling, infrastructure components, ETL\/ ELT and reporting\/analytic tools and environments, data structures and hands-on SQL coding.\n5+ years of demonstrated quantitative and qualitative business intelligence.\nExperience with significant product analysis based business impact.\n4+ years of large IT project delivery for BI oriented projects using agile framework.\n2+ years of working with very large data warehousing environment.\nExperience in designing and delivering cross functional custom reporting solutions.\nExcellent oral and written communication skills including the ability to communicate effectively with both technical and non-technical stakeholders.\nProven ability to meet tight deadlines, multi-task, and prioritize workload.\nA work ethic based on a strong desire to exceed expectations.\nStrong analytical and challenge process skills.\nAdditional Information\nWhy work with us?\nSIXT is the company with legacy of more than a century offering healthy work environment, friendly work culture and continuous learning. The leadership here believes in team empowerment and challenging opportunities are offered to solve real world problems.\nSixtians take care of Sixtians through various programs related to Learning, Fitness, Fun activities, Inclusion etc. which are driven by Passion.\nAbout the department:\nEngineers take note: cutting edge technology is waiting for you! We don't buy, we primarily do it all ourselves: all core systems, whether in the area of car sharing, car rental, ride hailing and much more, are developed and operated by SIXT itself. Our technical scope ranges from cloud and on-site operations through agile software development. We rely on state-of-the-art frameworks and architectures and strive for a long-term technical approach. Exciting? Then apply now!\nAbout us:\nWe are a leading global mobility service provider with sales of \u20ac1.53 billion and around 7,000 employees worldwide. Our mobility platform ONE combines our products SIXT rent (car rental), SIXT share (car sharing), SIXT ride (cab, driver and chauffeur services), SIXT+ (car subscription) and gives our customers access to our fleet of 205,400 vehicles, the services of 1,500 cooperation partners and around 1.5 million drivers worldwide. Together with our franchise partners, we are present in more than 110 countries at 2,070 rental stations. At SIXT, a first-class customer experience and outstanding customer service are our top priorities. We focus on true entrepreneurship and long-term stability and align our corporate strategy with foresight. Want to take off with us and revolutionize the world of mobility? Apply now!","298":"Job Description\nThis is a new role for a BI Developer to develop Business Intelligence Solutions for internal customers. Solutions developed are used to aid process and drive business decisions in all departments.  Interacting with key stakeholders at all levels of business the role has a strong customer focus. The successful candidate is expected to work collaboratively with their internal customers to provide solutions that are accurate, have integrity and are of value to the business. \nWhat does the job involve?\nThe key responsibilities of the role are as follows:\nIdentifying and refining data and reporting requirements from key stakeholders.\nDevelop reporting.\nVisualising and reporting data findings creatively in a variety of formats.\nThinking strategically about uses of data and how data use interacts with data design.\nPerforming data studies and data discovery around new data sources or new uses for existing data sources.\nData extraction from multiple sources for reporting purposes.\nCore Competencies and skills: \nMicrosoft BI Stack - SSRS, SSIS\nSQL Server 2014-2019\nVisual Studio\nData Warehouse knowledge\nComfortable commenting code and documenting solutions\nComfortable with source controlling developments (Git\/Bucket)\nAble to adhere to coding and development standards\nGood knowledge of IT products and systems\nGood analytical and problem-solving skills\nGood communication skills and comfortable working with both technical and non-technical teams\nAble to prioritise work effectively and multitask\nMS Office including Word, Excel, Outlook, and PowerPoint\nCustomer focused\nFlexible approach to work - team player\nAdaptable to changing environment.\nEmbraces continuous self-learning\nDesirable competencies and skills:\nKnowledge and experience of creating Data Marts\nPower BI \u2013 DAX, Power Query\nPython\nPower Shell\nPerformance Tuning\nJIRA \/ Confluence.\nAnalysis of large data sets\nAJ Bell is one of the fastest-growing investment platform businesses in the UK offering an award-winning range of solutions that caters for everyone, from professional financial advisers, to DIY investors with little to no experience. We have over 449,000 customers using our award-winning platform propositions to manage assets totalling more than \u00a371.5 billion. Our customers trust us with their investments, and by continuously striving to make investing easier, we aim to help even more people take control of their financial futures.\nHaving listed on the Main Market of the London Stock Exchange in December 2018, AJ Bell is now a FTSE 250 company.\nHeadquartered in Manchester with offices in central London and Bristol, we now have over 1100 employees and have been named one of the Sunday Times \u2018100 Best Companies to Work For\u2019 for five consecutive years.\nThere are opportunities for growth and professional development for employees wanting to progress within their career including induction training and our study support scheme which is part of our benefits package.\nThere is an active programme of social events throughout the year, which are open to all employees.\nIn return we will provide all the training and support you need in order to develop within your role.\nWhat we offer:\nCompetitive starting salary\nGenerous holiday allowance of 25 days, increasing up to 30 days with service, plus bank holidays\nHoliday buy\/sell scheme\nHybrid working policy\nCasual dress code\nDiscretionary bi-annual bonus\nContributory pension scheme\nBuy as you earn share scheme\nFree shares scheme\nPaid study support for qualifications\nEnhanced maternity\/paternity scheme from day one\nBike loan\nSeason ticket loan portal\nDiscounted PMI and Dental\nOn-site gym and personal trainer led classes\nPaid volunteering opportunities\nFree social events and more\nAJ Bell is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and all employees are empowered to bring their whole self to work.\nWe do not discriminate on the basis of race, sex, gender identity, sexual orientation, age, pregnancy, religion, physical and mental disability, marital status and any other characteristics protected by the Equality Act 2010. All decisions to hire are based on qualifications, merit and business need.","299":"Company Description\nAmwell is a leading telehealth platform in the United States and globally, connecting and enabling providers, insurers, patients, and innovators to deliver greater access to more affordable, higher quality care. Amwell believes that digital care delivery will transform healthcare. We offer a single, comprehensive platform to support all telehealth needs from urgent to acute and post-acute care, as well as chronic care management and healthy living. With over a decade of experience, Amwell powers telehealth solutions for over 150 health systems comprised of 2,000 hospitals and 55 health plan partners with over 36,000 employers, covering over 80 million lives.\nBrief Overview\nWorking closely with cross-functional business partners, the Sr. Business Intelligence Developer will proactively identify, define and lead development of BI reporting solutions. The role will work closely with Data Analysts and Data Scientists to ensure the solutions built surface insight and analytics up to the user base in the best way possible.\nThe ideal candidate is a self-starter with insatiable curiosity.  S\/he must be able to proactively identify and lead opportunities to improve processes and deliverables while demonstrating quality and accuracy of data assets and analytic deliverables through close attention to detail and strong follow-through.\nThe role is expected to thrive in a cross functional environment, working closely with other BI Developers, Data Scientists, Data Engineers and Data Analysts.\nCore Responsibilities\nBuild intuitive and modern analytic dashboards, while adhering to data visualization best practices\nInterpret data, analyze results and provide ongoing analysis to key stakeholders as needed\nIdentify and lead development of scalable and automated analytic processes and workflows\nEnsure quality and accuracy of data assets and analytic deliverables\nIdentify and lead initiatives to improve processes for, and quality of, data assets and analytic deliverables\nAnalyze data for anomalies and early indication of bugs in reporting\nStay abreast of analytic technologies\nDocument programming scripts, processes, and deliverables\nDevelop internal network of colleagues, based on a reputation for collaboration, execution, and high-quality work\nIdentify and lead development of ETL data flows\nQualifications\nBachelors or higher in an Informatics or Quantitative field (e.g. Mathematics, Statistics, Economics, Engineering, Computer Science, Information Management, Data Analytics)\n5+ years of experience in business intelligence, data analysis and data engineering\n5+ years of SQL, including complex queries of multiple data sources\n5+ years of developing scalable and automated ETL processes\n3+ years of experience in the SaaS industry (preferably in a data analyst type role) is a plus\nExpert level experience with Business Intelligence tools (Power BI, Looker, Tableau, etc.)\nExpert level data visualization skills\nBasic to intermediate proficiency with general purpose programming languages (e.g. JavaScript, VB, PHP, C++)\nKnowledge of R or Python is a plus\nCapable of working on multiple projects and context shift quickly in a fast-paced environment\nAbility to translate incomplete or immature objectives into well-defined requirements\nExcellent verbal and written communication\nFamiliarity with the health care industry is a plus\nAdditional information\nWorking at Amwell\nAmwell is changing how care is delivered through online and mobile technology. We strive to make the hard work of healthcare look easy. In order to make this a reality, we look for people with a fast-paced, mission-driven mentality. We\u2019re a culture that prides itself on quality, efficiency, smarts, initiative, creative thinking, and a strong work ethic. \nOur Core Values include One Team, Customer First, and Deliver Awesome. Customer First and Deliver Awesome are all about our product and services and how we strive to serve. As part of One Team, we operate the Amwell Cares program, which brings needed assistance to our communities, whether that be free healthcare for the underserved or for people affected by natural disasters, support for equality, honoring doctors and nurses, or annual Amwell-matched donations to food banks. Amwell aims to be a force for good for our employees, our clients, and our communities.\nAmwell cares deeply about and supports Diversity, Equity and Inclusion. These initiatives are highlighted and reflected within our Three DE&I Pillars - our Workplace, our Workforce and our Community.\nAmwell is a \"virtual first\" workplace, which means you can work from anywhere, coming together physically for ideation, collaboration and client meetings. We enable our employees with the tools, resources and opportunities to do their jobs effectively wherever they are!  Amwell has collaboration spaces in Boston, Tysons Corner, Portland, Woodland Hills, and Seattle.\nUnlimited Personal Time Off (Vacation time)\n401K match\nCompetitive healthcare, dental and vision insurance plans\nPaid Parental Leave (Maternity and Paternity leave)\nEmployee Stock Purchase Program\nFree access to Amwell\u2019s Telehealth Services, SilverCloud and The Clinic by Cleveland Clinic\u2019s second opinion program\nFree Subscription to the Calm App\nTuition Assistance Program\nPet Insurance","300":"Description de l'entreprise\nALTER SOLUTIONS est une soci\u00e9t\u00e9 de conseil et d\u2019expertise en technologies cr\u00e9\u00e9e en 2006. Notre vocation est d\u2019accompagner nos clients sur leurs enjeux de transformation num\u00e9rique. Notre offre s\u2019articule autour des expertises suivantes :\nSoftware Delivery\nInfrastructure & Cloud Computing\nAgile IT Performance\nBusiness Performance\nNous sommes un groupe international implant\u00e9 dans plus d\u2019une dizaine de pays et comptant 750 collaborateurs.\nNotre succ\u00e8s passant par le d\u00e9veloppement et l\u2019\u00e9panouissement de chaque collaborateur, nous attachons beaucoup d\u2019importance \u00e0 offrir les meilleures conditions de travail possibles :\nT\u00e9l\u00e9travail disponible sur une grande partie de nos missions\nUn environnement de travail en Flex Office disponible pour tous et tout le temps pour favoriser la communication et la collaboration\nDes communaut\u00e9s d\u2019experts pour partager et diffuser les comp\u00e9tences au sein du groupe\nUn encadrement projet et un suivi RH de proximit\u00e9\nDes formations et certifications propos\u00e9es annuellement\nUne valorisation des parcours d\u2019expertise de nos consultants\nUne ouverture forte sur la mobilit\u00e9 internationale ponctuelle ou de longue dur\u00e9e\nDes possibilit\u00e9s d\u2019intrapreneuriat\nDescription du poste\nVous int\u00e9grerez, au sein de notre P\u00f4le Transformation Num\u00e9rique, une \u00e9quipe d\u2019experts en d\u00e9veloppement de solutions logicielles.\nVous serez d\u00e9tach\u00e9(e) chez un acteur majeur du secteur Bancaire, pour intervenir sur de la migration de projets existants mais \u00e9galement sur la cr\u00e9ation de nouvelles applications.\nVos missions seront les suivantes :\nR\u00e9aliser conjointement avec les autres membres de l'\u00e9quipe l'architecture logicielle et technique\nR\u00e9aliser la conception des applications\nEtre le lead de l'\u00e9quipe d'un point de vue technique\nParticiper aux activit\u00e9s de d\u00e9veloppement\nEtre force de proposition sur les technologies adopt\u00e9es\nQualifications\nQuel profil pour ce poste :\nVous \u00eates issu(e) d\u2019une formation Bac+5 (\u00c9cole d\u2019ing\u00e9nieur, Universit\u00e9 ou \u00e9quivalent \u2026) en informatique\nVous justifiez d\u2019une exp\u00e9rience significative (sup\u00e9rieure \u00e0 3 ans) au sein d\u2019une \u00e9quipe de d\u00e9veloppement dans un environnement Big Data \u00e0 l\u2019\u00e9chelle du SI d\u2019un grand groupe\nVous \u00eates un bon communiquant et disposez de capacit\u00e9s d\u2019analyse et de synth\u00e8se \u00e9prouv\u00e9es\nVous accordez de l\u2019importance (et du temps) \u00e0 la veille \nQuelles comp\u00e9tences\/connaissances pour ce poste :\nComp\u00e9tences en Spark, Hadoop, Nexus, Ansible, Hive et en d\u00e9veloppement Java\nAnglais courant imp\u00e9ratif\nSi vous souhaitez relever de nouveaux d\u00e9fis et m\u00eame si vous ne disposez pas de toutes ces comp\u00e9tences, n\u2019h\u00e9sitez pas \u00e0 postuler. Nous nous engageons \u00e0 \u00eatre tr\u00e8s r\u00e9actif dans la gestion des candidatures.\nInformations suppl\u00e9mentaires\nAu-del\u00e0 de vos expertises et comp\u00e9tences, nous recrutons aussi des personnalit\u00e9s, qui vont participer au d\u00e9veloppement d\u2019ALTER SOLUTIONS.\nChez ALTER SOLUTIONS, vous pourrez \u00eatre sollicit\u00e9s pour :\nIntervenir sur des phases de recrutement\nParticiper \u00e0 des projets de R&D et veille\nR\u00e9diger des articles techniques et de publications diverses\nParticiper \u00e0 des phases d\u2019avant-vente\nAnimer des formations en interne\nParticiper \u00e0 nos \u00e9v\u00e8nements mensuels d\u2019Alter Campus, rendez-vous techniques de partages et d\u2019\u00e9changes\nRepr\u00e9senter ALTER SOLUTIONS dans le cadre d\u2019\u00e9v\u00e8nements (Devoxx, Hackathon, Cloud Expo Europe\u2026)\nNotre processus de recrutement se d\u00e9compose ainsi :\nUn premier entretien \u00e0 distance\nTest technique\nRencontre avec un Directeur Op\u00e9rationnel et un Consultant S\u00e9nior\nSi tout se passe bien, contractualisation RH\nInformations compl\u00e9mentaires \nContrat : CDI\nTemps de travail : Temps plein\nR\u00e9mun\u00e9ration : \u00e0 partir de 58 k\u20ac\nAvantages\nPrimes vacances\nRemboursement 50% Pass Navigo \/ Prime \u00ab v\u00e9lo \u00bb\nTickets restaurant (Carte Sodexo)\nPolitique de cooptation\nCompte Epargne Temps\nComit\u00e9 d\u2019Entreprise\nMutuelle de qualit\u00e9 \nFormation annuelle\nD\u00e9but : ASAP\nLocalisation : Nanterre\nT\u00e9l\u00e9travail : envisageable en fonction des contraintes des projets\nIf you applied for this position the Controller of your personal will be  ALTER SOLUTIONS France, with its registered office at 6 avenue du G\u00e9n\u00e9ral de Gaulle 78000 Versailles. The personal data provided by you will be processed for the purpose of the recruitment process and for future recruitment processes.\nYou have the right to access the content of your data, request their rectification, erasure, restriction of processing, the right to data portability, the right to object to the processing of your data and the right to lodge a complaint to the DPO (privacy@alter-solutions.com).","301":"Company Description\nWe organise over 500 large-scale branded and transaction-oriented events in 14 specialist markets. These are typically not-to-be-missed annual events where buyers and sellers build relationships, see and show products and do business.\nWe also provide year-round online platforms where companies showcase their businesses and products and buyers conduct research, generating valuable leads, and we provide data and digital content that supports the flow of knowledge and transactions in markets.\nJob Description\n6-month fixed term contract with a likely extension based on project work. The role is almost 100% working remotely.\nInforma Markets are looking to bring on a technically minded individual, who is interested in combining the analytical intelligence from data and developing technical solutions to problems in data systems. The key applications are PowerBI and SQL Server Analysis Services.\nWith a background in project work, they will be able to demonstrate the ability to meeting tight deadlines with system familiarity. They will be comfortable in both running their own projects and working alongside other developers on larger projects.\nWhat you\u2019ll be doing:\nThe PowerBI Developer is responsible for developing and supporting the Reporting Hub. This is new project currently in the development stage. The team is currently using IBM Planning Analytics for financial, FTE and KPI planning and reporting and would like to use PowerBI as the reporting front end for internal customers. This role is going to be the team expert on PowerBI and will help upskilling other members of the team. \nWhat we\u2019re looking for:\nTasks are likely to include:\nUsing best practice, develop the Product Tracker PowerBI reporting used by hundreds of people\nHelp develop the Finance standard reporting suite in PowerBI, which will service finance and business users across multiple Portfolios and Divisions.\nDevelop a series of prioritised dashboards based on prioritisation \nOptimise the data flow from the source systems to PowerBI\nChallenges current processes and ways of working, striving for an optimal level of output which delivers on requirements in a timely fashion\nQualifications\nStrong experience in a PowerBI development role\nBS Degree or equivalent professional qualifications\nHas a good knowledge of a wide area of information systems concepts and practice, both within and beyond own organization. Including all stages of systems development.\nFamiliarity with TM1 would be beneficial but not essential.\nCan demonstrate a rational and organized approach to the tasks undertaken and an awareness of the need to achieve quality\nAdditional Information\nContingent worker","302":"Company Description\nOur mission as a company providing IT services is to provide our clients all over the world with the best solutions. We manage to do this by analyzing the needs of our clients and matching them to the skills and aspirations of our employees. Therefore, one of our main motivations is to provide each Employee and Consultant with a satisfying experience. Joining us means being part of a community with diverse personalities. Start your adventure with ALTER SOLUTIONS!\nJob Description\nDevelopment of ETL\/ELT flows on the on-premise - as well as the cloud platform\nDesign data models\nProvide daily support and maintain solutions for our customers\nParticipate in knowledge sharing cross team and domain\nQualifications\nMust have\nData warehouse technologies\nSQL\nELT\/ETL tools\nDatabases\nNice to have\nWherescape\nData Vault 2.0\nMicrosoft Azure tech stack\nAdditional Information\nHybrid model (3 days in Warsaw office)\nType of contract: B2B or employment contract\nAccess to local and international projects - Clients from France, Germany, Portugal, UK and Benelux\nProfessional development support -trainings, technical certificates, conference participation, foreign language classes and soft skills trainings are subsidized up to 2 000 PLN\nFlexibility - You choose form of cooperation: employment or business-to-business contract\nBonus for recommending Candidates up to 6 000 PLN\nFully paid Medicover healthcare card\nMultisport card\nRegular integration events and gifts\nPsychological support program WellBee\nMobility Program\nLong term cooperation\nIf You applied for this position the Controller of your personal will be  ALTER SOLUTIONS POLSKA Sp. z o.o., with its registered office at ul. Emilii Plater 10\/47, Warsaw. The personal data provided by you will be processed for the purpose of the recruitment process and for future recruitment processes. You will have the right too choose one or both options on next page.\nYou have the right to access the content of your data, request their rectification, erasure, restriction of processing, the right to data portability, the right to object to the processing of your data and the right to lodge a complaint to the President of the Personal Data Protection Office.","303":"Location: Gurgaon, Noida, Hyderabad, Chennai, Bangalore, Pune, Kolkata, Indore, Jaipur, Ahmedabad,None,None\nAbout Material\nMaterial is a global strategy, insights, design, and technology partner to companies striving for true customer centricity and ongoing relevance in a digital first, customer-led world. By leveraging proprietary, science-based tools that enable human understanding, we inform and create customer-centric business models and experiences + deploy measurement systems \u2013 to build transformational relationships between businesses and the people they serve.\nAbout Srijan\nSrijan is a global engineering firm that builds transformative digital paths to better futures for Fortune 500 enterprises to nonprofits all over the world. Srijan brings advanced engineering capabilities and agile practices to some of the biggest names across FMCG, Aviation, Telecom, Technology, and others. We help businesses embrace the digital future with cloud, data, API and platform centric technologies and adapt to changing business models and market demands. Srijan leads in Drupal with 350+ Drupal engineers, 80+ Acquia certifications. Srijan is also a Drupal Enterprise Partner & Diamond Certified\nSkillls and Requrement :\nRequirement : -\nDesign, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals\nSolve complex data problems to deliver insights that helps business to achieve their goals\nCreate data products for analytics and data scientist team members to improve their productivity\nAdvise, consult, mentor and coach other data and analytic professionals on data standards and practices\nFoster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions\nLead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team\nDevelop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes\nPartner with tribe members and solutions architects to develop technical architectures for strategic projects and initiatives.\nLearn about machine learning, data science, computer vision, artificial intelligence, statistics, and\/or applied mathematics\nSkills : -\n\u25aaBachelor\u2019s degree required; Computer Science, MIS, or Engineering preferred\n\u25aa5+ years of experience working in data engineering or architecture role\n\u25aaExpertise in SQL and data analysis and experience with at least one programming language (Python or Scala preferred)\n\u25aaExperience developing and maintaining data warehouses in big data solutions\n\u25aaExperience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred)\n\u25aaDatabase development experience using Hadoop or Big Query and experience with a variety of relational, NoSQL, SAP BW and cloud database technologies\n\u25aaWorked with BI tools such as Tableau, Power BI, Looker, Shiny\n\u25aaConceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data.\n\u25aaExposure to machine learning, data science, computer vision, artificial intelligence, statistics, and\/or applied mathematics\nResponsibilities:\nRequirement Gathering & Analysis:\nResponsible for participating in business requirements gathering exercise and translating business requirements into functional and technical specifications.\nParticipate and provide inputs during requirements feasibility analysis and provide alternate solutions based on application architecture.\nResponsible for functional requirements interpretation and guiding the team on design and development process.\nTechnology Review:\nResponsible for end-to-end analysis of the application portfolio and provide inputs for transformation opportunities for a given line of business.\nTesting:\nResponsible for creating the test plan and associated functional test cases.\nPerform functional testing as required for a given release.\nProject Support:\nGuide the delivery team during impact analysis of incidents by providing inputs on upstream and downstream dependencies.\nProvide inputs for prioritizing incidents and problems.\nParticipate and provide inputs during change impact analysis and prioritization process.\nAssist the delivery team in complying with regulatory and compliance requirements.\nParticipate in release acceptance exercise and provide inputs for business signoff.\nPeople Management:\nDrive the SME development program to assess and develop domain experts.\nCreate a career road map for Application SME to become domain experts and track the progress periodically.\nBusiness Development:\nWork with pre-sales and practice on business development and existing growth opportunities in terms of discovery, solution options, evaluation, estimation, training and creation of collaterals\nCustomer Relationship Management:\nContribute to continuous service improvement plans (CSI).\nKnowledge Management:\nContribute and participate proactively in knowledge sharing sessions.\nAudits\nParticipate in security and compliance audits.\n What you will get:\nCompetitive Salaries with flexi benefits \nGroup Mediclaim Insurance and Personal Accidental Policy\n30+ Paid Leaves in a year \nLearning and Development of quarterly budgets for certification\n   Apply to this job","304":"Company Description\nTransforming businesses, driving success: SmarTek21\nSmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev\/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients\nJob Description\nSmarTek21 is looking for a hands-on architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.  \nQualifications\n\u2022 Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python.\n\u2022 Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks.\n\u2022 Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP).\n\u2022 Solid understanding of enterprise strategies for data security and data governance.\n\u2022 Experience in practice development, architecture, and consulting or product development.\n\u2022 Experience delivering data analytics projects and architecture guidelines.\n\u2022 Experience in engaging with enterprise architects. Non-technical Skills:\n\u2022 Excellent oral and written communication and presentation skills.\n\u2022 Ability to handle ambiguous situations and take trade-off decisions.\n\u2022 Strong problem solving and analytical skills to break down complex problems into smaller components.\n\u2022 Ability and willingness to perform in a team environment.\nRequirements:\n\u2022 Understand prospect\/customer\/partner technology landscape.\n\u2022 Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation.\n\u2022 Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers\/partners.\n\u2022 Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints.\n\u2022 Collaborate with the engineering team to create proof-of-concepts (POCs).\n\u2022 Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices.\n\u2022 Demonstrate business value of proposed solutions or current products to prospects and customers.\nSalary Range: $200,000-$215,000 (may be subject to change outside of WA State)\nAdditional Information\nWhat Is in It for You:\nPaid Time off \u2013 start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service.\nPaid Holidays - 8 paid holiday a year in addition to your PTO.\nHealth Insurance for FT employees \u2013 we pay 100 % premium of medical, dental and vision.\nHealth Insurance for FT employee\u2019s family \u2013 we pay 50% of premium for medical, dental and vision for dependents.\n401(k) \u2013 we administer 401(K) retirement contribution for FT employees.\nLife Insurance\/Short Term and Long-Term Disability \u2013 at no cost to you\nOpportunities for internal promotions\/career advancement\nFamily friendly work hours (closed on weekends and paid holidays)\nSmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and\/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class.","305":"Excella is a leading provider of Agile software development and data and analytics solutions to clients in the federal, commercial and non-profit sectors. We believe that great work leads to great things \u2013- our experts measure success by the positive impact we make on our clients, community, and colleagues. We are growing fast and need passionate, innovative people who love working with technology and are ready to make an impact. Here's what you can expect from us:\nWorkplace sites look different for everyone \u2013 whether it\u2019s your home or the office, we believe in a flexible work\/life balance that supports you regardless of your location. We offer a home office allowance that can be used for home office furniture\/equipment, a daily pass for a coworking space, etc. Our commute reimbursement plan has you covered for whether you bike, Metro, or drive to work.\nWe offer top of industry medical, dental, and vision benefits with multiple options to choose from such as an employer-contributed health savings account, infertility coverage, and orthodontia so you can select the plan that works best for you.\nRegardless of what stage of life you\u2019re in, Excella wants to support you. We provide 8 weeks of Parental Leave, discounted pet insurance, and a Care.com membership with 3 back-up emergency child or elder care days annually \u2013 all available to you on your first day.\nStarting day one, every employee is bonus eligible and receives 15 days of paid vacation, 6 federal holidays, and 4 floating holidays.\nDiversity and inclusion matter. Excella created and continues to support employee led-affinity groups and the Inclusion Diversity Equity Ambassador (IDEA) team, a cross-functional employee-led initiative to continually foster innovation and increase inclusion within Excella.\nWe have a \"bring your own device\" workplace and will share the cost of a new computer of your choice -- Mac or PC. It's up to you.\nWe'll invest in your career by providing 3 days of paid professional development every year, including travel and registration fees to attend classes and conferences.\nWe encourage mindfulness and overall well-being through employee wellness events, a HeadSpace membership, as well as access to TalkSpace and mental health coverage through our medical plans.\nOverview\nThe Data Visualization Developer is responsible for creating reports and dashboards using popular tools to support self-service analytics environments for our clients.\n  This is not a Data Science role and does not require the use of advanced statistical techniques to analyze data.\nResponsibilities\nInteracts directly with client stakeholders (business or technical) to understand client stakeholder needs.\nUses SQL queries to explore and understand data sources.\nCreates prototypes based upon stakeholder requirements in order to confirm the report or dashboard design meets the business need.\nCreates simple to complex reports and dashboards using visual analytics and business intelligence tools like Tableau and PowerBI\nUses SQL or other language to connect directly to data source for data quality checks and to ensure the numbers being represented in reports are accurate compared to source data.\nEnsures the final product follows data visualization and design best practices, is automated where feasible, and is easily transitioned into the client's environment for ongoing maintenance.\nCreates and delivers end-user training and documentation on BI deliverables.\nQualifications\nTechnical:\n3+ years developing reports and dashboards using Power BI.\n3+ years writing simple to medium complexity SQL queries.\nUnderstanding of relational databases structures (tables and relationships) in order to source effectively from these for reports and dashboards.\nKey Capabilities:\nAnalytical thinker and problem solver who can listen to a non-data person share a problem, and identify and package data to help them solve that issue\nAbility to write medium-complexity SQL queries\nPackages large, complex datasets into intuitive, easy to use dashboards, reports, and decks that help decisions makers answer questions\nDetail oriented, with a clear understanding of how to quality check reports and data pulls, due to the high visibility of the work\nSkilled in managing work intake\/requirements sessions, including mapping detailed documentation of requirements and tracking progress in shared collaboration tools (JIRA)\nWritten communication is paramount \u2013 needs to write clear, concise summaries of complex information and understand how to structure written communication for senior business stakeholders\/executives\nTakes a user-centered approach to developing data visualization products, like dashboards.\nEnthusiastic about learning about and using new features within tools like Tableau and PowerBI to ensure dashboards leverage the most up to date functionality\nStrong understanding of data visualization best practices, including chart selection, visual encodings, preattentive attributes, and Gestalt principles, and experience using those principles in the development of executive dashboards.\nSeeks and sees the larger business context of their work, and identifies opportunities to add value in complex and changing environments\nOptional, but industry or subject matter expertise (e.g., finance, employment, hospitality, digital analytics).\nExcella is an equal opportunity\/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.","306":"What if you could join a rapidly growing company and play a critical role in bringing new medicines to patients through looking at and treating disease in a revolutionary way?\nWhat this position is all about:\nAre you a highly motivated and organized computational biologist who is enthusiastic about exploring how emerging data technologies will enhance our understanding of cellular behaviors that drive disease phenotypes? Are you motivated to enable a computational biology team to realize as much value as possible from our data and to enable cross-functional communication with other technology teams?\nAs Senior Manager in Computational Biology, you will be responsible for optimizing our data strategy efforts, productionizing our processes, and bringing creative thinking to the integration of novel data modalities into the overall discovery process at Cellarity. You will get the opportunity to work in an innovative computational team, driven to deliver high-impact results. You will be in an early group of pioneers developing and applying the world's first AI platform that models disease based on complex cellular behaviors.\nYou will begin your career at Cellarity as part of a large team of world-class computational biologists and machine learning scientists (https:\/\/cellarity.com\/the-team), biologists (co-developing hypotheses), chemists, clinicians, and technologists (co-developing proprietary data assets).\nIf you think you can contribute to the capabilities that we are building and are keen on applying our platform to advance our exploratory drug programs and learning from some of the best scientists, while getting to work with proprietary and relevant data sets, then we are looking for you.\nWhat you would be responsible for:\nWork with the New Data Types team to prototype and develop capabilities for integration of novel data technologies into Cellarity\u2019s computational biology platform\nAct as a liaison between Computational Sciences, Technology, and Data & Software Engineering to ensure clarity in data flow, pipeline maintenance, optimization of processes\nContribute to the development of novel approaches to analyze complex data types such as single-cell RNA-seq, single-cell ATAC-seq, single-cell genotyping, Perturb-seq\nApply rigorous statistical techniques to improve our understanding of single-cell data at multi-omics levels\nBe an active member of the Computational Sciences team engaging in discussions on study designs that benefit programs, developing and maintaining SOPs for integration of varied data modalities into program ideation, and providing guidance and mentorship to the team on best practices for data analyses\nPresent your results in an interdisciplinary team of biologists, chemists, clinicians, technologists, and other machine learning colleagues in meetings covering cross-functional project teams, functional teams, to whole company and management meetings\nWhat experiences will you need:\nPh.D. or equivalent experience in biology, computational biology, mathematics, statistics, computer science, or related scientific field\nTwo or more years of experience (post academic training) working in an industry setting\nExtensive experience in analyzing and deriving hypothesis from single-cell data, across multiple modalities\nDemonstrated scientific understanding of molecular and systems biology, diverse molecular data types, and analysis tools\nExcellent programming and scripting skills, preferably in Python\nFast learner, analytical thinker, creative, \"hands-on\", strong communication skills.\nAble to work both independently and as part of a team\nWhat sets you apart:\nExperience with generating, analyzing, and deriving hypotheses from other single-cell omics data types or large-scale clinical datasets.\nExperience driving an impactful and relevant project within industry.\nBackground in statistics or machine learning.\nExperience with clinical or biological data.\nWhat it is like to work at Cellarity \nAt Cellarity, we \nPush Boundaries: We create a legacy with breakthrough science in service of patients.\nInject Energy: We build strengths from different perspectives and tell it like it is.\nOwn it: We transcend our job descriptions and relentlessly follow through on our commitments.\nGo all out: We work quickly and with conviction.\nCompany Summary:\u202f Cellarity\u2019s mission is to fundamentally redesign the way drugs are created for the sake of bringing new hope to patients.\u202f By shifting the focus from a single target to the underlying cellular dysfunction, we unravel the complexity of disease biology and create medicines that were not possible before. The company has developed unique capabilities that link biology and chemistry with high dimensional -omics data from which we design medicines against the cellular signature of disease. The Cellarity platform allows us to uncover new biology\u202fin diseases even in the absence of known causal targets. The company has drug discovery programs underway in several disease areas, including metabolic disease, hematology, and immunology.\u202f Cellarity recently completed a Series C financing and has raised a total of $274M from all funding rounds to date, with contributions from world-renowned investors alongside Flagship Pioneering who created the company.\u202f Cellarity\u2019s goal is to grow into a fully integrated next generation Biotech company driving a new age in drug creation. \nCellarity is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.\nRecruitment & Staffing Agencies: Cellarity does not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to Cellarity or its employees is prohibited unless contacted directly by Cellarity\u2019s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of Cellarity, and Cellarity will not owe any referral or other fees with respect thereto.\n ","307":"PowerBI Developer\nNTT DATA is a team of more than 139,000 diverse professionals, operating in more than 50 countries throughout the world. The sectors where we have activities include: telecommunications, finance, industry, utilities, energy, public administration and health.\nOur mission? Offer technological solutions, business, strategy, development and maintenance of applications, while being a benchmark in consulting. All thanks to the collaboration between teams, the human quality of our people and the fact that we do not conform to what is established, we always seek innovation that brings us closer to the future.\nOur essence has led us to the forefront of technology, breaking paradigms and providing solutions that truly respond to the needs of each client. Our talent has led us to be one of the top 6 technology companies in the world.\nBecause #Greattech, needs #GreatPeople, like you\nNTT DATA is looking for high-achieving team players that are quickly adaptable to new challenges and entrepreneurial ventures. We are looking for a PowerBI Developer to work in Orange, CT with our global client. This position would be hybrid 4 days a week onsite.\n\nResponsibilities:\nGather data from Altiris, SCCM, CMDB. ServiceNow, SAP, Excel, and other data sources\nUtilize PowerBI platform to transform the data and produce reports  \nPerform data model design and implementation\nIntegrate reporting components from multiple data sources\nRequirements:\n3+ years of experience working directly with Power BI\nExperience gathering data from data sources such as: Altiris, SCCM, CMDB. ServiceNow, SAP, Excel\nExperience developing reports and dashboards\nExperience in optimizing dashboards with focus on usability and performance\n  Why NTT DATA?   \nEmpowerment and rewards are the cornerstone of our career development model. We are a young, fast-growing company, with a highly innovative and entrepreneurial spirit, because of this professional experience and growth will be unmatched. Our talent and positive attitude allows us to transform our goals into achievements, and projects into realities.\nNTT DATA is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity\/Affirmative Action-Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. NTT DATA is an Equal Opportunity Employer Male\/Female\/Disabled\/Veteran and a VEVRAA Federal Contractor.\n#LI-JW1","308":"Sword is a leader in data insights, digital transformation, and technology services with a substantial reputation in software development, complex business IT projects, and mission critical operations. With over 2,500 technology, digital and software specialists working globally we unlock solutions for the most critical business technology challenges.\nIn Houston, we provide expert data and information management advisory, project, support and consulting services to the energy industry, helping our customers reduce costs and increased efficiency through effective data management.\nThis Environmental and Sustainability Data Manager role provides the opportunity from someone with the deep data management and analysis experience to shape the direction and structure of this important emerging business area. We are looking for someone who is passionate about the power of data to inform critical business decisions.\nRole Objectives:\nSupport all aspects of data management for ongoing operations and technical evaluations, as part of a E&S data team,\nBuilding data models for the increasing range of data feed that will be informing the E&S agenda. Build models that are robust and appropriate for this emerging business area,\nEstablishing and implementing data governance practices around the existing and future data elements. Able to develop appropriate and useable standards and documentation consistent with the clients existing systems,\nAbility to analyse the data to identify the key items and attributes that need to be defined in the data model. Also able to use analysis to establish appropriate data quality checks,\nGood stewardship of the data to provide confidence in the quality and accuracy of the data used for compliance reporting and critical decision making,\nWork with a dispersed team to define the forward direction in this important new area and help shape a sustainable data environment,\nAct as an interface with the data engineers to understand their needs and ensure that the data model is consistent with their needs and the digital ecosystem,\nNetwork with both data end users and those providing data streams to align the needs and system constraints in building the data models.\nRequirements\nRequired skills:\nExperience building and managing sustainable data models (any complex industry),\nAbility to analyse technical data, understand its quality and trouble shoot reliability issues,\nTrack record of establishing and implementing data governance,\nStrong demonstrated digital skills including, SQL, Python, PowerBI and Power Automate,\nUnderstanding and use of different database structures,\nAble to work with ambiguity and demonstrated ability to create new solutions,\nWork collaboratively, and able to communicate effectively with other disciplines.\nDesirable skills:\nExperience working with Environmental and Sustainability data,\nFamiliar working with Kanban and Agile processes to manage multiple tasks,\nKnowledge of Microsoft Azure stack,\nA degree or diploma like a BSc Degree or equivalent in the Information Technology field or a STEM subject.\nBenefits\nSword offers career paths in rapidly evolving technology spaces including Data & AI, Modern Managed Services, Information Management, Digital Services, Content Services, and Modern Workplace Transformation.\nThis role offers a highly competitive, success-driven, open-ended commission scheme where we reward those that over deliver.\nOur team culture is based on building inclusive teams, investing in training and development, the quality of our interactions with our customers and our position as an employer of choice in the areas in which we operate.\nAll Sword Group colleagues are supported and encouraged to develop their career with Sword through our personal training and development plan alongside a competitive salary, pension, private healthcare, and employee assistance programme.","309":"Company Description\nProekspert bridges the gap between the digital and the physical. We build world-changing solutions by combining data science and product development expertise with a design thinking approach.\nAlways more than just a software company, we have worked on clever machines and industrial automation, smart screws, production lines, complex device integrations, banking backbones, and management automatics: in short, advancing the new industrial revolution. Our code makes elevators move, heating systems run. Our software helps to grow useful bacteria, makes business decisions. It can analyze satellite images and is used to provide self-service to millions of people.\nJob Description\nOur Business Intelligence team helps local and international companies to transform data into actionable and relevant insights. This enables our clients to make informed strategic decisions and to improve their operational efficiency & business productivity.\nAre you as passionate about data and BI as we are? Then this BI Analyst role is for you!\nWhat you will do:\nWork with Proekspert customers to determine business requirements and priorities\nIdentify user needs together with users and the customer\nAnalyse the data sources necessary for the data model and make suggestions to the customer regarding the improvement of data quality\nPrepare initial tasks for a data developers to perform database structures and data transfers\nDesign and document dashboards, alerts and reports\nEducate and train customers to use data as an analytical tool\nApply good practices of agile development process\nQualifications\nWe\u2019re looking for\u202fa team member who:\nHas at least 2 years of experience as BI Analyst or similar role\nHas experience of using analytical tool\/s like Microsoft Power BI, Tableau, etc.\nHas strong SQL skills\nIs familiar with creating data models\nHas an analytical mindset and great communication skills\nHas an in-depth understanding of the business environment and an interest in going beyond the obvious\nHas the ability to present data in the form of user history (storytelling)\nHas skills to set priorities, systematically plan and coordinate activities\nPossesses skills in critical thinking, attention to detail\nIs motivated, self-directed, and proactive\nHas very good written and spoken English\nNice-to-haves:\nVery good written and spoken Estonian\nPrevious experience with Python, R scripting language\nFamiliarity with any cloud systems (AWS, Azure, Google app engine)\nEducation in economics-, statistics- or mathematics\nAdditional Information\nProekspert values individual freedom, decision-making and proactiveness. In our self-organizing and supportive work environment, teamwork is of the utmost importance. \nWhat we offer:\nInteresting, steady work. Our projects have a positive impact on people and the world. \nWe value the well-being of our people and their families. \nInspiring community and teams, who support and mentor you. \nAn exciting benefit package, including a personal growth budget and profit-sharing. \nA motivational program and competitive salary.","310":"Company Description\nBosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it\u2019s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.\nJob Description\nOverall 4 - 6 years with minimum 3 years relevant experience\nAbility to Propose and Design large, scaled-out, real-time, high performing Data Lake \/ Data Warehouse systems\nExperience in data management, data governance, master data management and meta data management.\nExperience in building modern data platforms and automation of data pipelines.\nLiaise with customers and manage customers expectations\nShould be flexible enough to connect and work whenever required\n Roles & Responsibilities\nHands on experience with Azure Data Lake, Azure Data Factory, SQL Data Warehouse Azure Blob, Azure Storage Explorer\nExperience in Data warehouse\/analytical systems using Azure Synapse.\nProficient in creating Azure Data Factory pipelines for ETL processing; copy activity, custom Azure development etc.\n Knowledge of Azure Data Catalog, Event Grid, Service Bus, SQL, Purview and Synapse\nGood technical knowledge in Microsoft SQL Server BI Suite (ETL, Reporting, Analytics, Dashboards) using SSIS, SSAS, SSRS, Power BI\nDesign and develop batch and real-time streaming of data loads to data warehouse systems\nQualifications\nQualifications\nB.E\/B.Tech\/MCA\nAdditional Information\nAdded advantage - Certifications in  Azure","311":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients\u2019 businesses through designing the products and services their customers truly value\nJob Description\nAs Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions.\nYou will independently drive design discussions to ensure the necessary health of the overall solution.\nThe role requires a hands-on technologist who has strong programming background like Java \/ Scala \/ Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components.\nYou are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. \nRole & Responsibilities:\nYour role is focused on the Design, Development and delivery of solutions involving:\nData Integration, Processing & Governance\nData Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations\nInfrastructure & Cloud Computing\nData Management Platforms\nImplement scalable architectural models for data processing and storage\nBuild functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode\nBuild functionality for data analytics, search and aggregation\nQualifications\nOverall 5+ years of IT experience with 3+ years in Data related technologies\nMinimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS \/ Azure \/ GCP)\nHands-on experience with the Hadoop stack \u2013 HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline.\nStrong experience in at least of the programming language Java, Scala, Python. Java preferable\nHands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc\n Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security \n Competency\n1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience\n2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc\n3. Knowledge on distributed messaging frameworks like ActiveMQ \/ RabbiMQ \/ Solace, search & indexing and Micro services architectures\n4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 \u2013 Data Engineering\n5. CI\/CD \u2013 Infra provisioning on cloud, auto build & deployment pipelines, code quality\n6. Cloud data specialty and other related Big data technology certifications\nPersonal Attributes:\nStrong written and verbal communication skills\nArticulaion skills\nGood team player\nSelf-starter who requires minimal oversight\nAbility to prioritize and manage multiple tasks\nProcess orientation and the ability to define and set up processe\nAdditional Information\nGender Neutral Policy\n18 paid holidays throughout the year for NCR\/BLR (22 For Mumbai)\nGenerous parental leave and new parent transition program\nFlexible work arrangements\nEmployee Assistance Programs to help you in wellness and well being","312":"As a Big Data Consultant, you will report to the Consulting Manager, Data, Analytics & Machine Learning. You will work with clients to understand their current environment, technical challenges, and future state needs. You will design and propose solutions, helping clients understand how the project will accomplish their goals. You will lead a team of Big Data Engineers to implement projects and build cutting-edge solutions.\nThis position is 100% remote, with up to 50% travel required (post-COVID).\nResponsibilities\nFacilitate design sessions with clients and Mission team to create the strategy, architecture, and implementation plan for data engineering projects\nDesign end-to-end modern data platforms for analytics and AI use cases for multiple clients simultaneously\nCommunicate the proposed solution to clients so they understand the benefits, translating the technical elements into business language\nDevelop strategic roadmaps and project plans based on customer goals\nWork with Big Data Engineers and Architects to break down complex development plans into LOE estimates, design documents and project plans\nOversee the implementation customer roadmaps in coordination with Big Data Engineers; ensure project tasks are completed on time, high quality, and progress toward the project goals\nDesign data ingestion, data storage, data modeling, data virtualization, self-service data preparation and analytics pipelines\nDevelop customer solutions for data privacy and security\nCreate workload orchestration using common tools like Jenkins, Airflow and MLFlow\nBe the technical liaison between customers and engineering teams; communicate complex technical concepts in easy-to-understand non-technical language\nWork with Project Managers to set customer expectations, drive alignment, and coordinate timelines\nSupport pre-sales engineers in proposal design and positioning, including helping define an approach to solving a prospect\u2019s technical challenges and helping the business development team estimate and plan projects\nMentor Big Data Engineers and more junior consultants\nSupport Data Science & Engineering process improvement initiatives\nSupport Data Science & Engineering recruiting efforts by participating on interview panels\nRequirements\n5+ years experience designing and implementing creative data solutions leveraging the latest in Big Data frameworks, especially from AWS\n5+ years experience architecting solutions for optimal extraction, transformation and loading of data from a wide variety of traditional and non-traditional sources such as structured, unstructured, and semi-structured data using SQL, NoSQL and data pipelines for real-time, streaming, batch and on-demand workloads\n3+ years experience with analytics\/data management strategy formulation, architectural blueprinting, and business case development \nSQL, Database, Data Modeling, Data Warehousing and Development skills\nExperience with AWS services like S3, Redshift, Athena, EMR, Glue, and Quicksight\nExperience with Dashboarding and Reporting Tools used in the Industry (Tableau, Qlik, etc.)\nExperience  leading teams, training, and mentoring more junior team members \nExperience with implementation of data security, encryption, PII\/PSI legislation, identity and access management across sources and environments\nAWS Data Analytics  Specialty Certification (required within 6 months of hire)\nAWS Solution Architect - Professional Certification (required within 6 months of hire)\nAdditional AWS Specialty Certification within the Data Analytics, Development or Machine learning space (required within 1 year of hire)\nPerks & Benefits\nMedical, dental, and vision insurance for employees and their dependents with options for 100% company paid premiums\n401(k) plan with company matching\nProfit sharing bonuses based on performance\nFlexible Spending Accounts (Health and Dependent Care)\nLife insurance paid by Mission\nPaid time off (FlexPTO, parental leave, volunteering time off)\nInclusive work environment with several Employee Resource Groups\nFully distributed team with flexible work hours\nHome office expense benefit\nCell phone stipend\nFlex stipend for use on cell phone, home internet, wellness, snacks, etc. It\u2019s up to you!\nParticipation in Mission\u2019s Cash Incentive Unit Award program\nAn internal department dedicated to helping team members on their career path\nCommitment to Diversity and Inclusion\nWe are committed to diversity and inclusion. We value every individual\u2019s unique story, experience, and perspective. We aim to amplify the voices of our team members and our community to create a safe, empathetic, and inclusive environment where everyone can contribute to one\u2019s authentic self. Mission Cloud makes every effort to ensure that all employees are compensated fairly regardless of gender, ethnicity, race, or past salary history. We understand that fair compensation practices establish that diversity, fair hiring processes, and fair pay are part of who we are as a company and maintain positive employee morale. We use market data to define salary ranges for each role and regularly review compensation adjustments as needed based on salary range updates.\nMission Cloud is an Equal Opportunity Employer and participant in the U.S. Federal E-Verify program. Mission will consider qualified applicants with criminal histories in a manner consistent with The Los Angeles Fair Chance Initiative for Hiring Ordinance.\nAbout Mission Cloud\nMission Cloud is an Amazon Web Services (AWS) Premier Consulting Partner and MSP. Clients depend on us to expertly and securely architect, migrate, manage, and optimize their cloud environments.Mission Cloud\u2019s team of AWS Certified Solutions Architects and DevOps Engineers are ready to help you harness the full power of the AWS cloud to transform your business and operations.","313":"So Energy was created in 2015 because we knew energy suppliers could be better. Since then, we\u2019re grown rapidly but sustainably, with 300,000+ customers and over 300 So Energists. But, we\u2019re not done. We\u2019re on the road to a million customers by the end of 2026 and, thanks to our recent merger with ESB Energy, we\u2019re well on the way. We\u2019re tech first, we\u2019re customer-centric and we\u2019re passionate about sustainability.\nWe want to do the best we can by our customers and by each other, so we\u2019ve created a workplace that is encouraging, supportive and offers the opportunity for growth. As a company, we live by six core values that guide everything we do.\nClear\nHonest\nAmbitious\nInquisitive\nCaring\nSustainable\n\nWe are looking for a Business Intelligence Data Analyst who will be responsible for supporting the business in our data driven focus on growth and efficiency. Within this role, you will be identifying reporting and data opportunities, analysing trends, and presenting back insights with potential solutions to solve some of the key business challenges. Our solutions are primarily built on the Google Cloud stack, of which Looker is our main BI reporting tool. This will require you to be adept to working on Looker with other BI tools being an added advantage.\nRequirements\nAs a BI Data Analyst you will need to be a detailed orientated individual who has a passion for analysing data\nThis will require you to learn and fully understand our data landscape both from a source system and reporting perspective\nYou will work closely with our Data Engineering team to build reporting friendly structures\nA key attention to detail will be required in the reviewing and validating of data prior to it being shared with the business\nYou should have experience in end user engagement on requirements elicitation and the ability to identify stakeholder problems that can be solved through data\nProven and extensive hands-on experience in building dashboards using Google Looker which are insightful and builds a data storyline which makes sense to your end users\nYou should be comfortable with communicating insights to senior management and across the organisation. - Provide technical support to other teams within the organisation as required\nYou should have a strong SQL background with a deep understanding of how to use SQL and interrogate data in the context of business objectives\nBe a team player, contributing towards the upliftment of our overall BI capability and supporting junior team members produce higher quality outputs\n\nWhat you will be doing\nGather and document requirements in a way that allows us to design well suited dashboards and reports\nTranslate requirements to technical solutions\nAnalyse data to identify trends and patterns\nInterrogate and curate the quality, consistency and completeness of data to ensure that the quality of insights are complete and relevant\nScript data transformation and business rules in SQL and Python\nResearch new data sources which will add value into the reporting that you will be delivering\nDefine metrics that are suited to business monitoring\nSupport the business in ad-hoc data analysis and data supply covering auditing, marketing campaigns and customer segmentation\nDesign reporting tables which facilitate the delivery of dashboards and insights\nBuild dashboards and reports in Google Looker\nDashboard design should follow intuitive data flow and presentation for easier end-user consumption and decision making\nModel data within Looker (LookML) which conforms to standards and principles that keeps the quality and integrity of the Looker backend intact\nInput and guide on new standards to improve our delivery of dashboards and the quality of our outputs\nPerform data reconciliation tasks to ensure that new reporting outputs are aligned or of better accuracy than existing reports\nWrite quality technical documentation of SQL coding as well as dashboards delivered\nContribute as part of an agile team with sprint planning sessions and daily standups\nCommunicate status, blockers, and progress clearly\nBenefits\nCompetitive salary\nHybrid remote working\nLife Assurance 4x Base Salary\nBonus Up to 10% of Base Salary\n25 days holiday, plus bank holidays, and an extra day holiday for your birthday\nPerkbox\nOngoing support and development as well as a generous learning and development budget\nFree daily breakfast\nGreat reward and recognition\nExposure to all parts of a growing business\nPension matching as part of auto-enrolment pension scheme\n\nSo Energy care about helping the energy industry become a much more diverse and inclusive environment and we work hard to lead by example. We are committed to Equal Employment Opportunity and building an inclusive environment for all.\nIf you are interested in finding out more please apply making sure to complete all the questions to the best of your ability and attached an up to date version of your CV.\n\nGood luck!","314":"Descripci\u00f3n de la empresa\nDevoteam Data Driven\nSomos m\u00e1s de 8.500 personas distribuidos en 18 pa\u00edses de EMEA y Oriente Medio  y de ellos m\u00e1s de 850 compa\u00f1eros estamos en Espa\u00f1a (y en aumento!!). Contamos con un Centro de Excelencia de Datos a nivel internacional, donde podemos replantear los modelos operativos y reinventar las relaciones con partners y clientes.\nDevoteam Data Driven es nuestra unidad transversal de proyectos relacionados con datos. Trabajamos con nuestros Partners Globales de Microsoft PowerBI, AWS y nuestros Partners Locales del mundo del Dato reconocidos internacionalmente tanto en la parte de Integraci\u00f3n y Gobierno (Enterprise Platinum Partner de Inform\u00e1tica, Collibra, Databricks, Alteryx, Snowflake) como en la parte de explotaci\u00f3n (Tableau, Qlik, Microstrategy).\nDevoteam Data Driven te da ahora la oportunidad de participar en todo el Ciclo de Vida de los datos, desde la extracci\u00f3n a la visualizaci\u00f3n usando las tecnolog\u00edas referentes del mercado actual. Si te consideras una persona amante de los datos y te gusta ofrecer experiencias personalizadas a organizaciones, con calidad en lo que haces, te interesa ayudar a dise\u00f1ar soluciones eficaces y consideras que tienes una mente abierta para reimaginar el futuro de  grandes empresas\u2026\u00a1Tu sitio es Devoteam Data Driven!\nPara m\u00e1s informaci\u00f3n,  accede a la web de la unidad: https:\/\/es.devoteam.com\/playground\/data-driven-intelligence\/ Y si te atrae lo que ves inscr\u00edbete ya en nuestras Ofertas Activas de Devoteam Data Driven en Infojobs (https:\/\/devoteamingenieria.ofertas-trabajo.infojobs.net\/ofertas) o busca tu perfil en todas nuestras vacantes en Devoteam Career (https:\/\/es.devoteamcareers.com\/envia-tu-solicitud\/?query=servicenow#). \u00a1No dejes pasar el momento y sube de nivel! \u00a1\u00a1Te estamos esperando!!\nDescripci\u00f3n del empleo\nEstamos en b\u00fasqueda de un perfil Big Data Engineer con AWS para que se incorpore a nuestro equipo de Data y que formar\u00e1 parte del equipo que configura la estrategia, la arquitectura y la infraestructura de datos del cliente.\nTus funciones principales ser\u00edan:\nDesarrollar pipelines en batch y tiempo real con Spark, dbt, Spark Structured Streaming y Kafka.\nDesarrollar y gestionar el Data Lake, el procesamiento de datos y las plataformas de datos end to end:\nDise\u00f1ar y gestionar soluciones de arquitectura cloud. Desarrollar integraciones de datos escalables y confiables para alimentar los modelos de Data Science.\nAdministrar y orquestar mecanismos adecuados de monitorizaci\u00f3n.\nDise\u00f1ar pipelines CI \/ CD. Participar en la automatizaci\u00f3n de tests, calidad del c\u00f3digo y despliegue autom\u00e1tico de aplicaciones.\nEstar conectado con los \u00faltimos avances en Big Data y colaborar\u00e1s en el I+D que aportar\u00e1n nuevos casos de uso y mejoras.\nRequisitos\nAl menos 3 a\u00f1os de experiencia desarrollando en Python, Scala, o cualquier otro lenguaje orientado a objetos.\nExperiencia en el desarrollo de ELT escalable, procesos de integraci\u00f3n de datos con Spark, Spark Structured Streaming o cualquier otra tecnolog\u00eda de procesamiento de datos.\nInteresado\/a en buenas pr\u00e1cticas: tests, automatizaciones, construyas pipelines en CI, etc.\nExperiencia en la construcci\u00f3n y el mantenimiento de cargas de datos de alto volumen complejas y orquestando dependencias (por ejemplo, Airflow).\nExperiencia con servicios de AWS (por ejemplo, S3, Lambda, DynamoDB, API Gateway, Glue, Athena, ECR\/ECS), y Databricks es muy deseable.\nPersona comprometida, proactiva, que se preocupe por la calidad de sus entregables, y una mentalidad hands-on.\nLa posici\u00f3n es presencial en Barcelona, la empresa proporciona transporte p\u00fablico desde Barcelona y el Vall\u00e8s para llegar a las oficinas del cliente.","315":"Company Description\nDiscover the Unexpected \nExperian is the world\u2019s leading global information services company. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index. We\u2019re passionate about unlocking the power of data in order to transform lives and create opportunities for consumers, businesses and society. For more than 125 years, we\u2019ve helped businesses grow, consumers and small businesses gain access to financial services, and economies and communities flourish \u2013 and we\u2019re not done.\nOur 18k amazing employees in 40+ countries believe the possibilities for you, and the world, are growing. We\u2019re investing in the future, through new technologies, talented people and innovation so we can help create a better tomorrow.\nTo do this we employ the greatest and brightest minds that share our purpose and want to make a difference. Experian Asia Pacific's culture, people and environments are key differentiators. We focus on what truly matters; diversity and inclusion, work\/life balance, flexible working, development, equity, engagement, collaboration, wellness, reward & recognition, volunteering... the list goes on. We\u2019re committed to fostering a strong sense of belonging and a place where you can bring your true self to work.\nOur uniqueness is that we truly value yours. We\u2019re an award winning organisation due to our strong people first focus. This includes Top Employer\u2122 and Great Place To Work\u2122 accreditations.\nLearn more at www.experianplc.com\nJob Description\nJob description\nYou will be working within a team of highly motivated and talented software engineering specialists, who develop and maintain reporting services for our corporate business communities.  Our primary systems and activities include development, integration, processing, and reporting applications using wide range of Oracle technologies that are located within Experian data centres and cloud-based platforms.\nWe are looking for experienced personnel who are keen to engage in development, analytical and support roles and who understand database management systems, data warehousing principles and have confidence in working with structural and procedural data query languages.\nYou will be working closely with our core integration and business intelligence team and internal business partners, using established development methodologies, secure practices, change and incident management procedures.\n Essential requirements\nBachelor\u2019s degree in information technology, computer science or closely related field\nHands-on development expertise with ELT technologies, reporting, data modelling techniques with solid knowledge of data warehousing concepts\nMust have development and implementation experience with Oracle Data Integrator integrated with Hyperion and business intelligence applications\nExperience working with the Hyperion Planning and Essbase applications\nExperience working with OBIEE\/OAS in the distributed architecture\nMust have experience in working on high-Availability and load-balanced BI Infrastructure environments.\nAbility to design and troubleshoot Oracle database queries and logic involved with business intelligence applications.\nAbility to provide Application Production Support as well as design & develop.\nGood understanding of diverse source systems and relational databases in BI space\nExperience handling the windows and Unix batch scripting.\nExperience working with Autonomous Data warehouse (ADW) and oracle cloud infrastructure (OCI) will be added advantage\nAnalyse ELT processes and ability to identify areas for performance improvements and automation\nIndependent, knowledgeable, and self\u2013motivated\nQualifications\nUseful requirements\nMinimum of 5-8 years of experience within the information technology industry\nAn understanding of security principles\nAgile development techniques\nShell scripting and Linux operating systems experience\nExperience in writing SQL and PL\/SQL\nCertified Oracle practitioner\nStrong analytical and problem-solving skills\nAbility to interact with cross-functional teams\nKnowledge of windows and Linux operating systems\nAbility to work in a fast-paced environment\n Additional Information\nExperian Careers - Creating a better tomorrow together\nFind out what its like to work for Experian by clicking here","316":"1099 or Corp to Corp\n12 month plus Remote may require 1-2 trips onsite expenses paid\n\nWe are looking for a passionate certified Data Analyst or BI. The successful candidate will turn data into information, information into insight and insight into business decisions. Data analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design. Data analysts will develop analysis and reporting capabilities. They will also monitor performance and quality control plans to identify improvements.We are looking for a Business Intelligence (BI) Developer to create and manage BI and analytics solutions that turn data into knowledge. In this role, you should have a background in data and business analysis. You should be analytical and an excellent communicator. If you also have a business acumen and problem-solving aptitude, we\u2019d like to meet you. Ultimately, you will enhance our business intelligence system to help us make better decisions.\nRequirements\nMinimum Technical Qualifications: a) Minimum of five (5) years of experience as a data analyst or in other quantitative analysis or related disciplines, such as researcher, data engineer or BI analyst. b) Possession of a bachelor\u2019s degree. Additional qualifying experience may be substituted for the required education on a year-for-year basis. Desirable Technical Qualifications: a) Four (4) years of Senior Data Analyst experience analyzing Structured Query Language (SQL) Server database structures, data, and implementations to identify any potential security, performance, or support concerns. b) Four (4) years of Senior Data Analyst experience recommending changes to improve security, performance, availability, and ease of access to PDR system data. c) Four (4) years of Senior Data Analyst experience creating secure databases that comply with State Information Security protection requirements, at the database level. d) Four (4) years of Senior Data Analyst experience modifying legacy databases to meet security requirements, and improve performance, availability, and data access. e) Four (4) years of Senior Data Analyst experience converting\/migrating legacy data into new database structure and participate in verifying application-database functionality. f) Four (4) years of Senior Data Analyst experience participating in configuration, migration, troubleshooting and remediation activities.","317":"Company Description\nOcorian is a global leader in corporate and fiduciary services, fund administration and capital markets. Wherever our clients hold financial interests, or however they are structured, we provide compliant, tailored solutions that are individual to their needs.\nWe manage over 17,000 structures for 8000+ clients with a global footprint operating from 18 locations. Our scale offers all our people great opportunities to develop their knowledge and skills and to progress their careers.\nJob Description\nPurpose of the job\nTo assist in the development of business intelligence and management information solutions for Ocorian taking information from the financial, HR, corporate administration systems, and Cloud-based solutions to create a reporting base for the business, the single source of truth\nDelivery of key dashboards and reporting requirements from the BI\/MI solutions with appropriate robust security models\nAssist with data cleansing and data loading exercises, which may extend to jurisdictional and regulatory filing requirements\nDocumentation of solutions, handover to BAU Teams, and supporting solutions\nPrior experience of creating\/supporting ETL, data warehouses and Tabular data models. Ocorian utilises Microsoft SQL Server technologies, including SSIS, SSAS, SSRS and Power BI and the successful candidate should have delivered projects using aspects of this technology stack in recent times\nThe individual will be expected to work across all levels of the Business to liaise with key stakeholders to ensure the design, development and documentation meets the requirements of the Business. The role will work extensively with IT functions and the role may be matrix-managed when required with tasks assigned by the BAU BI Team\n Main responsibilities\nDesign and implement data warehouse solutions and Tabular data models\nDevelop dashboards and reporting to meet business reporting needs\nDeliver approved projects within timeframe\nProvide regular updates to management\nMake recommendations for potential improvement or changes\nPromote the use of core systems for data capture aligned to standards and initiatives\nQualifications\n TECHNICAL SKILLS\nSQL Server 2016 onwards\nSQL Server BI stack \u2013 SSAS \/ SSIS \/ SSRS\nMicrosoft Power BI\nExperience of data cleansing tools and methodologies\nBUSINESS SKILLS\nDemonstrated ability to apply IT in solving business problems\nGood written, oral, and interpersonal communication skills\nAbility to present ideas in business-friendly and user-friendly language\nHighly self-motivated, proactive and attentive to detail\nAbility to effectively prioritise and execute tasks in a high-pressure environment\nExtensive experience working in a team-oriented, collaborative multi-jurisdictional environment\nExperience of working in project teams with mixed skillsets and levels of technical knowledge\nEnergy and enthusiasm to support the future growth and success of the business\nAdditional Information\nAll staff are expected to embody our core values that underpin everything that we do and that reflect the skills and behaviours we all need to be successful.  These are:\nWe are AMBITIOUS - We think and act globally, seizing every opportunity to support our clients and staff - wherever in the world they may be.\nWe are AGILE - Our independence from any financial institution gives us the flexibility and freedom to keep things simple, efficient and effective.\nWe are COLLABORATIVE - We take the time to understand our clients' needs so that we can deliver personalised solutions every time.","318":"Company Description\nVisa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.\nWhen you join Visa, you join a culture of purpose and belonging \u2013 where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world \u2013 helping unlock financial access to enable the future of money movement.\nJoin Visa: A Network Working for Everyone.\nJob Description\nThe Marketing, Sales, Services Technology Systems (MSST) Team manage the Customer Relationship Manager (CRM) systems, Business process management (BPM) applications and custom applications for Sales, Services, Marketing and Product teams. The Analytics team within this team integrate data from multiple applications like CRM, Contact Center applications, Appian and build executive and operational reports as well as enable self-service reporting and insights from to empower Business to monitor and track KPIs and make data driven decisions.\n The Sr. Data Engineer (ETL\/Power BI\/SQL) within the Analytics Delivery team will be responsible for solution design, development and implementation of Data integration and Analytics solutions on data platforms (SQL server) and Hadoop. This position requires designing database schemas for reporting, perform data engineering activities using ETL tools like Pentaho and\/or scripts to ingest data from multiple applications on the cloud and on premise, build Power BI data sets and enable self- service reporting on Power BI and Hadoop. This position requires close collaboration with Global Sales Business partners and Product owners to understand Business goals and requirements and implement Data Analytics solutions following agile methodologies. This position requires collaboration with multiple global IT teams including application teams, database teams, Infrastructure and Platform teams and respond to changing Business priorities with agility. This position provides Production support for applications, data analysis and requires investigation and resolution of issues.\nResponsibilities:\nParticipate in Technology project delivery activities such as gathering Business requirements, conceptual technology approach, design, development, enhance and build scalable solutions and support systems in production in a DevOps model.\nWork as a member of Sales domain scrum teams and provide solutions for complex reporting requirements.\nWork as a Subject matter expert on data from Sales and Marketing domain.\nArchitect solutions and build data management systems \u2013 on premise or on cloud.\nUnderstand application systems, architect solution, develop the source to target mapping documents and ETL code to load data from Cloud applications (MS Dynamics) other CRM applications to databases on premise.\nDevelop workflows using ETL tools like Pentaho.\nDevelop database components on premise databases (SQL Server) and\/or Hadoop for reporting.\nDevelop Power BI data models and dashboards.\nSupport QA, UAT and performance testing phases of development cycle and implement DevOps principles from development to deployment to production\nPartner with IT groups such as Engineering, Product, Cybersecurity, and Infrastructure on project delivery activities and security findings remediation.\nOwn Operational support for multiple applications\nPerform POC and build prototypes based on business and technology requirements.\nThis is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership\/site), with a general guidepost of being in the office 50% or more of the time based on business needs.\nQualifications\nBasic Qualifications:\n\u2022 2 or more years of work experience with a Bachelor\u2019s Degree or an Advanced Degree in Computer Science\/ Engineering, Information Science or a related discipline with strong technical experiences (e.g. Masters, MBA, JD, MD, or PhD).\nPreferred Qualifications:\n\u2022 Minimum of 2-3 years\u2019 experience with Master\u2019s degree or 4-5 years' experience with Bachelor\u2019s degree in Computer Science\/ Engineering, Information Science or a related discipline\n\u2022 Experience of at least four years in building data pipelines and utilizing data engineering techniques like ELT or ETL for building and scaling reporting and Analytical solutions\n\u2022 Strong expertise in Data analysis, writing SQL scripts and hands on experience working on Relational data bases like SQl Server required\n\u2022 Experience building Power BI data models and dashboards required\n\u2022 Extensive experience with ingesting and transforming data using ETL tools like Pentaho, Informatica is required\n\u2022 Experience using FetchXML, DAX functions, implementing Power BI security features required\n\u2022 Experience using MS Dynamics Sales and Services modules nice to have\n\u2022 Experience in provisioning databases and managing application servers (on premise or on cloud) nice to have\n\u2022 Experience with ensuring data quality for reporting and implementing data observability metrics highly desirable\n\u2022 Experience using Hadoop (Hive, Presto, Spark) highly desirable\n\u2022 Experience in Python, PowerShell, job scheduling (Control M) and version control (bitbuket, GitHub), implementing CI\/CD for Reporting components nice to have\n\u2022 Experience with embedding dashboards in MS Dynamics, Power apps, Power Automate nice to have\n\u2022 Experience working in Agile methodology owning end to end product solutions\n\u2022 Experience with cloud infrastructure like Azure data lake, Synapse, Snowflake on Azure nice to have\n\u2022 Good Presentation skills and communication skills presenting ideas and insights to Business is highly desired\n\u2022 Experience on Sales and Marketing domain nice to have\n\u2022 Demonstrated analytical rigor, strong attention to detail, team oriented, collaborative, agile and flexible style\nAdditional Information\nVisa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.","319":"With a passion to deliver high-end cinematic games, Supermassive Games is carving a unique and exciting path in the games industry. Want to join us on the journey?\nWe\u2019re looking for an experienced BI Analyst\/Developer to join our central Management Information Systems (MIS) team. This role will give you the opportunity to work with various groups across the business including publishing, game development, management, finance, and live service, with a view to providing them key performance information on both an ad hoc and regular basis. This is a new and growing team in the company and the knowledge and experience you bring will be instrumental in shaping how we develop and move forward.\nRole responsibilities:\nBuilding reports\/dashboards from various onsite\/cloud\/application data sources for purposes such as game telemetry, project tracking, finance & HR, using appropriate tools.\nProviding commentary and investigation\/analysis of data to highlight meaningful trends and information.\nGather requirements and respond to requests from customers for information on an ad hoc basis, or by including new requests into existing reports.\nWork with team members & customers across the company to identify, learn and understand their data points, key metrics, and other requirements thoroughly.\nCoordinate with and work alongside other MIS team members to prioritise and manage report delivery.\nHelp build a new game telemetry reporting service within MIS.\nRequirements\nSkills and experience:\nUnderstanding of metrics and data relevant to video games player telemetry e.g., player activities, retention, cross-product tracking, design metrics, purchases etc.\nBuilding secure, live, network accessible dashboards with filtering\/slicing capability and good use of visual formats to illustrate and highlight information.\nExperience using tools such as Azure Data Explorer\/SQL DB\/Synapse and Power BI.\nExperience querying large complex data sets from both onsite and cloud sources.\nFamiliarity with SQL, NoSQL, JSON, columnar data e.g. Parquet, and query performance optimisation.\nBasic understanding of GDPR compliance, particularly relating to PIl\n\nDesirable:\nKnowledge of data analysis, statistics, and statistical modelling methods relating to financial data and\/or live service operations\nExperience administering and querying data from PlayFab.\nKnowledge and use of REST API, advanced Excel, VBA, C#, Python, Power Query\/Pivot, MS Dynamics, Jet Reports, Jira, SharePoint etc.\nExperience dealing with cloud data tools and services in Azure and AWS\nQualification in computer science, statistics, mathematics, or related discipline.\nBenefits\nWhy join us?\nWe make big games with small teams - you will play a full and active role\nChallenging and rewarding projects as standard\n25 days annual leave\nPrivate health insurance\nPension\nLife assurance\u202fx6 time annual salary\nQuarterly profit related bonus scheme\nSocial events - including large summer party\nConstantly improving tools and workflow so you can focus on creativity\nFast decision-making allows good ideas to flourish\nWe celebrate and nurture talent\nOur supportive, inclusive and friendly team culture is something we are proud of\nWork-life balance is something we respect and protect\nUltimately, you\u2019ll work on the cutting edge - making innovative and immersive games","320":"Company Description\nBosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it\u2019s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.\nJob Description\nMandatory RequirementOverall 8+  years of experience in IT Industry.Min 3+ year experience working on Data Engineering using Databricks, Redshift, Glue, EMR.\nAtleast 4 Project experience in Building and maintaining ETL \/ ELT pipelines for large data sets , complex data and feature engineering processes\nMust Have skills : AWS Glue, Databricks (DB), AWS Redshift(SQL DW), AWS Athena, AWS EMR, AWS Kinesis, AWS S3,\nAWS RDS(SQL DB), SQLExperience with NoSQL databases such as DynamoDB, Cassandra, MongoDB.\nExperience in Real-Time Data Processing using AWS Kinesis, AWS IoT, Apache Kafka ,Structured Streaming and Stream analytics.\nExperience with SparkCore, Spark Streaming, PySpark, Hive, Impala, SparkSQL, DynamoDB, Kafka, AWS Glue, S3, Kinesis.\nSound Knowledge on AWS DevOps and CI\/CD tools  like Jira, Confluence, Bamboo, Bitbucket.Hands on experience in RDBMS  like MSSQL,Oracle,Mysql ,Teradata \nQualifications\nQualifications - BE, MS, M.Tech or MCA \nAdditional Information\nExperience \/ Knowledge on  Containerizations - Docker ,\nKubernetesExperience with Data Visualization tools Using Quicksight \/ Tableau  ....Designing Data modelling and Datawarehosuing solutions using tools like erwin etc\nExperience in designing \/ Architecting  Datalakes,Delta lakehouse.\nSound Knowledge in programming skills such as Python, R.\nMentor team members both onshore and offshore to ensure timely and high quality deliverable\nGood problem solving skills and communication skills.\nAWS Certified Solutions ArchitectAWS Certified Big Data - Specialty Certification","321":"Unternehmensbeschreibung\nBei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch.\nDie Robert Bosch GmbH freut sich auf Deine Bewerbung!\nStellenbeschreibung\nIm Gesch\u00e4ftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen \u2013 von hocheffizienten Antrieben \u00fcber das erste serienreife ABS f\u00fcrs Pedelec bis hin zu smarten Connectivity-L\u00f6sungen. F\u00fcr eine nachhaltige Mobilit\u00e4t, die Spa\u00df macht.\nDu bist Expert:in f\u00fcr den Bereich Data Engineering bei Bosch eBike Systems und stellst die relevanten Daten den Nutzern unserer Cloud-basierten Datenplattform zur Verf\u00fcgung.\nDu programmierst gerne und beherrschst Python und SQL. Zu Deinem Repertoire z\u00e4hlen au\u00dferdem ausgepr\u00e4gte Kenntnisse \u00fcber die performante Verarbeitung und Speicherung gro\u00dfer Datenmengen sowohl in Data Lakes als auch in Data Warehouse Systemen.\nIm Rahmen Deiner T\u00e4tigkeit f\u00fchrst Du Code-Reviews durch und definierst Best Practices und Leitplanken f\u00fcr die Entwicklung von Data Pipelines. \nWir unterst\u00fctzen Dich, damit Du Deine Kreativit\u00e4t in dem Bereich entfalten kannst und bieten Design Reviews mit anderen erfahrenen Kolleg:innen und Interessengruppen an.\nDu baust Deine Data Pipelines robust und mit einem hohen Fokus auf Observability, um eine einfache Fehleranalyse zu erm\u00f6glichen.\nZudem \u00fcbernimmst Du Verantwortung f\u00fcr deine entwickelten Daten Pipelines auch w\u00e4hrend des Betriebs und entwickelst diese kontinuierlich weiter, um eine optimale Qualit\u00e4t und Zuverl\u00e4ssigkeit sicherzustellen.\nDu hast Spa\u00df daran, dein Wissen weiterzugeben und agierst als Mentor:in f\u00fcr Junior Kolleg:innen im Team. Es macht Dir Spa\u00df mit dem Daten-Team, den Fachbereichen, der IT und den Kolleg:innen im fachlichen Diskurs die beste L\u00f6sung zu identifizieren.\nQualifikationen\nAusbildung: abgeschlossenes Hochschulstudium (Master\/Diplom\/Promotion) der Wirtschaftsinformatik oder eines vergleichbaren Studienganges\nPers\u00f6nlichkeit und Arbeitsweise: kommunikativ, selbstreflektiert, getting-things-done-Mindset, stetig lernbereit, Interesse f\u00fcr Innovationen im Arbeitsgebiet, eigenverantwortlich, l\u00f6sungs- und kundenorientiert, pragmatisch und problembewusst\nErfahrungen und Know-how: 5 Jahre Berufserfahrung als Data Engineer sowie Erfahrung im Aufbau von zuverl\u00e4ssigen Data Pipelines; Erfahrung in der agilen Softwareentwicklung (SCRUM, Kanban) und Erfahrung in der Datenmodellierung sowie in unterschiedlichen Ans\u00e4tzen f\u00fcr Daten Architekturen; Erfahrung im\nArbeiten in multinationalen Teams\nKnow-How: Breites Wissen \u00fcber unterschiedliche Technologien im Bereich Big Data Engineering (z.B. Databricks \/Spark, Snowflake, Apache Airflow, dbt, Kafka) sowie fundierte Kenntnisse in relevanten Programmiersprachen (Python, SQL, Scala) und CI\/CD (Gitlab CI\/CD, Jenkins); Au\u00dferdem Kenntnisse der Daten-Analyse, des Daten-Managements und der Softwareentwicklung\nBegeisterung: Spa\u00df daran, Wissen an andere zu vermitteln\nSprachen: sehr gute Deutsch- und Englischkenntnisse in Wort und Schrift\nZus\u00e4tzliche Informationen\nIn diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente.\n\nBewirb Dich jetzt in nur 3 Minuten!\nDu m\u00f6chtest Remote oder in Teilzeit t\u00e4tig sein - wir bieten tolle M\u00f6glichkeiten des mobilen Arbeitens sowie unterschiedliche Teilzeitmodelle. Sprich uns gerne dazu an.\nDu hast Fragen zum Bewerbungsprozess?\nNelly Ehrmann (Personalabteilung)\n+49 711 811 27525\nDu hast fachliche Fragen zum Job?\nDaniel Grimm (Fachabteilung)\n+49 7121 35 18668\nInteressierst Du Dich f\u00fcr diese oder weitere Stellen?\nDann bewerbe Dich auf die Virtual JobFair@BOSCH und verschaffe Dir einen \u00dcberblick \u00fcber die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de\/events\/                                        ","322":"We are growing rapidly, and looking for a talented Site Reliability engineer to join our team of engineers, designers, and data scientists to work on the development and maintenance of the Faculty Platform.\nThe Role\nYou will be working with truly cutting-edge technology which underpins a new generation of machine learning products produced at Faculty. The tooling you develop will make possible the delivery of high-impact AI applications which are robust, highly available and trusted by our customers.\n\nAt Faculty, we\u2019re passionate about productionising machine learning. We believe that both DevOps and MLOps have a huge part to play in realising the promise of AI. We continue to advocate for the development and adoption of MLOps with our partners and the wider community. As an SRE in the Faculty Platform team, you will be central in developing the tools that enable best practices for deploying complex machine learning systems\n\nWho we are\nFaculty is an applied AI company that helps organisations who have the scale, data, and foresight to adopt AI into their business. We\u2019re helping make AI real across society by providing a unique combination of strategy, software and skills to our customers: everything needed to successfully create value from AI. Founder-led and with over 80 PhDs, we\u2019re a team of specialists with experience across healthcare, finance, government, retail, engineering, construction and a host of other sectors.\nWe believe that AI should be trustworthy, impactful and beneficial across society. Those principles have shaped our work with more than 230 organisations across the public and private sectors as we help them use AI to act faster, make better decisions and understand more deeply.\nFaculty Platform is core to how we deliver our work. It provides the core algorithms we use to deliver AI solutions, an AI Safety layer to ensure our applications are explainable and fair, components common to robust, performant AI systems, such as data monitoring, workflow management, autoscaling, authentication and authorization, as well as a development and deployment environment for AI applications.\n\nWhat you will do\nCo-own our production infrastructure with the rest of the platform team.\nDesign, develop and deploy software that improves the stability, scalability, availability, and security of our solutions.\nImprove the quality of deployment, monitoring, and security automation tooling to improve reliability and velocity.\nResolve issues with our production systems and build solutions to prevent them from reoccurring.\nDevelop tools to assist the product teams with continuous integration and deployment.\nSupport the engineering teams with system design, developing software platforms and frameworks, and security reviews.\nRun postmortems of production issues.\nIn terms of technology, you will deploy Docker containers on Kubernetes in AWS and GCP, and use CloudFormation and Terraform to automate the deployment of Faculty Platform. You will create continuous integration and deployment on GitLab. You will use Python to automate manual tasks. You will also contribute to the Faculty Platform application layer, which is written in Scala.\nRequirements\nWho you are\nThe ideal candidate has a demonstrated passion for technology and building robust and resilient solutions. They can explain complex ideas simply and clearly, and have a focus on getting things done. They possess strong technical skills in computer science and software development, and enjoy keeping up with cutting-edge technologies.\nYou should be a systems expert that can also code with a passion for technology and solving the toughest problems. You should be comfortable jumping in at the deep end and learning new skills on a bleeding edge platform.\nExperience of containerisation and designing complex applications.\nExperience building infrastructure as code (for example using Terraform, Ansible, Chef, Puppet, Kops, or AWS CloudFormation).\nAn understanding of common web application architectures.\nExperience deploying and configuring machines in a cloud environment.\nUnderstanding of application deployment strategies and continuous integration.\nFamiliarity with network protocols such as TCP\/IP, HTTP and TLS.\nUnderstanding of security best practices.\nComfortable in a small, high-growth startup environment.\nKnowledge of Python and *nix systems\nKnowledge of Scala or other JVM languages is a plus.\nPost-COVID, we expect most team members will come to the office one or two days a week.\nWe value skills over certificates; speak to us if you think you would be great for the role, but do not have the conventional qualifications.\nBenefits\nWhat we can offer you\nThe Faculty team is diverse and distinctive, and we all come from different personal, professional and organisational backgrounds. We all have one thing in common: we are driven by a deep intellectual curiosity that powers us forward each day. This curiosity pushes us to seek truth and understanding in everything we do, to execute work in a nimble and pragmatic manner, to foster talent in one another and always to challenge assumptions.\nFaculty is the professional challenge of a lifetime. You\u2019ll be surrounded by an impressive group of brilliant minds working to advance our goal of making artificial intelligence real. Our consultants, product developers, business development specialists, operations professionals and more all bring something unique to Faculty, and you\u2019ll learn something new from everyone you meet. You\u2019ll also have the opportunity to make your mark on a high-growth start-up now poised to expand internationally.\nFostering talent is one of our core values, it\u2019s built into our culture and what we offer. Faculty was founded by people who are passionate about continuous learning, and adding value to our people.\nSome of our benefits\u2026..\nGenuinely flexible working: We believe people have needs, responsibilities and interests that require something different to a strict working day. We trust people to organise and take accountability for their own work and do our best to support their lives outside Faculty. We provide you with all you need to work from home, including a laptop, keyboard, chair\u2026even Sony headphones!\nEquity, we want you to benefit from Faculty\u2019s growth and success.\nUnlimited holidays: We encourage each other to use this time to take a break, work on personal projects, or to spend time with their friends and family.\nFantastic private health, optical and dental cover, for you & your family - including 24\/7 unlimited virtual private GP appointments and covering pre-existing medical conditions.\nAccess to mental health coaching with Sanctus\nBreakfast & Lunch daily, and more fruit, drinks and snacks than you could ever eat (for office-based employees).\nWe work hard and make sure we enjoy what we do. So we have frequent socials and informal get-togethers to help make sure you enjoy your time with us. You\u2019ll make friends and professional connections that will last a lifetime.\n#LI-Hybrid","323":"Company Description\nWolt is a technology company that makes it incredibly easy to discover and get the best restaurants, grocery stores and other local shops delivered to your home or office. Wolt is not just a delivery app \u2013 we\u2019re a technology company building a commerce platform to seamlessly connect our millions of customers with thousands of merchant and courier partners, in real-time across 23 countries and 250+ cities. Our apps (iOS and Android) have the industry\u2019s highest ratings, largely thanks to our customer-first-mindset, which shows in how we build products and run operations. In June 2022 we officially joined forces with DoorDash. Combined, we have a presence in 27 countries, 23 of which operate with the Wolt brand and app. Wolt and DoorDash continue largely independently, with Wolt\u2019s name, brand, product, technology and team.\nWorking in Product Development at Wolt\nAt Wolt, we\u2019re about getting things done. You\u2019ll probably enjoy it here if you like taking ownership, developing yourself and being around friendly, humble and ambitious people. \nThe behind the scenes of Wolt is run by an awesome bunch of over 400+ planners, builders, designers and data crunchers. We call ourselves Product+, as we\u2019re the very core of Wolt\u2019s products, tools and platforms. To build our products, we work in over 40  cross-functional, independent and autonomous teams. Teams are made up of a mix of talented individuals: engineers, designers, data scientists, analysts, and product leads. Each team takes ownership for solving customer problems in the best possible way.\nOur Commitment to Diversity, Equity & Inclusion\nWe want to have all sorts of people in our team \u2013 people like you and me, and people different from you and me. To be able to work with diverse teammates \u2013 when it comes to gender, age, ethnicity, life background, sexual orientation, political views, religion, or any other personal trait \u2013 we consciously aim to offer equal opportunity for everyone to work with us. This is because we believe diverse teams make the most thought-through decisions and build things in the most inclusive way.\nJoin us today to build Wolt together!\n#LI-ZF1\nJob Description\nAbout the program\n\nThe program will last for 4-6 months \u2014 you can decide the duration within this frame. The start date of the program is set for June 2023 (we can be flexible here).\nThe internship is paid (3300\u20ac\/month) and you\u2019ll be assigned to our Finance domain where your existing skills will find their best match in terms of mentorship and tech.\nWe are preferring candidates who are able to continue full-time after the internship period, so this is truly a chance for a career path - today we have numerous members in different product teams who originally started as interns!\nAnalytics at Wolt is a business-critical area that covers three different teams \u2014 data science, product data analytics, and business intelligence. The complexity of online delivery, differences between the economics and dynamics of the cities we operate in and vast amounts of data make our work truly interesting!\nAbout the team\nAs a BI developer intern, you\u2019ll join our awesome BI Platform team of seven people. Our team is focused on building a performant and reliable BI platform, maintaining and developing best practices for data developers and users as well as ensuring everyone working with data is empowered to do that independently and efficiently. In addition, we work on various data and reporting projects of key importance to Wolt. During the internship, your role will be to work on Financial projects together with a couple of teammates, who would also serve as your onboarding buddies.\nYour responsibilities\n\u2022 Working on all sorts of data affecting our profitability, ranging from various revenue sources to multiple types of costs related to our business operations. Familiarity with financial data and profit and loss (PnL) statement structure is a plus, but not required, as we will walk you through the basics during the onboarding. \n\u2022 Cooperation with other BI developers, analysts and data engineers at Wolt, as well as more direct project related stakeholders within the finance & planning domain.\n\u2022 Participating in periodical earnings reporting by producing main business KPIs such as retention and gross order volume that are shared with numerous stakeholders, requiring strong attention to detail from the applicant.\n\u2022 Working on financial metrics and datasets, which involves maintaining and building data pipelines with Airflow and exposing the data in our data warehouse (Snowflake) and providing data in an understandable, ready-to-use format in Looker (our BI tool).\nQualifications\nWe use SQL for data collection and processing, and Python for managing this data flow within our data warehouse. Most of the work during the internship relies on the former, thus SQL knowledge is also tested in the application phase. We also hope that you are familiar with the basics of Python or a similar language.\nStudies in a relevant field (programming, mathematics or finance) might be helpful in excelling in this role, but are not a hard requirement, as we are firm believers in the growth potential of our next teammate. This also means that we want to provide long-term career paths, and thus are prioritizing candidates who are able to continue with us full-time after the internship.\nWe want to welcome people from diverse backgrounds, with an open mindset and curiosity. We hope you are a person who does not refrain from asking questions and proposing improvements, nor a person who is scared of diving deep into financial data. \ud83d\udc99\nIdeally, you\u2019re already located in Helsinki or close by to have the possibility to visit the office at least once a week, to work as close as possible with your mentor and team members that are located in Helsinki.\nWe are unfortunately unable to offer relocation or visa support for internships, so you should be eligible for work in Finland for the duration of the program. If you\u2019re offered to stay with us on a permanent basis after the internship, we\u2019ll take care of your work visa if that\u2019s needed.\nAdditional Information\n\ud83d\udc40 The process is easy:\n1 - Read through the assignment instructions carefully. When your solution is ready, put it as a zip file to Google Drive, Dropbox, OneDrive (or similar). Remember to check permissions! If we cannot access the file, we cannot review your solution. Please don\u2019t store your solution in a public GitHub repository during the application period.\n2 - Click \u201cApply now\u201d, fill in your details, and attach your solution. If you have a CV, want to tell us more about yourself and your interests in a cover letter, or have some interesting projects that you\u2019d like to share with us, feel free to include those as well.\n3 - Send your application!\nPlease note that the assignment is a mandatory part of the process. Applications without attached solutions won\u2019t be accepted.\nThe deadline is the 22nd of February (end of the day).\nIf you have any questions you can turn to our Talent Acquisition Partner, Zhanna at zhanna.filintseva@wolt.com.\nPlease note that we do not accept applications via email or LinkedIn messages.","324":"Company Description\nBosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it\u2019s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.\nJob Description\nMandatory RequirementOverall 8+  years of experience in IT Industry.Min 3+ year experience working on Data Engineering using Databricks, Redshift, Glue, EMR.\nAtleast 4 Project experience in Building and maintaining ETL \/ ELT pipelines for large data sets , complex data and feature engineering processes\nMust Have skills : AWS Glue, Databricks (DB), AWS Redshift(SQL DW), AWS Athena, AWS EMR, AWS Kinesis, AWS S3,\n\nAWS RDS(SQL DB), SQLExperience with NoSQL databases such as DynamoDB, Cassandra, MongoDB.\nExperience in Real-Time Data Processing using AWS Kinesis, AWS IoT, Apache Kafka ,Structured Streaming and Stream analytics.\nExperience with SparkCore, Spark Streaming, PySpark, Hive, Impala, SparkSQL, DynamoDB, Kafka, AWS Glue, S3, Kinesis.\nSound Knowledge on AWS DevOps and CI\/CD tools  like Jira, Confluence, Bamboo, Bitbucket.\nHands on experience in RDBMS  like MSSQL,Oracle,Mysql ,Teradata \nQualifications\nQualifications - BE, MS, M.Tech or MCA \nAdditional Information\nAdditional Information\nGood to have:\n\u2022    Industry recognized Blockchain certification \/ course\n\u2022    Prior experience and knowledge of Hyperledger fabric 2.x and production scale implementation\n\u2022    Experience with microservices, NoSQL, Version control tools, building CI\/CD pipelines\n\u2022    Experience with any of the cloud platforms - AWS\/GCP\/Azure\n\u2022    Domain expertise in supply chain, mobility, industry 4.0 would be a bonus.\nAdditional information - Experience \/ Knowledge on  Containerizations - Docker , Kubernetes\nCertifications :  BigData , Azure and Azure architect certification","325":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to know our team:\nPartner Development is a team of creative entrepreneurs that develop solutions for Agoda\u2019s accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.\nIn this role you'll get to\nThis role is designed to mainly growth opportunity identification among mid to long tail hotels, experiment execution and data tracking within Partner Development team for the global teams. You will get to work directly with the regional team to design and put in place global experimentation and initiatives to drive tangible impact in each market.\nKey activities involved include but not limit to:\nApply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations\nOwn end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development\nBuild dashboards, identify new and track key metrics to closely monitor team\u2019s performance and identify quick and long term opportunities for improvements\nWork closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified\nSupport global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization\nWhat you'll need to succeed \nBachelor\u2019s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline\n4-8 years experience working in a business analysis, data analysis, reporting or business strategy role\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\nCoding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\nData visualization tool experience such as with Tableau or your weapon of choice.\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner \nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","326":"Company Description\nBosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it\u2019s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.\nJob Description\nOverall 8+  years of experience in IT Industry.\nMin 3+ year experience working on Data Engineering using Databricks,Synapse, ADF.\nAtleast 4 Project experience in Building and maintaining ETL \/ ELT pipelines for large data sets , complex data and feature engineering processes\nMust Have skills : Azure Data factory (ADF), Azure Databricks (ADB), Azure Synapse Analytics (SQL DW), Azure Analysis Services (AAS), Azure Data Lake Storage (ADLS),\nAzure SQL Database (SQL DB), SQL\nExperience with NoSQL databases such as cosmosdb, Cassandra, CosmosDB, MongoDB.Experience in Real-Time Data Processing using Eventhub,IoT Hub,Apache Kafka ,Structured Streaming and Stream analytics.\nExperience with SparkCore, Spark Streaming, PySpark, Hive, Impala, SparkSQL, CosmosDB, Kafka, Azure Data Factory (ADF), Blob, ADLS, EventHub.\nSound Knowledge on Azure DevOps and CI\/CD tools  like Jira, Confluence, Bamboo, Bitbucket.\nHands on experience in RDBMS  like MSSQL,Oracle,Mysql ,Teradata \nQualifications\nQualifications - BE, MS, M.Tech or MCA \nAdditional Information\nAdditional Information\nGood to have:\n\u2022    Industry recognized Blockchain certification \/ course\n\u2022    Prior experience and knowledge of Hyperledger fabric 2.x and production scale implementation\n\u2022    Experience with microservices, NoSQL, Version control tools, building CI\/CD pipelines\n\u2022    Experience with any of the cloud platforms - AWS\/GCP\/Azure\n\u2022    Domain expertise in supply chain, mobility, industry 4.0 would be a bonus.\nAdditional information - Experience \/ Knowledge on  Containerizations - Docker , Kubernetes\nCertifications :  BigData , Azure and Azure architect certification","327":"Company Description\nWolt is a technology company that makes it incredibly easy to discover and get the best restaurants, grocery stores and other local shops delivered to your home or office. Wolt is not just a delivery app \u2013 we\u2019re a technology company building a commerce platform to seamlessly connect our millions of customers with thousands of merchant and courier partners, in real-time across 23 countries and 250+ cities. Our apps (iOS and Android) have the industry\u2019s highest ratings, largely thanks to our customer-first-mindset, which shows in how we build products and run operations. In June 2022 we officially joined forces with DoorDash. Combined, we have a presence in 27 countries, 23 of which operate with the Wolt brand and app. Wolt and DoorDash continue largely independently, with Wolt\u2019s name, brand, product, technology and team.\nWorking in Product Development at Wolt\nAt Wolt, we\u2019re about getting things done. You\u2019ll probably enjoy it here if you like taking ownership, developing yourself and being around friendly, humble and ambitious people. \nThe behind the scenes of Wolt is run by an awesome bunch of over 400+ planners, builders, designers and data crunchers. We call ourselves Product+, as we\u2019re the very core of Wolt\u2019s products, tools and platforms. To build our products, we work in over 40  cross-functional, independent and autonomous teams. Teams are made up of a mix of talented individuals: engineers, designers, data scientists, analysts, and product leads. Each team takes ownership for solving customer problems in the best possible way.\nOur Commitment to Diversity, Equity & Inclusion\nWe want to have all sorts of people in our team \u2013 people like you and me, and people different from you and me. To be able to work with diverse teammates \u2013 when it comes to gender, age, ethnicity, life background, sexual orientation, political views, religion, or any other personal trait \u2013 we consciously aim to offer equal opportunity for everyone to work with us. This is because we believe diverse teams make the most thought-through decisions and build things in the most inclusive way.\nJoin us today to build Wolt together!\n#LI-ZF1\nJob Description\nAbout the program\n\nThe program will last for 4-6 months \u2014 you can decide the duration within this frame. The start date of the program is set for June 2023 (we can be flexible here).\nThe internship is paid (3300\u20ac\/month) and you\u2019ll be assigned to our Merchant group where your existing skills will find their best match in terms of mentorship and tech.\nWe are preferring candidates who are able to continue full-time after the internship period, so this is truly a chance for a career path - today we have numerous members in different product teams who originally started as interns!\nAnalytics at Wolt is a business-critical area that covers three different teams \u2014 data science, product data analytics, and business intelligence. The complexity of online delivery, differences between the economics and dynamics of the cities we operate in and vast amounts of data make our work truly interesting!\nAbout the team\nAs a BI developer intern, you\u2019ll join our awesome analytics team of BI developers and Data analysts. You\u2019ll be exposed to various business metrics related to merchants from a B2B point of view and build reporting infrastructure that can help these businesses grow on Wolt. During the internship, your role will be to work on one of the Merchant group's projects together with a couple of teammates, who will also serve as your onboarding buddies.\nThe Merchant team is responsible for all data needs related to the Merchant domain and helps various product teams in setting up the right metrics and enabling data-driven decision-making.\nYou will be embedded in the Merchant product team along with your teammates. This means you will work as close as possible where the decisions are made, and hence get to participate in decision-making yourself.\nYour responsibilities\n\u2022 Working on all sorts of Merchant related data, which involves maintaining and building data pipelines with Airflow and exposing the data in our data warehouse (Snowflake) and providing data in an understandable, ready-to-use format in Looker (our BI tool).\n\u2022 Implementing business metrics and KPIs to create visibility on business or product performance.\n\u2022 Exposing new data points from Snowflake to Looker in an easy-to-use format for further analysis and dashboard development.\n\u2022 Cooperation with other BI developers, analysts and data engineers at Wolt, as well as more direct project-related stakeholders within the Merchant domain.\n\u2022 You would have a chance to contribute to a variety of projects, such as:\nBuilding data pipelines for our Merchant Insights tool, where we provide valuable information for our Merchants about their performance\nHelping our product teams to collect vast amounts of app analytics data and turn that into insights about the new product features.\nCreating pipelines for possible 3rd party integrations and developing ways to connect that data to our data\nQualifications\nWe use SQL for data collection and processing, and Python for managing this data flow within our data warehouse. Most of the work during the internship relies on the former, thus SQL knowledge is also tested in the application phase. We also hope that you are familiar with the basics of Python or a similar language.\nStudies in a relevant field (programming, mathematics or finance) might be helpful in excelling in this role, but are not a hard requirement, as we are firm believers in the growth potential of our next teammate. This also means that we want to provide long-term career paths, and thus are prioritizing candidates who are able to continue with us full-time after the internship.\nWe want to welcome people from diverse backgrounds, with an open mindset and curiosity. We hope you are a person who does not refrain from asking questions and proposing improvements, nor a person who is scared of diving deep into the Merchant datasets. \ud83d\udc99\nIdeally, you\u2019re already located in Helsinki or close by to have the possibility to visit the office at least once a week, to work as close as possible with your mentor and team members that are located in Helsinki.\nWe are unfortunately unable to offer relocation or visa support for internships, so you should be eligible for work in Finland for the duration of the program. If you\u2019re offered to stay with us on a permanent basis after the internship, we\u2019ll take care of your work visa if that\u2019s needed.\nAdditional Information\n\ud83d\udc40 The process is easy:\n1 - Read through the assignment instructions carefully. When your solution is ready, put it as a zip file to Google Drive, Dropbox, OneDrive (or similar). Remember to check permissions! If we cannot access the file, we cannot review your solution. Please don\u2019t store your solution in a public GitHub repository during the application period.\n2 - Click \u201cApply now\u201d, fill in your details, and attach your solution. If you have a CV, want to tell us more about yourself and your interests in a cover letter, or have some interesting projects that you\u2019d like to share with us, feel free to include those as well.\n3 - Send your application!\nPlease note that the assignment is a mandatory part of the process. Applications without attached solutions won\u2019t be accepted.\nThe deadline is the 22nd of February (end of the day).\nIf you have any questions you can turn to our Talent Acquisition Partner, Zhanna at zhanna.filintseva@wolt.com.\nPlease note that we do not accept applications via email or LinkedIn messages.","328":"Company Description\nOur brand Deutsche Telekom IT Solutions Slovakia entered the life of Ko\u0161ice region in 2006 under the name of T-Systems Slovakia and ever since has been inextricably linked with the region when became one of the founding members of Ko\u0161ice IT Valley. We have managed to grow from scratch to the second largest employer in the eastern part of the country with more than 3900 employees. Our goal is to proactively find new ways to improve and continuously transform into the type of company providing innovative information and communication technology services.\nJob Description\nPurpose\nDesign new solution (standard and non-standard) to fulfill customer requirements. Execute testing and analyzes to identify flaws of the configuration. Create migration concepts and plans describing all necessary steps to deliver successful migration of new solution. Execute and support migrations\/implementation of designed solution to deliver new functionality to the customer. Test, validate and document new releases in order to identify flaws and provide migration plan from old to new version of the release.\nGeneral description\nMaintenance, improvement, cleaning, and manipulation of data in the business\u2019s operational and analytics tools\nLeads innovation through exploration, benchmarking, making recommendations, and implementing big data technologies\nExplore and implement new technologies within area of Cloud based Big Data solutions, like  Databricks, Data Warehouse, Confluent, Spark, HD Insight, etc..\nEnabling and running data migrations across different technologies and platforms\nBuild stable, scalable, and repeatable data-driven products\nPerform, coordinate and improve most complex activities (3rd level environment) needed to provide IT services and the supporting infrastructure in order to fulfill relevant KPI\u2019s\nKey accountabilities\nDesign, develop, test, implement and support big data cloud based application in order to deliver  quality standard cloud product portfolio\nBuild and develop concepts, processes and methods for automation, optimization and standardization to satisfy  efficiency and automation requirements\nAnalyze complex data elements and systems, data flow, dependencies, and relationships in order to contribute to conceptual physical and logical data models\nTesting and validation in order to support the accuracy of data transformations and data verification used in machine learning models\nManaging the life cycle of multiple database tools by enabling smooth upgrades and\/or installation and support of new capabilities\nContribute to the development of the capacity planning function to properly identify needed hardware, software, database configuration \/ architecture to support application \/ business needs\nDesigns, builds, verifies, implements and maintains the structure of databases to support business needs including integration of vendor database solutions into data environment\nData munging, manipulation, cleansing and blending from multiple data sources and exposure to various data types and storage paradigms\nWorking with data to solve business problems and will build and maintain the infrastructure to answer questions with data\nProvide project deliverables in order to fulfil the project scope\nProvide overall solutions and principles in planning, developing and implementing new cloud products to satisfy  business requirements\nMentor developers to spread knowledge level in the team and develop their skills\nMay provide consulting services to project teams on areas of expertise\nResearches development in assigned technology, determines business requirements, proposes changes and develop implementation plans\nQualifications\nSpecial technical skills\nExperience with programming languages (Python,R, Scala_\nExperience with Cloud PaaS solution with BigData area (Azure, or AWS)\nOR Experience with application engineering & Linux OS,\nKnowledge of data processing methods (Hadoop, Kafka, Spark)\nOverview of distributed file systems, SQL and NoSQL Databases\nKnowledge about Data streaming, Data warehousing\nBackground about cloud products in range of data processing\nCapability of communicating effectively with business and data science leaders on project status, timeline and technical results\nEducation\nUniversity degree \nExperience\n3-5  years\u2019 experience in the area of responsibility , valid certification in given technology\nLanguages\nEnglish C1,\nGerman B2 - advantage\nOthers\nStrong presentation skills,\nProject leadership skills\nValid certification in given technology\nAdditional Information\nBenefits\nWe believe in balance between work and personal life. An attractive and extensive work-life balance portfolio guarantees lasting motivation for employees and thus a better quality of life, promotes physical and mental well-being and contributes to a positive work environment. All this with the aim of providing more freedom in reconciling work, career growth, private life and individual lifestyle. Therefore we offer to our employees over 25 different benefits to improve their personal and professional life in these areas:\nFinancial benefits\nBenefits with focus on learning and development\nBenefits with focus on health and sport\nBenefits with focus on family and work \u2013 life balance\nOther benefits\nFor more information about our benefits click to Benefits\nSalary\nFinal salary is negotiable.\nWe are offering base salary depending on seniority level and previous experience of candidate. In addition to base salary we provide variable part and other financial benefits. Base salary will not be lower than 1900 \u20ac \/brutto.\nAdditional information\n* Please be informed that our remote working possibility is only available within Slovakia due to European taxation regulation.","329":"About Alltrna\nFlagship Pioneering has conceived of and created companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune\u2019s \u201cChange the World\u201d list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies.\nAlltrna is the world\u2019s first tRNA platform company to decipher tRNA biology and pioneer tRNA therapeutics to treat thousands of diseases. Alltrna unlocks tRNA biology to correct disease. The company's platform incorporates AI\/ML tools to learn the tRNA language and deliver diverse programmable molecules with broad therapeutic potential. Alltrna has an unprecedented opportunity to advance a single tRNA medicine to unify treatment across a wide range of diseases with the same underlying genetic mutation. Alltrna was founded in 2018 by Flagship Pioneering. For more info, visit www.alltrna.com.\nAbout The Role \nCome join a creative and collaborative team of scientists at Alltrna dedicated to leveraging emerging insights in RNA biology to develop a novel class of human therapeutics. In this role you will apply computational biology methods to turn diverse data streams into scientific insights, which will have a major impact on Alltrna\u2019s tRNA platform.\nYou will develop computational analyses for Next-Generation Sequencing, proteomics, and high-throughput screening data, and will partner with teams throughout Alltrna to visualize and interpret study results. You will contribute to Alltrna\u2019s computational biology strategy, working in partnership with our Machine Learning, Informatics, Computational Chemistry, and leadership team to address computational technology and infrastructure needs. You will also work closely with other wet- and dry-lab scientists to develop, evaluate, and benchmark performance of new molecular and computational methods. Through these collaborations you will help generate hypotheses and design experiments that drive forward our understanding of tRNA medicines.\nCore Responsibilities \nContribute to Alltrna\u2019s computational strategy in collaboration with colleagues in Machine Learning, Informatics, Computational Chemistry, and the leadership team\nDevelop computational pipelines to analyze NGS data generated using both established and proprietary library preparation methods, whole-cell and targeted proteomics data, and high-throughput screening data\nPerform exploratory analyses on internal and public data to develop new hypotheses for subsequent wet-lab testing\nFormulate and evaluate hypotheses that advance our understanding of tRNA medicines through collaboration with other wet- and dry-lab scientists\nContribute to improving the software infrastructure underlying analysis pipelines, visualizations, and data apps\nDevelop and implement criteria for evaluating experiment integrity and ensuring pipeline and data robustness\nCollaborate with our informatics team to automate analysis pipelines and deploy data apps that promote broader-team access to data and analyses\nCreate effective data visualizations and communicate study results to cross-functional teams\nQualifications and Skills\nPh.D. in computational biology, bioinformatics, or a related field and an additional 5+ years of relevant experience, including 3+ years working with NGS data in an academic or industry setting\nExpert in Python, common data science packages and bioinformatic toolkits\nExperience with computational pipeline development and maintenance (snakemake, nextflow, etc)\nStrong data visualization skills and experience developing data apps (Streamlit\/Dash\/Flask)\nExperience with computational notebooks (i.e., Jupyter), version control (i.e., Git), code documentation, coding standards, and unit tests\nExcellent communication skills and the ability to clearly explain computational analyses and their implications to team members of diverse backgrounds and drive decision-making\nThe preferred candidate will ideally also possess the following skills:\nExperience working with proteomics, pooled screening, high-throughput screening, and\/or single-cell sequencing data\nExperience working in a cloud computing environment (AWS\/GCP)\nWhat We\u2019ll Offer You\nComprehensive, competitive healthcare and dental coverage through Blue Cross Blue Shield, vision coverage through VSP, family leave, paid time off, 401k retirement plan, disability and life insurance, and fully covered parking\/commuter benefits.\nA dynamic early-stage work environment and highly interdisciplinary, talented, and collaborative team.\nParticipation in an unprecedented opportunity to advance a single tRNA medicine to restore disrupted protein production, regardless of target, for thousands of diseases with the same underlying genetic mutation.\nProfessional growth opportunities through mentoring, training, immersion in cross-functional projects, and opportunities to learn and try new things.\nDaily on-site snacks, cold brew coffee, and Bevi, as well as weekly catered lunches.\nOur Core Values\nFast-acting\/efficient. Moves quickly and proactively with a strong work ethic to produce high-quality results while fostering a positive work environment. Focuses on key priorities. Demonstrates tenacity and willingness to go the distance to get something done.\nIntegrity. Does not cut corners ethically. Earns trust and maintains confidences. Does what is right not just what is politically expedient. Speaks plainly and truthfully. Follows-through on commitments. Expects a high level of personal performance and team performance.\nCritical thinking. Learns quickly. Demonstrates ability to proficiently understand new information and independently achieve meaningful outcomes. Able to structure and process qualitative\/quantitative data and draw insightful conclusions.\nCreativity & Innovation. Scientifically curious and bold. Generates new and creative approaches to problem solving. Positive \u2018can-do\u2019 attitude. Views the toughest challenges as the greatest opportunities for personal growth and company innovation. Able to challenge dogma.\nTeamwork. Fully engaged in facilitating personal and team success. Reaches out to peers and cooperates with the team to establish an overall collaborative work environment. Often solicits and responds well to constructive feedback. Possesses good written and oral communication skills with the ability to clearly and concisely convey ideas and opinions.\nFlexibility\/adaptability. Adjusts quickly to changing strategic and tactical priorities. Comfortable with ambiguity. Self-starter mentality.\nFlagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.\nRecruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, \u201cFSP\u201d) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering\u2019s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.\nWhat We\u2019ll Offer You\nComprehensive, competitive healthcare and dental coverage through Blue Cross Blue Shield, vision coverage through VSP, family leave, paid time off, 401k retirement plan, disability and life insurance, and fully covered parking\/commuter benefits.\nA dynamic early-stage work environment and highly interdisciplinary, talented, and collaborative team.\nParticipation in an unprecedented opportunity to advance a single tRNA medicine to restore disrupted protein production, regardless of target, for thousands of diseases with the same underlying genetic mutation.\nProfessional growth opportunities through mentoring, training, immersion in cross-functional projects, and opportunities to learn and try new things.\nDaily on-site snacks, cold brew coffee, and Bevi, as well as weekly catered lunches.\nOur Core Values\nFast-acting\/efficient. Moves quickly and proactively with a strong work ethic to produce high-quality results while fostering a positive work environment. Focuses on key priorities. Demonstrates tenacity and willingness to go the distance to get something done.\nIntegrity. Does not cut corners ethically. Earns trust and maintains confidences. Does what is right not just what is politically expedient. Speaks plainly and truthfully. Follows-through on commitments. Expects a high level of personal performance and team performance.\nCritical thinking. Learns quickly. Demonstrates ability to proficiently understand new information and independently achieve meaningful outcomes. Able to structure and process qualitative\/quantitative data and draw insightful conclusions.\nCreativity & Innovation. Scientifically curious and bold. Generates new and creative approaches to problem solving. Positive \u2018can-do\u2019 attitude. Views the toughest challenges as the greatest opportunities for personal growth and company innovation. Able to challenge dogma.\nTeamwork. Fully engaged in facilitating personal and team success. Reaches out to peers and cooperates with the team to establish an overall collaborative work environment. Often solicits and responds well to constructive feedback. Possesses good written and oral communication skills with the ability to clearly and concisely convey ideas and opinions.\nFlexibility\/adaptability. Adjusts quickly to changing strategic and tactical priorities. Comfortable with ambiguity. Self-starter mentality.\n    Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.   Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, \u201cFSP\u201d) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering\u2019s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.","330":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to Know our Team: \nPartner Development is a team of creative entrepreneurs that develop solutions for Agoda\u2019s accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.\nIn this role you'll get to\nAs a Data Analyst in the PD Analytics team, you will be using data and modeling techniques to identify opportunities and build models and tools to improve efficiency and effectiveness for Agoda's supply team. \nKey activities involved include but not limit to:\nApply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations\nOwn end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development\nBuild dashboards, identify new and track key metrics to closely monitor team\u2019s performance and identify quick and long term opportunities for improvements\nWork closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified\nSupport global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization\nWhat you'll need to succeed \nBachelor\u2019s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline\n3-6 years experience working in a business analysis, data analysis, reporting or business strategy role\nExcellent problem-solving skills including the ability to analyze and resolve complex problems using data\nTeam player with strong interpersonal, relationship-building, and stakeholder management skills\nCoding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\nData visualization tool experience such as with Tableau or your weapon of choice.\nAbility to work under pressure in a fast-paced and rapidly changing environment\nExcellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner \nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","331":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nGet to Know our Team: \nThe Supply, Operations, Analytics and Programs (SOAP) team is a team of creative entrepreneurs that develop solutions for Agoda\u2019s non-accommodation partners and promote Agoda\u2019s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda\u2019s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek.  Utilizing our strong brand and resources, we build new channels to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. \nThe Opportunity:  \nThe role sits within the Supply Analytics team under SOAP team of Partner Services, where new business ideas, and partnership types are incubated and scaled. We are looking for a\u202fSenior BI Analyst\u202fwhose main focus areas are providing visibility and insights for people-related issues through Business Intelligence tools like Tableau and SQL, managing data warehouses, building ETL processes, and helping build other tools to optimize the business. This role will be involved in strategic projects and work closely with commercial owners and business stakeholders, using data to identify and translate business needs and opportunities into actionable initiatives.\nIn this Role, you\u2019ll get to:\nTranslate internal briefs into analytical projects (to include refining the initial brief and asking the \u2018right questions\u2019, working through potential hypotheses and storyboarding the output)\nUse and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders.\nProactively identify opportunities for growth within supply and the wider business.\nDrive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply.\nIdentify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence.\nAutomate manual operational processes and present back on time savings gained through modernization of business operations\nWhat you\u2019ll Need to Succeed:\n4+ years of experience in analytics\/data science\/insights\/strategy.\nBachelor\u2019s degree ideally in a business or quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance).\n3+ years of experience with BI & analytics tools (SQL, Tableau, Metabase or similar technologies)\n2+ years of solid project management\nGood stakeholder management experience. Comfortable presenting to senior leadership and C-suite.\nStrong experience in finding data insights and provide business recommendation to the business\nA hacker\u2019s mindset \u2013 the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping.\nExcellent communicator with superior written, verbal, presentation and interpersonal communication skills.\nData driven in both decision making and performance measurement.\nExtreme comfort in ambiguous, fast-paced environment.\nAbility to multi-task, prioritize and coordinate resources.\nIt\u2019s Great if you Have:  \nTravel industry \/ e-commerce \/ tech \/ consulting experience.\nExperience in conducting A\/B testing experimentation (a plus)\nA good understanding of statistical modelling knowledge or any machine learning technique knowledge is a plus (regression, logistic regression, random forest, etc.)\n  #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluisdata representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner \nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       ","332":"About Agoda \nAgoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership,\u202fenhancing the ability for our customers to experience the world.\nOverview:\nThe Agoda Content department is currently looking for a curious and questioning self-starter and proactive analyst, who will help drive decision making with insights from content, marketing and partner performance data.\nYou will get the opportunity to own analytical projects to direct our department\u2019s focus, and prioritize our actions. By joining Agoda, you will become part of a truly international team, with leading experts of different backgrounds coming from 50+ countries around the world. This is a genuine opportunity to gain valuable experience in a challenging and cutting-edge tech environment. The ideal candidate would have a passion for high-converting content, great user-experience, data and analysis tools and methods. This position reports to the Associate Director of Content Operations, in Bangkok, Thailand.\n  Main responsibilities:\nUnderstand Content goals and KPIs and be able to align reports and insights based on them. Identify and investigate trends, anomalies and opportunities to improve Agoda\u2019s Content strategy.\nIdentify content opportunities that drive customer value, bookings and conversion\nHelp build business cases around the opportunity and get buy-in from stakeholders\nEnsure appropriate data\/tools\/dashboards to measure execution and enable deeper analysis\nTrack execution and report up in regular updates\nWork with product, data\/BI team and IT to create data resources and build appropriate reporting\nWork with Content team leads to understand their business needs and identify opportunities in terms of team actions prioritization and focus.\nUse multiple data sources to report Content projects insights and impact; support Content tests and experiments.\nEncourage and train the Content team in best practice use of Agoda data, analysis techniques and interpretation.\nCoordinate with other Cross Functional departments like Analytics, Partner Services, and Product Owners\nUse Web-Analytics for Research and Analysis\nRequirements:\nBachelor degree or higher\n2+ years of relevant experience\nExperience \/ knowledge in statistics, SQL, Python\/R, Tableau and advanced Excel \u2013 required\nAbility to demonstrate data manipulation using data warehouse and create meaningful insight and visualization\nExperience \/ knowledge in Vertica and \/ or Impala \u2013 advantage\nExperience in generating data and \/ or preparing experiments for product development \u2013 advantage\nProfessional characteristics:\nAttentive to detail and committed to data integrity\nKeen and curious nature; able and willing to share your opinion\nOrganized; able to manage multiple, competing priorities and deliver results under tight deadlines\nAble to communicate effectively; fluent in English \u2013 both spoken and written\n#STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner \nEqual Opportunity Employer \nAt Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person\u2019s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.\nWe will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy.\nTo all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.\n       "}}