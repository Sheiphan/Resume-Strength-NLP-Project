{"Job Description":{"0":"Who is Flock?\nFlock Safety provides the first public safety operating system that empowers private communities and law enforcement to work together to eliminate crime. We are committed to protecting human privacy and mitigating bias in policing with the development of best-in-class technology rooted in ethical design, which unites civilians and public servants in pursuit of a safer, more equitable society. \nOur Safety-as-a-Service approach includes affordable devices powered by LTE and solar that can be installed anywhere.  Our technology detects and captures objective details, decodes evidence in real-time and delivers investigative leads into the hands of those who matter. \nWhile safety is a serious business, we are a supportive team that is optimizing the remote experience to create strong and fun relationships even when we are physically apart. Our flock of hard-working employees thrive in a positive and inclusive environment, where a bias towards action is rewarded. Flock Safety is headquartered in Atlanta and operates nationwide. We have raised over $380M in venture capital including a recent Series E round led by Tiger Global.  Now surpassing a 3B valuation, Flock is scaling intentionally and seeking the best and brightest to help us meet our goal of reducing crime in the United States by 25% in the next three years.\nAdditional Information\nHow To Succeed at Flock Video \nFlock\u2019s Series E Announcement \nHow We Stop Crime and Protect Privacy \nFlock\u2019s Framework \nEthics Center\nThe Role\nAs Senior Manager, Data Architecture, you will lead the efforts tied to building and improving Flock\u2019s current data warehouse ecosystem for analytics use cases, driving best technical practices to enable data integrity, accuracy, and completeness, and implementing processes to maximize the value and cohesion of Flock data for analytics by partnering with stakeholders from across the business. \nHow you\u2019ll make an impact:\nLead a team of data architects to execute on Flock\u2019s data objectives\nLead the architecture of the marts and analytical layers that enables other teams to self-serve and perform more streamlined reporting and analytics \nPartner with Data Engineering team by identifying data ingestion needs that enable architecture work\nPartner with Business Intelligence and Data Science teams by understanding their data needs and drive the implementation of supporting data transformation layers\nOwn\/manage strong central documentation framework of data, enabling both technical and non-technical users to understand Flock data \nOwn\/manage the design of technical processes to improve Flock\u2019s data warehouse transformation pipelines\nWork directly with business stakeholders, Data Engineering, Business Intelligence, and Data Science teams to maintain a prioritized roadmap of data architecture outputs \nDefine and drive a data governance framework that will be owned cross-functionally across Flock\nWe\u2019re looking for people who:\nBS\/MS in Computer Science, Mathematics, Statistics, Engineering or related field, or equivalent industry experience\n5+ years proven experience as a data engineer, database architect, or business intelligence engineer\n5+ years prior experience architecting and modeling data to drive analytics, ideally leveraging DBT\n2+ years experience working to align central\/conformed data definitions across business units\n2+ years of experience working with orchestration tools (Prefect, Airflow, etc.)\nStrong experience building roadmaps and communicating project timelines\/dependencies to leadership and internal teams \nStrong understanding and experience with software engineering principles of version control, containerization, and CI\/CD\nExperience with infrastructure-as-code (Kubernetes, Terraform, etc.)\nExperience working to enable Business Intelligence applications like Tableau and Looker with requisite analytical data\nAbility to communicate and drive for solutions to complex and abstract problems\nFeeling uneasy that you haven\u2019t ticked every box? That\u2019s okay, we\u2019ve felt that way too. Studies have shown women and minorities are less likely to apply unless they meet all qualifications. We encourage you to break the status quo and apply to roles that would make you excited to come to work every day.\nOur Values\nOur values define how we approach our work every single day:\nDo the Work\nOptimism With a Plan\nEmbrace Change to Grow\nProtect the Whole Community\nTo read more about our values, click here.\nWhy Join Us?\nWhile being surrounded by a bunch of cool people working to eliminate crime is its own reward, we have plenty more to offer: \nWe have raised over $380M in venture capital and are backed by some of the top VCs including a16z, Tiger Global, Meritech and more\n91% of our employees recommend working here\nWe have an audacious goal of reducing crime in the United States by 25% over the next three years\n5% of crimes in the US are solved by Flock, and we help to solve ~200 crimes a day\nWe partner with 2100+ cities and 1500+ agencies across the US and process 1.5B+ images a week (we process more images than Instagram \ud83e\udd2f)\nThe Perks\n\ud83d\udcb0Salary & Equity: In this role, you\u2019ll receive a starting salary of $175,000 - $200,000 as well as stock options\n\ud83c\udf34Use what you need PTO: We seriously mean it, plus 11 company holidays and your birthday off!\n\u2695\ufe0fFully-paid health benefits plan for employees: including Medical, Dental, and Vision and an HSA match. \n\ud83d\udc6aFamily Leave: We provide 16 weeks of 100% paid leave for primary caregivers and 12 weeks of 100% paid leave for secondary caregivers. \n\ud83c\udf7cFertility & Family Benefits: We have partnered with Maven, a complete digital health benefit for starting and raising a family. We will reimburse $10,000 a year for adoption, surrogacy, or infertility.\n\ud83e\udde0Mental Health: All employees receive an annual subscription to Headspace\n\ud83d\udc96Caregiver Support: We have partnered with Cariloop to provide our employees with caregiver support \n\ud83d\udcb8Carta Tax Advisor: Employees receive 1:1 sessions with Equity Tax Advisors who can address individual grants, model tax scenarios, and answer general questions. \n\ud83d\udcbbWFH Stipend: $150 per month to cover the costs of working from home.\n\ud83d\udcdaL&D Stipend: $250 per year to use on Audible, Calm, Masterclass, Duolingo, Grammarly and so much more.\n\ud83c\udfe0Home Office Stipend: A one-time $750 to help you create your dream office.\n\ud83c\udfe2Coworking Space: If you\u2019re not local to our ATL HQ, we\u2019ll provide $250 a month to get you set up with an All Access Membership to WeWork (or a local coworking space in your area).\n\ud83d\udc3ePet Insurance: We\u2019ve partnered with Pumpkin to provide insurance for our employee\u2019s fur babies. \nFlock is an equal opportunity employer. We celebrate diverse backgrounds and thoughts and welcome everyone to apply for employment with us. We are committed to fostering an environment that is inclusive, transparent, and collaborative. Mutual respect is central to how Flock operates, and we believe the best solutions come from diverse perspectives, experiences, and skills. We embrace our differences and know that we are stronger working together.\nIf you need assistance or an accommodation due to a disability, please email us at careers@flocksafety.com. This information will be treated as confidential and used only to determine an appropriate accommodation for the interview process.","1":"The Company\nFounded in 2009, Cubic Telecom has grown to become one of the leading providers of connectivity solutions and analytics services that help vehicle and IoT device manufacturers manage and grow revenue streams. Fast paced, smart, ambitious, and continually seeking new, ideas. That\u2019s us, is it you? At Cubic you will find an environment filled with energy and collaboration, where we set out every day to improve not just the world, but ourselves and each other.\n\nThe Role\nWe are looking for an experienced data architect with experience working across multiple departments and teams with a variety of data owners.\n\nOur teams are at the forefront of building and adapting the latest technologies to propel the automotive IOT space forward in a way that better serves everyone. Our work touches all aspects of automotive connectivity, and we use some of the most advanced development tools, data science and innovative approaches to make our systems work better for everyone.\n\nWe are looking for you to join us on this journey and in optimising our data asset, building a best-in-class data architecture and infrastructure to support our growing business and innovative ideas. We are using some of the latest and best tools in our goal to strive for excellence in data management and data structure.\nYour key responsibilities will be to oversee our company\u2019s data systems, optimise and unify the data assets and support in the development and optimisation of the data architecture and\nKey responsibilities\nData Infrastructure: Management of data infrastructure across the organisation (Data Lake, Data bases)\nData Modelling: Designing and developing data models that meet the organization's requirements for data storage, retrieval, and analysis.\nData Governance: Developing and implementing policies, procedures, and standards for data management, ensuring that data is secure and compliant with industry regulations and best practices.\nData Quality: Ensuring that data is accurate, complete, and timely, and that data quality standards are maintained across the organization. Work with organisational stakeholders to support the optimisation and unification of data assets across our various teams.\nData Security: Developing and implementing security protocols to ensure that data is secure, both at rest and in transit.\nData Storage and Retrieval: Designing and implementing data storage systems that are scalable, flexible, and responsive to the organization's needs for data storage and retrieval.\nData Analysis: Collaborating with other teams to develop and implement data analysis strategies that leverage the organization's data assets to inform business decisions.\nTechnology Evaluation: Evaluating new technologies and tools to determine their suitability for the organization's data architecture and data management needs.\nWork with organisational stakeholders to support with data-related technical issues.\nManage the cost of the data asset.\nRequirements\nExperience in a Data Architecture role working cross functionally with multiple data sources.\nExperience with NoSql technologies\nExperience within a high transaction systems environment\nExperience with both OLAP and OLTP\n5 years as DBA or database developer\nExperience in implementing data compliance and regulatory requirements,\nStrong problem solving with ability to scope, structure and solve complex issues with high levels of ambiguity. Curios and committed to finding solutions.\nDesired technologies \u2013 Azure Data lake, SQL database and Azure components, Cosmos DB, Snowflake","2":"Definitive Logic is currently seeking an experienced Master Data Engineer \/ Data Architect. This role focuses specifically collecting data, interpretation of data for business analysis. Candidates for this position will be able to sift through data, apply statistics, compare data points, and create reports outlining business predictions. The data engineer will provide extensive technical expertise, help businesses make decisions and develop innovative solutions to complex problems. We want innovative problem solvers that are passionate about data and enjoy a challenge.\nResponsibilities:\n\u00b7  Collecting data through means such as analyzing business results\u00b7  Transferring data into a new format to make it more appropriate for analysis\u00b7   Design and implement effective database solutions and models to store and retrieve relevant system data to meet requirements\nREQUIRED QUALIFICATIONS:\nBachelor\u2019s Degree\nA minimum of 12 years of work experience in a technical field with at least 10 years of hands-on experience with data solutions\nInterim Secret Clearance or higher\nUnderstand requirements and map them into the existing data environment or create new structures as needed\nBackground developing data solutions and can operate in a fast paced, highly collaborative environment\nExperience with SQL, Python, PySpark, leading ETL technologies and approaches\nIndependent, creative, and determined\nStrong SQL and data management experience\nExperience with machine learning and statistical analysis\nExperience with a modern programming language such as Python\nStrong analytical skills with the ability to organize, analyze and prioritize\nExperience or exposure to one or more: Redshift, Teradata, Snowflake\nDESIRED QUALIFICATIONS:\nMinimum Two (2) years of experience working in an agile development environment\nAbility to quickly learn technical concepts and communicate with multiple functional groups\nAbility to display a positive, can-do attitude\nStrong verbal and written communication skills\nAbout Definitive Logic Definitive Logic (DL) is a management and technology consulting firm known for delivering outcomes and ROI for agencies\u2019 most complex business challenges.\u202f DL delivers performance-based and outcome-driven technology consulting solutions that directly support the strategic intent of our Defense, Homeland Security, Emergency Management, Federal Civilian and Commercial clients. We\u2019re the preferred technology integration partner for Federal agencies to apply the best of data science, app dev, DevSecOps, cyber and cloud solutions to improve decision support, empower front-line employees and enhance back-office operations. We serve as trusted advisors providing objective, fact-based, vendor & technology-neutral consulting services.  Definitive Logic is ultimately a team of problem solvers \u2014 thought leaders, domain experts, coders, data enthusiasts, and technophiles.\u202f Our exciting projects and learning and sharing culture have consistently resulted in validation as a Great Place to Work: 2023 Washington Post Top Workplaces\u202f(8-time winner) | 2023 Virginia Best Places to Work\u202f(10 years running, #1 midsize in 2019). \nDefinitive Logic is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity\/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class.\nIf you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable, or limited in your ability, to use or access our Careers page: https:\/\/www.definitivelogic.com\/careers\/open-opportunities\/ as a result of your disability. You can request a reasonable accommodation by sending an e-mail to Recruiting@DefinitiveLogic.com or via phone: 703-955-4186. In order to quickly respond to your request, please use the words \"Accommodation Request\" as your e-mail subject line.\nDL BenefitsHealthDentalVisionLife\/AD&D: Company paid STD\/LTD:Company paidSupplemental Plans: TriCare Supplement, Pet Insurance through Nationwide, Legal Resources and hospital\/accidental indemnity plans and Wellness initiatives. Compensation Benefits:Competitive Base SalaryAnnual performance based bonus401(k) & Roth option: You are fully (100%) vested on day 1 and DL matches up to 5%Spot Bonuses Referral Bonuses Additional Benefits:Flexible Time Off (FTO): Under our FTO plan, there is no cap in the amount of leave you choose to take, with proper coordination and prior approval.Volunteer Hours: DL allocates up to 8 hours for you to use every year to volunteer for a 501c3 organization of your choice and DL will donate to that charity based on how many hours you volunteer.Cell Phone Reimbursement: $80\/monthLocation Specific Metro\/Parking Tuition Reimbursement Training & Certifications","3":"WELCOME to Aetion! We are a global leader in science-driven technology using real-world evidence to provide innovative healthcare solutions. Our Aetion Evidence Platform is used to evaluate the safety, effectiveness and value of medications, delivering better outcomes to patients, medical professionals, and clients. We\u2019ve partnered with top biopharma companies and are backed by leading venture capital firms to help increase our medical research and expand our product line. Aetion is headquartered in the US and has expanded throughout Europe with EU headquarters in Barcelona. \nRecent Achievements: \nEuropean Medicines Agency selected Aetion to support safety and effectiveness research in Europe\nCollaboration with the National Institute for Health and Care Excellence (NICE)\nAetion and Cegedim Health Data long-term partnership to expand real-world evidence research in Europe\nAetion and Aetion\u2019s leadership are a recipients of a number of prestigious awards: \nBuilt In Boston and Built In New York 2022 Best Places to Work\nParity.org\u2019s 2022 Best Companies for Women to Advance\nNYC Health Business Leaders\u2019s 2022 Digital Health 100\nCB Insights\u2019 2022 Digital Health 150\nCome join us! \nPERKS of being an A-Teamer: \n25 vacation days\nDaily in-office lunch stipend (and a fully stocked kitchen)  \nSabbatical opportunity after five years of employment \nCommitment to professional development opportunities with access to Skillsoft learning experience platform\nEmployee-led initiatives including annual company-wide innovation day & DEI resource groups \nComprehensive private health coverage w\/ out-of-network reimbursements options\nPeer & company recognition programs\nMental Health & Wellness Benefits \nMonthly educational lunch & learn\nWhy join Aetion\u2019s tech team? \nYou\u2019ll join and collaborate with our global team and engineering leaders on all matters that impact the Engineering team, including resourcing and building technology\/product vision\nThe team works on a technical stack which includes both cloud and on-premise deployments, big-data ingestion and analytics, distributed systems and algorithmic complexity.\nYou\u2019ll have the opportunity to develop your career, including coaching and mentoring colleagues (code reviews, higher-level software design) and \/ or direct management\nLooking for more insight into our culture? Check out our LinkedIn Life page here:  https:\/\/www.linkedin.com\/company\/aetion-inc-\/life\/lifeataetion\nDESCRIPTION:\nOur Machine Learning Architect \/ Engineer is a critical leader of defining, implementing, and integrating innovative, robust, and reusable ML pipelines into the Aetion technology platform.\nAs a first-of-a-kind European role in our organization, the Machine Learning Architect \/ Engineer will have a combined role of subject matter expert, individual contributor, and evangelist, with the opportunity to work with our executive team to help grow our capabilities over the next 18 months.\nDefining the problem, designing a solution, collecting input, and executing to achieve results is crucial. The successful candidate is expected to lead and contribute to all parts of the software development lifecycle, including architecture, design, development, documentation, testing and operations.\nAs a member of a rapidly expanding organization, the Machine Learning Architect \/ Engineer will need to be able to cross functions easily and collaborate with other highly effective individuals, including members of the C-suite.\nThis is a challenging engineering role that offers a great opportunity to grow with Aetion and make a difference by helping expand the use of Aetion's products.\nRESPONSIBILITIES: \nWork alongside engineering, science, and product to identify and solve high-value machine learning use-cases.\nUse a variety of machine learning methods to solve healthcare-related problems using cloud-based technologies.\nDesign and implement robust, re-usable data\/ML pipelines using open-source technology such as Python, Spark, and R. Drive the validation and transparency of these ML models.\nEvangelize new ML tools and their benefits with both our internal and client-facing teams; engage with our clients to understand their needs, and how Aetion\u2019s ML tools can meet these needs.\nResearch topics in machine learning and statistics to stay up-to-date on emerging trends in the field.\nQUALIFICATIONS: \nRequired\nA BSc\/MSc\/PhD degree (or equivalent) in mathematics, statistics, computer science, electrical engineering, or a related STEM field.\n5-8+ years of relevant work experience.\nHighly analytical, problem-solving mindset with a demonstrated ability for conducting statistical and machine learning research (in the form of a thesis, publications, or side projects) and independently solving ill-defined problems on data from heterogeneous sources.\nExpert in Python and\/or R programming for full data science lifecycle (ETL \/ database connection, data exploration and visualization, cleaning\/pre-processing, feature engineering, classification and regression, model evaluation, deployment \/ monitoring). Example of libraries: Tensorflow\/Keras, Pytorch \/ Scikit-learn.\nProven ability to partner with product teams to define workflows that meet client needs.\nDemonstrated excellence in written and verbal communication, in fluent English, with ability to explain complex analyses to a variety of audiences.\nPreferred\nDetail-oriented with a demonstrated ability to work under time pressure and balance multiple competing \/ changing priorities.\nExperience working with large, complex medical \/ healthcare data (e.g., insurance claims, EHR, CDISC)\nExperience with version control software (e.g., Git)\nExperience with big data workloads (e.g., Spark, Databricks)\nExperience working within cloud-centric systems (AWS)\nExperience working with containerized compute (e.g., Docker)\nExperience working with relational databases\nKnowledge of software engineering best practices\nExperience in the healthcare industry\n  Aetion is an Equal Opportunity Employer. Aetion is committed to being an employer of choice, not just a good place to work, but a great and inclusive place to work. To that end, we strive to recruit and maintain a workforce that meaningfully represents the diverse and culturally rich communities that we serve. Qualified applicants will receive consideration for employment without regard to their race, color, religion, national origin, sex, sexual orientation, gender identity, protected veteran status or disabled status or genetic information.","4":"Company Description\nBosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it\u2019s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.\nJob Description\nJob Description\n10+ years of experience working with large data sets or do large scale quantitative analysis\nWill be responsible for leading architecture, design and implementation of AI\/ML \/ NLP \/ Computer Vision and MLOps solutions across team of Data Scientists, Data Engineers, ML Engineers, Cloud, Analytics, DevOps and Visualization teams\nExperience in analyzing complex problems and translating them to data science algorithms with due attention to computational efficiency and testing at scale.\nAuthoritative experience in the field of Data Science to influence stake holders across varied work streams and geographical locations, ability to challenge the status quo to improve the base line models and the models which are already productionized.\nExperience in machine learning, supervised and unsupervised: Forecasting, Classification, Data\/Text Mining, NLP, Search Algorithms, Deep Learning Algorithms.\nExperience in using MLOps frameworks like Kubeflow, MLFlow, Airflow Pipelines for building, deploying, and managing multi-step ML workflows based on Docker containers and Kubernetes.\nExperience with workflow orchestration tools like Kubeflow, Airflow, Argo or similar tools\nExposure to deep learning approaches and modeling frameworks (PyTorch, Tensorflow, Keras, etc.)\nExperience in frameworks to depict interpretability of models using libraries like Lime, Shap etc.\nExperience working with big data - identifying trends, patterns, and outliers in large volumes of data.\nStrong implementation experience with Python, and familiarity with Linux\/Unix\/Shell environments\nStrong hands-on skills in sourcing, cleaning, manipulating and analyzing large volumes of data using distributed computing platform\nExperience with Hive \/ Spark \/ Teradata and NOSQL databases\nExperience in using code versioning tools like GIT, bit bucket; building CI\/CD pipelines for ML projects\nExperience in productionizing ML models in any of the cloud platforms - AWS\/GCP\/Azure\nGood to have experience in building automated\/semi-automated model retraining pipelines.\nSuperior verbal, visual and written communication skills to educate and work with cross functional teams on controlled experiments.\nCandidates with prior publications in the field of Data Science are highly preferred.\nTech savvy and willing to work with open-Source Tools\nWillingness to learn IoT, Edge AI and keep up to date with technologies\nGood to have previous whitepaper submissions and IP filings\nQualifications\nQualifications\nBE, BTech, MTech, MS\nAdditional Information\nAdditional information\nGood to have \nWhitepaper submissions and IP filings","5":"Company Description\nAre you a high-performer who wants to contribute to a mission-driven and values-based organization? If you are motivated by doing impactful work and making a difference in people\u2019s lives, then the Indiana University Foundation (IUF) is the place for you.\u202fAt the IUF, we believe in making the dream of higher education attainable, providing support for life-changing research, and preparing the next generation of leaders.\nAs a trailblazer among our peers, we provide fundraising leadership and endowment stewardship to support needs and initiatives across all of Indiana University\u2019s campuses. As part of our team, you will help make IU donor\u2019s dreams last forever.\nAt the IUF we work hard, celebrate achievements, and foster an environment where everyone\u2019s contributions matter. We are nimble and innovative, and we want you to bring your ideas and energy to join forces with some of the best talent in our industry.\nIn addition to being part of a meaningful mission as an IUF employee, you\u2019ll find there are many ways to connect and collaborate. Our diversity, equity, and inclusion initiatives ensure that our colleagues are celebrated for who they are and have a voice.\u202fOur FUNdation (see what we did there?) Committee helps us connect and unwind with food truck lunches, holiday gatherings, costume contests, free snacks, IU spirit-wear Fridays, and spontaneous gestures that surprise and delight. Our Wellness Committee ensures that the health and well-being of our employees is top of mind, offering yoga, a lunchtime walking group, meditation breaks, the Headspace app, and topical workshops. We encourage community leadership and service and make space for our staff to pursue their passions. Our total rewards philosophy ensures that we support employees financially, emotionally, and in their career growth. If the IUF sounds like a fit for you, we invite you to join us today.\nJob Description\nThe IU Foundation is seeking a dedicated IT leader to serve as Director of Applications, Integrations, and Data Architecture. \nThis position leads three teams responsible for the development and integration of organizational applications, reporting environments, data warehouses, and processes, to further advancement and alumni relations efforts of Indiana University (IU), Indiana Alumni Association (IUAA), and Indiana University Foundation (IUF).  This position ensures cohesive strategies for applications, integrations, and data\/reporting infrastructure align with the overall technology and organizational strategies of IUF and IUAA.\nThe ideal candidate for the role will be an experienced IT people leader, with strong leadership and collaboration skills. This team requires a high level of customer service, and regularly owns communications with stakeholders, ensuring timely updates, transparent processes, and a shared understanding of technology. The ideal candidate has great experience with performance management and goal setting, proven success with building and growing emerging leaders within the organization, and sets clear goals and expectations that align with the goals, mission, and values of the organization. \nQualifications\nEducation & Experience\nBachelor\u2019s degree required in a technical-related field\nMinimum 5 years in management\nPreference for individuals with strong technology management experience and experience working with Agile teams\nCombinations of experience and education will be considered\nKnowledge, Skills & Abilities\nStrong supervisory experience with emphasis on mentoring, coaching, and team building\nAwareness of industry trends in application development, application integration, application architecture, business intelligence, data warehousing, data processing, artificial intelligence, and enterprise architecture\nDemonstrable written and verbal communication skills with emphasis on negotiation, conflict resolution, and change management\nDemonstrated success in building an environment of trust, collaboration, and open honest communication with internal and external stakeholders\nAttention to detail and quality\nStrong organizational skills including experience with matrix\/collaborative management\nStrong follow-through skills\nAbility to multitask and set personal and team priorities\nDemonstrated analytical ability for problem-solving\nAbility to handle stress and work in an environment with competing priorities from multiple organizations\nCandidates must reside in, or be willing to relocate to, Indiana. This role can be on-site or hybrid-remote (quarterly in-person team meetings required).\nWe are unable to offer visa sponsorship for this position.\nAdditional Information\nA cover letter highlighting your interest in the organization, and your skills and experiences related to the position is recommended for your application to be considered. \nThe IUF is committed to providing a safe, respectful, and professional work environment that is free of Discrimination and Harassment. The IUF will not tolerate any form of Discrimination or Harassment based on the Individual\u2019s race, ethnicity, religion, color, sex, age, national origin, genetic information, sexual orientation, disability, gender identity or expression, ancestry, marital status, protected veteran status, pregnancy, or any other basis prohibited by law.","6":"Company Description\nTransforming businesses, driving success: SmarTek21\nSmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev\/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients\nJob Description\nSmarTek21 is looking for a hands-on Big Data Solution Architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.  \nQualifications\n\u2022 Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python.\n\u2022 Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks.\n\u2022 Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP).\n\u2022 Solid understanding of enterprise strategies for data security and data governance.\n\u2022 Experience in practice development, architecture, and consulting or product development.\n\u2022 Experience delivering data analytics projects and architecture guidelines.\n\u2022 Experience in engaging with enterprise architects. Non-technical Skills:\n\u2022 Excellent oral and written communication and presentation skills.\n\u2022 Ability to handle ambiguous situations and take trade-off decisions.\n\u2022 Strong problem solving and analytical skills to break down complex problems into smaller components.\n\u2022 Ability and willingness to perform in a team environment.\nRequirements:\n\u2022 Understand prospect\/customer\/partner technology landscape.\n\u2022 Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation.\n\u2022 Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers\/partners.\n\u2022 Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints.\n\u2022 Collaborate with the engineering team to create proof-of-concepts (POCs).\n\u2022 Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices.\n\u2022 Demonstrate business value of proposed solutions or current products to prospects and customers.\nSalary Range: $200,000-$215,000 (may be subject to change outside of WA State)\nAdditional Information\nWhat Is in It for You:\nPaid Time off \u2013 start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service.\nPaid Holidays - 8 paid holiday a year in addition to your PTO.\nHealth Insurance for FT employees \u2013 we pay 100 % premium of medical, dental and vision.\nHealth Insurance for FT employee\u2019s family \u2013 we pay 50% of premium for medical, dental and vision for dependents.\n401(k) \u2013 we administer 401(K) retirement contribution for FT employees.\nLife Insurance\/Short Term and Long-Term Disability \u2013 at no cost to you\nOpportunities for internal promotions\/career advancement\nFamily friendly work hours (closed on weekends and paid holidays)\nSmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and\/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class.","7":"Company Description\nAbout Spark Foundry: \n \nSpark Foundry is a global media agency that exists to bring HEAT \u2013 Higher Engagement, Affinity, and Transactions \u2013 to brands. By combining flawless media fundamentals with aggressive innovation, Spark inspires consumers to pay more attention; to care more about our clients\u2019 brands; and to buy more products and services from them. \n \nBalancing the nimble spirit of a startup with the powerhouse soul of Publicis Media, Spark Foundry delivers the best of both worlds to a client roster that spans some of the world\u2019s best and most beloved brands and companies. We combine boutique-caliber insights and service with the buying clout and first-look access of a global leader, bringing the heat to challenger brands that want to act like giants, and to giant brands that want to act like challengers. \n \nWith a bottom-up culture that celebrates diversity and aims for all voices to be heard, Spark has become a magnet for the industry\u2019s best talent, with one of the best retention rates in the industry. And by applying a whole-person approach to professional and personal development, Spark develops a workforce that is well prepared for today\u2019s challenges, and also poised to create meaningful careers in the years to come.  \n \nBecause we know that heat arises the intersection of complementary forces, our professionals come from myriad disciplines and backgrounds: data, analytics, and insights; content and creative production; communications and strategy; finance and marketing; and sociology, psychology, and other liberal arts disciplines. \nJob Description\nOverview: \nThe Data Architecture team is an elite team of data and marketing technology specialists with expertise in the ever-changing universe of ad technology, precision marketing and data management. The Associate Director will be integral in driving ad\/mar tech and data integration conversations and strategies on behalf of our clients, and then implementing these strategies with the Programmatic activation and operations teams. The Associate Director will become an expert in the Data advertising landscape and will consult with internal teams and clients on partner\/vendor selection, data onboarding, platform integrations, audience activation and testing framework, and audience reporting\/insights. \nThis highly motivated, detail-oriented individual will work with both the client and internal stakeholders to educate them on the myriad uses of data and to drive innovation in the use of data and technology for the client. He\/she will also generate key insights and audience profiles to align with strategic planning and will also work with 3rd party data vendors and publishers to maximize the data opportunity for the client and go beyond what is currently available. The successful candidate will have a fully-rounded knowledge of the digital advertising and data landscape and a passion for working with marketers and clients to drive advertising value. \n \nRole Objectives: \n\u2022 Be an in-house expert on how Data and Programmatic advertising can provide ROI for clients  \n\u2022 Guide and drive use of audience data to impact media strategies for client account(s) based on overall objectives  \n\u2022 Understand how platform\/data technologies work and offer the ability to explain technical concepts in ordinary terms (be technically savvy - understand the opportunities and limitations)  \n\u2022 Identify opportunities \u2013 industry learning, meet with vendors and provide a POV, with a client lens and in desired format -- education\/evangelize the findings  \n\u2022 Oversee relationship with the Identity Resolution platforms, CDPs, or other AdTech solutions and project manage the deployment and activation of data technology solutions  \n\u2022 Partner with internal Programmatic and media investment arms to support campaign activation as well as advanced data use cases  \n\u2022 Oversee, author and\/or constructively edit and review the writing of media documents (timelines, POVs, RFPs, plans, agreements, client memos, and correspondence from within and outside the agency).  \n\u2022 Share knowledge with client and internal teams regarding audience insights and results to impact business needs  \nQualifications\n\u2022 3+ years\u2019 managing 2+ direct reports \n\u2022 5-7 years\u2019 experience in digital media and ad technology \n\u2022 Excellent oral, written and client presentation skills \n\u2022 This role requires travel to client location \n\u2022 In-depth technical knowledge of ad and marketing technology, including ad servers, rich media, dynamic creative, streaming video, OBA, ad verification, customer data management platforms, identity resolution solutions, DSPs, etc \n\u2022 Strong project management skills and keen ability to delegate \n\u2022 Strong understanding of digital media planning and management processes \n\u2022 Previous agency-side experience \n\u2022 Strong track record managing multiple client verticals across variety of third-party marketing measurement technology platforms \n\u2022 Strong track record in quickly adapting to new ad measurement platforms in the most detailed of the sense (DSP, Ad Servers, Rich Media, Video, Mobile web and in-app tracking deployment experience necessary) \nAdditional Information\nAll your information will be kept confidential according to EEO guidelines.\nCompensation Range: $106,500-$167,500.  This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. For this role, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off\n23-2658","8":"Company Description\nInforma is a leading international events, intelligence and scholarly research group.\nWe\u2019re the specialist\u2019s specialist. Through hundreds of powerful brands, we work with businesses and professionals in specialist markets, providing the connections, intelligence and opportunities that help customers grow, do business, make breakthroughs and take better informed decisions.\nInforma is listed on London Stock Exchange and a member of FTSE 100, with over 11,000 colleagues working in more than 30 countries.\nInforma\u2019s divisions include: Informa Connect, Informa Intelligence, Informa Markets, Informa Tech, Taylor & Francis and Global Support.\nGlobal Support is Informa's sixth division, with major hubs in the United Kingdom, United States, Hong Kong and Singapore as well as several smaller locations.  As the team behind the teams, Global Support colleagues provide shared, efficient business services and function-specific expertise to each of Informa's operating divisions, enabling our commercial teams to focus on their markets and customers.\nAbout Group Technology \u2013 Strategic Context\nInforma is a successful and diverse FTSE 100 business that has been built over the past twenty years through a mix of organic growth and acquisition. The Group has needed to transform itself post-COVID-19 to increase digital capability and the mix of revenues, with the expectation that far higher proportions of revenue are derived from new digital products and through the sales of all products through digital channels.\nEqually, as a contemporary B2B provider of solutions and services, we anticipate the need to enable customer touchpoints through digitalising processes that are currently offline, and through shaping and establishing a digital ecosystem over the next 5 years, whilst firmly establishing our position within it, thereby providing our B2B customers with end-to-end go-to-market solutions. This has resulted in a group-wide programme, GAP II, which is focused on a digital acceleration programme and associated investment.\nJob Description\nKey Areas of Responsibility\/Accountability\nWorking across divisions and data domains lead the creation Informa\u2019s enterprise data architecture including the enterprise data model, enterprise data inventory, associated mappings, tagging and information value streams.\nDefine the strategy and target state for the enterprise data model working with domain owners and key business and technology stakeholders, including the creation and maintenance of blueprints, roadmaps, data management and governance practices and alignment with strategic business outcomes and 3 year planning activities.\nWork as a team with Enterprise Architecture colleagues to ensure the overall enterprise architecture is aligned with the target state Enterprise Data Architecture and evolves as a component part of Informa\u2019s overall data and technology capabilities.\nAlign Data Management and Data Governance frameworks and practices and ensure the data domains owned by group operations are apply consistent best practices across domains.\nBe the primary point of contact for the Group Technology data domains and lead the associated data architecture and strategy on a go-forward basis\nCollaborate with divisional and programme data architects to ensure that initiatives and  proposed solutions are aligned with the enterprise data architecture and comply with the recommendations of architectural governance\nMaintain and align Informa\u2019s enterprise architecture body of knowledge with the enterprise data architecture and maintain this to reflect the evolution and outcomes of the initiatives.\nEnsure the enterprise data architecture is used to facilitate data and technology governance and management within Divisions and across Group Operations, performing impact analysis and risk identification for change initiatives and transformation programmes.\nCollaborate with the Technology and Business stakeholders to identify risks associated with proposed initiatives and roadmaps\nCollaborate with colleagues within Information Security and Compliance to ensure alignment between Enterprise Data Architecture and the Informa IT Controls framework, Information Security and Compliance\nProviding target architecture and roadmap knowledge to assist with business case development, cost benefit modelling and project initiation documents to support the approval and delivery of change initiatives\n Qualifications\nExperience leading enterprise data architecture on complex transformation or digital initiatives or for specific data domains or at an enterprise scope.\nIdeally experience of defining data management and governance frameworks and processes and implementing associated capabilities and tooling across multiple data domains.\nExperience of leading the definition of data architecture and data management practices associated with customers, products, orders, payments, suppliers, workforce and technology assets and master data etc.\nExperience of the Compliance and Regulatory concerns related to data management.\nExperience of working within Agile and non-Agile working practices and frameworks\nExperience of working within a multi-tenanted architecture\nExtensive experience performing in an Enterprise Data Architecture role across multiple divisions or business units, developing and maturing the data architecture capabilities, while also operating as part of a centralised, federated or co-ordinated enterprise architecture capability\nExtensive experience of working with Business Leadership and critical senior stakeholders, e.g.  Divisional CEO, SMT, Market or Product Owners, to define and align architectures to strategic objectives\nExtensive experience collaborating with CIO, CTO and IT Leadership, including governance, conflict and strategic alignment scenarios\nUnderstanding of the impact of acquisitions, joint ventures or divestments on an enterprise data architecture and data management practices\nExperience of adopting\/adapting multiple enterprise architectural methodologies and frameworks (e,g, TOGAF, Zachman), relevant industry associations and reference models (e.g. DMBOK, APCQ, etc.) and the tools or notations (e.g. BPML) used to define and communicate architectures with all stakeholder groups\nExperience working with in global corporate organisations operating within ITIL Service Management , IT Control, Risk management and compliance frameworks\nExperience of multiple industries is desirable\nAdditional Information\nWe adopt a Balanced Working policy that supports colleagues in taking a task-based approach to their working location \u2013 allowing time at home for focused work, individual tasks and virtual meetings. We also value team connection and collaboration highly, so encourage visits to the office to meet in-person, to collaborate, for coaching\/learning and work as teams. \nWe embrace and respect individuality, difference and diversity.  We know our personal limitations and, whilst we celebrate personal learning and growth, we also look to others to complement our thinking. As such, we believe in the strength of teams and in enabling every team member to contribute.  We like people to speak up, take responsibility for their actions and \u2018muck in\u2019 to support their colleagues.\nIf you want to be part of a team driving tangible change in a dynamic organisation that doesn\u2019t stand still, this could be the team \u2013 and the company to join.\nFlexible working environment\nLearning and Development plan to assist with your career development\n25 days annual leave plus bank holidays, 4 days for volunteering and a day off for your Birthday\nCentral offices in Blackfriars and Victoria, close to mainline and Underground stations, and a variety of amenities nearby\nOther flexible benefits include Healthcare, Cycle to Work scheme and Season Ticket Loans\n5% Pension match and Life assurance\nShare-Match options - become a shareholder\nRegular Social Events and Networking opportunities across Informa","9":"We Breathe Life Into Data\nAt Komodo Health, our mission is to reduce the global burden of disease. And we believe that smarter use of data is essential to this mission. That\u2019s why we built the Healthcare Map \u2014 the industry\u2019s largest, most complete, precise view of the U.S. healthcare system \u2014 by combining de-identified, real-world patient data with innovative algorithms and decades of clinical experience. The Healthcare Map serves as our foundation for a powerful suite of software applications, helping us answer healthcare\u2019s most complex questions for our partners. Across the healthcare ecosystem, we\u2019re helping our clients unlock critical insights to track detailed patient behaviors and treatment patterns, identify gaps in care, address unmet patient needs, and reduce the global burden of disease. \nAs we pursue these goals, it remains essential to us that we stay grounded in our values: be awesome, seek growth, deliver \u201cwow,\u201d and enjoy the ride. At Komodo, you will be joining a team of ambitious, supportive Dragons with diverse backgrounds but a shared passion to deliver on our mission to reduce the burden of disease \u2014 and enjoy the journey along the way.\nThe Opportunity at Komodo Health\nKomodo aims to build the best healthcare data analytics platform in the industry.  As we are maturing, we are investing in our core data assets, building on our strengths in medical and prescription claims, to create the best healthcare data management system to support self-service exploration and advanced analytics. \nThe Staff Data Architect will act as a key enabler and contributor to the different engineering teams in enhancing their maturity in terms of adopting modern data stack for healthcare data ingestion, preparation & analytics. This position will integrate the transversal Office of the CTO (OCTO) group.\nLooking back on your first 12 months at Komodo Health, you will have\u2026\nSupported the design, development and deployment in production of end-to-end data flows, including compute and storage of big healthcare datasets in a multi-tenant environment\nAdvised on technologies, scout and identified technologies which can support our heavy data processing constraints for cleansing & analytics\nDeveloped data pipelines in modern data stack environment\nInteracted with the product teams in order to refine technical assumptions\nEnabled our Engineering teams in adopting the best practices and maturing their techniques to develop and operate SaaS data pipelines\nWhat you bring to Komodo Health:\nCreative spirit that develops and seeks ideas. Screening of various sensors and innovation source\nProficiency in a data processing-friendly language (Python, Java, SQL\u2026)\nExpertise in Big Data environment (Spark, K8S, Databricks, AWS Glue, Snowflake)\nStrong understanding of modern data modeling and data architecture practices, including Data Governance and Data Quality & Ops\nDeep knowledge of change data capture and event-driven architectures\nProficiency in cloud-native orchestrators (Serverless, Kubernetes, Docker...) is a plus\nDemonstrated capabilities to communicate to business and technical stakeholders and work across departments\nAbility to communicate effectively and clearly in English, both verbally and in writing.\nExperience in working within a distributed & international agile team environment.\nAdditionally:\nPassion! We hope you are passionate about our mission and technology\nOwnership! We hope you own your work, be accountable, and push it through the finish line. We hope you treat yourself as a cofounder and do not hesitate to share any idea that helps Komodo\nExpertise! We do not need you to know everything, but we hope you have deep knowledge in at least one area and can start contributing quickly. And we would love to learn from you in your area(s) of expertise\n  #LI-CT1 #LI-REMOTE\nWhere You\u2019ll Work\nKomodo Health has a hybrid work model; we recognize the power of choice and importance of flexibility for the well-being of both our company and our individual Dragons. Roles may be completely remote based anywhere in the country listed, remote but based in a specific region, or local (commuting distance) to one of our hubs in San Francisco, New York City, or Chicago with remote work options. \nWhat We Offer\nOn top of our commitment to providing competitive, fair pay for all roles at Komodo Health, we\u2019re proud to offer robust and inclusive benefits to all Dragons at Komodo Health. We offer global time off programs, extensive internal and external career development and learning opportunities, multiple affinity groups celebrating our team\u2019s diversity, and an annual wellness and productivity stipend to support you in being your healthiest, best self. \nEqual Opportunity Statement\nKomodo Health provides equal employment opportunities to all applicants and employees. We prohibit discrimination and harassment of any type with regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. ","10":"At Neo, we\u2019re reimagining everyday financial services from the ground up and shaping the financial future for millions of people in Canada. We\u2019re a tech company consistently pushing for the next best thing, which provides many opportunities to grow and learn personally and professionally. Ready to materialize your passion into a connected purpose? Come join a high-speed startup in a community of high-achieving dreamers and doers, set on innovating the best solutions.\n\nAbout The Role:\nNeo Financial has an opportunity for a Principal Data Architect to join our team in Calgary, AB. As a Principal Data Architect, you\u2019ll play a pivotal role in planning, building, and improving Neo\u2019s data platform alongside a team of talented colleagues. This highly visible position will be the most senior technical individual on the data side helping redefine our data strategy and architecture as we scale and grow.\nBeing our in-house data expert, this individual will be working with multiple product and engineering teams across the company on key strategic initiatives. The Principal Data Architect will up-level the organization in terms of best practices and will provide technical leadership as we build out our data team.\n\nWhat you\u2019ll be doing:\nAssess and understand the current state of data at Neo - from ingestion of data, to aggregation, storage, access, analytics, export, and more.\nMaster the tech stack that drives data at Neo, being able to work in any area to make big improvements that move the needle, or provide mentorship to the rest of the team.\nDevelop strategies for data quality, including planning detailed projects to build out automation or testing environments.\nProvide architectural recommendations and formulate the technical roadmap, helping prioritize in a way that matches our business goals.\nTranslate Neo\u2019s long-term, high-level data vision into exact action items for the technology team, while also devoting some of your time to the hardest hands-on problems.\nProvide technical and architectural oversight for systems and projects that are required to be reliable, massively scalable, highly available and maintainable.\nPerform \u201ccode reviews\u201d to ensure that the work done by the team meets the highest standards and best practices.\nHelp select and then setup infrastructure, tooling, or vendor products as needed to build out our data ecosystem.\nDefine, document, and communicate our data modeling standards, conventions, and foundational best practices so that all teams can work in the same way.\nWork with our product managers to develop business requirements or assess architecture or data impacts when changes are proposed.\nMentor team members in best practices, processes, and technologies in data platforms.\n\nWho we are looking for:\n10+ years of hands-on experience in Data Warehouse, ETL, Data Streaming, Data Modeling & Reporting.\n7+ years of hands-on experience in productionizing and deploying data platforms and applications, personally setting up technologies for data ingestion all the way through to BI, export, or end-of-life archival.\nDemonstrated industry leadership in the fields of Data Warehousing, Data Science, or any Big Data related technologies.\nExperience with DBT, Snowflake, Airflow, AWS and Kafka. Experience with Databricks and Apache Spark is nice to have.\nExtensive experience in understanding a variety of complex business use cases and mapping many different systems into a unified model for data in the data warehouse.\nAbility to take business needs and constraints into account; optimizing for speed, effective estimation, cost management, team scalability, etc.\nStrong understanding of database technologies (NoSQL and relational), such as MongoDB, or PostgreSQL\/MySQL or similar.\nExpert when it comes to writing and optimizing even complex SQL queries.\nAble to code data-related projects using Python or JavaScript. Additional experience in other programming languages and backend stacks is preferred.\nUnderstanding of distributed systems, cloud infrastructure, devops and CI\/CD tooling.\nExpert level understanding of data architecting principles (ie: Data Mesh).\nExperience with automated testing in the data space; ability to architect testing solutions and develop automation while mentoring and upskilling our team to drive data quality.\nUnderstanding all of the challenges and solutions for data at scale.\n\nAbout applying with us:\nAt Neo, you\u2019ll be working with industry-leading technology that changes the way we live and redefines Canada\u2019s financial future. It\u2019s a serious deal, and we\u2019re building a high performance, mission-driven, and fast-paced team that strives to make a difference in every Canadian's life. We value personal growth, autonomy, leadership at all levels, and the ability to learn quickly from mistakes. We\u2019re a team: in it together, always. Join a world class team building truly disruptive technology, right here in the Canadian prairies.","11":"Company Description\nVericast is a premier marketing solutions company that accelerates profitable revenue growth for the thousands of businesses it serves directly by influencing consumer purchasing and transaction behavior at scale while engaging with over 120 million households daily.  We are recognized as leading providers of incentives, advertising, marketing services, transaction solutions, customer data and cross-channel campaign management, and intelligent media delivery that create millions of customer touch points annually for their clients.  For more information, visit http:\/\/www.vericast.com or follow Vericast on LinkedIn.\nJob Description\nValassis Digital (a division of Vericast) is seeking a Principal Software Engineer to develop services, tools, bots, and workflows for our big data processing infrastructure.\nThe Big Data Platform Team owns and operates the world-class big data processing infrastructure that over a dozen engineering teams use to power their 24\/7 technical marketing products. We own and operate a large hadoop+spark processing cloud on which we store 6PB of data, and run 30 thousand jobs every day. We write a fabric of java microservices and bots to manage all those jobs, extend hadoop's functionality, and help us operate and optimize our investment. We write custom data streaming services that ingest and curate 100TB of data each day that drives the entire advertising data ecosystem. We also participate in all our users' groundbreaking workflow projects so that we can constantly stay abreast of our developer's tooling needs.\nWhat you're like:\nThis position is perfect for a far-sighted engineer who always wants to be the first to apply cutting-edge technologies to solve complex business and engineering problems. You want to have a leading voice on our team and across our organization. You will work throughout the software lifecycle including customer interaction and product planning, requirements analysis, architecture, directing our team of developers, development, testing and operations. If you are energized by the thought of developing new system stacks and tools for big data processing and analytics we want to talk to you. If you have worked on big data engineering, cloud migration, or infrastructure tooling projects, we want to talk to you. If you have ever worked on a collection of data workflows or a service mesh and thought 'I could make this better', we want to talk to you!\nWhat you'll do:\nWork with our users, architects, and product leaders to architect and plan our data platforms\nDesign, develop, and maintain the software and systems that make up the data platform that runs our entire business\nPartner with the Data Engineering and Data Science teams who use our platform to diagnose, predict and address scaling problems\nWork on new products initiatives to provide design support and establish best practices\nContribute to our team\u2019s growing set of development platforms, tools, processes, and products\nQualifications\nExperience working on big data systems and technologies with emphasis on the Hadoop platform\nGeneral knowledge of design patterns & UML with a few years of taking a lead on architectural design and development\nProficiency in Java, Scala, or Python programming; exposure to microservices and Spark dataframe programming.\nProficiency in networking, Thrift, Spring Framework and\/or Spring Boot for microservices is a plus. \nUnderstand RDMS and proficiency in DML, SQL & PL\/SQL a plus\nHands on experience with Spark; exposure to Kafka and YARN or similar technologies\nExperience with migration of infrastructure from on-prem to cloud or vice versa is a big advantage\nCuriosity to learn and apply new technologies and a background full of diverse design challenges\nExcellent problem-solving abilities\nExcellent verbal, graphical, and written communication skills\nExperience with agile development methodologies\n\nYour qualifications:\nBS\/MS in Computer Science or other technical discipline (with significant computer coursework)\n10+ recent years of professional software development experience using java, scala, or python\n3+ recent years working with the hadoop+spark big data platform or similar\nAdditional Information\nSalary:  180,000-200,000 with 10% bonus opportunity\nThe ultimate compensation offered for the position will depend upon several factors such as skill level, cost of living, experience, and responsibilities.\nVericast offers a generous total rewards benefits package that includes medical, dental and vision coverage, 401K and flexible PTO. A wide variety of additional benefits like life insurance, employee assistance and pet insurance are also available, not to mention smart and friendly coworkers!\nAt Vericast, we don\u2019t just accept differences - we celebrate them, we support them, and we thrive on them for the benefit of our employees, our clients, and our community.\u202fAs an Equal Opportunity employer, Vericast considers applicants for all positions without regard to race, color, creed, religion, national origin or ancestry, sex, sexual orientation, gender identity, age, disability, genetic information, veteran status, or any other classifications protected by law. Applicants who have disabilities may request that accommodations be made in order to complete the selection process by contacting our Talent Acquisition team at talentacquisition@vericast.com. EEO is the law. To review your rights under Equal Employment Opportunity please visit: www.dol.gov\/ofccp\/regs\/compliance\/posters\/pdf\/eeopost.pdf.\n#LI-TE1\n#LI-Remote","12":"What does BPM stand for? Innovation, opportunity, community, diversity, inclusivity, flexibility and so much more. B-P-M stands for \u201cBecause People Matter,\u201d because at our core, our people drive everything we do and how we do it.  We are a forward-thinking, full-service accounting firm providing modern solutions to businesses across the globe. We focus on comprehensive assurance, tax, and consulting services for our clients, and we provide our people and our community with the resources to lead meaningful and purposeful lives.\nCulture of Data As BPM continues to build a data-driven culture, the Data Architect will be supporting the continued success of that effort.  For BPM, the culture of data represents the firm\u2019s approach to data management, stewardship, lineage, architecture, collection, storage, and utilization for delivering analytic results.  It also includes tools, applications and approaches which lead the firm to have access to timely and accurate data.  This role will play an integral part in the delivery, maintenance, building of business relationships and success to the culture of data. JOB OVERVIEW:The Data Architect will be responsible for designing data infrastructure to extract and organize data for authorized individuals to access. Duties include oversight to master data management, identifying BPM\u2019s internal and external data sources, collaborating with practice group\/department heads to determine their data storage\/utilization and organizational needs and using the information to create and maintain data infrastructure for BPMs employees. This role is also responsible for maintaining relationships with key stakeholders and ensuring that the data architecture function is aligned with the strategic objectives of the organization.\nRESPONSIBILITIES:\nBuild master data management approaches.\nManage table structures\/data elements within our applications.\nSupport ETL processes moving data between various DB platforms.\nBuild and guide our data growth, analysis, and storage strategies.\nBuild\/design dashboards within respective BI applications.\nFullfill analytic needs for stakeholders.\nRequirements:\nUndergraduate degree in the field of data or computer science, information technology, statistics, or mathematics, and\/or 10 years equivalent work experience.\nHands-on experience with data architecting, data mining, large-scale data modeling, and business requirements gathering\/analysis.\nDirect experience in implementing enterprise data management processes, procedures, and decision support.\nStrong understanding of relational data structures, theories, principles, and practices.\nStrong familiarity with metadata management and associated processes.\nHands-on knowledge of enterprise repository tools, data modeling tools, data mapping tools, and data profiling tools.\nDemonstrated expertise with repository creation, and data and information system life cycle methodologies.\nExperience with business requirements analysis, entity relationship planning, database design and reporting structures.\nProven experience with business and technical requirements analysis, elicitation, modeling, verification, and methodology development.\nExperience overseeing the design, development, and implementation of business intelligence dashboards and\/or reporting.\nAbility to create systematic and consistent requirements specifications in both technical and user-friendly language.\nExceptional analytical and statistical skills with the ability to apply them to business needs as required.\nAbility to communicate with both technical and business end-user colleagues to deliver meaningful outcomes.\nDemonstrated project management skills and project management software skills, including planning, organizing, and managing resources.\nSolid business acumen, including deep understanding of financial data and KPIs.\nExtensive experience with business intelligence tools such as Power BI and Tableau.\nExcellent critical thinking skills and the ability to understand the relationships between data and business intelligence.\nAble to communicate effectively to stakeholders.\nAdvanced Data Science programming language skills, such as R, Python and SQL.\nBe able to work with ETS in partnership.\nDeep understanding of data governance principles\nWondering if you should apply?\nBPM is powered by knowledgeable, enthusiastic, and forward-thinking people committed to developing a culture of inclusion. We recognize, develop, and empower talent and encourage diversity of thought. Your point of view, skillset and experience will only make us stronger, so if you're eager to share new ideas and try new things, we want to hear from you.\n***************\nBPM provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.\nFor positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.\nPlease note - this posting is for prospective candidates only. Unsolicited third party resume submissions will be considered property of BPM and will not be acknowledged or returned.\nBPM COVID Vaccination Policy\nEffective July 1, 2021, only fully vaccinated employees will be permitted to enter our offices until further notice. Fully vaccinated means there has been a 2 full week period since the last vaccine. All employees must wear a mask until further notice.","13":"Company Description\nAbout Spark Foundry: \n \nSpark Foundry is a global media agency that exists to bring HEAT \u2013 Higher Engagement, Affinity, and Transactions \u2013 to brands. By combining flawless media fundamentals with aggressive innovation, Spark inspires consumers to pay more attention; to care more about our clients\u2019 brands; and to buy more products and services from them. \n \nBalancing the nimble spirit of a startup with the powerhouse soul of Publicis Media, Spark Foundry delivers the best of both worlds to a client roster that spans some of the world\u2019s best and most beloved brands and companies. We combine boutique-caliber insights and service with the buying clout and first-look access of a global leader, bringing the heat to challenger brands that want to act like giants, and to giant brands that want to act like challengers. \n \nWith a bottom-up culture that celebrates diversity and aims for all voices to be heard, Spark has become a magnet for the industry\u2019s best talent, with one of the best retention rates in the industry. And by applying a whole-person approach to professional and personal development, Spark develops a workforce that is well prepared for today\u2019s challenges, and also poised to create meaningful careers in the years to come.  \n \nBecause we know that heat arises the intersection of complementary forces, our professionals come from myriad disciplines and backgrounds: data, analytics, and insights; content and creative production; communications and strategy; finance and marketing; and sociology, psychology, and other liberal arts disciplines. \nJob Description\nOverview: \nThe Data Architecture team is an elite team of data and marketing technology specialists with expertise in the ever-changing universe of ad technology, precision marketing and data management. The Associate Director will be integral in driving ad\/mar tech and data integration conversations and strategies on behalf of our clients, and then implementing these strategies with the Programmatic activation and operations teams. The Associate Director will become an expert in the Data advertising landscape and will consult with internal teams and clients on partner\/vendor selection, data onboarding, platform integrations, audience activation and testing framework, and audience reporting\/insights. \nThis highly motivated, detail-oriented individual will work with both the client and internal stakeholders to educate them on the myriad uses of data and to drive innovation in the use of data and technology for the client. He\/she will also generate key insights and audience profiles to align with strategic planning and will also work with 3rd party data vendors and publishers to maximize the data opportunity for the client and go beyond what is currently available. The successful candidate will have a fully-rounded knowledge of the digital advertising and data landscape and a passion for working with marketers and clients to drive advertising value. \n \nRole Objectives: \n\u2022 Be an in-house expert on how Data and Programmatic advertising can provide ROI for clients  \n\u2022 Guide and drive use of audience data to impact media strategies for client account(s) based on overall objectives  \n\u2022 Understand how platform\/data technologies work and offer the ability to explain technical concepts in ordinary terms (be technically savvy - understand the opportunities and limitations)  \n\u2022 Identify opportunities \u2013 industry learning, meet with vendors and provide a POV, with a client lens and in desired format -- education\/evangelize the findings  \n\u2022 Oversee relationship with the Identity Resolution platforms, CDPs, or other AdTech solutions and project manage the deployment and activation of data technology solutions  \n\u2022 Partner with internal Programmatic and media investment arms to support campaign activation as well as advanced data use cases  \n\u2022 Oversee, author and\/or constructively edit and review the writing of media documents (timelines, POVs, RFPs, plans, agreements, client memos, and correspondence from within and outside the agency).  \n\u2022 Share knowledge with client and internal teams regarding audience insights and results to impact business needs  \nQualifications\n\u2022 3+ years\u2019 managing 2+ direct reports \n\u2022 5-7 years\u2019 experience in digital media and ad technology \n\u2022 Excellent oral, written and client presentation skills \n\u2022 This role requires travel to client location \n\u2022 In-depth technical knowledge of ad and marketing technology, including ad servers, rich media, dynamic creative, streaming video, OBA, ad verification, customer data management platforms, identity resolution solutions, DSPs, etc \n\u2022 Strong project management skills and keen ability to delegate \n\u2022 Strong understanding of digital media planning and management processes \n\u2022 Previous agency-side experience \n\u2022 Strong track record managing multiple client verticals across variety of third-party marketing measurement technology platforms \n\u2022 Strong track record in quickly adapting to new ad measurement platforms in the most detailed of the sense (DSP, Ad Servers, Rich Media, Video, Mobile web and in-app tracking deployment experience necessary) \nAdditional Information\nAll your information will be kept confidential according to EEO guidelines.\nCompensation Range: $106,500-$167,500.  This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. For this role, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off\n23-2658","14":"Pie's mission is to empower small businesses to thrive by making commercial insurance affordable and as easy as pie. We leverage technology to transform how small businesses buy and experience commercial insurance.   Like our small business customers, we are a diverse team of builders, dreamers, and entrepreneurs who are driven by core values and operating principles that guide every decision we make.\nPie's mission is to empower small businesses to thrive by making commercial insurance affordable and as easy as pie. We leverage technology to transform how small businesses buy and experience commercial insurance.\n  Like our small business customers, we are a diverse team of builders, dreamers, and entrepreneurs who are driven by core values and operating principles that guide every decision we make.\n  About The Opportunity\nAs a Data Architect at Pie, you will be an integral part of an agile team responsible for the design, construction, and maintenance of the company's data warehouse. You will collaborate with both technical and business staff to understand data requirements, develop data architecture solutions, and enforce data governance policies to ensure efficient, secure, and easily accessible data for stakeholders. This critical role supports strategic company-level objectives and plays a key part in defining the future state of Pie's data architecture by designing data pipelines and implementing data governance.\nSuccess in this position will be establishing how data comes into and flows through the Pie insurance platform. This data will be used to help our organization quote customers based on best policy and prices for their workers compensation insurance. \nHow You\u2019ll Do It\nDesign and implement data architecture solutions, including data modeling, data integration, and data management.\nDesign efficient data pipelines to transform raw data sources into powerful, reliable components ensuring data quality, efficient processing, and timely delivery of accurate and trusted data.\nDesign data models for optimal storage and retrieval, to meet critical business requirements\nWork with stakeholders including the Executive, Product, and Engineering teams to assist with data-related technical issues and support their data infrastructure needs\nMaintain high standards of engineering excellence through code reviews, unit tests, and robust alerting\nIdentify and work with our analytics engineers, analysts and scientists to ensure we have optimal, documented and adequately tested dimensional data models\nDefining and enforcing data governance policies\nDeveloping and maintaining data dictionaries and data lineage\nThe Right Stuff\n2+  years experience as a data architect\nDemonstrable experience designing and implementing modern data warehouse\/data lake solutions with an understanding of best practices\nPrevious work experience in a cloud-based environment \nAdvanced proficiency in writing complex SQL statements and manipulating large structured and semi-structured datasets.\nStrong demonstrated knowledge with industry standard ETL\/ELT and data orchestration tools such as Airflow, Stitch, or Fivetran\nExperience modeling data in a data warehouses such as Snowflake, Redshift, and or BigQuery\nStrong analytical and problem-solving skills\nWorking knowledge of visualization tools such as Looker or Tableau\nKnowledge of data governance best practices\nBase compensation for position: $125,000 - $170,000\nCompensation & Benefits \nCompetitive cash compensation\nA piece of the pie (in the form of equity)\nComprehensive health plans\nGenerous PTO\nFuture focused 401k match\nGenerous parental and caregiver leave\nOur core values are more than just a poster on the wall; they\u2019re tangibly reflected in our work \nOur goal is to make all aspects of working with us as easy as pie. That includes our offer process. When we\u2019ve identified a talented individual who we\u2019d like to be a Pie-oneer , we work hard to present an equitable and fair offer. We look at the candidate\u2019s knowledge, skills, and experience, along with their compensation expectations and align that with our company equity processes to determine our offer ranges. \nEach year Pie reviews company performance and may grant discretionary bonuses to eligible team members.\nLocation Information \nUnless otherwise specified, this role has the option to be hybrid or remote. Hybrid work locations provide team members with the flexibility of working partially from our Denver or DC office and from home. Remote team members must live and work in the United States* (*territories excluded), and have access to reliable, high-speed internet.\nAdditional Information\nPie Insurance is an equal opportunity employer. We do not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, marital status, age, disability, national or ethnic origin, military service status, citizenship, or other protected characteristic.\nPie Insurance participates in the E-Verify program. Please click here, here and here for more information.\nPie Insurance is committed to protecting your personal data. Please review our Privacy Policy.  \nPie Insurance Announces $315 Million Series D Round of Funding\nBuilt In honors Pie in its 2023 Best Places to Work Awards\nPie Insurance Named a Leading Place to Work in Colorado   Check out our great reviews from current and former employees on Glassdoor   #LI-REMOTE #BI-REMOTE","15":"Description de l'entreprise\nLa mission de CS GROUP : \u00eatre \u00e0 la pointe des technologies pour garantir la s\u00e9curit\u00e9 de tous dans un monde en pleine mutation. L\u2019expertise reconnue du groupe lui permet d\u2019intervenir l\u00e0 o\u00f9 les enjeux sont les plus critiques : a\u00e9ronautique, d\u00e9fense, \u00e9nergie, spatial. Et, aussi, l\u00e0 o\u00f9 les r\u00e9ponses sont \u00e0 inventer ou \u00e0 r\u00e9inventer : lutte anti-drones, cybers\u00e9curit\u00e9\u2026\nNotre esprit Tech et pragmatique, ainsi que notre agilit\u00e9 d\u2019ETI nous permettent d\u2019allier proximit\u00e9, engagement et innovation, pour diffuser notre culture \u00e0 tous les niveaux : dans la relation client, dans le mode de management interne, dans notre engagement social et environnemental\u2026\nEt bien s\u00fbr, dans le d\u00e9veloppement de votre carri\u00e8re, notre ambition est de faire de vous un collaborateur accompli : formations, revue de carri\u00e8re, mobilit\u00e9, programme ambassadeur\u2026\nNous sommes engag\u00e9s \u00e0 vos c\u00f4t\u00e9s, au service de votre \u00e9panouissement professionnel !\nDescription du poste\nNous recrutons un.e Architecte Plateforme Big Data pour rejoindre notre Business Unit INDUSTRIE au sein de la Business Line Digitalisation Processus & Applications M\u00e9tier. Elle accompagne nos clients dans leurs probl\u00e9matiques associ\u00e9es \u00e0 la transformation digitale. Nos offres se d\u00e9clinent autour de la digitalisation des processus industriels et du SI M\u00e9tiers.\nVotre mission :\nDans un contexte technologique et motivant, o\u00f9 la curiosit\u00e9 technique est n\u00e9cessaire, vous serez int\u00e9gr\u00e9 \u00e0 l\u2019\u00e9quipe en charge des plateformes Big Data.\nVotre mission sera de configurer des serveurs, plateformes et services pour les solutions Big Data \u00e0 destination de diff\u00e9rents groupes utilisateurs ou \u00e9quipes de d\u00e9veloppement dans un contexte Agile et DevOps.\nVous r\u00e9aliserez diff\u00e9rentes activit\u00e9s parmi celles dont l\u2019\u00e9quipe est en charge :\n- Comprendre les besoins et identifier les diff\u00e9rentes briques qui vont y r\u00e9pondre ;\n- Participer \u00e0 la r\u00e9alisation de POC, \u00e0 la configurations des plateformes et aux d\u00e9ploiements ;\n- Administrer les plateformes, g\u00e9rer et planifier les activit\u00e9s d\u2019op\u00e9rations et de monitoring ;\n- Assurer le support techniques aux \u00e9quipes des projets h\u00e9berg\u00e9s ;\n- Assurer la veille technologique et participer \u00e0 la d\u00e9marche d\u2019am\u00e9lioration continue ;\n- Faire le suivi technique des activit\u00e9s et le reporting au responsable de service.\nEnvironnement technique :\n- Linux (Redhat), Windows Server\n- IaC : Ansible, CDK, Terraform\n- Monitoring : Prometheus, Nagios, Ambari, Splunk, Grafana\n- S\u00e9curit\u00e9 : AD \/ Kerberos\u2026\n- IAM : SSO solutions, Keycloak\n- Conteneurisation :  Kubernetes, Docker, Helm\n- Langages : Python, Bash, Spark, Java\n- Stockage : S3, Private object storage, DFS, NFS.\nQualifications\nQui \u00eates-vous ?\n\nDe formation ing\u00e9nieur informatique ou \u00e9quivalent universitaire (Bac+5), vous avez au moins 3 ans d\u2019exp\u00e9rience. La ma\u00eetrise des environnements Big Data, plateformes et outils, notamment Hadoop (HDP), Kubernetes (Rancher), Spark, Elasticsearch et AWS, est n\u00e9cessaire \u00e0 l\u2019exercice de votre fonction. Vous avez des comp\u00e9tences dans les domaines de la s\u00e9curit\u00e9 et de la gestion des identit\u00e9s et acc\u00e8s (IAM).\nUn niveau d\u2019anglais courant est requis.\nVous \u00eates organis\u00e9.e et vous savez faire preuve de capacit\u00e9 d\u2019analyse ? Vous \u00eates curieux.se et rigoureux.se, et avez le sens du service client ? Alors vous \u00eates la p\u00e9pite que nous recherchons !\nA comp\u00e9tences \u00e9gales, ce poste est ouvert aux personnes en situation de handicap.\nInformations suppl\u00e9mentaires\nQui sommes-nous ?\nLa Business Unit INDUSTRIE contribue aux d\u00e9veloppements de programmes dans les domaines de la simulation, la transformation digitale et le d\u00e9veloppement de syst\u00e8mes critiques. Elle est un acteur r\u00e9f\u00e9rent sur l\u2019Intelligence de la donn\u00e9e (Data Engineering & Data Science), la digitalisation des processus (PLM), la simulation num\u00e9rique, le d\u00e9veloppement de logiciels embarqu\u00e9s & certifi\u00e9s ainsi que la s\u00e9curisation des syst\u00e8mes (cybers\u00e9curit\u00e9).\nPourquoi choisir CS GROUP ?\nPour notre fili\u00e8re Expert qui valorise vos comp\u00e9tences techniques, notre engagement dans l\u2019innovation avec un budget R&D de 30 millions d\u2019euros\/an, nos engagements soci\u00e9taux et environnementaux : index d\u2019\u00e9galit\u00e9 professionnelle \u00e0 86\/100, partenaire de l\u2019association Elles bougent, membre de la plan\u00e8te Tech Care etc.\nEt bien s\u00fbr : la possibilit\u00e9 de t\u00e9l\u00e9travailler, un programme de cooptation, la compl\u00e9mentaire sant\u00e9, les RTT, le CE.\nN\u2019attendez plus, partagez votre CV et additionnons nos talents !\nLa suite des \u00e9v\u00e9nements :\nSi votre profil est un match, vous aurez un entretien technique avec un de nos Responsables op\u00e9rationnels. Puis, vous rencontrerez Emeline lors d\u2019un entretien RH.  \n #CSGROUP #hiring #LI-Hybrid #LI-EQ1 #DevOps","16":"Company Description\nWe\u2019re over 2,700 strong across the globe. We\u2019re scientists, strategists, creatives, and innovators. We value individual brilliance and build a strong foundation for Teamwork across all our business. We love the challenge of our industry. We\u2019re changing lives and redefining success every step of the way.\nYou are dynamic. You are curious. You are more than your job. For you, excellence isn\u2019t just a word; it\u2019s the measure for all you do. You\u2019re passionate. Driven. Dedicated. You can\u2019t stand mediocrity. And you might be the team member we're looking for. \nJob Description\nPSI CRO is looking for a hands-on, experienced Database Architect & ETL Developer who is a visionary, self-directed and comfortable supporting the various data & analytics needs of multiple teams, systems, and products. In this role, the Database Architect\/ETL Developer will be responsible for requirements, analyzing, designing, coding & testing various databases & ETL processes required by the Data Platform team to build world class data lakes, databases, and data repositories utilizing both Microsoft SQL Servers as well as cutting-edge Azure cloud data technologies.\nRequirements:\nDemonstrated ability to have successfully completed multiple, complex technical projects and create high-level design and architecture of the solution, including class, sequence, and deployment infrastructure diagrams.\nDevelop and maintain documentation of the data architecture, data flow and data models of the data warehouse appropriate for various audiences.\nEnsure new features and subject areas are modelled to integrate with existing structures and provide a consistent view.\nProvide input on Azure technologies and industry best practices in the field of data warehouse architecture and modelling.\nTake ownership or assistance of technical solutions from design and architecture perspective for projects from conceptual phase through architecture, feasibility, design, and implementation\nMaintain, monitor, upgrade and secure the SQL Server\/Azure platform in partnership with established vendor.\nDevelop ETL (extract, transform and load) processes to populate Data Marts and Warehouses\nDevelop systems integrations across between traditional databases and modern Cloud APIs.\nFollow established Software Development Lifecycle (SDLC) activities and AGILE including Analysis, Design, Development, UAT, Pilot, Testing & lessons learned.\nDesign, model and develop across both Relational Databases and Data Warehouse and Synapse\nTroubleshoot data integrations\/data feeds between systems.\nQualifications\n5+ Years\u2019 Experience in SQL Server Database Management\n5+ Years\u2019 Experience in SQL Server Database Development and SQL scripting (T-SQL)\nMust have experience with at least one end to end implementation of Azure cloud data warehouse\nExpertise in Azure \u2013 data modelling, ELT using Azure ADF pipelines, implementing complex stored Procedures and standard DWH and ETL concepts.\nExpertise in Azure advanced concepts like setting up resource monitors, RBAC controls, virtual warehouse sizing, query performance tuning, Zero copy clone, time travel and understand how to use these features.\nExpertise in deploying Azure features such as data sharing, events, and lake-house patterns\nHands-on experience with Azure utilities, PySpark, ADF, Synapse, Big Data model techniques using Python or similar.\n3+ years of hands-on experience with on prem and Azure Data warehouse, ETL, BI projects, Azure Synapse.\nAdditional Information\nIf you feel it is time to make your skills and knowledge visible within a growing company with true focus on its people, then PSI is the right choice for you.","17":"Company Description\nPublicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. As digital pioneers with 20,000 people and 53 offices around the globe, our experience spanning technology, data sciences, consulting and customer obsession \u2013 combined with our culture of curiosity and relentlessness \u2013 enables us to accelerate our clients\u2019 businesses through designing the products and services their customers truly value. Publicis Sapient is the digital business transformation hub of Publicis Groupe. For more information, visit publicissapient.com.\nJob Description\nPublicis Sapient is looking for Senior Manager  (in-office 2-3 days per week) to join our team of bright thinkers and doers. You will team up with top-notch technologists to enable real business outcomes for our enterprise clients by translating their needs into transformative solutions that provide valuable insight. Working with the latest data technologies in the industry, you will be instrumental in helping the world\u2019s most established brands evolve for a more digital future.\nYour Impact: \nWork closely with our clients providing evaluation and recommendations of design patterns and solutions for data platforms with a focus on batch, near-real time, structured and unstructured data \nDefine SLAs, SLIs, and SLOs with inputs from clients, product owners, and engineers to deliver data-driven interactive experiences \nProvide expertise, proof-of-concept, prototype, and reference implementations of architectural solutions for Azure Data Platform\nProvide technical inputs to agile processes, such as epic, story, and task definition to resolve issues and remove barriers throughout the lifecycle of client engagements\nCreation and maintenance of infrastructure-as-code and CI\/CD for Azure environment using tools such as Terraform and Ansible\nMentor, support and manage team members\nQualifications\nYour Skills And Experience: \nDemonstrable experience in enterprise level data platforms involving implementation of end-to-end data pipelines \nHands-on experience with at Azure  \nExperience with column-oriented database technologies (e.g., Synapse), NoSQL database technologies (e.g., DynamoDB, Cosmos DB, etc.) and traditional database systems (e.g., SQL Server, Oracle, MySQL)\nExperience in architecting data pipelines and solutions for both streaming and batch integrations using tools\/frameworks like Azure Data Factory, Azure functions and Stream analytics \nMetadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, and Azure Purview\nTest plan creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks\nData modeling, querying, and optimization for relational, NoSQL, timeseries, graph databases, data warehouses and data lakes\nData processing programming using SQL, Python, and similar tools\nLogical programming in Python, Spark, PySpark, Java, Javascript, and\/or Scala\nCloud-native data platform design with a focus on streaming and event-driven architectures\nParticipate in integrated validation and analysis sessions of components and subsystems on production servers\nData ingest, validation, and enrichment pipeline design and implementation\nSDLC optimization across workstreams within a solution \nBachelor\u2019s degree in Computer Science, Engineering, or related field\nSet Yourself Apart With: \nCertifications in Azure \nExperience working with code repositories and continuous integration\nUnderstanding of development and project methodologies\nAdditional Information\nPay Range:$108,000 -$210,000\nBenefits of Working Here:\nFlexible vacation policy; time is not limited, allocated, or accrued\n16 paid holidays throughout the year\nGenerous parental leave and new parent transition program\nTuition reimbursement \nCorporate gift matching program \nAs part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at hiring@publicissapient.com or you may call us at +1-617-621-0200.","18":"At Databricks we work on some of the most complex distributed processing and machine learning problems in the world and our customers challenge us daily with interesting new big data and AI use cases. As Director, Resident Solutions Architects at Databricks, you will provide strategic leadership for delivering professional services engagements to high-value Databricks customers, helping shape the future big data and machine learning landscape for leading Fortune 500 organisations. You will report directly to the regional Vice President of Field Engineering.\nIn the Director, Resident Solutions Architects role, you will will lead a team of exceptional Resident Solution Architects, responsible for core aspects of building and managing the Resident Solutions Architect team. Through your oversight and mentorship, this team will guide our largest customers, implementing pipelines spanning data engineering through model building and deployment, plus other technical tasks to help customers get value out of their data with Databricks. Your responsibilities will include hiring and developing the team, and providing oversight of customer projects to ensure they are managed and delivered to target and exacting standards.\n  The impact you will have:\nYou will achieve regional team targets for billable utilisation and hiring\nYou will partner with account executives, customer success and field engineering leaders while guiding Resident Solutions Architects to achieve success with professional services projects with customers\nHelp resolve customer concerns on strategic accounts and professional services engagements\nAnalyze operational processes, escalation procedures and perform training needs assessments for identifying opportunities for services delivery improvements and contribution to customers.\nManage a team of Resident Solution Architects and act in a supportive manager capacity, including handling escalations, mentoring team members, building a career path for the assigned team members.\nWhat we look for:\nGreat at hiring qualified candidates and mentoring \/ growing leaders\nHave experience in hiring, mentoring and growing Team Leads, Managers & Senior Managers\nHave experience scaling field and\/or technical teams from scratch to 50+ - ideally at hyper-growth speed\nGreat at instituting processes for technical field members to drive efficiency and effectiveness\nHave experience in building and operationalising a technical specialist\nLeadership experience experience managing consultant\/delivery teams or solution architects\nSignificant prior individual contributor experience, as a hands-on technical solutions architect that will allow you to act in a supportive manager capacity with technical architects that report to you\nExperience driving software platform adoption in Fortune 500 organisations in markets such as: Finance, Media, Retail, Telco, Energy, and Healthcare\nImplement a project schedule with experience with customer engagement\nExperience with Databricks products, Spark ecosystem, and direct competitors\nUp to 30% of travel (depending on Covid regulations)\nBenefits\nPrivate hospital plan and extras coverage\nLife, disability and income protection coverage\nSuperannuation\nEquity awards\nPaid parental leave\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nBusiness travel insurance\nMental wellness resources\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.\n  Compliance\nIf access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.","19":"Location: Delhi, Gurgaon, Bangalore, Chennai,Indore, Ahmedabad, Jaipur, Kolkata,Pune.,None,None\nAbout Material\nMaterial is a global strategy, insights, design, and technology partner to companies striving for true customer centricity and ongoing relevance in a digital first, customer-led world. By leveraging proprietary, science-based tools that enable human understanding, we inform and create customer-centric business models and experiences + deploy measurement systems \u2013 to build transformational relationships between businesses and the people they serve.\nAbout Srijan\nSrijan is a global engineering firm that builds transformative digital paths to better futures for Fortune 500 enterprises to nonprofits all over the world. Srijan brings advanced engineering capabilities and agile practices to some of the biggest names across FMCG, Aviation, Telecom, Technology, and others. We help businesses embrace the digital future with cloud, data, API and platform centric technologies and adapt to changing business models and market demands. Srijan leads in Drupal with 350+ Drupal engineers, 80+ Acquia certifications. Srijan is also a Drupal Enterprise Partner & Diamond Certified\nRequirements: 8+ years of experience in designing, implementing, and managing data-intensive systems. Expertise in data-intensive systems, including data architectures, storage solutions, and data processing workflows. Experience with Kubernetes and other container orchestration technologies. Experience with at least one data orchestration tool, such as Apache Airflow, Apache NiFi, Kedro, Stepfunction or Similar Technologies. Experience with at least one distributed data processing framework, such as Apache Spark, Apache Flink, Apache Beam or Similar Technologies. Very strong experience in stream processing, including real-time data processing, data ingestion, and data transformations. Experience with an event queuing system, such as Apache Kafka, AWS Kinesis, or Azure Event Hubs. Strong experience with cloud platforms such as AWS, Azure, or GCP. Advanced experience with CI\/CD pipelines and tools such as Jenkins, GitLab, or CircleCI, including infrastructure as code, automated testing, and continuous monitoring. Excellent analytical and problem-solving skills. Strong leadership and communication skills with the ability to collaborate with cross-functional teams. Ability to work in a fast-paced, dynamic environment and manage multiple projects simultaneously. Responsibilities: Collaborate with clients and internal stakeholders to identify business requirements and design innovative solutions that meet their needs. Lead architecture design, development, and deployment of complex data-intensive systems using Kubernetes, data orchestration tools, distributed data processing frameworks, event queuing systems, and other modern technologies. Provide technical expertise and leadership to the project team, ensuring successful delivery of high-quality solutions on time and within budget. Design and implement efficient data architectures, storage solutions, and data processing workflows, with a focus on stream processing, event queuing capabilities, and advanced CI\/CD pipelines. Provide guidance and support to development teams in coding, testing, and implementing solutions. Ensure the scalability, performance, and security of data-intensive systems, with a particular focus on stream processing, event queuing capabilities, and advanced CI\/CD pipelines. Stay current with emerging trends and technologies in data-intensive systems and provide thought leadership on best practices and solutions. Collaborate with sales and marketing teams to develop proposals and pitches that demonstrate our expertise in data-intensive systems, Kubernetes, data orchestration tools, distributed data processing frameworks, stream processing capabilities, event queuing systems, and advanced CI\/CD pipelines. If you have a passion for designing and implementing innovative data-intensive solutions with very strong stream processing and event queuing capabilities using Kubernetes, data orchestration tools, distributed data processing frameworks, and cloud platforms, and are a self-starter who enjoys working in a fast-paced, dynamic environment, we encourage you to apply for this exciting opportunity. Apply to this job","20":"At Kinaxis, who we are is grounded in our common belief that people matter. Each one of us plays an important part in accomplishing our work, building our culture and making a global impact.\nEvery day, we\u2019re empowered to work together to help our customers make fast, confident planning decisions. This is how we create a better planet \u2013 for each other, for our customers and for generations to come. Our cloud-based platform RapidResponse ensures that the products we need \u2013 everything from medicine and cars, to day-to-day items like toothpaste \u2013 make it to market and into our hands when we need them with minimal ecological footprint.\nWe make the world better, and you can too.\nData Architect, Corporate IT\nJob location: This position is to be hired in Canada and will be remote unless you live in the Ottawa area in which the role will be hybrid with a minimum of working in the office 2 to 3 days a week. This is a 16 month term position.\nAbout the team\nAs the Data Architect of Kinaxis\u2019 Corporate Information Technology team, you will be a leader in designing and implementing data solutions to drive and support Kinaxis global business by enabling them to make intelligent business decisions. As a technical expert, you will be key in developing a Center of Excellence and mentoring other technical resources. The successful candidate will collaborate with skilled and enthusiastic team members to develop a world class data environment. In addition, identification and assisting in the management of vendors to provide software and IT services.\nWhat you will do\nDefine the technical data architecture with cross-functional teams that enable consistency and scalability\nDesign, develop and deploy data warehouse solutions for the business, driving initiatives focused on data preparations, data integration, data exploration, ETL \/ELT development, and advanced data modeling techniques.\nUnderstand data technology trends and the practical application of existing, new, and emerging technologies to enable new and evolving business needs\nPartner closely with leadership and business stakeholders as a trusted and influential evangelist to identify important questions, define key metrics, cultivating a data driven decision making culture\nTake ownership of complex or time critical support issues.\nParticipate in an IT environment that is focused on security by design, education, and communication.\nWhat we are looking for\nBS or BA in Computer Science, Information Systems, or demonstrated equivalent experience.\n8+ years of experience as a data architect\nDeep understanding of data and information architecture, including experience with Big Data, Cloud Base Analytics, streaming and batch data processing\nDeep knowledge and experience with Snowflacke\nDeep knowledge of data modelling (Dimensional vs Relational) and ETL\/ELT development processes and tools i.e., Informatica, SAP, Microsoft, ...\nExperience deploying and operating global IT infrastructure with remote users\nStrong written, verbal, and interpersonal communication skills\nAbility to communicate complex, technical concepts to executive staff, business sponsors and technical resources in clear concise language\n What we have to offer\nChallenging Work - We love solving highly complex problems. And as the global leaders in our industry, we never stop innovating\u2014our work is never \u201cdone. That\u2019s because across our teams and in all roles, every employee is empowered to bring their best ideas forward and to jump in and solve the problems they\u2019re passionate about.\nGreat People - We take our work seriously, but we don\u2019t take ourselves too seriously! It\u2019s in our DNA to celebrate, laugh, and have fun. We are stronger, together, when we are open, honest, and above all, real. Every person is valued here and plays an important role in our shared success.\nGlobal Impact - As a global team spanning continents, boundaries, and cultures, every day we are inspired by the impact our work has on our colleagues, our customers, our communities, and the world at large.\nDiversity, Equity and Inclusion - Diversity, equity and inclusion are more than words to us. They are the guiding principles for building a culture where we celebrate each others\u2019 differences, continuously strive for equality and recognize that inclusion makes us stronger as individuals, a company and a global citizen. \nFor more information, visit the Kinaxis web site at www.kinaxis.com or the company\u2019s blog at http:\/\/blog.kinaxis.com\/.\nKinaxis strongly encourages diverse candidates to apply to our welcoming community. We strive to make our website and application process accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at recruitmentprograms@kinaxis.com. This contact information is for accessibility requests only and cannot be used to inquire about the status of applications.","21":"Identify the to-be architecture required to implement TCIP, to move to cloud(-native), introduction of strategic capabilities and tooling, through:\nProviding best practices on implementing the strategic capabilities\nLinking in on-going initiatives to implement target platforms (e.g. ServiceNow, Microsoft Dynamics)\nPerform interviews with client's Enterprise Architecture and potentially head of Strategic Platforms and other architects\nCollect existing information, architecture models, as-is application overviews, mapping to business processes and information\/data flows\nProvide structure in what an Enterprise Architecture should consist of, and identify missing artefacts\nWork with the client's Enterprise Architect and where applicable domain and solution architects to write the required artefacts\nCreate a presentable overview of the Target Enterprise Architecture for IML, Portfolio Board and potentially Executive Board\nModelling business capability maps: Map business capabilities based on EA best practices and discover applications related to each business capability.\nIT landscape reports: Discover and manage all applications within the organization, dependencies, and data flows.\nMigration roadmap and project plans Current state vs. future state diagrams: Build diagrams that represent as-is architecture and target architecture.\nProduce lifecycle roadmaps of IT landscapes: Assess applications by business criticality and functional & technical fit.\nRequirements\nMandatory requirements:\nMasters degree in Computer Science or other areas relevant to the role (or Bachelors + 4 years of professional experience)\nMinimum 8 years of experience relevant to the objective of this assignment\nTOGAF 9 Certification, IBM Certified Data Architect or other equivalent and valid certificates\nSAFe for Architects qualification\nIT Service Management \/ ITIL 4 certification\n\nThe successful consultant is expected to have experience with the following:\nGood knowledge of Microsoft Azure, AWS, Microsoft 365, Microsoft 365 CRM, PowerApps Portal, SAP cloud solutions, Informatica MDM.\nGood knowledge of DevSecOps processes and tools: Confluence, JIRA, ServiceNow\nExperience with developing Enterprise Architecture for clients that have complex stakeholder field\nExperience with translating IT strategy to Enterprise Architecture that is implementable\nExperience devising roadmap and linking in on-going initiatives\nExperience with presenting architecture to senior management\nKnowledge of different architectural modelling methodologies\nKnowledge and experience on crafting architectural artefacts\nGood knowledge of English language is required.","22":"Company Description\nCompany Overview\nHitachi Solutions is a global solutions integrator passionate about designing, developing, and delivering cutting edge cloud solutions to help our clients innovative across their entire business.  Our firm develops the business services and technology powering some of the products you use every day \u2013 and is closely aligned with Microsoft and other leaders in the cloud computing space.  \nWhat sets Hitachi Solutions apart is both our industry focus, and the intellectual property that we bring to our customers.  Recognized for our achievements year after year, we strive to be the trusted advisor of large and medium sized enterprises alike \u2013 helping them move fast to achieve strategic business initiatives with distinguished engineering, hard work, and compassion.  With over 3,000 team members across 14 countries, in our 18 years of focus our company has seen explosive growth and high customer satisfaction.  This has allowed us to offer exceptionally compelling salaries, 401k match, family leave, and health benefits.  And no \u2013 we will not make you come into an office or ask for an inflexible work schedule. \nA part of Hitachi, Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world\u2019s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies\nJob Description\nNEW PRODUCT DEVELOPMENT AND INNOVATIONS TEAM \nThis position is housed in our New Product Development team formed in 2021.  Joining this team represents an opportunity to fast-track your career and to work with a team of fun and nerdy colleagues in a disruptive startup atmosphere: focused on hypergrowth, moving quickly, and making mistakes in the furtherance of innovation and sound engineering.  \n\nArmed with an existing book of business, and a stable financial parent \u2013 it is the goal of this group to transform our company into a billion-dollar product company, by focusing on engineering excellence and making the cloud easier for our customers. \nSpark Solution Architect (Databricks, Python, Spark) \nThis is a full-time role on the Empower product team architecting Big Data solutions. Our Empower product is Platform-as-a-Service (PaaS) \/ Software-as-a-Service (SaaS) Datalakehouse and Business Intelligence, subscription-based, Intellectual Property.\nIndividuals in this role will architect complex data pipelines products that manage business critical operations, and large-scale analytics pipelines.   Qualified applicants will have expert Spark data engineering expertise and have robust Python software engineering experience.  \nResponsibilities:\nScope business problems and architect Big Data pipeline solutions \u2013 for structured, unstructured and live streaming data \u2013 in Spark and Databricks platforms\nDesign complex data pipeline products which manage business-critical operations and large-scale analytics applications\nUtilize Airflow, Dbt, Data Factory, or similar DAG Tools for orchestration of robust data pipelines\nSupport analytics, data science and\/or engineering teams and understand their unique needs and challenges\nDesign & POC integration of new features into proprietary Spark package(s)\nPartner with Product Management team to identify user stories and maintain prioritized backlog\nAn owner of Empower's Spark repository; review & approve pull requests\nEnforce code standards: formatting, comments, documentation, unit tests, etc.\nInstill excellence into the processes, methodologies, standards, and technology choices embraced by the team\nMentor developers in Spark and Python best practices\nIdentify opportunities for continued improvement of existing proprietary Spark package(s)\nDedicate time to continuous learning to keep the team appraised of the latest developments in the space\nCommitment to developing technical maturity across the company\nQualifications\nPlease note: Although our position is remote \/ virtual \/ work-from-home, you MUST reside, and be authorized to work, in Canada.\n10+ years of Data Engineering expertise including 6+ years designing and building data pipelines for batch and streaming data is REQUIRED\n6+ years of experience with Spark\/PySpark is REQUIRED\n4+ years of experience with Databricks is REQUIRED\n4+ years of hands-on experience implementing Big Data solutions in a cloud ecosystem, including Data\/Delta Lakes, is REQUIRED\n2+ years of experience with DAG Tools (Data Factory, Airflow, Dbt or similar) is REQUIRED\nAzure cloud experience preferred; will consider AWS, GCP or other cloud platform experience in lieu of\n2+ years of experience with Kafka or other live streaming technology is REQUIRED\nExperience with unit testing or data quality frameworks is REQUIRED\n2+ years of experience with source control (git) on the command line is REQUIRED\n5+ years of SQL experience, specifically writing complex, highly optimized queries across large volumes of data is REQUIRED\nExperience with CI\/CD deployment pipelines\nKnowledge of software design patterns\n   #LI-CA1\n#REMOTE\n#DATABRICKS\n#SPARK\n#PYTHON\n#DATALAKEHOUSE\nAdditional Information\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.","23":"We currently have a vacancy for a Data Architect (Azure) fluent in English, to offer his\/her services as an expert who will be based in Valetta, Malta. The work will be carried out either in the company\u2019s premises or on site at customer premises or remotely. In the context of the first assignment, the successful candidate will be integrated in the Development team of the company that will closely cooperate with a major client\u2019s IT team on site.\n\nYour tasks\nGather and assist on the business requirements process, identifying and map relevant data sources;\nWork with data providers to fill data gaps and\/or to adjust source-system data structures to facilitate analysis and integration processes on the overall data ecosystem;\nDesign, develop, document and maintain data architecture, data modelling, data collection, transformation processes;\nDesign, develop, document and maintain BI models, reports, dashboard, security, governance and automation, ETL\/ELT, integration, data cleaning, analysis and automation processes;\nDesign, develop, document, maintain and ensure data quality, validation and data lineage, as well as improve and maintain the Data Warehouse ecosystem (e.g. the Data DevOps lifecycle, architecture).\n\nRequirements\nUniversity degree, combined with professional experience of more than 10 years;\nExperience with Azure Data Platforms (such as Azure Data Factory, Azure Logic Apps, Azure SQL Server, ADLS, Azure Databricks, Power BI, Azure Cognitive Services);\nExperience with Databricks, Apache Spark and Python Pandas as well as software development and\/or data processing using Python, SQL, Power M and DAX;\nExperience with the use of structured, semi-structured and unstructured data types and related file format (e.g. Parquet, Delta);\nExperience in advanced data analysis and data visualization concepts and techniques creating reports, visualizations, and dashboards using business intelligence tools using Power BI;\nExperience in advanced Power BI Online Services and best governance practices Data Lakes and Data Lakehouse architecture, concepts and governance;\nExperience in Master data and reference data management and creation\/editing business glossaries, data dictionaries, and data catalogues;\nExperience with the use of data integration and data warehouse modelling techniques, concepts and methods (e.g. SCD, Functional Engineering, Data Vault, etc.);\nExperience in Data Modelling principles and methods and DAMA Data Management best practices and standards;\nKnowledge in WebAPIs and OpenAPI standard, Data Governance and Discovery tools such as Azure Purview, Natural Language Processing libraries and techniques, Enterprise Architecture software such as BizzDesign would be considered an asset;\nExcellent command of the English language.\nBenefits\nIf you are seeking a career in an exciting and dynamic company, where you will offer your services as part of a team of a major European Institution, operating in an international, multilingual and multicultural environment where you can expect real chances to make a difference, please send us your detailed CV in English, quoting reference: (14877\/03\/2023).\nWe offer a competitive remuneration (either on contract basis or remuneration with full benefits package), based on qualifications and experience. All applications will be treated as confidential.\nEUROPEAN DYNAMICS (www.eurodyn.com)is a leading Software, Information and Communication Technologies company, operating internationally (Athens, Brussels, Luxembourg, Copenhagen, Stockholm, London, Nicosia, Hong-Kong, Valetta, etc). The company employs over 600 engineers, IT experts and consultants (around 3% PhD, 36% MSc and 53% BSc or equivalent). We design and develop software applications using state-of-the-art technology. The group generates annual revenues in the range of EURO 40 million, with an EBITDA in the range of 20%. The value of our contract portfolio exceeds EURO 250 million. EUROPEAN DYNAMICS is a renowned supplier of IT services to government institutions, multinational corporations, public administrations and multinational companies, research and academic institutes.\nAs part of our dedication to the diversity of our workforce, we are committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, disability, sexual orientation, gender identity, or religion.\nEUROPEAN DYNAMICS (ED) adheres to the General Data Protection Regulation principles by applying its Privacy Policy as published in www.eurodyn.com\/privacy. By submitting an application to this position and by sharing your personal data with ED, you acknowledge and accept its Policy and authorise ED to process your personal data for the purposes of the company's recruitment opportunities, in line to the Policy.","24":"We currently have a vacancy for an Enterprise Architect (Big Data) fluent in English, to offer his\/her services as an expert who will be based in Brussels. The work will be carried out either in the company\u2019s premises or on site at customer premises. In the context of the first assignment, the successful candidate will be integrated in the team of the company that will closely cooperate with a major client\u2019s IT team on site.\nYour tasks\nSupport designing and follow up deployment of new data processing workflows, especially the Analytics Data Models and Data processing\/ Data flows;\nAnalyse, clarify, and document priorities for each set of requirements to ensure they are implemented within applicable constraints (timing, contractual, technology, infrastructure);\nEnsure that the design of the system will fulfil the business requirements and non-functional requirements (volume, scalability, stability, confidentiality, security, integrity, availability, usability).\nRequirements\nUniversity degree in IT combined with minimum 13 years of IT professional experience;\nMinimum 5 years of professional experience as Enterprise Architect working in Analytics or Big Data project responsible for data\/functional\/IT architecture and at least 4 years of specialised experience in data architecture, experience in design of large-scale IT systems and high availability;\nStrong experience in business process analysis, business needs analysis, Use cases, , users stories and producing functional specifications;\nGood knowledge of interoperability technology (e.g. APIs, web services, message oriented middleware, service oriented bus);\nGood knowledge of service implementation patterns (synchronous, asynchronous, request\/response), distributed system design and messaging layer;\nCapability for modelling components, data modelling, data processing models, service interfaces, service data and reference models;\nCapacity to review and assess the quality, integrity and completeness of the various IT and Business specification documentation such as IT Architecture documents, conceptual and logical data models, use case specification, user interface specification, Web service specification, business specification (BPMs);\nExcellent command of the English language.\nBenefits\nIf you are seeking a career in an exciting and dynamic company, where you will offer your services as part of a team of a major European Institution, operating in an international, multilingual and multicultural environment where you can expect real chances to make a difference, please send us your detailed CV in English, quoting reference: (14886\/03\/23).\nWe offer a competitive remuneration (either on contract basis or remuneration with full benefits package), based on qualifications and experience. All applications will be treated as confidential.\nEUROPEAN DYNAMICS (www.eurodyn.com)is a leading Software, Information and Communication Technologies company, operating internationally (Athens, Brussels, Luxembourg, Copenhagen, Stockholm, London, Nicosia, Hong-Kong, Valetta, etc). The company employs over 600 engineers, IT experts and consultants (around 3% PhD, 36% MSc and 53% BSc or equivalent). We design and develop software applications using state-of-the-art technology. The group generates annual revenues in the range of EURO 40 million, with an EBITDA in the range of 20%. The value of our contract portfolio exceeds EURO 250 million. EUROPEAN DYNAMICS is a renowned supplier of IT services to government institutions, multinational corporations, public administrations and multinational companies, research and academic institutes.\nAs part of our dedication to the diversity of our workforce, we are committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, disability, sexual orientation, gender identity, or religion.\nEUROPEAN DYNAMICS (ED) adheres to the General Data Protection Regulation principles by applying its Privacy Policy as published in www.eurodyn.com\/privacy. By submitting an application to this position and by sharing your personal data with ED, you acknowledge and accept its Policy and authorise ED to process your personal data for the purposes of the company's recruitment opportunities, in line to the Policy.\nFurthermore, when providing your data, it is up to you to explicitly consent that your data can be assessed for future job openings, for as long as you do not withdraw such consent. If you do not consent, we will not be able to consider the data you provide to us for future job openings.","25":"About Caption Health\nCaption Health\u2019s mission is to detect disease early \u2013 when there is the highest potential for impact \u2013 by leveraging artificial intelligence and ultrasound. Our breakthrough AI platform enables any healthcare professional to perform high-quality ultrasound exams for early disease detection, in convenient and lower-cost outpatient settings including patients\u2019 homes. It was recognized as one of TIME\u2019s 100 Best Inventions of 2021 and one of Fast Company\u2019s Next Big Things in Health Tech.\nThrough our work with health plans, providers, patients, and industry partners, we are transforming care, expanding access, and reducing costs.\nTo learn more, visit captionhealth.com.\nThe Cloud Data Architect is responsible for designing and managing the data infrastructure needed to support all Caption Health products.  Duties include identifying the company\u2019s internal and external data sources, developing company data standards, documenting, and optimizing data flows, collaborating with department heads to determine their data needs, and developing the infrastructure and processes to manage all data securely. Design and buildout the enterprise data warehouse (EDW). \nResponsibilities\nOwn company data architecture and standards.\nDesign and implement effective database solutions and models to store and retrieve company data.\nBuild and manage data infrastructure, including but not limited to: patient demographic and visit details, DICOM ultrasound scans and associated meta data, product data stores and data flows.\nEnsure data storage meets government regulations and guidelines for technical systems and safeguarding of data, including international data compliance.\nDefine data security and backup procedures.\nDefine disaster recovery strategy.\nDetermine data storage strategy to minimize cloud storage cost.\nDesign and build Caption Health\u2019s enterprise data warehouse.\nHelp integrate DOMO to the EDW and establish standard reports.\nPerform other duties as assigned.\nRequirements\nBachelor's degree in computer science, information systems, or a similar field. \nA minimum of 5 years\u2019 experience in a similar role. \nPlanning and execution of big data solutions, healthcare experience preferred.      \nProven work experience as a Data Architect, Data Scientist, Data Analyst, or similar role.\nIn-depth understanding of database structure principles.\nExperience gathering and analyzing system requirements.\nKnowledge of data mining and segmentation techniques.\nExpertise in SQL and Postgres database administration.\nExcellent verbal and written communication skills.\nProficient with Microsoft Office 365 or similar software.   \nCaption Health is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. Caption Health does not make hiring or employment decisions on the basis of race, color, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender-identity, sexual orientation, disability, age, military or veteran status, or any other basis protected by applicable local, state, or federal laws or prohibited by Company policy. Caption Health strives for a healthy and safe workplace and strictly prohibits harassment of any kind. Pursuant to the San Francisco Fair Chance Ordinance and other similar state laws and local ordinances, and its internal policy.","26":"Company Description\nPublicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients\u2019 businesses through creating the products and services their customers expect.\nJob Description\nAs a  Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.\n\nYour role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.\n\nAs a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration.\nQualifications\n Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS \/ Azure \/ GCP)\nExperience delivering end to end Big Data solutions on premise and\/or on Cloud\nKnowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases\nExpertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions\nProficiency in Java and Scala programming languages (Python a plus)\nExpertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.)\nExperience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub\/Sub etc.)\nExpertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc.\nKnowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding\nKnowledge of performance tuning, optimization and scaling solutions from a storage\/processing standpoint\nExperience building DevOps pipelines for data solutions, including automated testing\nYou\u2019ll Also Likely Have Some Of The Following\nKnowledge of containerization, orchestration and Kubernetes engine\nAn understanding of how to setup Big data cluster security (Authorization\/ Authentication, Security for data at rest, data in transit)\nA basic understanding of how to manage and setup Monitoring and alerting for Big data clusters\nExperience of orchestration tools \u2013 Oozie , Airflow , Ctr-M or similar\nExperience of MPP style query engines like Impala, Presto, Athena etc.\nKnowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\nExposure to data governance, catalog, lineage and associated tools would be an added advantage\nA certification in one or more cloud platforms or big data technologies\nAny active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV\/POC, hackathon)\nAdditional Information\nThere is a superb package of benefits waiting for you at Publicis Sapient.\nWe cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension.\nThe learning opportunities here are endless. Most importantly, of course, there\u2019s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine.\nFlexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services.","27":"Amazon Web Services (AWS) is looking for a senior manager to coach, grow, and partner with technically skilled, customer-facing Solutions Architects for our customers. If you have experience leading technical teams, and are interested in helping customers embrace technologies, come and talk to us.\n\nSpecialist Solutions Architects work with partners and customers to accelerate their transformation. They engage in a wide range of activities around their domain of expertise, providing technical advice to customers, helping the internal and external communities, presenting publicly on their domain, and providing a preferred path between service teams and customers.\n\nThis role will specifically focus on Services helping our customers and partners build innovative Solutions that focus on leveraging the value of data. As a Senior Solutions Architect (SA) Manager, you will lead a team of Solutions Architects who help customers select the technologies that will support their business requirements. You will guide team members in their ramp-up on as well as develop speaking, writing, presentation, and executive interaction skills. You will be a practitioner as well as a manager. You will interact, communicate and partner with other departments within such as our services teams, marketing, business development, and professional services, as well as representing your team to senior management.\n\nCandidates will have the ability to engage with customers at different levels in the organization, from executive to developer. Previous experience with AWS is desired but not required, provided you have experience building large scale solutions. You will get the opportunity to work directly with senior engineers at customers, partners and service teams, influencing their road-maps and driving innovation. If you are someone who enjoys innovating, likes solving hard problems and working on the cutting edge of technology, we would love to have you on the team.\n\nAmazon's Culture\nOur positive and supportive culture encourages our people to do their best work every day. We have 16 leadership principles that help guide us in our every-day decision making process. We believe they are a clear articulation of those things that have always been a part of what makes Amazon great \u2013 things that we must consciously hold on to in fulfilling our mission to be Earth\u2019s Most Customer Centric Company. We are continuously looking for new ways to maintain a culture where our people excel and lead healthy and happy lives. It is always Day One.\n\nHow You\u2019ll Grow\nAt Amazon, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there\u2019s always room to learn and develop your career. We offer opportunities to help sharpen your skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.\n\nRoles and responsibilities\n\n* Coach: hire, on-board, train, and develop new Solutions Architects from internal and external sources, ensure they have the required skills needed to perform their function, have clearly defined goals, appropriate feedback and tracking, and work with them on their career development\n* Sponsor: support your team and provide them with support internally and with customers by acting as a facilitator, an executive sponsor, and an escalation point\n* Customers' trusted advisor: collaborate with account, training and support teams to help partners and customers learn and use services and solutions\n\n* Business partner: serve as a key member of the business development and account management team in helping to ensure customer success in building and migrating applications, software and services on the platform.\n* Public engagement: provide thought leadership on solutions that benefit customers through the use of Services. This takes the form of contribution to external publications such as the Blogs, Whitepapers and Reference architectures, or public presentations at Summits, re:Invent, User Groups or Industry events\n* Community player: capture and share best-practices, participate, and contribute as a member of the worldwide technical community of Solution Architects, Professional Services Consultants, Technical Account Managers, and Trainers\n* Service team point of : act as a conduit between the Service teams and the customers, providing detailed guidance for the broader field organization and the customers, and acting as an advocate for the customers towards the central teams\n\nBasic Qualifications\n\n* Experience leading and growing teams of senior technology professionals\n* 10+ years of technical design\/implementation\/consulting experience working with technologies, particularly in Data\n* 5+ years of leadership experience in a technical, customer-facing role in the technology industry\n* High level of comfort communicating effectively across internal and external organizations, with both technical and non-technical audiences.\n* Track record of building rapport with senior customer executives (e.g. CEO, CIO, CTO)\n* Ability to speak in public and in front of an audience is required\n* Bachelor's degree, or equivalent work experience\n\n\nPreferred Qualifications\n* History of successful technical consulting and\/or architecture engagements with large-scale customers or enterprises\n* Previous professional experience architecting\/operating solutions in cloud technologies\n* MBA\/Technical Master's Degree\n* Experience leading other leaders\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.","28":"PeopleFun\u2122 is the award-winning creator of mobile games for players across the globe. We are part of the AppLovin\u2122 studios family, a publicly traded company, with world-class projects, resources, and infrastructure. PeopleFun\u2122 is a Dallas-based game studio founded and maintained by game industry veterans, where game developers thrive on collaboration, creativity, teamwork and fun. Our games are played by over 25 million players each month, and we have a number of exciting mid-core and casual games in development. Our mission is twofold: excellence in creativity and data-driven product innovation, and to be a best-in-class workplace providing unique opportunities to learn and exercise curiosity.\nCandidates who reside or will reside in the following locations are eligible for this role: California, Colorado, Florida, Georgia, Iowa, Maryland, Massachusetts, Minnesota, Nevada, New Hampshire, New Jersey, Ohio, Oregon, Pennsylvania, Tennessee, Texas, Virginia, Washington DC, Washington State\nJob SummaryPeopleFun is seeking a highly skilled Data Architect focused on our Platform Services and infrastructure for both existing and new games. Some of our Platform Services we are working towards include identity, analytics event ingestion, monitoring, LiveOps and config systems, experiments, segmentation, and more for up to Wordscapes scale PeopleFun games.\nYou will report directly to the VP Platform Engineering and work on a GCP \/ BigQuery \/ PubSub \/ Dataflow and Dataproc \/ Cloud Run \/ Airflow tech stack in development for gaming and data services for analytics, experimentation, liveops, and more. We are also improving existing Platform technologies, for example moving away from legacy data ingestion and data warehouse as we scale up new services.\nResponsibilities\nCreate performant and maintainable data services at the top grossing mobile game scale of our new and existing games\nBring your expert big data experience and architectural knowledge to bear on exciting Platform Technology problems and projects to improve services game quality and value for players while also helping democratize our data for product teams\nDefine and evangelize data governance, standards, and data engineering best practices for the studio data platforms \nWork with the broader game development teams to architect, extend and develop new data platform pipelines and systems (reports, analytics, experiments, segmentation) \nReviewing and mentoring team member contributions including code quality and test coverage\nContribute and improve production processes, coding, and operational practices for our game backends\nRequirements\n10+ years developing big data services and infrastructure for games and\/or relevant big data experience\nDemonstrated expertise in cloud data infrastructure and services using cloud technologies like GCP \/ AWS\nLeader with fearless attitude and willingness to jump into unfamiliar areas\nTechnical expertise across a range of backend technology - database, caching, networking, storage, streaming, or micro-services and other architectures\nAdvanced SQL and python at scale\nSolid Airflow and ETL experience\nCI\/CD and Infrastructure as code experience\nForward-looking mentality, taking into account scale, performance and a DevOps mindset\nStrong problem-solving and meticulous organizational skills\nExcellent verbal and written communication skills with the ability to build relationships with team stakeholders\nDesired Qualities\nFamiliar with mobile\/F2P and a passion for games\nDegree in Computer Science, Mathematics, Physics, or Engineering\nBenefitsCompetitive compensation packagePerformance bonuses401K with 3% employer matchingFamily friendly cultureFlex PTO policyMedical\/Dental\/Vision insuranceOn-Site Gym and free Yoga classes$1,500 annual budget for career development & education$1,000 annual game device and IAP budgetFree drinks & snacks, catered lunch on FridaysHappy hours, social events and more\nPeopleFun is an equal opportunity employer. All applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, ancestry, pregnancy, age, sexual orientation, gender identity, marital status, protected veteran status, medical condition or disability, or any other characteristic protected by law.","29":"Company Description\nWe help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable.\nJob Description\nThe Data Engineering & Analytics Lab (DEAL) is responsible for the design and implementation of our core statistical data-systems including data ingestion, data integration, data transformation, data analysis, and analytic dataset construction. We\u2019re an innovation group that is charged with visualizing the future of our organization\u2019s operations and leveraging our expertise in data, technology, P&C insurance, and process optimization to provide a first-class analytics environment to our data-collection, data-management, actuarial, and data-analytics colleagues.  \nThe DEAL team is looking to hire an experienced Actuarial Associate, ideally having a good combination of an analytical\/innovative mindset, technical aptitude, line of business experience, and communication skills. For internal candidates, this position is open to grade level 15-17.  \nThis is a hybrid role that will combine actuarial and data engineering skills and will be expected to manage multiple work-streams supporting a wide array of internal customers. \nThe role will have responsibility for managing all aspects of a line of business's data-infrastructure from ingestion to analytic frameworks to content generation.  \nSome anticipated work assignments include: \nBuild and maintain robust data engineering process to develop and implement self-serve data \nSupport product implementation on a new and innovative technology platform with product requirements, actuarial calculations, methods, and validation \nDesign, build and launch extremely efficient & reliable data pipelines to move data (both large and small amounts) in\/out of our Snowflake Data Lake \nAssist with product development and implementation including modeling and assumption development \nExecute data engineering projects ranging from small to large either individually or as part of a project team \nPerform other tasks on R&D, data governance, system infrastructure, and other cross team functions, on an as-needed basis \nAdopt an agile framework to schedule work, adjust as needed and continuously improve performance \nCommunicate performance with relevant internal stakeholders \nWork with data analysts to develop reports and visualizations \nAssist in scoping and designing analytic data assets \nFind opportunities to create, automate and scale repeatable analyses or build self-service tools for business users \nYou will be part of a culture that embraces learning and innovation, values teamwork, recognizes and rewards achievements and excellence, and provides personal and professional enrichment opportunities. \nQualifications\nBachelor\u2019s degree in a quantitative (STEM) discipline with 4+ years of work experience in data\\actuarial analysis & data engineering \nCompletion of CAS Exam 5 (Basic Ratemaking), ACAS or higher preferred \nMinimum 4 years of experience working with property & casualty insurance data, preferably supporting an actuarial\/data-science function in one of the following lines of business (Commercial Property, General Liability, Commercial Auto, Personal Auto) \nHighly proficient with SQL and database concepts \nFamiliarity with rating manuals, loss cost (rate) filings, and statistical data \nExperience in preparing and conducting extensive business analysis and studies, process assessments, data analysis, and requirement specification  \nProficiency in Python, object-oriented programming, and data structures \nStrong technical and project management\/process leadership skills \nExcellent verbal and written communication skills required \nAdditional Information\nIn 2022, Verisk received Great Place to Work\u00ae Certification for our outstanding workplace culture for the sixth year in a row and second-time certification in the UK, Spain, and India. We\u2019re also one of the 38 companies on the UK\u2019s Best Workplaces\u2122 list and one of 18 companies on Spain\u2019s Best Workplaces\u2122 list.\nFor over fifty years and through innovation, interpretation, and professional insight, Verisk has replaced uncertainty with precision to unlock opportunities that deliver significant and demonstrable impact. From our historic roots in risk assessment, we\u2019ve grown to provide analytic insights that help transform industries focused on some of the world\u2019s most critical areas. Today, the insurance industry relies on Verisk to be, and to make the world, more productive, resilient, and sustainable.\nVerisk works in collaboration with our customers and at the intersection of people, data, and advanced technologies. Through proprietary platformed analytics, advanced modeling, and interpretation, we deliver immediate and sustained value to our customers and through them, to the individuals and societies they serve, with greater speed, precision, and scale.\nWe\u2019re 9,000 people strong, committed to translating big data into big ideas. We help others see new possibilities and empower certainty into big decisions that impact individuals and societies. And we relentlessly and ethically pursue innovation to help move our customers, and the world, toward better tomorrows.\n\nEveryone at Verisk\u2014from our chief executive officer to our newest employee\u2014is guided by The Verisk Way, to Be Remarkable, Add Value, and Innovate.\n\u2022 Be Remarkable by doing something better each day in service to our customers and each other\n\u2022 Add Value by delivering immediate and sustained results that drive positive outcomes\n\u2022 Innovate by redefining what\u2019s possible, embracing challenges, and pushing boundaries\nVerisk Businesses\nUnderwriting Solutions \u2014 provides underwriting and rating solutions for auto and property, general liability, and excess and surplus to assess and price risk with speed and precision\nClaims Solutions \u2014 supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences\nProperty Estimating Solutions \u2014 offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient\nExtreme Event Solutions \u2014 provides risk modeling solutions to help individuals, businesses, and society become more resilient to extreme events.\nSpecialty Business Solutions \u2014 provides an integrated suite of software for full end-to-end management of insurance and reinsurance business, helping companies manage their businesses through efficiency, flexibility, and data governance\nMarketing Solutions \u2014 delivers data and insights to improve the reach, timing, relevance, and compliance of every consumer engagement\nVerisk Maplecroft \u2014 provides intelligence on sustainability, resilience, and ESG, helping people, business, and societies become stronger\nAt Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We have received the Great Place to Work\u00ae Certification for the 7th consecutive year. We\u2019ve been recognized by Forbes as a World\u2019s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.  Verisk\u2019s Statement on Racial Equity and Diversity supports our commitment to these values and affecting positive and lasting change in the communities where we live and work.\nVerisk Analytics is an equal opportunity employer.\nAll members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and\/or expression, sexual orientation, veteran's status, age or disability.\nhttp:\/\/www.verisk.com\/careers.html\nUnsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.\nHR CCPA Privacy Notice.pdf\nAt Verisk, the health and safety of our people is our number one priority.  Effective November 15, 2021, and subject to applicable law, all prospective hires for office based roles or roles that support any of our businesses\u2019 government contracts will be required to demonstrate that they are fully vaccinated against COVID-19 by their start date, or qualify for a legally-required medical or religious accommodation to this vaccination requirement, as a condition of employment. Hired candidates who do not demonstrate that they are fully vaccinated against COVID-19 by their start date, and who have not been approved for a legally-required medical or religious accommodation will no longer meet the requirements for employment and their offers of employment will be immediately rescinded, in accordance with applicable law.","30":"This role can be remote. \nAs a Specialist Solutions Architect (SSA), you will guide customers in building the Azure Databricks Lakehouse Platform that span a large variety of use cases. You will be in a customer-facing role, working with and will support the Solution Architects, that requires hands-on experience with Apache Spark\u2122 and expertise in other data technologies. SSAs help customers through design and implementation of essential workloads while aligning their technical roadmap for expanding the usage of the Databricks Lakehouse Platform. As a deep go-to-expert reporting to the Specialist Field Engineering Manager, you will continue to strengthen your technical skills through mentorship, learning, and internal training programs and establish yourself in an area of specialty - whether that be performance tuning, machine learning, industry expertise, or more.\nThe impact you will have:\nProvide technical leadership to guide customers to successful implementations on big data projects, ranging from architectural design to data engineering to model deployment\nArchitect production level workloads, including end-to-end pipeline load performance testing and optimization\nBecome a technical expert in an area such as data management, cloud platforms, data science, machine learning, or architecture\nAssist Solution Architects with more advanced aspects of the technical sale including custom proof of concept content, estimating workload sizing, and custom architectures\nProvide tutorials and training to improve community adoption (including hackathons and conference presentations)\nContribute to the Databricks Community\nWhat we look for:\n5+ years experience with expertise in at least one of the following big data technologies:\nSoftware Engineer\/Data Engineer: query tuning, performance tuning, troubleshooting, and debugging Spark or other big data solutions\nData Applications Engineer: Build out use cases that extensively utilize data - such as risk modeling, fraud detection, customer life-time value, etc.\nExperience with design and implementation experience in big data technologies such as Hadoop, NoSQL, MPP, OLTP, and OLAP or full lifecycle data science solutions\nMaintain and extend production data systems to evolve with complex business needs\nProduction programming experience in Python, R, Scala or Java\nDeep Specialty Expertise in at least one of the following areas:\nExperience with scaling big data workloads that are performant and cost effective\nExperience with Development Tools for CI\/CD, Unit and Integration testing, Automation and Orchestration, REST API, BI tools and SQL Interfaces (e.g. Jenkins)\nExperience designing data solutions on cloud infrastructure and services, such as AWS, Azure, or GCP utilizing best practices in cloud security and networking\nExperience with ML concepts covering Model Tracking, Model Serving and other aspects of productionizing ML pipelines in distributed data processing environments like Apache Spark, using tools like MLflow\nExperience implementing industry specific data analytics use cases\n[Desired] Degree in a quantitative discipline (Computer Science, Applied Mathematics, Operations Research)\n{Nice to have} - Databricks Certification\nAbility to travel up to 30% when needed\nBenefits\nComprehensive health coverage including medical, dental, and vision\n401(k) Plan\nEquity awards\nFlexible time off\nPaid parental leave\nFamily Planning\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nEmployee Assistance Program (EAP)\nBusiness travel accident insurance\nMental wellness resources\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.\n  Compliance\nIf access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.","31":"Company Description\nBosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it\u2019s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.\nJob Description\nJob Description\nJob Description\n10+ years of experience working with large data sets or do large scale quantitative analysis\nWill be responsible for leading architecture, design and implementation of AI\/ML \/ NLP \/ Computer Vision and MLOps solutions across team of Data Scientists, Data Engineers, ML Engineers, Cloud, Analytics, DevOps and Visualization teams\nExperience in analyzing complex problems and translating them to data science algorithms with due attention to computational efficiency and testing at scale.\nAuthoritative experience in the field of Data Science to influence stake holders across varied work streams and geographical locations, ability to challenge the status quo to improve the base line models and the models which are already productionized.\nExperience in machine learning, supervised and unsupervised: Forecasting, Classification, Data\/Text Mining, NLP, Search Algorithms, Deep Learning Algorithms.\nExperience in using MLOps frameworks like Kubeflow, MLFlow, Airflow Pipelines for building, deploying, and managing multi-step ML workflows based on Docker containers and Kubernetes.\nExperience with workflow orchestration tools like Kubeflow, Airflow, Argo or similar tools\nExposure to deep learning approaches and modeling frameworks (PyTorch, Tensorflow, Keras, etc.)\nExperience in frameworks to depict interpretability of models using libraries like Lime, Shap etc.\nExperience working with big data - identifying trends, patterns, and outliers in large volumes of data.\nStrong implementation experience with Python, and familiarity with Linux\/Unix\/Shell environments\nStrong hands-on skills in sourcing, cleaning, manipulating and analyzing large volumes of data using distributed computing platform\nExperience with Hive \/ Spark \/ Teradata and NOSQL databases\nExperience in using code versioning tools like GIT, bit bucket; building CI\/CD pipelines for ML projects\nExperience in productionizing ML models in any of the cloud platforms - AWS\/GCP\/Azure\nGood to have experience in building automated\/semi-automated model retraining pipelines.\nSuperior verbal, visual and written communication skills to educate and work with cross functional teams on controlled experiments.\nCandidates with prior publications in the field of Data Science are highly preferred.\nTech savvy and willing to work with open-Source Tools\nWillingness to learn IoT, Edge AI and keep up to date with technologies\nGood to have previous whitepaper submissions and IP filings\nQualifications\nQualifications\nBE, BTech, MTech, MS\nAdditional Information\nAdditional information\nGood to have \nWhitepaper submissions and IP filings","32":"Description de l'entreprise\nAvec pr\u00e8s de 8000 collaborateurs \u00e0 travers le monde, nous accompagnons les entreprises dans leur transformation num\u00e9rique. Nous imaginons et concr\u00e9tisons leurs ambitions gr\u00e2ce aux possibilit\u00e9s infinies des plateformes digitales, pour faire \u00e9voluer leur culture et leur mode de travail, et cr\u00e9er de la valeur dans leurs organisations.\nPr\u00e9sent dans 18 pays d\u2019Europe et du Moyen-Orient et fort de 25 ans d\u2019exp\u00e9rience, nous mettons la \u201cTechnologie au service de l\u2019Homme\u201d afin de construire un monde plus humain et plus durable.\nTravailler chez Devoteam, c\u2019est : \ntravailler aux c\u00f4t\u00e9s de partenaires comme Google, Microsoft, AWS ou Salesforce dont nous impl\u00e9mentons les solutions chez nos clients.\n\u00e9voluer dans un groupe international qui vous accompagne dans le d\u00e9veloppement de votre carri\u00e8re avec des parcours de formation et de certification adapt\u00e9s.\nrejoindre une \u00e9quipe sp\u00e9cialis\u00e9e, accompagn\u00e9 par un manager de proximit\u00e9 qui saura vous guider dans vos choix et favoriser les \u00e9changes avec vos pairs, que ce soit lors d'\u00e9v\u00e9nements techniques ou conviviaux.\ngrandir dans une entreprise qui challenge ses \u00e9quipes en \u00e9tant agile et ambitieuse, s\u2019adaptant pour permettre les succ\u00e8s individuels et collectifs.\nDescription du poste\nGarance et son \u00e9quipe n\u2019attendent que vous pour relever de nouveaux d\u00e9fis autour de l\u2019\u00e9cosyst\u00e8me Data.\nEnsemble vous accompagnerez nos clients dans la transformation de leur Syst\u00e8me d\u2019information et la mise en place de solutions BIG DATA.\nPour  nos clients, la transformation digitale induit une modification profonde des processus m\u00e9tier pouss\u00e9e par le d\u00e9veloppement des nouvelles technologies. Ce changement de mod\u00e8le \u00e0 plusieurs objectifs : accro\u00eetre l'efficacit\u00e9, optimiser les co\u00fbts et cr\u00e9er de nouveaux produits et services innovants pour les clients.\nNotre offre data se d\u00e9compose en deux offres distinctes: une offre orient\u00e9e Data Foundation en amont de la pipeline data et une offre Data for Business qui se positionne sur l\u2019analyse de donn\u00e9es au profit du m\u00e9tier.  \nQue vous soyez Data Architect ou Data Engineer, nous vous proposons d\u2019int\u00e9grer une \u00e9quipe d\u2019ing\u00e9nieurs exp\u00e9riment\u00e9s et multi-comp\u00e9tences.\nAu sein de nos clients issus de diff\u00e9rents secteurs d'activit\u00e9 (Industrie, Services, Transport, Banque, Assurances, \u00c9nergie) et en fonction de vos comp\u00e9tences, les missions que vous serez amen\u00e9(e) \u00e0 r\u00e9aliser pourront concerner:\n- La conception et mise en place de cha\u00eene de processing Big Data\n- La conception et le d\u00e9veloppement des modules de traitements de donn\u00e9es - ETL  (transformation, extraction, stockage)\n- Le d\u00e9veloppement d\u2019API\n- La participation aux d\u00e9ploiements des solutions dans une d\u00e9marche Agile \/ DevOps\n- La mise en place de solutions d\u2019automatisation\n- etc.  \nPour r\u00e9ussir ces diff\u00e9rents challenges, nous vous proposerons des actions de formation, des parrainages, des certifications sur les outils concern\u00e9s et un dispositif d\u2019\u00e9valuation personnel r\u00e9gulier.\nQualifications\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieurs ou d\u2019un Master 2 en informatique, vous \u00eates dot\u00e9(e) d\u2019un excellent relationnel, d\u2019un sens prononc\u00e9 du service et de la qualit\u00e9. Vous aimez travailler en \u00e9quipe, and you are fluent in english, of course !  \nVous poss\u00e9dez id\u00e9alement un minimum de deux ans d\u2019exp\u00e9rience professionnelle dans le domaine.\nVous ma\u00eetrisez \u00e0 minima SQL, Python et Git, et vous \u00eates \u00e0 l'aise avec au moins 2 technologies de la liste suivante:\nMongoDB \/ Snowflake \/ Databricks \/ Hadoop \/ Spark \/ Scala \/ Apache \/ Matillion \/ Talend \/ Kafka \/ SAP \/ Power BI \/ Kubernetes \/ Docker \/ Cloudera \/ Cloud (AWS, GCP, Azure)\nVous \u00eates d\u00e9sireux.se de vous investir dans des projets challengeants et gagner rapidement en responsabilit\u00e9s et en comp\u00e9tences.\nUne activit\u00e9 sur des projets Open Source serait un plus.\nAlors n\u2019h\u00e9sitez plus ! \nVous vous sentez plus proche de l\u2019analyse ? On a aussi besoin de vous par ici\nInformations suppl\u00e9mentaires\nLe Groupe Devoteam \u0153uvre pour l'\u00e9galit\u00e9 des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m\u00e9rite et lutte activement contre toute forme de discrimination. Nous sommes persuad\u00e9s que la diversit\u00e9 contribue \u00e0 la cr\u00e9ativit\u00e9, au dynamisme et \u00e0 l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.","33":"OUR VISION\nBlockchains is committed to defining and owning the category of Web3 Identity. We believe that, in the new and exciting world of the decentralized internet, otherwise known as Web3, it is an individual\u2019s fundamental right to own and control their digital identity. To ensure that the individual is paramount in Web3, we are developing a suite of applications to enable everyone to safely engage, take part, and transact in the emerging, decentralized world of the internet. Our platform centers on Web3 Identity and leverages that identity to provide individuals with secure digital asset storage and recovery, access to decentralized finance, the ability to prove ownership of their creations, and gateways to digital interactions and experiences \u2013 all to empower and benefit every Web3 user.\nWe believe that the decentralized nature of Web3 creates an opportunity for everyone to challenge the digital status quo\u2014to own and control their identity, data, finances, creations, and future. This is the chance to get it right \u2013 to rally a movement of individuals so Web3 belongs to everyone, not to trillion-dollar companies. To fulfill this vision, we are seeking dynamic people who want to join us in leading the way to this new world. \nWHAT YOU WILL DO\nAs Head of Software Architecture, AI\/ML, you will assist in the development and execution of the overall technology roadmap, lead the company\u2019s AI strategy, and develop and execute on a compelling Web3 vision  which is forward-looking. You are an effective communicator and a collaborative, yet direct leader. You will frequently contribute to critical business initiatives, regularly inform stakeholders of progress, and navigate between short-term and long-term compromises in existing and planned software design.\nThe essential functions include, but are not limited to, the following:\nEstablish the technical AI\/ML architecture across multiple Web3 product lines to drive continuous technology transformation.\nAdvise senior stakeholders on the overall AI strategy with high quality insight, and provide recommendations which are innovative, but risk averse.\nWork collaboratively with Engineering, IT\/Cyber, PMO, Product, Strategy, and GRC to develop and orchestrate technology processes and to define standards.\nInfluence the adoption of Web3 standards and AI best practices through strong partnerships with Product, Engineering, IT, and GRC stakeholders.\nSet an exceptionally high bar for technical design decisions, including third-party systems, architectural structuring, and algorithms.\nWHAT YOU WILL NEED TO SUCCEED\nTo ensure success, you are a deeply technical polyglot engineering leader who is proficient in programming language semantics, and have experience working with AI systems and blockchain technology. You have a deep AI\/ML background with experience in prompt engineering, and have hands-on experience working with NLP and\/or language models. You have a solid understanding of the Web3 space, including but not limited to decentralized identity, wallets, payments, and key management ecosystems. You are proactive and diligent, eager to work collaboratively, and are proficient in navigating complex technology stacks, including hybrid infrastructure systems. Experience in regulated industries is preferred.\nEDUCATION\/EXPERIENCE\nThis role requires a bachelor\u2019s degree in Computer Science, Engineering, Mathematics, Data Science, or equivalent experience. A minimum of 7 years of software development with at least 3 years working with blockchain and AI technology is required. Additional points for having experience with selective-disclosure identity frameworks, non-custodial wallets, key management solutions, and\/or metaverse architecture.\nBlockchains, Inc. (\u201cBlockchains\u201d) is proud to be a diverse workforce, and we are committed to inclusion and diversity to ensure equal opportunity for all applicants. Blockchains provides equal employment opportunities to all employees and applicants regardless of race, color, religion, sex, sexual orientation, gender identity and\/or expression, national origin, age, marital status, physical or mental disability, veteran status, or any other characteristic protected by federal, state, or local laws.\nWhen you apply to a job on this site, the personal data contained in your application will be collected by Blockchains, Inc. (\u201cController\u201d), which is located at 610 Waltham Way, Sparks, NV 89437 and can be contacted by emailing privacy@blockchains.com. Controller\u2019s data protection officer is Edward O'Connor, who can be contacted at privacy@blockchains.com. Your personal data will be processed for the purposes of managing Controller\u2019s recruitment related activities, which include setting up and conducting interviews and tests for applicants, evaluating and assessing the results thereto, and as is otherwise needed in the recruitment and hiring processes. Such processing is legally permissible under Art. 6(1)(f) of Regulation (EU) 2016\/679 (General Data Protection Regulation) as necessary for the purposes of the legitimate interests pursued by the Controller, which are the solicitation, evaluation, and selection of applicants for employment.\nYour personal data will be shared with Greenhouse Software, Inc., a cloud services provider located in the United States of America and engaged by Controller to help manage its recruitment and hiring process on Controller\u2019s behalf. Accordingly, if you are located outside of the United States, your personal data will be transferred to the United States once you submit it through this site. Because the European Union Commission has determined that United States data privacy laws do not ensure an adequate level of protection for personal data collected from EU data subjects, the transfer will be subject to appropriate additional safeguards under [either the standard contractual clauses or the Privacy Shield]. You can obtain a copy of the standard contractual clauses by contacting us at privacy@blockchains.com. \nYour personal data will be retained by Controller as long as Controller determines it is necessary to evaluate your application for employment.  Under the GDPR, you have the right to request access to your personal data, to request that your personal data be rectified or erased, and to request that processing of your personal data be restricted. You also have to right to data portability. In addition, you may lodge a complaint with an EU supervisory authority.","34":"Mission:\nAt Databricks we are on a mission to empower our customers to solve the world's toughest data problems by utilising the Lakehouse platform. As a Delivery Solutions Architect (DSA), you will play a critical role during this journey. You will collaborate with our sales and field engineering teams to accelerate the adoption and growth of the Databricks platform in your accounts. As a DSA, you will help ensure customer success by driving focus and technical accountability to our most complex customers who need guidance to accelerate consumption on Databricks workloads that they have already selected.\nThis is a hybrid technical and commercial role. It is commercial in the sense that you will be required to own and drive growth in your assigned customers and use cases through leading your customers' stakeholders, owning executive relationships and creating and driving plans and strategies for Databricks colleagues to execute upon. This is in parallel to being technical, with expectations being that you become at least Level 200 across all Databricks products\/workloads and that you become the Use Case-specific technical lead post-Technical Win. This requires you to utilize relationship management skills and technical credibility to effectively engage and communicate at all levels with an organisation. You will report directly into a DSA manager as part of your Business Unit's Technical GM organisation.\nYour day-to-day responsibilities:\nEngage with the Solutions Architect to understand the full Use Case Demand Plan for prioritised customers.\nOwn the Post-Technical Win technical account strategy and investment plan for the majority of Databricks Use CTAMases within our most strategic accounts.\nBe the accountable technical leader assigned to specific Use Cases and customer(s) across multiple selling teams and internal stakeholders, creating certainty from uncertainty\/ambiguity and driving onboarding, enablement, success, go-live and healthy consumption of the workloads where the customer has made the decision to consume Databricks.\nBe the first point of contact for any technical issues or questions related to production\/go live status of agreed upon Use Cases within an account, oftentimes services multiple use cases within the largest and most complex organisations.\nLeverage both Shared Services of User Education, Onboarding\/Technical Services and Support resources, along with escalating to Level 400\/500 technical experts (Specialist Solution Architects and Product Specialists) to execute on the right tasks that are beyond your scope of activities or expertise.\nCreate, own and execute a PoV as to how key use cases can be accelerated into production, bringing EM\/PM in to prepare Professional Services proposals.\nNavigate Databricks Product and Engineering teams for New Product Innovations, Private Previews and Upgrade needs (DBR, E2 and Unity Catalog).\nBuild and maintain mutual success plan that covers all activities of Customer, PS, Partner, SSA, Product Specialist, SA to cover the below workstreams:\nKey use cases moving from 'win' to production\nEnablement \/ user growth plan\nProduct adoption (strategy and activities to increase adoption of LH vision)\nOrganic needs for current investment Eg. Cloud Cost control, Tuning & Optimisation\nExecutive and operational governance\nProactively provide internal and external updates - KPI reporting on the status of consumption and customer health, covering investment status, key risks, product adoption and use case progression - to your Technical GM.\nWhat we look for (Competencies):\n5+ years in a customer-facing pre-sales, technical architecture, customer success, or consulting role\nExperience understanding architecture-related distributed data systems, specifically within one of the following:\nData Engineering technologies (e.g. Spark, Hadoop, Kafka)\nData Warehousing (e.g. SQL, OLTP\/OLAP\/DSS)\nData Science and Machine Learning technologies (e.g. pandas, scikit-learn, HPO)\nComfortable managing multiple projects at once, and engaging a virtual team of subject matter experts to address any onboarding or technical challenges outside of your remit or bandwidth.\nInfluencing and leading teams - especially without having direct reporting line responsibility for individuals within account and leadership teams, both internally and externally\nStakeholder management - experience in effectively engaging and influencing a variety of audiences (technical, non technical) at all levels of an organization (CxO to developer)\nExecutive escalation management - experience in resolving complex and critical escalation with senior customer and Databricks executives\nStrategic Management Consulting - experience of conducting open-ended discovery workshops, creating strategic roadmaps, conducting business analysis and managing delivery of complex programmes\/projects\nBuilding and steering to a value case - business value consulting and realisation\nQuota ownership, achievement and track record of great performance against objective target\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.\n  Compliance\nIf access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.","35":"Company Description\nResultant is a modern consulting firm with a radically different approach to solving problems.\nWe don\u2019t solve problems for our clients. We solve problems with them.\nThrough outcomes driven by data analytics, technology solutions, digital transformation, and beyond, our team works with clients in both the public and private sectors to solve their most complex challenges. We start by learning as much as we can about who they are, how they work, and what they\u2019re striving for so we can feel their problems as our own. Partnering with our clients means their desired outcomes are always top of mind, their challenges and strengths guiding our efforts. We build client-focused relationships before we build unique solutions that blaze past expectations.\nOriginally founded in Indianapolis as KSM Consulting in 2008, Resultant now employs more than 350 team members who operate from offices around the United States including Indianapolis, Fort Wayne and Odon, Indiana; Columbus, Ohio; Lansing, Michigan; Denver, Colorado; Dallas, Texas and Atlanta, Georgia.\nWe\u2019re Resultant. Clients partner with us to see a difference. People join us to make one.\nJob Description\nAt Resultant we are fearless problem solvers.  We are passionate about helping our clients solve their toughest problems.  Data analytics is a core component of how we do this. We are looking for a Data Architect to join our internal IT team and help lead the charge as we continue to implement our new data warehouse and onboard new enterprise systems.  As a Data Architect, you will work closely with many teams across our company on complex, advanced analytical projects to perform data sourcing, data quality, and other data manipulation functions.  You will be directly responsible for the solutions we build that address their business needs through requirements gathering and collaborating on solution reviews. We are looking for self-starters with the skills necessary to empathize with the clients\u2019 needs, translate technical complexities, develop appropriate solutions, and contribute to the growth of our technology and data-driven company.\nConsider your day-to-day responsibilities in this role:\nArchitecting data models to support backend development of advanced data pipelines for our new data warehouse\nArchitecting data models to support onboarding of new enterprise back office systems\nLeading the architecture design and engineering implementation of end-to-end data analytics solutions\nWorking closely with a team comprised of data engineers, BI developers, business analysts, and project managers\nParticipating in project activities such as assessments, requirements gathering, solution reviews, and explaining technical complexities and business benefits in layperson terms\nQualifications\nSome of the qualifications and skills we are expecting include the following:\nBachelor\u2019s degree in Computer Science, Engineering or a similar field is required\n3+ years as a Data Architect\n5+ years of data engineering, software engineering, or similar experience\nHands-on experience with all aspects of data architecture design and engineering implementation including data sourcing, data modeling of warehouses\/marts\/repositories, data integration\/transformation\/ETL, APIs, reporting, business intelligence and analytics\nExperience with data strategies related to data assessments, data quality, metadata, data security and data governance\n3+ years hands-on industry experience working with SQL on various relational database platforms (Microsoft, Oracle, Hana, Postgres, etc.)\n2+ years hands-on industry experience working with Snowflake.  Experience with Azure Data Factory, Redshift, Informatica a plus\nExperience with Wherescape or Coalesce transformation tools a plus\n1+ years hands-on experience with cloud platforms like AWS, Azure, GCP, etc. \nHands-on experience with modern programing languages like Python, C#, JavaScript, etc. a plus\nHands-on experience with Graph databases like Neo4j (preferred), Cosmos DB, Neptune, etc. a plus\nExperience with NoSQL databases like MongoDB, CouchDB, Cassandra, HBase, etc. a plus\nExperience with \u201cbig data\u201d and distributed tools like Hadoop, Spark, Cloudera, etc. a plus\nExperience with Docker for containerization and Kubernetes for orchestration a plus\nCollaborative team player who is detailed oriented, focused on solution quality and execution\nProgressive mindset particularly around deployment models and emerging technologies\nComfortable working across wide range of project sizes and industries\nAdditional Information\nWhat you should know about us: \nWe are humble, hungry, and smart. We solve big problems, serve lots of clients, and are entirely committed to delivering transformative outcomes. \nWe are team players, deeply dedicated to the mission of the organization, and to helping everyone around us be successful. \nWe compensate well, rewarding performance that delivers positive outcomes for our clients. \nOur leaders work hard, serving as shining examples of what it means to live out our values. They are servant leaders, helping their teams to be successful in all possible ways. \nWe offer several opportunities to develop yourself. \nWe pride ourselves in having the best talent in the industry and hope that you're up for the challenge! \nWhat our team members say about us:\n\u201cI love our true empathy and concern for our clients, it's very rare and appreciated. It is a pleasure to be a part of an organization like Resultant.\u201d \n\"I learn something new every single day, and I feel like I'm a part of building an organization that has legs. I appreciate that I'm consistently humbled by the talent and caliber of our team.\u201d \n\u201cThe culture of the company is amazing, and the climate of my team is great. The benefits that employees are offered are better than competitors, and the one-on-one presence that my team lead gives is extremely beneficial to me.\u201d \nAll qualified applicants will receive consideration for employment without regard to age, color, sex, disability, national origin, race, religion, or veteran status. \nEqual Opportunity Employer ","36":"Jobbeskrivelse\nBr\u00e6nder du for at levere komplekse, samfundskritiske og banebrydende datal\u00f8sninger? Besidder du h\u00f8j teknisk faglighed og har evnen til hurtigt at opn\u00e5 forretningsforst\u00e5else? Kan du h\u00e5ndtere hele l\u00f8sninger \u2013 fra analyse, systemarkitektur og teknologisammenligning til datamodellering, integrationsdesign og continuous integration and development? S\u00e5 er du m\u00e5ske vores nye Managing Architect.\nArbejdsopgaver og teknologier\nI Netcompanys Data Management team arbejder vi i sp\u00e6ndet mellem det tekniske og forretningen. Data er omdrejningspunktet for vores hverdag, hvor den prim\u00e6re opgave er at anvende data til at skabe v\u00e6rdi for vores kunder. Vi \u00f8nsker ikke at v\u00e6re leverand\u00f8r, men en samarbejdspartner. Det betyder at arbejdet, n\u00e5r muligt, foreg\u00e5r hos kunden. Vi g\u00f8r en dyd ud af at arbejde mere med end for kunden. Dermed sikrer vi, at leverancen ikke kun er af h\u00f8j kvalitet, men stemmer overens med kundens forventninger og behov.\nSom Managing Architect f\u00e5r du ansvar for, at forretningens krav bliver omsat til den rigtige tekniske l\u00f8sning baseret p\u00e5 den rette arkitektur og de mest velegnede teknologier. I forl\u00e6ngelse heraf, vil du ogs\u00e5 v\u00e6re involveret i planl\u00e6gningen af implementeringen samt den daglige sparring med teamet. Du vil l\u00f8fte et stort ansvar indenfor arkitektur, design- og kodeudviklingen p\u00e5 projektet. Derfor forventes det ogs\u00e5, at du er med til at definere design, fastl\u00e6gge best-practices og retningslinjer for kodeudviklingen samt udvikle komplekse og kritiske dele af projektet.\n\nOm dig\nVi forestiller os, at du har en naturlig interesse for aktivt at f\u00f8lge den tekniske udvikling og forst\u00e5r, hvordan denne viden aktivt kan bidrage til at kvantificere kundens krav. Derudover forventes det, at du har teknisk erfaring, gerne med afs\u00e6t i f\u00f8lgende eller lignende teknologier:\nETL\/ELT: Azure Data Factory, SSIS, dbt, Informatica\nDatabaser: Azure SQL Database, Microsoft SQL Server, PostgreSQL\nDataplatforme: Snowflake, Databricks, Azure Synapse, Google BigQuery\nOrkestrering: Dagster, Prefect eller Airflow\nBI-v\u00e6rkt\u00f8jer: Power BI, Tableau\nProgrammeringssprog: SQL, Python, R\nDerudover forestiller vi os, at du har en videreg\u00e5ende uddannelse, men vigtigst er, at du br\u00e6nder lige s\u00e5 meget for at arbejde med data, som vi g\u00f8r. Vi forestiller os, at du:\nHar solid erfaring med arkitektur indenfor IT og Data Management samt kendskab til IT-infrastruktur\nHar flere \u00e5rs erfaring i en lignende rolle, hvor fokus har v\u00e6ret p\u00e5 Data Warehousing, Business Intelligence og\/eller Data Science\nHar dybt kendskab til og solid erfaring med analyse og behandling af b\u00e5de strukturerede og ustrukturerede data\nHar st\u00e6rke formidlingsevner samt motiveres af at dygtigg\u00f8re dig selv og andre\nBehersker b\u00e5de dansk og engelsk i skrift og tale\nVi sikrer din udvikling!\nI Netcompany vil du fra start blive tildelt en erfaren personlig mentor. Din mentor vil altid st\u00e5 til r\u00e5dighed til faglig sparring og r\u00e5dgivning i, hvilken retning du kan g\u00e5, s\u00e5 du selv kan pr\u00e6ge din karriere.\nYderligere vil du ogs\u00e5 indlede et forl\u00f8b i vores interne uddannelsesprogram, Netcompany Academy. Gennem en r\u00e6kke moduler, sikrer vi dig kontinuerligt muligheden for at dygtigg\u00f8re dig igennem hele din karriere, i alt fra forskellige teknologier til kundeh\u00e5ndtering. Hvis du \u00f8nsker at videreudvikle dine tekniske kompetencer, tilbyder vi ogs\u00e5 certificeringer. Med andre ord vil din karriere aldrig g\u00e5 i st\u00e5 hos os, og du vil udvikle dig langt hurtigere, end noget andet sted i branchen.\nIngen prioriterer det sociale h\u00f8jere end os\nI Netcompany har vi et unikt sammenhold, og der findes ikke et sted i IT-branchen, som prioriterer det sociale h\u00f8jere end os. Vi tilbyder en lang r\u00e6kke forskellige klubber og foreninger indenfor b\u00e5de sport, br\u00e6tspil, E-sport og kulturliv. Derudover nyder vi at m\u00f8des p\u00e5 vores ugentlige fredagsarrangementer, til firmafester og teamevents. Mulighederne er mange, da vi tror p\u00e5, at vi pr\u00e6sterer bedst, n\u00e5r vi kender hinanden og har det sjovt sammen.\nSend os en ans\u00f8gning\nUpload dit CV og en motiveret ans\u00f8gning til vores rekrutteringssystem via linket.\nHar du ikke f\u00e5et svar p\u00e5 alle dine sp\u00f8rgsm\u00e5l, s\u00e5 er du velkommen til at skrive til hr.dk@netcompany.com\nI Netcompany tror vi p\u00e5, at en mangfoldig og inkluderende arbejdsplads er central for vores succes, og derfor inviteres alle kvalificerede kandidater til at s\u00f8ge uanset k\u00f8n, seksuel orientering, handicap, alder, religion og tro, etnisk baggrund, nationalitet, k\u00f8nsidentitet eller kultur. Vi \u00f8nsker at udleve en kultur, hvor vi giver lige muligheder for alle. #LI-SA2","37":"See yourself at Twilio\nJoin the team as our next Data Architect for Segment CDP\nWho we are & why we\u2019re hiring\nTwilio powers real-time business communications and data solutions that help companies and developers worldwide build better applications and customer experiences.\nAlthough we're headquartered in San Francisco, we have presence throughout South America, Europe, Asia and Australia. We're on a journey to becoming a globally anti-racist, anti-oppressive, anti-bias company that actively opposes racism and all forms of oppression and bias. At Twilio, we support diversity, equity & inclusion wherever we do business. We employ thousands of Twilions worldwide, and we're looking for more builders, creators, and visionaries to help fuel our growth momentum.\nAbout the job\nThis position is needed to lead data architecture for the industry-leading CDP inside Twilio.\nThis role will guide building of key systems and products as part of the Twilio\/Segment product portfolio, including stream data processing, storage and other mission-critical systems. This role will also provide oversight to engineering efforts for all engineering teams that are part of the Segment CDP group.\nResponsibilities\nIn this role, you\u2019ll:\nDesign and review core system designs making up the Segment CDP product\nPartner with other engineering leads across Twilio to build world-class products\nEnsure world-class reliability, security and cost-efficiency for all the products we build\nMentor other engineers on the team throughout their journey\nQualifications \nNot all applicants will have skills that match a job description exactly. Twilio values diverse experiences in other industries, and we encourage everyone who meets the required qualifications to apply. While having \u201cdesired\u201d qualifications make for a strong candidate, we encourage applicants with alternative experiences to also apply. If your career is just starting or hasn't followed a traditional path, don't let that stop you from considering Twilio. We are always looking for people who will bring something new to the table!\nRequired:\nHave a track record of designing and building large-scale, cloud-based, highly available software platforms.\nDomain expertise in Modern Data stack with experience in developing cloud-based data solution components and architecture covering data ingestion, data processing and data storage \nA thought leader in the cloud architecture space with a demonstrated bias for action\nHave the ability to balance long-term objectives with urgent short-term needs \nHave demonstrated the ability to design complex systems in an iterative and evolutionary manner.\nLocation \nThis role will be remote, and based in the USA. \nWhat We Offer\nThere are many benefits to working at Twilio, including, in addition to competitive pay, things like generous time-off, ample parental and wellness leave, healthcare, a retirement savings program, and much more. Offerings vary by location.\nTwilio thinks big. Do you?\nWe like to solve problems, take initiative, pitch in when needed, and are always up for trying new things. That's why we seek out colleagues who embody our values \u2014 something we call Twilio Magic. Additionally, we empower employees to build positive change in their communities by supporting their volunteering and donation efforts.\nSo, if you're ready to unleash your full potential, do your best work, and be the best version of yourself, apply now!\nIf this role isn't what you're looking for, please consider other open positions.\n*Please note this role is open to candidates outside of Colorado, California, New York, and Washington. The information below is provided for candidates hired in those locations only.\nThe estimated pay ranges for this role are as follows:\nBased in Colorado: $213,120 - $266,400\nBased in New York, Washington State or California (outside the San Francisco Bay Area): $225,680 - $282,100\nBased in the San Francisco Bay area, California: $250,720 - $376,080\nThis role is eligible to participate in Twilio's equity plan and the following benefits: health care insurance, 401(k) retirement account, paid sick time, paid personal time off, paid parental leave. \nThe successful candidate\u2019s starting salary will be determined based on permissible, non-discriminatory factors such as skills, experience, and geographic location within the state. \n  Twilio is proud to be an equal opportunity employer. Twilio is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, genetic information, political views or activity, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Additionally, Twilio participates in the E-Verify program in certain locations, as required by law.\nTwilio is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, please contact us at accommodation@twilio.com.","38":"Company Description\nTalan est un cabinet de conseil en innovation et transformation par la technologie.\nDepuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en \u0153uvre leurs projets de transformation et d\u2019innovation en France et \u00e0 l'international. Pr\u00e9sent sur cinq continents, le groupe pr\u00e9voit de r\u00e9aliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant\u00b7e\u00b7s et vise \u00e0 d\u00e9passer la barre du milliard d\u2019\u20ac de CA \u00e0 horizon 2024.\nLe Groupe met l'innovation au c\u0153ur de son d\u00e9veloppement et intervient dans les domaines li\u00e9s aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.\nPr\u00e9sent dans les \u00e9v\u00e9nements incontournables du secteur, comme Viva Technology, Talan prend r\u00e9guli\u00e8rement la parole sur les enjeux de ces technologies r\u00e9volutionnaires aux c\u00f4t\u00e9s d'acteurs majeurs du secteur et de parlementaires (Syntec Num\u00e9rique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny\u2026).\nTalan est une entreprise responsable, attach\u00e9e \u00e0 la diversit\u00e9. Des am\u00e9nagements de poste peuvent \u00eatre organis\u00e9s pour tenir compte des personnes en situation de handicap.\nRetrouvez nos engagements RSE ici et nos actions en faveur de la diversit\u00e9 ici\nJob Description\nAu c\u0153ur de la strat\u00e9gie Data du groupe, Talan recherche un(e) Architect(e) Data capable d\u2019accompagner les projets, les avant-ventes, avec une approche de bout en bout, sur toute la cha\u00eene de valeur de la donn\u00e9e. \nQui sommes-nous ? \nLe p\u00f4le Data Intelligence est compos\u00e9 de +200 experts (AMOA Data, Agile Data, Data Gov, Data Streaming, Data Engineer, Data Analyst\u2026), vous intervenez sur des projets de modern data platform et d\u2019innovation pour accompagner les entreprises vers une organisation Data Driven. \nNos r\u00e9alisations tournent autour de th\u00e9matiques telles que : \nMove to cloud\u202f: passer du on-premise vers une modern data platform, \u2026 \nReal time :\u202fstreaming, change data capture\u2026 \nMod\u00e9lisation DWH\u202f: DataVault et Dimensionnelle, \nData Warehouse as Service:\u202fSnowflake, BigQuery, Redshift, Azure Synapse\u2026 \nData Virtualisation\u202f: acc\u00e9l\u00e9rer l\u2019acc\u00e8s aux donn\u00e9es, \nNous intervenons autant dans des DSI que dans des direction m\u00e9tiers, dans des modes forfaitaires ou en r\u00e9gie. \nVenez int\u00e9grer notre communaut\u00e9 d'experts Data chez Talan\u202f! \nTalan renforce\u202fsa communaut\u00e9 au sein du p\u00f4le Data pour intervenir sur les diff\u00e9rents projets de nos clients grands comptes. \nNous sommes \u00e0 la recherche d\u2019un Architect Data capable d\u2019accompagner le d\u00e9marrage des projets sur la mise en place d\u2019une\u202fplateforme modern data, d\u00e9finition des solutions \u00e0 mettre en place, dimensionnement, s\u00e9curisation, participer aux avants ventes\u202f: r\u00e9daction, soutenance\u2026 \nLes responsabilit\u00e9s d\u2019un Architect Data comprennent des activit\u00e9s d\u2019expertise, de mentoring - coaching, d\u2019avant-vente et de s\u00e9curisation de projet au forfait. Vous devrez faire preuve d\u2019un \u00e9tat d\u2019esprit \u00e0 la fois innovant, m\u00e9thodique, orient\u00e9 solution (et non probl\u00e8me\u202f!), et communiquant. \nVotre but ultime sera de garantir l\u2019excellence d\u2019une \u00e9quipe de sp\u00e9cialistes, pi\u00e8ce maitresse de la r\u00e9alisation de projets \u00e0 forts enjeux pour nos clients. \nVOTRE ROLE SUR NOS PROJETS:\nEn mission\u202f: analyse des exigences techniques, d\u00e9finition des normes et bonnes pratiques, r\u00e9daction de document d\u2019architecture, aide \u00e0 la mise en place des solutions, s\u00e9curisation des acc\u00e8s, d\u00e9finition des r\u00f4les et acc\u00e8s \nCoacher techniquement les \u00e9quipes \nAvant-vente\u202f: participation aux r\u00e9ponses \u00e0 appel d\u2019offre au forfait \nCommunication\u202f: \u00e9criture d\u2019article, animation d\u2019\u00e9v\u00e8nement \nVeille\u202f: sur les solutions Data, m\u00e9thodologie de datawarehousing, ... \nVOTRE ROLE CHEZ TALAN :\nBenchmark de solutions et conseil aupr\u00e8s de nos clients sur les solutions technologiques \u00e0 adopter, en lien avec leurs besoins \nR\u00e9alisation de POC (Proof Of Concept) \nParticipation \u00e0 des projets internes et partage de connaissances au sein de nos \u00e9quipes \nPartage de connaissances et formations interne \nEnsemble r\u00e9alisons de nouveaux projets Talantueux!!\n Qualifications\nVOTRE PROFIL:\nConnaissance des syst\u00e8mes de f\u00e9d\u00e9rations d\u2019identit\u00e9s, et des m\u00e9canismes d\u2019authentification \nMaitrise des techniques de Data management, de DataViz \nM\u00e9thodologie de conception et de mod\u00e9lisation d\u2019entrep\u00f4t \/ lac de donn\u00e9es \nDesign d\u2019architecture technique et applicative \nBonnes connaissances des technologies Data en g\u00e9n\u00e9rale (stockage, ingestion et transformation de donn\u00e9es, data visualisation, data sharing, API Management, cloud provider\u2026)  \nForce de proposition \nQualit\u00e9 r\u00e9dactionnelle, vulgarisation \nAutonomie, organisation, sens du partage \nExcellente communication \nOrientation m\u00e9tier \nAlors n'attendez plus ! Postulez vite !\nAdditional Information\nAVANTAGES :\nTop 5 du Palmar\u00e8s Great Place to Work \nManagement de proximit\u00e9 par des experts \nOrganisation sous forme de\u202fcommunaut\u00e9s \nUn parcours excellence Agile DevOps \nFinancement de plusieurs certifications officielles \u00e0 l\u2019ann\u00e9e gr\u00e2ce \u00e0 nos partenaires \u00e9diteurs \nUn acc\u00e8s \u00e0 la plateforme CampusTalan avec plus de 1000 formations disponibles d\u00e8s votre arriv\u00e9e \nUne mobilit\u00e9 interne facilit\u00e9e \nUn engagement aupr\u00e8s des travailleurs en situation de handicap \nDes \u00e9v\u00e9nements et afterworks r\u00e9guliers \nSi\u00e8ge parisien situ\u00e9 \u00e0 Charles-De-Gaulle Etoile \nTickets restaurants digitalis\u00e9s \nMutuelle d\u2019entreprise prise en charge \u00e0 100% \nPrime vacances \nPrime de participation \nPrimes de cooptation \nActionnariat \n1% logement \nPartenaire de l'organisme Mobility dans le cadre de l'accompagnement \u00e0 la mobilit\u00e9 et \u00e0 la recherche de logement \nRTT ","39":"About this position:\nThis position is fully remote\n5 Years of relevant experience is required\nBachelor's Degree in Business Administration, Business Management, Computer Science, Information Systems, Information Resource Management, Industrial Engineering, Operations Research or related fields is required\nEducational substitutions: Certifications in relevant technology plus 3-5 years of relevant experience; or 5 to 7 years of relevant experience may be substituted for education\nUnderstand stakeholder needs for registries and the data they contain through discovery and interviews.\nDevelop a definition for Registries, and recommendations for registries future states.\nDevelop a unified Data Dictionary to standardize data definitions across VA registries.\nWork on things that matter\nAd Hoc is a digital services company that helps the federal government better serve people. Our teams use modern, agile methods to design and engineer government systems that connect Veterans with services, bring affordable health care to millions of people, and support important programs like Head Start. And as we work to make critical government services intuitive, accessible, and human-centered, we\u2019re also changing how the government thinks about and uses technology. If you thrive on change, want to help close the gap between consumer expectations and government services, and can see the possibilities in ambiguity, then we want you here with us. \nThe Veterans Affairs business unit helps transform the VA into a modern digital services organization where Veteran outcomes are at the center of every effort. We partner with the Office of the Chief Technology Officer - Digital Experience, the Office of Information Technology, Veterans Health Administration, and Veterans Benefits Administration to design and deliver seamless user experiences for Veterans, their Families and Caregivers, and VA employees.  By applying better practices in service design, product management, and technology, we enable VA to increase the usage, throughput, quality, and reliability of services and decrease the time Veterans spend waiting for outcomes.\nThe Lead Data Architect is responsible for identifying data needs that are critical to the organization's short, medium, and long-term strategy to ensure that data is translated and modeled to drive measured and actionable results. A Lead Data Architect will exhibit strong communication skills, with the ability to engage with data owners, engineers, and analysts to define requirements, evaluate data sets, identify variances, and recommend solutions that support a strategic and holistic approach to data integration, management, and reporting. \nThe Lead Data Architect is responsible for (Essential Functions):\nResponsible for engaging with data owners to identify business components and translating requirements into functional business intelligence portals and dashboards\nAccountable for the development and execution of data strategies, with the ability to provide oversight of the data components associated with acquisition, engineering and consumption work streams\nResponsible for developing an ontology-based semantic layer and setting standards for a common and recognizable visual language for all data users and sources\nResponsible for data governance, conducting inventory evaluations and subsequently developing solutions to eliminate identified data gaps and improve data maturity\nIdentifies approaches for data management based on specific variables, inclusive of importance, complexity and probability of success\nExhibits strategic and critical analysis leadership, with the ability to summarize findings and provide comprehensive recommendations\nExecutes effective governance by collaborating with data owners and users to modify or implement new repeatable and reliable businesses processes \nAlign data architecture and standardize data access patterns to make data available to business intelligence tools, apps, websites\nAbility to prioritize and translate complex data into dashboards and reports to inform decisions and drive actionable results that meet strategic goals\nProficient in SQL and complex data schema design.\nStrong understanding of how to analyze large sets of data using statistical software languages such as R or Python\nCollaborates with a multidisciplinary team of product owners, engineers, designers, and researchers, and adapts communication style to the audience\nProvides oversight of data organization, data dictionary standardization, and glossary development to align with data models\nUnderstand stakeholder needs for registries and the data they contain through discovery and interviews.\nDevelop a definition for Registries, and recommendations for registries future states.\nDevelop a unified Data Dictionary to standardize data definitions across VA registries.\nRefine research findings and insights into actionable product and feature requirements and artifacts that support registry future state and eligibility streamlining.\nBenefits\nCompany-subsidized Health, Dental, and Vision Insurance\nVanguard 401K Plan\nUnlimited Vacation\nContinuing Education\/Annual Conference Attendance Stipend\nAd Hoc LLC is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, sex, sexual orientation, gender identity or expression, religion, age, pregnancy, disability, work-related injury, covered veteran status, political ideology, marital status, or any other factor that the law protects from employment discrimination.\nIn support of the\u202fColorado Equal Pay Transparency Act, and others like it across the country, Ad Hoc job descriptions feature the starting range we reasonably expect to pay to candidates who would join our team with little to no need for training on the responsibilities we've outlined above. Actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, and responsibility. The range of starting pay for this role is $113,900 - $149,040 and information on benefits offered is here. Our recruiters will be happy to answer any questions you may have, and we look forward to learning more about your salary requirements.\nJob reference:  1860","40":"At Jamf, people are at the core of everything we do. We do what\u2019s right for our customers, our employees, our communities and our world. We take pride in simplifying technology for tens of thousands of customers around the globe and helping organizations succeed with Apple.\n  Jamf operates as a choice-based office model. Choose to work in the office, connect 100% remote from your home, or find the blend that works best for you.\n SUMMARY\nAt Jamf, we empower people to be their best selves and do their best work. The business Intelligence group at Jamf manages and delivers insights about company data so businesses can make informed decisions. Through the core disciplines of data management and data analytics the team delivers data visualizations and analytics while managing the data infrastructure to support our growing systems at Jamf. The Business Intelligence Data Architect II is an integral member of data management, responsible for ensuring we have the right data architecture to deliver on our vision to democratize data to users and consumers across major business lines. By development of a Business Intelligence and Analytics framework to put accurate and current data to the people who need to make business decisions.\nThe Business Intelligence Data Architect II will collaborate closely with stakeholders, Enterprise Architecture, Data Analysts, Data Engineers, end-users and other members across the company in the design, orchestration, and management of our corporate data within our ecosystem - ensuring our data is secured, governed, and consumed by major business lines at Jamf resulting in a data-driven culture.\nRESPONSIBILITIES\nProvide feasible, efficient, and performant data solutions and implementations for our business.\nCollaborating cross-functionally to define and prioritize requirements for data needed from internal and external sources to support analytics and decision making.\nWork with engineering and analyst teams to capture and delivered required data to the Enterprise Data Platform while meeting multi-dimensional standards for data quality.\nDevelop key performance measures for data integration, quality, and operations.\nBuild a framework of principles to ensure data integrity across the business (including but not limited to ERP, CRM, BI, Data warehouse, external interfaces etc.)\nManage and help build a robust and scalable Data Integration pipeline of the ETL\/ELT process\nUnderstand and document data flow throughout critical business systems\nWork with stakeholder groups on definition of a Unified Data Model that serves as the foundation for the single source of truth for all product, customer and reference data used for BI & analytics.\nUse the best-fit data warehousing methodologies and modeling techniques\nAssists with cloud Infrastructure design best practices, templates, and processes.\nHelp achieve and maintain compliance with regulatory, legal and company standards.\nParticipate an active contributor to how Jamf evolves Data Governance practices and influence the adoption of data standards.\nEnsure that the BI Data Architecture strategy and roadmap is aligned to the business and technology strategies.\nContribute to, participate in, and deliver architectures through architecture reviews.\nAdvocate of data security principles and ensure appropriate security practices are incorporated into solutions\/capabilities.\nMentor\/coach team members in data architecture, engineering and dimensional modelling.\nSKILLS AND EXPERIENCE\nMinimum 3 years of Data Architecture experience including but not limited to:\nExperience in architecting and implementing Business Intelligence and Data warehouse platforms, Master data management and data integration (Required)\nExperience in business intelligence and analytics architecture framework: ability to collect, integrate, and store the data so it is accessible and actionable (Required)\nMinimum 5 years of experience in Logical and Physical data modelling. (Required)\nDemonstrated experience using Agile\/Scrum frameworks and software development workflows (Required)\nAbility to lead technical initiatives, communicate with leadership and guide projects (Required)\nExperience communicating project direction and status with stakeholders (Required)\nComfortable with resolving conflicting viewpoints and achieving agreement (Required)\nExperience coaching teams on modelling\nExperience integrating data governance functions into the data delivery process\nStrong understanding of cloud platforms, databases, and data capabilities to source, integrate, manage, and leverage data\nAbility to understand existing and new technologies and lead their adoption across the enterprise\nEDUCATION & CERTIFICATIONS\n4 Year\/ Bachelor\u2019s degree in Science, Technology, Engineering, Mathematics, or related field (Required)\nA combination of relevant experience and education may be considered \n  At Jamf, people are at the core of everything we do. We do what\u2019s right for our customers, our employees, our communities and our world. We take pride in simplifying technology for tens of thousands of customers around the globe and helping organizations succeed with Apple.\nJamf operates as a choice-based office model. Choose to work in the office, connect 100% remote from your home, or find the blend that works best for you.\n What is a Jamf?\nYou go above and beyond for others, are willing to help, and support the team around you. You value and learn from different perspectives. You are curious and resourceful, a problem-solver, self-driven and constantly improving. You are excited by not knowing what may lie ahead. You are willing to take risks, try new things, even fail just to do it better next time. You\u2019re not a jerk. You are someone who cares about doing the right thing.\n\nWhat does Jamf do?\nJamf extends the legendary Apple experience people enjoy in their personal lives to the workplace. We believe the experience of using a device at work or school should feel the same, and be as secure as, using a personal device. With Jamf, IT and security teams are able to confidently manage and protect Mac, iPad, iPhone and Apple TV devices, easing the burden of updating, deploying and securing the data used by their end-users. Jamf\u2019s purpose is to simplify work by helping organizations manage and secure an Apple experience that end-users love and organizations trust.\n  We are free-thinkers, can-doers and problem crushers with a passion for helping customers empower their workforce to focus on their jobs, not the hassles of managing technology \u2013 freeing nurses to care, teachers to teach and businesses to thrive. We have over 2,500 employees worldwide who are encouraged to bring their whole selves to work each and every day.\n  Get social with us and follow the conversation at #OneJamf\n  #LI-REMOTE","41":"Company Description\nWe\u2019re the world\u2019s leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business.\nJob Description\nOVERVIEW\nCome work for one of the fastest growing sports tech companies in the world. Our NASDAQ-listed organization is aligned around shared passions for sports and technology and includes nearly 3,000 employees in over 30 countries.\nSportradar is looking for an experienced Architect to develop and implement the Architecture and Technical Strategy for the Computer Vision Tribe. As a member of Computer Vision Tribe, you will contribute to the ongoing development of revolutionary Computer Vision & Deep Learning solutions.\nAs a form of AI that enables the visual world to be interpreted and understood in unprecedented depth, Computer Vision will provide fans with evermore immersive experiences whilst delivering richer insights to teams and leagues. Computer Vision is transforming sports data collection processes, providing a 100-fold increase in the depth of statistics and data available.\nMISSION\nDevelop the technical strategy with our tribe leadership and stakeholders\nExplore new technology opportunities in the marketplace and with existing vendors\nHelp shape the technology platforms of our internal facing systems\nEnsure technical cohesion across our engineering teams\nBe a technology leader across the tribe\nForm a strong partnership with our product and engineering delivery teams\nEvangelize the widescale adoption of modern engineering best practices\nEnsure the architecture is designed to meet the right software quality attributes\nYOUR PROFILE\nLifetime learner, interested in understanding the technology state of the art\nPositive and inclusive communicator and collaborator\nPragmatic practitioner, able to balance an idealized solution with real world constraints\nStrategic thinker, able to keep the long-term goal in sight whilst delivering today\u2019s needs\nRelevant architectural experience, with a range of items from:\nPublic Cloud, e.g., AWS, Azure, Google Cloud or Oracle\nML frameworks, e.g TensorFlow, Sci-kit learn, PyTorch, MXNet, SageMaker\nData Processing pipelines, e.g. Airflow, Spark\nDatabases, e.g., Relational, Key-value, Wide column, Document, Graph\nContainer hosting, e.g., Kubernetes, Functions as a Service\nPrevious programming experience with Java, Python, C++, SLQ\nService integration using Event Brokers e.g., Kafka, Rabbit MQ, NATS\nModern engineering methods, e.g., TDD\/BDD, DevOps, Domain Driven Design, Lean, Agile\nIt is not essential to have all these skills, but an aptitude and willingness to develop those you do not know is key.\nOUR OFFER\nTo be part of shaping the next generation of sports data technology services\nThe chance to work with a highly skilled, inclusive, and multi-national team\nBe part of a global architecture practice\nInvestment in your continued development\nAdditional Information\nSportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences ","42":"Company Description\nGenomics England partners with the NHS to provide whole genome sequencing diagnostics. We also equip researchers to find the causes of disease and develop new treatments \u2013 with patients and participants at the heart of it all.\nOur mission is to continue refining, scaling, and evolving our ability to enable others to deliver genomic healthcare and conduct genomic research.\nWe are accelerating our impact and working with patients, doctors, scientists, government and industry to improve genomic testing, and help researchers access the health data and technology they need to make new medical discoveries and create more effective, targeted medicines for everybody.\nJob Description\nThe Data Architect will be joining the Enterprise Data Squad and will take responsibility for ensuring that our digital products are underpinned by a robust data architecture.\nIn this role, you will ensure enterprise products across operational and research aspects of Genomics England business systems are supported by a clear and maintained data architecture.\nYou will manage the data flows, data dictionaries and data models as well as the enterprise information architecture. This includes leading High and Low level designs and implementations for enterprise wide data solutions.\nKey Responsibilities\nUnderstand and manage the data requirements by working with stakeholders to analyse requirements and identifying those of architectural significance\nDeveloping data architectures including different data flows, data lifecycle, data security, durability, as well as applying consistent documentation standards and architecture methods \nVerifying implementations and ensuring the delivered systems is consistent with the agreed architecture and meets requirements  \nEnsuring solutions are documented and assured through defined architecture governance processes \nKey skills\nKnowledge in database technologies adopted by Genomics England including AWS native services, AWS Aurora, Neptune, OpenSearch, Redshift, Dynamo, Document DB, MongoDb, Hbase \/ Solar\nFamiliar with TOGAF and other enterprise architecture frameworks\nExperience and knowledge of data governance, data quality, and data cataloguing\nKnowledge of master, metadata and reference data management\nQualifications\nTOGAF Certification\nAWS Solution Architect \nAdditional Information\nBeing an integral part of such a meaningful mission is extremely rewarding in itself, but in order to support our people, we\u2019re continually improving our benefits package. We pride ourselves on investing in our people and supporting them to achieve their career goals, as well as offering a benefits package including: \n30 days\u2019 holiday (plus bank holidays), with additional days for long service awards\nA generous pension scheme of up to 15% combined contribution\nLife Assurance (3 x salary)\nIndividual learning budgets for every colleague, a Blinkist account and a wide variety of courses on our portal\nA wide variety of wellness benefits including Gympass, a Headspace account, free weekly Yoga classes\nEnhanced maternity & paternity benefits\nBlended working arrangements\nTalk to our Talent Team and find out how a career with Genomics England will benefit you.\n#LI-Hybrid\nAs part of our recruitment process, all successful candidates are subject to a Standard Disclosure and Barring Service (DBS) check.  We therefore require applicants to disclose any previous offences at point of application, as some unspent convictions may mean we are unable to proceed with your application due to the nature of our work in healthcare. \nGenomics England operates a blended working model as we know our people appreciate the flexibility. We expect most people to come into the office 2 times each month as a minimum. However, this will vary according to role and will be agreed with your team leader. For some people this is 1 day a quarter, for others it is several days a week. There is no expectation that staff will return to the office full time unless they want to. The exception would be some of our roles that would require you to be on site full time e.g., lab teams, reception team. \nOur teams and squads have, and will continue to, reflect on what works best for them to work together successfully and have the freedom to design working patterns to suit, beyond the minimum. Our office locations are Canary Wharf, Cambridge and Leeds.\n#LI-Hybrid","43":"Company Description\nVericast is a premier marketing solutions company that accelerates profitable revenue growth for the thousands of businesses it serves directly by influencing consumer purchasing and transaction behavior at scale while engaging with over 120 million households daily.  We are recognized as leading providers of incentives, advertising, marketing services, transaction solutions, customer data and cross-channel campaign management, and intelligent media delivery that create millions of customer touch points annually for their clients.  For more information, visit http:\/\/www.vericast.com or follow Vericast on LinkedIn.\nJob Description\nValassis Digital (a division of Vericast) is seeking a Principal Software Engineer to develop services, tools, bots, and workflows for our big data processing infrastructure.\nThe Big Data Platform Team owns and operates the world-class big data processing infrastructure that over a dozen engineering teams use to power their 24\/7 technical marketing products. We own and operate a large hadoop+spark processing cloud on which we store 6PB of data, and run 30 thousand jobs every day. We write a fabric of java microservices and bots to manage all those jobs, extend hadoop's functionality, and help us operate and optimize our investment. We write custom data streaming services that ingest and curate 100TB of data each day that drives the entire advertising data ecosystem. We also participate in all our users' groundbreaking workflow projects so that we can constantly stay abreast of our developer's tooling needs.\nWhat you're like:\nThis position is perfect for a far-sighted engineer who always wants to be the first to apply cutting-edge technologies to solve complex business and engineering problems. You want to have a leading voice on our team and across our organization. You will work throughout the software lifecycle including customer interaction and product planning, requirements analysis, architecture, directing our team of developers, development, testing and operations. If you are energized by the thought of developing new system stacks and tools for big data processing and analytics we want to talk to you. If you have worked on big data engineering, cloud migration, or infrastructure tooling projects, we want to talk to you. If you have ever worked on a collection of data workflows or a service mesh and thought 'I could make this better', we want to talk to you!\nWhat you'll do:\nWork with our users, architects, and product leaders to architect and plan our data platforms\nDesign, develop, and maintain the software and systems that make up the data platform that runs our entire business\nPartner with the Data Engineering and Data Science teams who use our platform to diagnose, predict and address scaling problems\nWork on new products initiatives to provide design support and establish best practices\nContribute to our team\u2019s growing set of development platforms, tools, processes, and products\nQualifications\nExperience working on big data systems and technologies with emphasis on the Hadoop platform\nGeneral knowledge of design patterns & UML with a few years of taking a lead on architectural design and development\nProficiency in Java, Scala, or Python programming; exposure to microservices and Spark dataframe programming.\nProficiency in networking, Thrift, Spring Framework and\/or Spring Boot for microservices is a plus. \nUnderstand RDMS and proficiency in DML, SQL & PL\/SQL a plus\nHands on experience with Spark; exposure to Kafka and YARN or similar technologies\nExperience with migration of infrastructure from on-prem to cloud or vice versa is a big advantage\nCuriosity to learn and apply new technologies and a background full of diverse design challenges\nExcellent problem-solving abilities\nExcellent verbal, graphical, and written communication skills\nExperience with agile development methodologies\n\nYour qualifications:\nBS\/MS in Computer Science or other technical discipline (with significant computer coursework)\n10+ recent years of professional software development experience using java, scala, or python\n3+ recent years working with the hadoop+spark big data platform or similar\nAdditional Information\nSalary:  180,000-200,000 with 10% bonus opportunity\nThe ultimate compensation offered for the position will depend upon several factors such as skill level, cost of living, experience, and responsibilities.\nVericast offers a generous total rewards benefits package that includes medical, dental and vision coverage, 401K and flexible PTO. A wide variety of additional benefits like life insurance, employee assistance and pet insurance are also available, not to mention smart and friendly coworkers!\nAt Vericast, we don\u2019t just accept differences - we celebrate them, we support them, and we thrive on them for the benefit of our employees, our clients, and our community.\u202fAs an Equal Opportunity employer, Vericast considers applicants for all positions without regard to race, color, creed, religion, national origin or ancestry, sex, sexual orientation, gender identity, age, disability, genetic information, veteran status, or any other classifications protected by law. Applicants who have disabilities may request that accommodations be made in order to complete the selection process by contacting our Talent Acquisition team at talentacquisition@vericast.com. EEO is the law. To review your rights under Equal Employment Opportunity please visit: www.dol.gov\/ofccp\/regs\/compliance\/posters\/pdf\/eeopost.pdf.\n#LI-TE1\n#LI-Remote","44":"Company Description\nBLEND360 is an award-winning, new breed Data Science Consultancy focused on powering exceptional results for our Fortune 500\/1000 clients and other major organizations. We are a growing company\u2014born at the intersection of advanced analytics, data, and technology.\nWho we are:\nPeople are everything here at BLEND360.  We are inspired by advancing our Client\u2019s most critical initiatives, products and projects by matching our clients with the right talent. BLEND360 has been among the Inc. 5000 fastest growing companies 8 years in a row, and we\u2019re very proud of our World Class NPS score. Our success is a direct result of our passion for advancing the careers of the talented people we work with every day. When you work at BLEND360, you will:\nCollaborate with a smart, passionate group of people who are invested in your success.\nPartner with an impressive list of clients, who value Blend360\u2019s services and the world class experience we deliver with every engagement.\nThrive with a company and leadership team who are committed to growth.\nJob Description\nYour role will be to be in charge of technical architecture operations day to day. This will require you to run point on creating a kick-ass backend architecture leveraging the latest and greatest in cloud technology to power transformative, data-driven products. The team will be depending on you to select the right technology for the job and provide a blueprint for implementing any given technology successfully. You should consider the business requirements, performance needs, cost and implementation complexity when designing your new architecture.\n Your role will be primarily focused on design and blueprinting, but this is NOT a hands-off role. You will be expected to roll up your sleeves and dive into code to help us solve complex problems should the team not find an adequate resolution. We need an individual that can think outside the box and innovate to solve technical challenges that do not have simple, out of the box solutions.\n The immediate ask of this role will be focused on a big data migration project to rejuvenate an old pipeline in a bleeding edge Kubernetes deployment. You will be responsible for overseeing the code conversion work-stream as well as predict challenges and hurdles associated. Deep Spark expertise is essential for this role. Familiarity with the end-to-end MLOps flows is an advantage\n Outside of architecting new frameworks, you will be responsible for helping the organization upskill for the upcoming needs in the world of big data analytics.\n You will get the ability to get creative in the world of big data technology without the encumberment of a large-scale organization. You will have the freedom to explore the latest technologies out there to not only improve your own skillset, but also help the organization as a whole improve.\nQualifications\nStrong experience with multiple cloud providers (GCP, AWS, Azure)\nExcellent Python programming capabilities\nGood understanding of databases\/warehouses\nPrevious experience deploying data products end to end\nData governance and security experience.\nPrevious experience architecting efficient processing frameworks.\nIn-depth Spark understanding\n Must have one of these skills: \nETL pipeline architecture involving dbt, Snowflake or similar tools in Cloud environment\nExperience in architecting microservice based architecture using queuing systems, streaming with NoSQL databases or data warehouses\nAdditional Information\nA diverse workforce is a strong workforce\nTo deliver growth at BLEND360 and for our clients, we have a responsibility and unique opportunity to positively impact the workforce. Diversity has played a critical role in our history, our growth, and continues to have a profound impact on our success.  We are determined to have equality in the workplace, within our team and as an extension of our clients\u2019 team. \nThis is not the work of the moment, this requires continued learning and purposeful actions.  We are investing resources to understand and improve the sourcing, selection and retention of the talent we hire.","45":"Company Description\nDear trailblazers, forward-thinkers, and doers - We want you. DataStax is the real-time data company. With DataStax, any enterprise can mobilize real-time data and quickly build the smart, highly scalable applications required to be a data-driven business. We subscribe to a set of principles that guide how we collaboratively work together. We inspire each other with our values, obsessing over developers and enterprises, taking action and focusing on results, innovating in technology, products, and everything we do, and defining success as the team winning. We foster a diverse working environment that is respectful, generates new ideas, promotes ownership, and encourages highly motivated individuals to shape tomorrow. These form the foundation of the DataStax culture and help drive our decisions.\nJob Description\nPre-Sales Architect\nAs a Pre-Sales Architect, you will work as part of the go-to-market team to qualify, educate and lead the design and adoption of DataStax products and solutions. You will be on the front line working with our sales team in a dynamic, high-energy environment. You will own the technical relationships with customers as they modernize and realize business value over time. This is a technical pre-sales position.\nWhat you will do:\nPresent how DataStax products and solutions can support the enterprises data modernization strategy and achieve transformational outcomes\nCollaborate with account executives to develop account strategies and plans\nQualify technical requirements and effectively articulate DataStax's ability to meet these needs\nDeliver hands-on developer and architectural interactions remotely or on-site at customer locations\nProvide market feedback from the field to Product Management and Engineering\nEmbrace learning new technologies and stay abreast of the distributed computing landscape\nWork remotely and travel up to 25-30% of the time\nYour experience should include:\nPassion to engage with customers and future customers\nExcellent interpersonal and communication skills\nComfortable presenting technical solutions to customers or prospects\nWillingness to help customers with architecture for internet-scale applications\nPassion to learn new skills (technical and non-technical)\nDesire to help build a culture of knowledge sharing in a fast-paced startup environment\nNot sure if you qualify?\nApply anyway! We extend opportunities to a broad array of candidates, including those with diverse workplace experiences and backgrounds. Whether you're new to the corporate world, returning to work after a gap in employment, or simply looking to transition or take the next step in your career path, we are excited to connect with you.\nAdditional Information\nSalary Range: $92,000 - $138,000","46":"Company Description\nCompany Overview\nHitachi Solutions is a global solutions integrator passionate about designing, developing, and delivering cutting edge cloud solutions to help our clients innovative across their entire business.  Our firm develops the business services and technology powering some of the products you use every day \u2013 and is closely aligned with Microsoft and other leaders in the cloud computing space.  \nWhat sets Hitachi Solutions apart is both our industry focus, and the intellectual property that we bring to our customers.  Recognized for our achievements year after year, we strive to be the trusted advisor of large and medium sized enterprises alike \u2013 helping them move fast to achieve strategic business initiatives with distinguished engineering, hard work, and compassion.  With over 3,000 team members across 14 countries, in our 18 years of focus our company has seen explosive growth and high customer satisfaction.  This has allowed us to offer exceptionally compelling salaries, 401k match, family leave, and health benefits.  And no \u2013 we will not make you come into an office or ask for an inflexible work schedule. \nA part of Hitachi, Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world\u2019s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies\nJob Description\nPlease note:  Although this is a Remote \/ Virtual \/ Work-From-Home career opportunity, candidates MUST reside, and be authorized to work without sponsorship, in Canada.\n This is a full-time role in our New Product organization for professionals with a proven history of execution, and a desire to rapidly expand a product organization.  Our team is seeking a Senior Data Architect, with a strong background in data definition, modeling, and implementation.  \n This is a hands-on architect role where the individual will be responsible for the overall design of solutions within the data ecosystem serving our customers. This role will require someone who is experienced in designing data schemas using Kimball\/Dimensional modeling and pipelines in Databricks for data warehouses\/lakehouses and reporting systems, is able to evaluate multiple technologies and technical solutions, and be a hands-on contributor for engineering goals for multiple engineering teams. Additionally, as a technical leader within the team, you will mentor and coach your team members; therefore, top candidates have experience as either a team lead or manager. \n Responsibilities\nScope and execute with independence. Work with the product team to understand platform capabilities and leverage those capabilities to bring customer\u2019s data estate. \nIdentify and articulate technical and operational requirements for data pipelines and the models they populate; be able to optimize these pipelines for high performance\/resiliency workloads. \nInstill excellence into the processes, methodologies, standards and technology choices embraced by the team with customer teams, and junior staff. \nLead requirements discovery and delivery workshops \u2013 helping customers understand their options and guiding them to the best options. \nBe an advocate for the customer, and support delivery leadership (Director, VPs) in managing client expectations. \nDedicate time to continuous learning to keep the team and customers appraised of the latest developments in the space.\nA committed teacher and someone who enjoys developing technical maturity across the company. \nExperience supporting analytics, data science and\/or engineering teams and understand their unique needs and challenges.\nQualifications\n8+ overall years of professional experience including 4+ years\u2019 experience in designing high-scale, Big Data, Datalakehouse Solutions is REQUIRED \n4+ years of experience with data modeling (Kimball\/Dimensional modeling), schema design patterns and modern data access patterns (including API, streams, data lake) is REQUIRED\n2+ years as a proven leader interacting with customers (client facing) to collect requirements and manage a technical data backlog is REQUIRED; therefore you must have excellent interpersonal skills, both written and spoken, as well as a consultative\/collaborative style.\n2+ years with Databricks and Spark framework are REQUIRED\n2+ years of experience building data applications, microservices and\/or APIs using Python, Scala or an equivalent language is REQUIRED\n2+ years of experience with SQL, knowledgeable in complex queries and joins is REQUIRED; experience with UDF and\/or Stored Procedure development is HIGHLY DESIRED\n2 + years Azure Data Services including Azure Data Factory, ADLS, and Synapse is HIGHLY DESIRED; strong experience with AWS or other major cloud platform will be considered in lieu of.\n  #REMOTE\n#LI-CA1\n#azure\n#databricks\n#datalakehouse\n#datamodeling\nAdditional Information\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.","47":"Joining Capco means joining an organisation that is committed to an inclusive working environment where you\u2019re encouraged to #BeYourselfAtWork. We celebrate individuality and recognize that diversity and inclusion, in all forms, is critical to success. It\u2019s important to us that we recruit and develop as diverse a range of talent as we can and we believe that everyone brings something different to the table \u2013 so we\u2019d love to know what makes you different. Such differences may mean we need to make changes to our process to allow you the best possible platform to succeed, and we are happy to cater to any reasonable adjustments you may require. You will find the section to let us know of these at the bottom of your application form or you can mention it directly to your recruiter at any stage and they will be happy to help.\nAbout Us\nCapco is global technology and business consultancy with a focus on the financial services sector. We are passionate about helping our clients succeed in an ever-changing industry, combining innovative thinking with unique expert know-how.  The solutions we offer our customers every day are as diverse as our employees.\nWould you like to make a difference and put your ideas into practice with us?\nWhat we are looking for:\nPosition: Data Modelling Consultant \nLocation: London, UK\nYour Capco Day\nConducting business analysis to gain the necessary level of understanding for data definition and usage\nWorking closely with subject matter experts & data architects, analyse the data requirements & produce and update logical and physical data models\nIdentifying data entities and describing the relationships between them, as a model, based on business context, process and existing systems clearly showing source to target mappings\nSupporting both intra-system data design and embedding of metadata management behaviours\nBe able to generate the physical implementation of the data model\nExecution of governance related activities, including review forums and project delivery in adherence to standards\nPreferred Experience\nStrong data modelling experience, preferably within the financial services industry working on large scale data migration programmes\nGood understanding of financial reference data and experience with FS industry standard models (e.g. fpML, FIX, FIBO) is highly preferred\nData modelling skills and a solid understanding of the difference between conceptual, logical and physical models\nStakeholder Management experience and skills - able to converse with all levels of stakeholders to understand and extract the required business requirements\nProject lifecycle implementation experience including familiarity of agile projects\nUnderstanding of UML and\/or logical data models\nUnderstanding of RDBMS\u2019s and proficiency with SQL\nUnderstanding and experience of modelling semi-structured schemas such as JSON and\/or XML\nExperience with data modelling tools e.g. Sparx Enterprise Architect, Erwin modelling software, Power designer, Visual Paradigm or similar\nExperience with curating ontologies and experience with RDF\/OWL\/TTL is highly preferred.\nWHY JOIN CAPCO?\nYou will work on engaging projects with some of the largest banks in the world, on projects that will transform the financial services industry.\nWe offer:\nA work culture focused on innovation and building lasting value for our clients and employees\nOngoing learning opportunities to help you acquire new skills or deepen existing expertise\nA flat, non-hierarchical structure that will enable you to work with senior partners and directly with clients\nA diverse, inclusive, meritocratic culture\nEnhanced and competitive family friendly benefits, including maternity \/ adoption \/ shared parental leave and paid leave for sickness, pregnancy loss, fertility treatment, menopause and bereavement","48":"FLO (FLO Recharge pour V\u00c9) est \u00e0 la recherche d\u2019un.e Architecte de donn\u00e9es pour rejoindre les \u00e9quipes Data Platform et gouvernance de donn\u00e9es, avec le mandat principal de d\u00e9finir des normes d\u2019architecture de donn\u00e9es et de fa\u00e7onner le cadre de traitement des donn\u00e9es, de l\u2019acquisition de donn\u00e9es brutes depuis les chargeurs de v\u00e9hicule jusqu\u2019\u00e0 la diffusion d\u2019\u00e9v\u00e9nements aux applications orient\u00e9es client.\nLieu : Montr\u00e9al ou Ville de Qu\u00e9bec, QC, Canada\n\u00c0 PROPOS DU R\u00d4LE\nD\u00e9finir le cadre d\u2019architecture de donn\u00e9es.\nD\u00e9finir les normes, les principes, y compris la mod\u00e9lisation, les m\u00e9tadonn\u00e9es, la s\u00e9curit\u00e9, les donn\u00e9es de r\u00e9f\u00e9rence, les donn\u00e9es de base, la gestion des versions, la lign\u00e9e et le cycle de vie des donn\u00e9es.\nDiriger des discussions d\u2019architecture et des exercices de conception pour \u00e9duquer sur les meilleures pratiques de gestion de donn\u00e9es.\nIdentifier les domaines d\u2019am\u00e9lioration dans les syst\u00e8mes actuels; inclure la dimension des donn\u00e9es lorsqu\u2019il s\u2019agit de d\u00e9cider d\u2019acheter ou de construire une solution logicielle.\nTravailler avec les \u00e9quipes de d\u00e9veloppement pour mettre en \u0153uvre des solutions de stockage et de livraison de donn\u00e9es, qui sont communes \u00e0 diff\u00e9rentes applications dans un contexte de modernisation infonuagique.\n\u00c9tablir des objectifs clairs qui s\u2019harmonisent avec ceux des d\u00e9partements R&D logiciel, R&D mat\u00e9riel, science, ing\u00e9nierie et gouvernance de donn\u00e9es.\nCollaborer efficacement avec les \u00e9quipes non techniques, les chefs de produits, les chefs de projets et les membres des \u00e9quipes support.\nDiriger en assurant un bon fonctionnement et un progr\u00e8s constant de l\u2019\u00e9quipe.\n\u00c0 PROPOS DE VOUS\nBaccalaur\u00e9at en g\u00e9nie, sciences ou domaine connexe.\nUn minimum de 5 ans d\u2019exp\u00e9rience dans le domaine \u00e0 travailler avec les donn\u00e9es, que ce soit en conception, tests de donn\u00e9es, programmation et script (SQL, Python, Scala, Terraform).\nExp\u00e9rience de travail dans la cr\u00e9ation d\u2019une infrastructure de donn\u00e9es dans un environnement Cloud de production r\u00e9parti sur plusieurs sites.\nExp\u00e9rience \u00e9prouv\u00e9e avec les mod\u00e8les de gestion de donn\u00e9es pour des environnement h\u00e9t\u00e9rog\u00e8nes de type lac, entrep\u00f4ts, et \u201clakehouses\u201d.\nNiveau avanc\u00e9 avec le \u201cstreaming\u201d de donn\u00e9es et les technologies bas\u00e9es sur les \u00e9v\u00e9nements.\nCapacit\u00e9 \u00e0 g\u00e9rer et planifier simultan\u00e9ment des t\u00e2ches et leurs priorit\u00e9s.\nCapacit\u00e9 d\u00e9montr\u00e9e \u00e0 travailler en \u00e9quipe et volont\u00e9 de contribuer activement.\nCapacit\u00e9 \u00e0 communiquer efficacement en fran\u00e7ais et en anglais, que ce soit en personne ou \u00e0 l\u2019aide d\u2019outils de communication.\nVOS ATOUTS\nUne ma\u00eetrise dans un domaine pertinent est un plus.\nInter\u00eat pour les \u00e9cosyst\u00e8mes de donn\u00e9es massives et d\u2019apprentissage statistiques, comme Databricks et Snowflake.\n\u00catre l'heureux conducteur d'un v\u00e9hicule \u00e9lectrique!\nENGLISH\nFLO (FLO EV Charging) is looking for a Data Architect to join the Data Platform and Governance teams, with the main mandate to define data architecture standards and shape the data handling framework, from EV charger raw data acquisition to customer-facing application event streaming.\nLocation : Montr\u00e9al or Qu\u00e9bec City, QC, Canada\nABOUT THE ROLE\nSet the data architecture framework.\nDefine standards, principles, including modeling, metadata, security, reference data, master data, versioning, lineage, and data lifecycle.\nLead architectural discussions and design exercises to educate best practices for data management.\nIdentify areas of improvement across current systems; weight in when it comes to decide whether to buy or build.\nWork with development teams to implement data storage and delivery solutions that are common across different applications to reach our cloud modernization milestones.\nEstablish clear goals and objectives that align with those of R&D Software, R&D Hardware, Data Science, Engineering, and Governance departments.\nCollaborate effectively with non-technical teams, product managers, project managers, and support team members.\nLead, make things work, get things done, and be a great team player.\nABOUT YOU\nBachelor's degree in engineering, science, or related field. A Master\u2019s is a plus.\nA minimum of 5 years industry experience working with data, coding and scripting (SQL, Python, Scala, Terraform) design and testing.\nWorking experience building a data infrastructure in a production Cloud environment distributed over multiple sites.\nProven experience with data management models for data lake, data warehouses and data lakehouses.\nAdvanced level with data streaming and event-based technologies.\nCapacity to manage and plan simultaneously concurrent tasks and priorities.\nDemonstrated ability to teamwork and willingness to contribute actively.\nAbility to communicate effectively in French and English, whether it is in person or using communication tools.\nYOUR ASSETS\nA master\u2019s degree in a relevant field is a plus.\nInterest for Big Data and Machine Learning ecosystems, such as Databricks and Snowflake.\nProud owner of an electric vehicle!\nBenefits\n\u00c0 PROPOS DE FLO\nLe si\u00e8ge social de FLO est situ\u00e9 \u00e0 Qu\u00e9bec, avec des \u00e9quipes r\u00e9gionales r\u00e9parties aux \u00c9tats-Unis et au Canada. Notre entreprise poss\u00e8de une culture dynamique et veille \u00e0 ce que les employ\u00e9s soient soutenus et engag\u00e9s, notamment \u00e0 travers l'\u00e9volution de leur carri\u00e8re dans l'\u00e8re post-pand\u00e9mique.\nFLO est une entreprise prosp\u00e8re qui affiche de solides r\u00e9sultats d'une ann\u00e9e \u00e0 l'autre, notamment en mati\u00e8re de ventes et gr\u00e2ce \u00e0 l'expansion des op\u00e9rations et de la pr\u00e9sence sur le march\u00e9 en Nord Am\u00e9ricain. Il y a une mentalit\u00e9 positive et entrepreneuriale pour la croissance, le d\u00e9veloppement des affaires et une culture de haute performance o\u00f9 nous travaillons en \u00e9quipe pour atteindre des objectifs ambitieux.\nVous serez \u00e9paul\u00e9 par des coll\u00e8gues exp\u00e9riment\u00e9s et comp\u00e9tents qui soutiendront le processus d'int\u00e9gration et vous stimuleront dans votre d\u00e9veloppement professionnel au quotidien.\nDes r\u00e9unions hebdomadaires avec notre Chef de la direction pour partager la vision de l'\u00e9quipe de direction et impliquer les employ\u00e9s dans les principaux d\u00e9veloppements de l'entreprise.\nFLO offre une atmosph\u00e8re de travail agr\u00e9able et respectueuse de l'individu.\nUne r\u00e9mun\u00e9ration et des avantages conforment aux normes du secteur.\nABOUT FLO\nFLO is headquartered in Quebec City, with regional teams located throughout the US and Canada. Our company has a vibrant culture and a commitment to ensuring employees are supported and engaged, especially through the evolution of employment in the post pandemic era.\nFLO is a successful business with strong year-on-year results including direct sales, revenue generation, and through the expansion of operations and market presence across North America. There is a positive and entrepreneurial mentality for growth, business development and a high-performance culture where we work as a team to reach ambitious goals.\nYou will be backed up by experienced and knowledgeable colleagues who will support the onboarding process and engage you in your day-to-day professional development.\nWeekly townhall meetings with our CEO to share our executive team\u2019s vision and engage employees in major developments at the company.\nFLO has a pleasant working atmosphere with respect for the individual.\nCompensation package and benefits according to industry standards.","49":"Description de l'entreprise\nBusiness & Decision est un groupe international des services du num\u00e9rique, sp\u00e9cialis\u00e9, depuis sa cr\u00e9ation, dans l\u2019exploitation et l\u2019analyse de donn\u00e9es.\nBusiness & Decision conseille et d\u00e9ploie les solutions et les services les plus innovants pour accompagner les directions m\u00e9tier \u00e0 relever les d\u00e9fis majeurs de cr\u00e9ation de valeur de leurs organisations. Data Intelligence, Big Data, Data Gouvernance, v\u00e9ritables socles de l\u2019intelligence artificielle et de l\u2019exp\u00e9rience digitale, sont les domaines d\u2019expertise et de sp\u00e9cialisation du groupe.\nBusiness & Decision, filiale d\u2019Orange Business Services, emploie 2 500 talents dans 10 pays dans le monde et dans 14 villes en France.\nDescription du poste\nAu sein de notre agence Rennaise, vous int\u00e9grez une \u00e9quipe projet et contribuez \u00e0 toutes les phases de mise en \u0153uvre d\u2019une application d\u00e9cisionnelle.\nVos principales missions :\nAnimer des \u00e9tudes de cadrage.\nAuditer des architectures DATA existantes\nD\u00e9ployer des infrastructures DATA cloud ou on-premise\nTransmettre ses comp\u00e9tences \u00e0 des profils ayant une trajectoire d\u2019expertise\nRester informer, se former et former sur les nouvelles solutions DATA\nDomaine de comp\u00e9tences techniques :\n Ma\u00eetrise des technologies du Big Data (Hadoop, Spark, Kafka, Nifi, ELK\u2026)\n Maitrise des outils de d\u00e9ploiement automatis\u00e9 et DEVOPS (ANSIBLE, JENKINS, DOCKER, KUBERNETES\u2026)\nConnaissance au moins d'une architecture Cloud (AWS, AZURE, GCP\u2026)\nConnaissances d'au moins un langage de programmation objets ou\/et de langage scripts (Java, Javascript, Scala, Python\u2026)\nConnaissances en solutions de bases de donn\u00e9es (SQL, NoSQL\u2026)\nQuelques exemples de missions actuelles :\nRevue d\u2019une architecture hybride Cloudera\/Azure pour un client souhaitant \u00e9voluer vers l\u2019industrie 4.0\nMise en place d\u2019une plateforme data sous Kubernetes \u00e0 base de composants open source pour b\u00e9n\u00e9ficier des avantages du cloud sur un environnement s\u00e9curis\u00e9 souverain\nIndustrialisation d\u2019outils de monitoring Kafka sous Ansible pour un client dans le secteur du transport\nQualifications\nProfil de formation bac+5, vous justifiez d'au moins 3 ans exp\u00e9riences significatives en qualit\u00e9 d'Ing\u00e9nieur DATA et BIG DATA. \nInformations suppl\u00e9mentaires\nCe que nous vous proposons :\nUne carri\u00e8re dans un environnement multiculturel, dynamique et formateur,\nDu temps d\u00e9di\u00e9 \u00e0 des chantiers innovants permettant de tester de nouvelles technologies\nUne r\u00e9elle possibilit\u00e9 de t\u00e9l\u00e9travail,\nUn appui et un suivi r\u00e9gulier d\u2019un manager s\u00e9nior dans le m\u00e9tier,\nDes formations et les certifications associ\u00e9es au parcours de carri\u00e8re choisi.\nDes possibilit\u00e9s d\u2019activit\u00e9s compl\u00e9mentaires (avant-vente, formation, conseil, expertise, montage d\u2019offre, POC..),\nDes \u00e9v\u00e9nements festifs,\nUne int\u00e9gration au sein d\u2019une communaut\u00e9s d\u2019experts passionn\u00e9s\nPour aller plus loin\u202f: https:\/\/fr.blog.businessdecision.com\/\nVous \u00eates partant pour vivre l\u2019aventure ? Postulez d\u00e8s maintenant en nous envoyant votre CV.\nTous nos postes sont accessibles, \u00e0 comp\u00e9tences \u00e9gales, aux travailleurs en situation de handicap.","50":"This is a fully remote position. This position requires experience with the Centers for Medicare & Medicaid.\nWork on things that matter\nAd Hoc is a digital services company that helps the federal government better serve people. Our teams use modern, agile methods to design and engineer government systems that connect Veterans with services, bring affordable health care to millions of people, and support important programs like Head Start. And as we work to make critical government services intuitive, accessible, and human-centered, we\u2019re also changing how the government thinks about and uses technology. If you thrive on change, want to help close the gap between consumer expectations and government services, and can see the possibilities in ambiguity, then we want you here with us. \nWhat matters most\nAd Hoc operates according to our commitment to inclusivity, acceptance, accountability, and humility. We aren\u2019t heroes. We believe in missions larger than our individual selves and leave our egos at the door, learn from our mistakes, and iterate in order to better serve the people in our country. We prioritize building teams that represent the diversity of the people our government serves. We love the challenge of government-size projects. We want to bring skills to federal agencies, help them better meet the needs of their users, and close the gap between consumer expectations and government. \nBuilt for a remote life\nAd Hoc is remote-first and remote-always. We\u2019ve designed our culture, communications, and tools to support a nationwide distributed team since the beginning. Being remote by design allows Ad Hoc to be thoughtful and intentional about creating diverse teams and supporting them with a work environment that fits their lives. With a generous PTO policy and Slack channels for every interest (from bird watching to space nerds to parenting) our culture embraces the things happening in your life. Maybe you need to adjust your schedule to care for your family or take a bike ride. At Ad Hoc, that\u2019s embraced. \nThe Lead Data Architect is a subject matter expert in Medicaid\/CHIP data responsible for identifying data needs that are critical to the organization's short, medium and long-term strategy to ensure that data is translated and modeled to drive measured and actionable results. A Lead Data Architect will exhibit strong communication skills, with the ability to engage with Clients, data owners, engineers, and analysts to define requirements, evaluate data sets, identify variances, and recommend solutions that support a strategic and holistic approach to data integration, management and reporting. \nThe CMS business unit covers our work with the Centers for Medicare & Medicaid Services, including HealthCare.gov, Medicare.gov, and the Blue Button API. Our team supports CMS in building and improving online public experiences and APIs that are reliable, accessible, and user-centered. We are deeply embedded within CMS, partnering agency-wide to include with the Office of Communications, Office of Enterprise Data and Analytics, Center for Medicaid and CHIP Services, and Center for Medicare and Medicaid Innovation. Our work includes helping millions of people enroll in healthcare and access Medicare and Medicaid benefits, as well as helping CMS improve the quality of Medicare and Medicaid services for beneficiaries and clinicians.\nRequired:\n8+ Years of relevant experience\nCloud-based lakehouse \nPrior experience with state or federal Medicaid and\/or CHIP data\nOur Federal contracts require that you be a U.S. Citizen to be eligible for employment.\nAll work must be conducted within the U.S.\n  Nice to have:\nExperience with DataBricks, AWS QuickSight, Alation, Scala, PySpark or similar\n  The Data Analyst is responsible for (Essential Functions):\nDemonstrates experience in gathering information from end users and project stakeholders, identifying (and validating existing) requirements, and translating these into relevant data analysis and reporting\nApplies sampling techniques to determine groups to be surveyed or uses complete enumeration methods\nCleans and manipulates raw data using SQL and Python\nCompares models using statistical performance metrics, such as loss functions or proportion of explained variance\nEffectively communicates complex technical and business issues for a wide range of stakeholders\nDemonstrates an ability to evaluate metrics for purposes of informing intended goals and outcomes\nGuiding the development and execution of business logic, with the ability to provide oversight of the development of acquisition, transformation, and downstream consumption work streams\nAdvancing data governance, conducting inventory evaluations and subsequently developing solutions to eliminate identified data gaps and improve data maturity\nIdentifying approaches for data management based on specific variables, inclusive of importance, complexity and probability of success\nExhibiting strategic and critical analysis leadership, with the ability to summarize findings and provide comprehensive recommendations\nExecuting effective governance by collaborating with data owners and users to modify or implement new repeatable and reliable businesses processes \nAligning data architecture and standardize data access patterns to make data available to business intelligence tools, apps, and websites\nFostering team excellence in SQL and complex data schema design. \nCollaborating with a multidisciplinary team of product owners, engineers, designers and researchers, and adapting communication style to the audience\nProviding oversight of data organization, data dictionary standardization, and glossary development to align with data models\nBenefits\nCompany-subsidized Health, Dental, and Vision Insurance\nVanguard 401K Plan\nUnlimited Vacation\nContinuing Education\/Annual Conference Attendance Stipend\nAd Hoc LLC is an Equal Opportunity\/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, national origin, ancestry, sex, sexual orientation, gender identity or expression, religion, age, pregnancy, disability, work-related injury, covered veteran status, political ideology, marital status, or any other factor that the law protects from employment discrimination. \nIn support of the\u202fColorado Equal Pay Transparency Act, and others like it across the country, Ad Hoc job descriptions feature the starting range we reasonably expect to pay to candidates who would join our team with little to no need for training on the responsibilities we've outlined above. Actual compensation is influenced by a wide range of factors including but not limited to skill set, level of experience, and responsibility. The range of starting pay for this role is $113,900 - $149,040 and information on benefits offered is here. Our recruiters will be happy to answer any questions you may have, and we look forward to learning more about your salary requirements.","51":"ItsaCheckmate is a growing and dynamic start-up organization founded in 2016. A leader in the restaurant-tech space, ItsaCheckmate provides a two-way integration layer between the restaurant\u2019s Point of Sale (POS) system and the evolving digital ordering ecosystem. ItsaCheckmate\u2019s 21,000+ restaurant clients include small \u201cmom-and-pops\u201d to major chains like Wendy\u2019s, Arby\u2019s, Five Guys, Buffalo Wild Wings, and White Castle, and is proudly integrated with 50+ POS systems and 100+ ordering platforms including UberEats, DoorDash, and Grubhub.\nThe Data Architect We are looking for a high performing professional who can dive in, get their hands filthy and actually build out and maintain our data architecture.\n\nResponsibilities:\nThis person should be an expert in ETL \/ data architecture.\nWe are beginning to focus more and more on analytics and are using tools like Matillion. Someone with strong experience and expertise in ETL can help run systems and reports efficiently.\nThis person will also be responsible for creating reports and fulfilling the company's analytics needs.\nThey should have a specific background in working with Postgres to help solve some of the database problems.\nRequirements\nPassion for Data Architecture\n6-8 years of experience in Data Analysis and Architecture\nMust have hands-on experience with ETL tools and Data transformations\nspecifically in addition to robust SQL knowledge.\nAny graduation \/ post-graduation.\nMust be flexible to work in the US working hours.\nExcellent communication\n\nBenefits\nCompetitive salary\nAwesome work environment at a fast growing company with a huge vision\nWorking in a company that started off with a remote first culture.","52":"INTRACOM TELECOM is a global telecommunication systems and solutions vendor operating for over 40 years in the market. The company innovates in the wireless access and transmission field, offers a competitive telco software solutions portfolio and combines its offerings with a complete range of professional services.\nOur mission is to shape the future through technology and we recognize that human capital is the key factor to achieve this in today's business environment. Our company's highly specialized and experienced personnel are pivotal to achieving demanding objectives and advancing the capabilities of the company to better serve its customers.\nWithin this framework, we are looking for an experienced Big Data Solution Architect to join our Data Analytics team. As a Big Data Solution Architect, you will be responsible for designing and implementing large-scale, high-performance data solutions that meet the needs of our clients.\nResponsibilities:\nWork with clients in multiple industries including Telco, Finance, Utilities and Retail to understand their business requirements and design solutions that meet their needs\nDesign large-scale, high-performance data solutions using Big Data technologies such as Hadoop, Spark, Hive, MinIO, Trino and Kafka\nDesign data integration, storage, and retrieval solutions that meet performance and scalability requirements and coordinate development with teams of Data Engineers.\nWork with data scientists and analysts to build data pipelines and models for analysis and reporting\nCollaborate with infrastructure and DevOps teams to ensure data solutions are deployed and managed in a scalable and reliable manner\nStay up-to-date with the latest Big Data technologies and trends and recommend new solutions and approaches to clients\nRequirements\nBachelor's or Master's degree in Computer Science or a related field\nAt least 5 years of experience as a Big Data Solution Architect\nStrong experience with Big Data technologies such as Hadoop, Spark, Hive, and Kafka\nExperience designing and implementing large-scale data solutions\nExperience with data integration, storage, and retrieval solutions\nExperience with data modeling, data warehousing, and data visualization\nStrong understanding of cloud-based infrastructure and deployment models\nStrong communication skills and the ability to work effectively with clients and cross-functional teams\n\nIf you have a passion for solving complex data problems and enjoy working in a fast-paced, dynamic environment, we encourage you to apply for this exciting opportunity.\nBenefits\nINTRACOM TELECOM provides an excellent working environment which encourages team spirit, cooperation and continuous learning, in which the career prospects depend on each employee\u2019s performance. Remuneration is competitive and aligned with the company\u2019s credo \u201cour competitive advantage is our human capital\u201d.\nFurther, the facility of a company bus is convenient for every employee.\nEducation and continuous personal improvement constitute major priorities for the company to keep abreast with the technology evolution and maintain the high growth rate and its strategic position.\nOur company applies policies for equal opportunities irrespective of caste, national origin, religion, disability, gender, sexual orientation, union membership, political affiliation or age.","53":"Company Description\nCompany Overview\nHitachi Solutions is a global solutions integrator passionate about designing, developing, and delivering cutting edge cloud solutions to help our clients innovative across their entire business.  Our firm develops the business services and technology powering some of the products you use every day \u2013 and is closely aligned with Microsoft and other leaders in the cloud computing space.  \nWhat sets Hitachi Solutions apart is both our industry focus, and the intellectual property that we bring to our customers.  Recognized for our achievements year after year, we strive to be the trusted advisor of large and medium sized enterprises alike \u2013 helping them move fast to achieve strategic business initiatives with distinguished engineering, hard work, and compassion.  With over 3,000 team members across 14 countries, in our 18 years of focus our company has seen explosive growth and high customer satisfaction.  This has allowed us to offer exceptionally compelling salaries, 401k match, family leave, and health benefits.  And no \u2013 we will not make you come into an office or ask for an inflexible work schedule. \nA part of Hitachi, Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world\u2019s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies\nJob Description\nNEW PRODUCT DEVELOPMENT AND INNOVATIONS TEAM \nThis position is housed in our New Product Development team formed in 2021.  Joining this team represents an opportunity to fast-track your career and to work with a team of fun and nerdy colleagues in a disruptive startup atmosphere: focused on hypergrowth, moving quickly, and making mistakes in the furtherance of innovation and sound engineering.  \n\nArmed with an existing book of business, and a stable financial parent \u2013 it is the goal of this group to transform our company into a billion-dollar product company, by focusing on engineering excellence and making the cloud easier for our customers. \nSpark Solution Architect (Databricks, Python, Spark) \nThis is a full-time role on the Empower product team architecting Big Data solutions. Our Empower product is Platform-as-a-Service (PaaS) \/ Software-as-a-Service (SaaS) Datalakehouse and Business Intelligence subscription-based Intellectual Property,\nIndividuals in this role will architect complex data pipelines products that manage business critical operations, and large-scale analytics pipelines.   Qualified applicants will have expert Spark data engineering expertise and have robust Python software engineering experience.  \nResponsibilities:\nScope business problems and architect Big Data pipeline solutions \u2013 for structured, unstructured and live streaming data \u2013 in Spark and Databricks platforms\nDesign complex data pipeline products which manage business-critical operations and large-scale analytics applications\nUtilize Airflow, Dbt, Data Factory, or similar DAG Tools for orchestration of robust data pipelines\nSupport analytics, data science and\/or engineering teams and understand their unique needs and challenges\nDesign & POC integration of new features into proprietary Spark package(s)\nPartner with Product Management team to identify user stories and maintain prioritized backlog\nAn owner of Empower's Spark repository; review & approve pull requests\nEnforce code standards: formatting, comments, documentation, unit tests, etc.\nInstill excellence into the processes, methodologies, standards, and technology choices embraced by the team\nMentor developers in Spark and Python best practices\nIdentify opportunities for continued improvement of existing proprietary Spark package(s)\nDedicate time to continuous learning to keep the team appraised of the latest developments in the space\nCommitment to developing technical maturity across the company\nQualifications\nPlease note: Although our position is remote \/ virtual \/ work-from-home, you MUST reside, and be authorized to work, in Canada.\n10+ years of Data Engineering expertise including 6+ years designing and building data pipelines for batch and streaming data is REQUIRED\n6+ years of experience with Spark\/PySpark is REQUIRED\n4+ years of experience with Databricks is REQUIRED\n4+ years of hands-on experience implementing Big Data solutions in a cloud ecosystem, including Data\/Delta Lakes, is REQUIRED\n2+ years of experience with DAG Tools (Airflow, Dbt, Data Factory, or similar) is REQUIRED\nAzure cloud experience preferred; will consider AWS, GCP or other cloud platform experience in lieu of\n2+ years of experience with Kafka or other live streaming technology is REQUIRED\nExperience with unit testing or data quality frameworks is REQUIRED\n2+ years of experience with source control (git) on the command line is REQUIRED\n5+ years of SQL experience, specifically writing complex, highly optimized queries across large volumes of data is REQUIRED\nExperience with CI\/CD deployment pipelines\nKnowledge of software design patterns\n   #LI-CA1\n#REMOTE\n#DATABRICKS\n#SPARK\n#PYTHON\n#DATALAKEHOUSE\nAdditional Information\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.","54":"Description de l'entreprise\nDans un monde o\u00f9 savoir se transformer est la cl\u00e9 du succ\u00e8s, Wavestone s'est donn\u00e9 pour mission d'\u00e9clairer et guider les grandes entreprises et organisations dans leurs transformations les plus critiques avec l'ambition de les rendre positives pour toutes les parties prenantes. C'est ce que nous appelons \u00ab The Positive Way \u00bb.\nLe cabinet Wavestone r\u00e9alise un chiffre d\u2019affaires de l\u2019ordre de 470 M\u20ac et rassemble pr\u00e8s de 4 000 collaborateurs en Europe \u2013 o\u00f9 il figure parmi les leaders ind\u00e9pendants du conseil \u2013 aux Etats-Unis et en Asie.\nWavestone est cot\u00e9 sur Euronext \u00e0 Paris.\nPour plus d'informations, consulter www.wavestone.com.\nEn stage de fin d'\u00e9tudes ou alternance, rejoignez notre Bureau de Nantes, fort de plus de 130 collaborateurs !\nLe bureau de Nantes offre l\u2019opportunit\u00e9 d\u2019intervenir sur des missions vari\u00e9es et \u00e0 forte valeur ajout\u00e9e, du cadrage strat\u00e9gique \u00e0 la r\u00e9alisation du projet.\nNos consultant.e.s interviennent au sein d'entreprises de r\u00e9f\u00e9rence implant\u00e9es dans la r\u00e9gion Grand Ouest, et accompagnent en proximit\u00e9 nos clients dans leurs transformations digitales et leurs d\u00e9cisions strat\u00e9giques.\n Nous intervenons en particulier sur les terrains d\u2019excellence suivants :\nCybersecurity & Digital Trust : strat\u00e9gie et conformit\u00e9 Cybers\u00e9curit\u00e9 (gestion de crise, infrastructures critiques, r\u00e9glementations), s\u00e9curisation de la transformation digitale (cloud, SOC, IT Security), identit\u00e9 num\u00e9rique et services de confiance (IAM, PAM, PKI, f\u00e9d\u00e9ration d'identit\u00e9s), audit, tests d'intrusion et r\u00e9ponse aux incidents (pentest, audit PASSI, red team, forensics, gestion de crise)\nIT & Data Architecture : business transformation (open architecture), industrial IoT (embedded system, IoT platforms), data (gouvernance de donn\u00e9es, plateformes nouvelle g\u00e9n\u00e9ration), Next Gen IT (cloud, devops, automation, container, laC)\nDigital & Emerging Technologies : Next Gen IT (smart networks, telecoms), digital workplace (New Ways of Working, change, employee experience, workplace, communication), business transformation (UX, design thinking), industrial IoT (LoRa, Sigfox, lpwan)\nDigital & IS Strategy : business transformation (digital strategy, CRM, sch\u00e9ma directeur, digitalisation de processus), mod\u00e8le op\u00e9rationnel (optimisation, agilit\u00e9, Devops), change (communication, formation, comp\u00e9tences), performance (portefeuille projet, ITSM, qualit\u00e9, risques), num\u00e9rique responsable\nPublic Sector : transformation digitale des services publics, assistance au pilotage de grands projets, organisation des collectivit\u00e9s, Smart City\/Territoire Intelligent, sant\u00e9 publique, relations usagers, \u00e9ducation, transports et mobilit\u00e9\nPendant votre stage, vous aurez l'occasion d'intervenir sur :\nLa r\u00e9alisation d'une \u00e9tude autour d'un sujet prospectif et innovant permettant d'enrichir vos connaissances acad\u00e9miques, de d\u00e9couvrir en profondeur les sujets qui font l'actualit\u00e9 chez nos clients et d'appr\u00e9hender la m\u00e9thodologie reconnue de Wavestone dans les missions de conseil.\nDes missions op\u00e9rationnelles clients, au sein d'\u00e9quipes projets, permettant de d\u00e9velopper les comp\u00e9tences cl\u00e9s attendues pour un.e consultant.e junior (analyse et synth\u00e8se, relationnel, compr\u00e9hension de l'environnement et du march\u00e9, responsabilit\u00e9 client\/mission).\nDescription du poste\nDans le cadre de votre \u00e9tude, voici quelques des exemples de sujets que nous vous proposons d\u2019adresser au sein du Bureau de Nantes :\nOffres IT & Data Architecture :\nQue valent les challengers du cloud public ?\nApplications modernes : microservices & cloud\nAzure Stack, AWS Outposts et autres : le cloud public chez soi ?\nBig Data & Cloud : comment le Cloud revoit les architectures de donn\u00e9es ?\nLes APIs, le nouveau Mary Poppins de l'infra ?\nQualifications\n\u00c9tudiant.e au sein d'une \u00e9cole d'ing\u00e9nieur.e.s, de management ou grande universit\u00e9, vous \u00eates \u00e0 la recherche d'un stage de fin d'\u00e9tudes ou d\u2019une alternance dans un cabinet de conseil. Vous poss\u00e9dez un excellent relationnel, le go\u00fbt du travail en \u00e9quipe et un sens prononc\u00e9 de la qualit\u00e9. Vous savez associer analyse et synth\u00e8se et \u00eatre force de proposition.\nSi votre objectif est d'\u00eatre consid\u00e9r\u00e9.e comme un.e collaborateur.rice \u00e0 part enti\u00e8re : soucieux.se d'\u00eatre acteur.rice d'un projet d'entreprise ambitieux, ayant envie de mettre \u00e0 profit son talent et son enthousiasme dans une soci\u00e9t\u00e9 o\u00f9 il est possible de prendre des responsabilit\u00e9s rapidement et de vivre une exp\u00e9rience riche, alors donnez-vous les chances de rejoindre nos \u00e9quipes et postulez ! \nInformations suppl\u00e9mentaires\nNos stages et alternances s'inscrivent tous dans une logique de pr\u00e9-embauche.\nLe dispositif de t\u00e9l\u00e9travail est largement d\u00e9ploy\u00e9 au sein de Wavestone pour tous les m\u00e9tiers.  \nWavestone est un employeur inclusif qui s'engage pour l'\u00e9galit\u00e9 des chances. Dans le cadre de cette politique de diversit\u00e9 et inclusion, Wavestone accompagne les personnes en situation de handicap et\/ou n\u00e9cessitant un am\u00e9nagement durant leur process de recrutement et lors de leur prise de poste.","55":"Company Description\nCompany Overview\nHitachi Solutions is a global solutions integrator passionate about designing, developing, and delivering cutting edge cloud solutions to help our clients innovative across their entire business.  Our firm develops the business services and technology powering some of the products you use every day \u2013 and is closely aligned with Microsoft and other leaders in the cloud computing space.  \nWhat sets Hitachi Solutions apart is both our industry focus, and the intellectual property that we bring to our customers.  Recognized for our achievements year after year, we strive to be the trusted advisor of large and medium sized enterprises alike \u2013 helping them move fast to achieve strategic business initiatives with distinguished engineering, hard work, and compassion.  With over 3,000 team members across 14 countries, in our 18 years of focus our company has seen explosive growth and high customer satisfaction.  This has allowed us to offer exceptionally compelling salaries, 401k match, family leave, and health benefits.  And no \u2013 we will not make you come into an office or ask for an inflexible work schedule. \nA part of Hitachi, Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world\u2019s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies\nJob Description\nNEW PRODUCT DEVELOPMENT AND INNOVATIONS TEAM \nThis position is housed in our New Product Development team formed in 2021.  Joining this team represents an opportunity to fast-track your career and to work with a team of fun and nerdy colleagues in a disruptive startup atmosphere: focused on hypergrowth, moving quickly, and making mistakes in the furtherance of innovation and sound engineering.  \n\nArmed with an existing book of business, and a stable financial parent \u2013 it is the goal of this group to transform our company into a billion-dollar product company, by focusing on engineering excellence and making the cloud easier for our customers. \nSpark Solution Architect (Databricks, Python, Spark) \nThis is a full-time role on the Empower product team architecting Big Data solutions. Our Empower product is Platform-as-a-Service (PaaS) \/ Software-as-a-Service (SaaS) Datalakehouse and Business Intelligence subscription-based Intellectual Property,\nIndividuals in this role will architect complex data pipelines products that manage business critical operations, and large-scale analytics pipelines.   Qualified applicants will have expert Spark data engineering expertise and have robust Python software engineering experience.  \nResponsibilities:\nScope business problems and architect Big Data pipeline solutions \u2013 for structured, unstructured and live streaming data \u2013 in Spark and Databricks platforms\nDesign complex data pipeline products which manage business-critical operations and large-scale analytics applications\nUtilize Airflow, Dbt, Data Factory, or similar DAG Tools for orchestration of robust data pipelines\nSupport analytics, data science and\/or engineering teams and understand their unique needs and challenges\nDesign & POC integration of new features into proprietary Spark package(s)\nPartner with Product Management team to identify user stories and maintain prioritized backlog\nAn owner of Empower's Spark repository; review & approve pull requests\nEnforce code standards: formatting, comments, documentation, unit tests, etc.\nInstill excellence into the processes, methodologies, standards, and technology choices embraced by the team\nMentor developers in Spark and Python best practices\nIdentify opportunities for continued improvement of existing proprietary Spark package(s)\nDedicate time to continuous learning to keep the team appraised of the latest developments in the space\nCommitment to developing technical maturity across the company\nQualifications\nPlease note: Although our position is remote \/ virtual \/ work-from-home, you MUST reside, and be authorized to work, in the US.\n10+ years of Data Engineering expertise including 6+ years designing and building data pipelines for batch and streaming data is REQUIRED\n6+ years of experience with Spark\/PySpark is REQUIRED\n4+ years of experience with Databricks is REQUIRED\n4+ years of hands-on experience implementing Big Data solutions in a cloud ecosystem, including Data\/Delta Lakes, is REQUIRED\n2+ years of experience with DAG Tools (Airflow, Dbt, Data Factory, or similar) is REQUIRED\nAzure cloud experience preferred; will consider AWS, GCP or other cloud platform experience in lieu of\n2+ years of experience with Kafka or other live streaming technology is REQUIRED\nExperience with unit testing or data quality frameworks is REQUIRED\n2+ years of experience with source control (git) on the command line is REQUIRED\n5+ years of SQL experience, specifically writing complex, highly optimized queries across large volumes of data is REQUIRED\nExperience with CI\/CD deployment pipelines\nKnowledge of software design patterns\n   #LI-CA1\n#REMOTE\n#DATABRICKS\n#SPARK\n#PYTHON\n#DATALAKEHOUSE\nAdditional Information\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.","56":"Company Description\nMerkle is a leading data-driven, technology-enabled, global performance marketing agency that specializes in the delivery of unique, personalized customer experiences across platforms and devices. For more than 30 years, Fortune 1000 companies and leading nonprofit organizations have partnered with Merkle to maximize the value of their customer portfolios. The agency\u2019s heritage in data, technology, and analytics forms the foundation for its unmatched skills in understanding consumer insights that drive people-based marketing strategies. Its combined strengths in performance media, customer experience, customer relationship management, loyalty, and enterprise marketing technology drive improved marketing results and competitive advantage. With 9,600+ employees, Merkle is headquartered in Columbia, Maryland, with 50+ additional offices throughout the US, EMEA, and APAC. In 2016, the agency joined the Dentsu Aegis Network. For more information, contact Merkle at 1-877-9-Merkle or visit www.merkleinc.com.\nJob Description\nThe purpose of this role is to take database implementation projects through the entire development life cycle.  This role will work as the solution lead and will be directly involved in the architecture, solution design, development, testing and deployment of the solution. This role serves as the technical subject matter expert for the solution.\nKey responsibilities:\nArticulates feasible technology choices that meet the requirements; ability to put forth a viable, scalable technology point of view; be knowledgeable and conversant with the offline and online (digital) marketing technology landscape\nBridges business and technical requirements to provide a cohesive, seamless solution to scale and perform\nHas the ability to wear multiple technology hats across systems integration, technology consulting and technology solution design and architecture\nParticipates and leads technology discussions with prospects (RFP support)\nLeads large-scale technology implementations including understanding of scoping, estimation and managing timeline\/budget\nHas experience in legacy migration and re-platform of technology solutions\nLeads technology conversations with senior management (be an internal and external technology solutions evangelist) and be the technology voice of the solution\nIs responsible and accountable for the underlying client technology solution architecture\nLeads CRM platform development programs and roadmap Data warehouse architecture and ETL design\nHas experience in DB integration and execution, data architecture, database, process (ETL and services), identity Management, open source (GNU, Apache, Java, Linux, HDFS et al) tools and technologies, real-time application integration (web services)\n Additional Information\nDentsu (the \"Company\") is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant or employee of the Company, on the basis of age, sex, sexual orientation, race, color, creed, religion, ethnicity, national origin, alienage or citizenship, disability, marital status, veteran or military status, genetic information, or any other legally recognized protected basis under federal, state or local laws, regulations or ordinances. Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and\/or certain state or local laws. A reasonable accommodation is a change in the way things are normally done that will ensure an equal employment opportunity without imposing an undue hardship on the Company. Please contact recruiting@dentsuaegis.com if you need assistance completing any forms or to otherwise participate in the application process or to request or discuss an accommodation in connection with a job at the Company to which you are applying.\nThe anticipated salary range for this position is $113,000-$130,000. Salary is based on a range of factors that include relevant experience, knowledge, skills, other job-related qualifications, and geography.  \n#LI-DB2\nAbout dentsu \nDentsu is the network designed for what\u2019s next, helping clients predict and plan for disruptive future opportunities in the sustainable economy. Taking a people-centered approach to business transformation, dentsu combines Japanese innovation with a diverse, global perspective to drive client growth and to shape society www.dentsu.com. \nWe are champions for meaningful progress and we strive to be a force for good\u2014for our people, for our clients, for the industry and for our society. We keep our people at the center, creating space for growth, understanding and learning so they can thrive. We embed diversity, in our mindset, in our solutions and in our teams to empower an inclusive, equitable and culturally fluent environment. Building this culture within our teams makes us better collaborators with each other and with our clients, driving better outcomes for all.\nDentsu (the \"Company\") is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant or employee of the Company, on the basis of age, sex, sexual orientation, race, color, creed, religion, ethnicity, national origin, alienage or citizenship, disability, marital status, veteran or military status, genetic information, or any other legally-recognized protected basis under federal, state or local laws, regulations or ordinances. Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and\/or certain state or local laws. A reasonable accommodation is a change in the way things are normally done that will ensure an equal employment opportunity without imposing an undue hardship on the Company. Please contact recruitingops@dentsu.com if you need assistance completing any forms or to otherwise participate in the application process or to request or discuss an accommodation in connection with a job at the Company to which you are applying. ","57":"Position Title: Senior Business Data Engineer\/Data Architect\nLocation: India, Remote\nJob Description\nHands-on Enterprise Data Architect for a growing company with many data needs.  Influence and define corporate Data Lake and Data Warehouse practice.   Administer existing data flows and resource managers, and prescribe current and future data flows based on corporate Data Lake and Data Warehouse practice.\nHelp prescribe and administer big data practice. \nAdminister and enhance current procedures, ETL, views, and other data mechanics hands-on.  Manage folks who help with the same.\nWhat you will do: \nDesign, prototype, prescribe, administer practice, ETL technology, data bridging technology (ODATA\/other), data lake, and data warehouse.  Provide examples and prescription to corporate clients.  Support legacy data projects.  Be the data expert.\nWork with proprietary technologies like ADF, Snowflake, S3, SQLServer, FiveTran, ODATA, SAP CDS Views scripting, other.\nQualifications\n5+ years of RDBMS administration, DDL, DML\n5+ years of Working with cloud storage technologies hands-on:  S3, Redshift, Snowflake, Azure, other, combination thereof.\nExperience using ETL tools like ADF, OpenPrise, Informatica, scripting, Oracle, other.\nComfortable scripting in Python, PowerShell, other\nUnderstanding of dimensional schemas and BI tools.  Facts and measures.  Experience with PowerBI, Tableau, Domo, or similar reporting tools.\nUnderstanding of Big Data concepts, tools, and techniques\nPractical experience with machine learning applications and AI\n#LI-VG2","58":"Location: Gurgaon,Uttar Pradesh,India\nAbout Material\nMaterial is a global strategy, insights, design, and technology partner to companies striving for true customer centricity and ongoing relevance in a digital first, customer-led world. By leveraging proprietary, science-based tools that enable human understanding, we inform and create customer-centric business models and experiences + deploy measurement systems \u2013 to build transformational relationships between businesses and the people they serve.\nAbout Srijan\nSrijan is a global engineering firm that builds transformative digital paths to better futures for Fortune 500 enterprises to nonprofits all over the world. Srijan brings advanced engineering capabilities and agile practices to some of the biggest names across FMCG, Aviation, Telecom, Technology, and others. We help businesses embrace the digital future with cloud, data, API and platform centric technologies and adapt to changing business models and market demands. Srijan leads in Drupal with 350+ Drupal engineers, 80+ Acquia certifications. Srijan is also a Drupal Enterprise Partner & Diamond Certified\n What you will get:\nCompetitive Salaries with flexi benefits \nGroup Mediclaim Insurance and Personal Accidental Policy\n30+ Paid Leaves in a year \nLearning and Development of quarterly budgets for certification\nNote: By applying to this position you will have an opportunity to work from your preferred Hybrid working location from the following: Bengaluru, Delhi, Gurgaon, Kolkata,Chennai,Hyderabad,Pune,Indore,Jaipur and Ahmadabad\n Job description\nExperience in service architecture, development, and high performance and scalability.\nExperience in Spark, SQL performance tuning, and optimization.\nExperience with architectural design and development of large-scale data platforms and data applications.\nGood hands-on experience in AWS\nIn-depth understanding of Spark Hive Frameworks and their internal architecture\nStrong programming background with Java \/ Python.\nPractical exposure to end-to-end design and implementation process of Near-Real-Time and Batch Data Pipelines.\nStrong SQL (Hive\/Spark) skills and experience tuning complex queries\nExcellent understanding of AWS storage, and its compute services. Able to effectively use of AWS managed services - Step function, EMR, Lambda, Glue and Athena.\nHands-on experience on Data Lake and ETL pipeline development\nExpertise on designing and building new Cloud Data platform and its optimization at organization level.\nHands-on experience in Big Data technologies - Hadoop, Sqoop, Hive and Spark including DevOps.\nMust Have:\n12-15 years of big data technologies or data platform architecture experience with deep technology expertise in Hive, HDFS, Spark, Kafka, Java, or Scala,Python, Pyspark etc.\nExperience in service architecture, development, and high performance and scalability.\nExperience in Spark, SQL performance tuning, and optimization.\nExperience with architectural design and development of large-scale data platforms and data applications.\nExpertise in design and management of complex data structures and data processes like ETL\/ELT.\nExpertise in managing and operating distributed big data systems, including but not limited to the Hadoop ecosystem.\nA deep understanding of issues in multiple areas such as data acquisition and processing, data management, distributed processing, and high availability is required.\nKnowledge of Teradata.\nExpertise on designing and building new Cloud Data platform and it s optimization at organization level.\nStrong past experience on designing AWS data lake and surrounding ecosystem development.\nGood to have\nUnderstanding of sage maker and ML algorithms\nExperience in migrating workloads from on-premise to cloud and cloud to cloud migrations\nExperience on AWS services like RDS, DynamoDB, Redshift\nAbility to drive the deployment of the customers workloads into AWS and provide guidance, cloud adoption model, service integrations, appropriate recommendations to overcome blockers and technical road-maps for AWS cloud implementations.\nExtensive, real-world experience designing technology components for enterprise solutions and defining solution architectures and reference architectures with a focus on cloud technologies.\nAct as a subject-matter expert OR developer around AWS and become a trusted advisor to multiple teams.\nCoach and mentor engineers to raise the technical ability of the rest of the team, and\/or to become certified in required AWS technical certifications\n  Apply to this job","59":"High performing team members. Challenging projects. A stable and profitable company. And a great place to work! This is what you can expect if you join the Quisitive team. Founded in 2016, Quisitive is a publicly traded, global Microsoft partner specializing in Microsoft platform and complementary technologies, custom solutions, and offerings that drive digital transformation and business value for enterprise customers. Our team of professionals has a long history of successfully delivering award-winning Microsoft solutions, and our culture of continual learning ensures that we remain committed to Microsoft\u2019s long-term strategy. Quisitive was recently named the 2022 Microsoft US Health and Life Sciences Partner of the Year.\nWhat do we attribute our award-winning success to? The people we hire, of course! People don\u2019t join the Quisitive team for a job. They come to Quisitive to build a career \u2013 to continue their infinite quest to learn; to deliver on the most innovative and exciting work of their lives; and to be part of a high-performing and fun culture. We\u2019ll provide you the tools and leadership that you need to be successful, and let you do what you do best!\nIt is a very exciting time of growth for Quisitive and we are currently hiring a Data Architect to join our Global IT and Innovation team.  This team is responsible for the strategy, design, and implementation of best of breed solutions to enable our Sales, Delivery, Finance, and Operations teams.  In addition, this team is responsible for setting and governing the strategy, architecture, and investments in intellectual property and products that we take to market to our customers.\nThis person will work in our corporate headquarters in Dallas, TX (Irving) in a hybrid work model. \nWhat will my role be?\nAs a Data Architect, you will:\nDefine, design, and establish data practices, architecture, and solutions within Azure to support all aspects of Quisitive\u2019s business.\nPlan and deliver short- and long-term projects utilizing strong business, technical and interpersonal skills that will include architecting, engineering, developing, and deploying data solutions to create business insights that are targeted, accurate, fast, and reliable; facilitate architecture review workshops with the team to ensure technology and business alignment.\nProvide hands-on development, enhancement, and maintenance of our internal data warehouse, analytics, and AI platform including an effort to review and re-architect the existing data warehouse and extend\/enhance it by incorporating data sets from disparate sources to provide a consolidated view of our business (e.g., Finance, Sales, Delivery Operations, Marketing\u2026) through dashboards and reports that utilize data intelligence. technologies like Azure Synapse, SQL Data Warehouse, and visualizations in Power BI\nWork with Quisitive leadership to analyze business goals, define technical\/functional needs, and develop strategies and execution plans using Microsoft\u2019s big data tools to benefit the longer-term business strategy.\nUnderstand the business data, source systems, and data flows between systems.\nCollaborate on best practices with our external customer-facing Data and AI consulting team.\nWhat\u2019s required?\nStrong proficiency with Microsoft data and analytics technologies including Azure Synapse, Azure Analysis Services, Azure Data Factory, Azure Data Lake, Azure SQL, SQL Data Warehouse, query languages (e.g., T-SQL\/MDX), and Power BI.\nDesire to work in a team environment and ability to work across organization functional boundaries, and also work on individual assignments and projects.\nA credible, professional presence; strong written and verbal communication skills.\nStrong problem solving, analytical, time management, and organizational skills.\nTechnical Capabilities and Experience:\n10+ years of technical experience analyzing System Requirements, Architecting, Designing, Implementing, Sourcing Star Schema & Relational Data Modeling, ETL, Processing\nLarge-scale analytical platforms and modern data warehouse design and development\nAbility to implement Azure based data ingestion solutions\nAzure Data Lake, Delta Lake and Lakehouse frameworks and concepts\nAzure SQL and cloud data solutions; strong SQL database skills\nHands-on experience migrating mission critical databases\nMulti-dimensional and Tabular Cube design, development, performance tuning and troubleshooting\nAutomated processing, data validation, error checks, and alerts design\nLeadership in dashboard and reporting design and implementation\nData Visualization, Validation Mining and Auditing\nAptitude for data manipulation with T-SQL, Python, Scala, etc.\nFamiliarity with Agile\/Scrum\nExperience with Git\/Azure DevOps, ARM Templates, and CI\/CD pipelines related to data work\nKnowledge of Master Data Management (MDM) and Data Quality tools and processes\nWhat would set me apart?\nExperience with Azure and cloud data solutions working with data from multiple sources including Dynamics CRM and ERP.\nExperience with big data technologies including Azure Cosmos DB, Kubernetes Services, Azure ML, and NoSQL\nSpark\/Databricks certification or experience\nMicrosoft certifications in database and business intelligence technologies (DP-203, MB-260, AZ-400, AZ-500, AI-102)\nExperience with data science and machine learning tools and techniques\nAlthough this is not a direct customer facing role, previous consulting experience is a plus to allow for deeper understanding of Quisitive\u2019s business\nWe are looking for curious initiative takers to join our team, so if you are passionate about being a leader and working with smart people that are committed to accomplishing great things, then apply today!\nNo agencies or third parties, please.\nUS Citizens and those authorized to work in the US are encouraged to apply.  We are unable to offer visa sponsorships at this time.\nAbout Quisitive\nWith significant growth since 2016, Quisitive is rapidly achieving our vision of becoming the premier, global Microsoft partner, and we continue to expand across the United States, Canada and India. Our teams have grown by diversifying our delivery model to include nearshore and offshore capabilities.  Within our growing Global Cloud Solutions business, we deliver technical business solutions through a portfolio of IP solutions aligned to industry or business function to accelerate customer business goals, and we deliver technical cloud solutions to help customers achieve their digital transformation goals. In addition, Quisitive has a portfolio of industry-focused solutions that address customer challenges in healthcare, manufacturing, state & local government, performance management, and payment processing.\n   ","60":"Company Description\nCapTech is a team of master builders, creators, and problem solvers who help clients grow efficient, successful businesses. We unite diverse skills and perspectives to transform how data, systems, and ingenuity enable each client to advance what\u2019s possible in a changing world.  \nAs perceptive partners, our U.S-based consultants find inspiration in the unknown and enjoy getting our hands dirty solving our clients\u2019 myriad of challenges. Across industries and business goals, we fuse technical depth and analytical prowess with creative savvy to move clients forward. This drive helps each organization use technology, management, and insight to turn ideas into action. Together, we create outcomes that exceed the expected \u2014 which is one of the reasons we\u2019ve been on the Inc. 500\/5000 list for over a decade. \nJob Description\nCapTech Data Architects match our clients\u2019 business goals with available technologies when developing a strategy for a successful data delivery implementation. We improve our clients\u2019 business value by enhancing data use, improving effectiveness of information stewardship, and streamlining data flows. After gaining in-depth understanding of our client\u2019s business challenges, our architects apply experience-based insight and use state-of-the-art tools and techniques to identify the best solutions. We view our Data Architects as thought leaders in the data space. We task them with growing CapTech talent and expanding data and analytics delivery capabilities. \nSpecific responsibilities for the Data Architect position include:  \nAssessing and advocating data management technologies and practices eliminating gaps between the current state and a well-targeted future state \nInterpreting and delivering impactful strategic plans improving data integration, data quality, and data delivery in support of business initiatives and roadmaps \nFormulating and articulating architectural trade-offs across solution options before recommending an optimal solution ensuring technical requirements are met \nMotivating and developing staff through teaching, empowering, and influencing technical and consulting \u201csoft\u201d skills \nCollaborating with client stakeholders and development staff to ensure data architecture recommendations maximize the value of client data across the organization \nDriving innovative technology solutions through thought leadership on emerging trends \nSharing project solutions and outcomes with colleagues to improve delivery on future projects \nPartnering with CapTech business development team to demonstrate CapTech\u2019s technical capabilities, envision a proposed solution CapTech can offer, and estimate proposed work plans. \nQualifications\n5+ years of experience implementing with a variety of on-premises and cloud data management, integration, visualization, and analytical technologies \nAdvanced proficiency in end-to-end data architecture solutions including ingestion, storage and relational modeling leveraging industry standard languages including SQL and Python\nDemonstrated proficiency in the design and implementation of modern data architectures and concepts such as cloud services (e.g., AWS, Azure, GCP), real-time data distribution (e.g., Kafka, Kinesis, DataFlow, Airflow), NoSQL (e.g., MongoDB, DynamoDB, HBase, CosmosDB) and modern data warehouse tools including Snowflake and DataBricks\nAbility to think strategically and relate architectural decisions and recommendations to business needs and client culture \nAbility to assess traditional and modern data architectural components based on business needs \nFamiliarity with recommending data governance best practices including MDM, security, privacy and policies\nAdditional Information\nWe want everyone at CapTech to be able to envision a lasting and rewarding career here, which is why we offer a variety of career paths based on your skills and passions.  You decide where and how you want to develop, and we help get you there with customizable career progression and a comprehensive benefits package to support you along the way.  Alongside our suite of traditional benefits encompassing generous PTO, health coverage, disability insurance, paid family leave and more, we\u2019ve launched extended benefits to help meet our employees\u2019 needs. \nCapFlex \u2013 Employee-first mentality that supports a remote and hybrid workforce and empowers daily flexibility while servicing our clients\nLearning & Development \u2013 Programs offering certification and tuition support, digital on-demand learning courses, mentorship, and skill development paths\nModern Health \u2013A mental health and well-being platform that provides 1:1 care, group support sessions, and self-serve resources to support employees and their families through life\u2019s ups and downs\nCarrot Fertility \u2013Inclusive fertility and family-forming coverage for all paths to parenthood \u2013 including adoption, surrogacy, fertility treatments, pregnancy, and more \u2013 and opportunities for employer-sponsored funds to help pay for care\nFringe \u2013A company paid stipend program for personalized lifestyle benefits, allowing employees to choose benefits that matter most to them \u2013 ranging from vendors like Netflix, Spotify, and GrubHub to services like student loan repayment, travel, fitness, and more\nEmployee Resource Groups \u2013 Employee-led committees that embrace and incorporate diversity and inclusion into our day-to-day operations\nPhilanthropic Partnerships \u2013 Opportunities to engage in partnerships and pro-bono projects that support our communities. \n401(k) Matching \u2013 Generous matching and no vesting period to help you continue to build financial wellness\nCapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness \u2014 each foundational to our core values.  We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace. For more information about our Diversity, Inclusion and Belonging efforts, click HERE. \nAt this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.  \n#LI-LM1 \n#LI-Remote","61":"Company Description\nHitachi Solutions is a global Microsoft solutions integrator passionate about developing and delivering industry-focused solutions that support our clients to deliver on their business transformation goals. Our industry focus, expertise, and intellectual property is what truly sets us apart. We have earned, and continue to maintain, a strategic relationship with Microsoft. Recognized for our achievements - teaming with our clients to deliver innovative digital solutions and services - is how we have achieved year after year recognition.\nAs their trusted advisor, we support our clients to deliver on their strategic business initiatives as they unify, automate, and modernize their data and operations to increase efficiency, reduce costs, and enhance their customer\u2019s experience. Our over 3,000 team members across 14 countries, and our 18 years of 100% focus on Microsoft technologies and business applications, is how we deliver excellence through expert services and industry-focused cloud solutions. \nA part of Hitachi, Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world\u2019s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies.\nJob Description\nPlease note:  Although this is a Remote \/ Virtual \/ Work-From-Home career opportunity, candidates MUST reside, and be authorized to work without sponsorship, in Canada.\n This is a full-time role in our New Product organization for professionals with a proven history of execution, and a desire to rapidly expand a product organization.  Our team is seeking a Senior Data Architect, with a strong background in data definition, modeling, and implementation.  \n This is a hands-on architect role where the individual will be responsible for the overall design of solutions within the data ecosystem serving our customers. This role will require someone who is experienced in designing data schemas using Kimball\/Dimensional modeling and pipelines in Databricks for data warehouses\/lakehouses and reporting systems, is able to evaluate multiple technologies and technical solutions, and be a hands-on contributor for engineering goals for multiple engineering teams. Additionally, as a technical leader within the team, you will mentor and coach your team members; therefore, top candidates have experience as either a team lead or manager. \n Responsibilities\nScope and execute with independence. Work with the product team to understand platform capabilities and leverage those capabilities to bring customer\u2019s data estate. \nIdentify and articulate technical and operational requirements for data pipelines and the models they populate; be able to optimize these pipelines for high performance\/resiliency workloads. \nInstill excellence into the processes, methodologies, standards and technology choices embraced by the team with customer teams, and junior staff. \nLead requirements discovery and delivery workshops \u2013 helping customers understand their options and guiding them to the best options. \nBe an advocate for the customer, and support delivery leadership (Director, VPs) in managing client expectations. \nDedicate time to continuous learning to keep the team and customers appraised of the latest developments in the space.\nA committed teacher and someone who enjoys developing technical maturity across the company. \nExperience supporting analytics, data science and\/or engineering teams and understand their unique needs and challenges.\nQualifications\n8+ overall years of professional experience including 4+ years\u2019 experience in designing high-scale Kimball\/Dimensional models is REQUIRED \n4+ years of experience with data modeling, schema design patterns and modern data access patterns (including API, streams, data lake) is REQUIRED\n2+ years as a proven leader interacting with customers (client facing) to collect requirements and manage a technical data backlog is REQUIRED; therefore you must have excellent interpersonal skills, both written and spoken, as well as a consultative\/collaborative style.\n2+ years with Databricks and Spark framework are REQUIRED\n2+ years of experience building data applications, microservices and\/or APIs using Python, Scala or an equivalent language is REQUIRED\n2+ years of experience with SQL, knowledgeable in complex queries and joins is REQUIRED; experience with UDF and\/or Stored Procedure development is HIGHLY DESIRED\n2 + years Azure Data Services including Azure Data Factory, ADLS, and Synapse is HIGHLY DESIRED; strong experience with AWS will be considered in lieu of.\n  #REMOTE\n#LI-CA1\n#azure\n#databricks\n#datalakehouse\n#datamodeling\nAdditional Information\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.","62":"Every journey begins with a first step.\nEvery discovery begins with an idea.\nEvery Innovation Centre begins with the first employees.\nConsult Red combines world class experts in Digital Media to offer a unique service to giants in the media industry (e.g., Comcast, Liberty Global, DirecTV) and beyond. We are small, dynamic and agile. Our clients have big ideas, our work is technically challenging and, because we are small, we offer an outstanding service and an honest, and a unique friendly culture internally.\nOur clients want more from us. They want to see more people who share our values and so we seek best-in-class professionals who share our passion for doing more than the ordinary. We will offer the highest quality of technical services in areas of embedded, middleware, cloud computing, virtualisation and even AI, all wrapped up in a culture of values that makes us unique.\nAnd now our journey in India begins \u2013 are you ready to begin something exciting, fresh? Somewhere you will be the first, have a say in everything that happens and impress the world with your skills? We are seeking for our Innovation Centres an AI Solution Architect!\nMain responsibility for the AI architect is to bring his\u202fexperience in production AI systems\u202frelated to computer vision currently (still and video). In future we expect to look at other areas of AI. Note that this is NOT a data scientist role - model development role. It is about using, tailoring deploying existing models into production.\nWhat we need you to bring\nShall have experience and be fluent with deploying AI models to production (currently mostly Computer Vision)\no on the embedded devices with restricted computing power and memory\no deploying models on powerful edge machines\no computing optimisation and balance between accuracy, speed and memory usag\nCapable create an AI area selecting approaches and building architectures solving business needs\nModel training experience and training parametrisation to optimise training sessions to match critical project goals\nKnowledge transfer and reuse of\u202falready existing models\u202f(i.e application of Transfer Learning and similar techniques)\nKeep pace with recent papers and breakthroughs in computer vision. Understanding architectures and their pros and cons in context of the use-case.\nModel deployment lifecycle including A\/B testing, failure case gathering, model refinement and re-deploy\nRunning experiments and optimising business cases\nExamine training data and propose enrichment\nUnderstand edge devices lifecycle and upgradeability\nDecide on performance monitoring KPIs of deployed code and propose improvements\nArchitecture in feedback loop to the product to improve\nWork with our customers to validate business approaches and propose solutions\nWorking with other teams to incorporate AI modules into existing firmware or cloud deployments.\nPossess general data science and engineering skills\nSpecific skills\nMust have knowledge of at least one ML frameworks:\u202fTensorflow, PyTorch, Scikit-learn or similar\nMust have experience with deploying models on constrained devices. E.g. conversion to Tensorflow lite\nUsing pre trained DNN and transfer learning highly desirable\nExperience of using ML for Image (still or video) processing\nThe Rewards of Starting this Journey with us:\nA strong voice in how we grow in India (recruitment, culture, operations)\nFlexible time and hybrid working\nCompany bonus scheme\nPaid time off including holidays, bank holidays and sick days for flexible use\nLong service award (additional holidays)\nOpportunities to train, develop and grow, as well as learn from talented colleagues\nHealth care for you and your family\nPersonal Accident Insurance\nLife Assurance\nReferral bonus\nAbout Us\nConsult Red was started about 20 years ago by five engineers with a shared vision. They created a place where top talents are valued and appreciated, where prestigious international customers get excellent quality of service, and where people simply take care of each other. With this DNA we have consistently grown, and we are now 350 people with 6 offices in the UK, US and Poland. And we want to take it further. Indian talent is at the heart of our growth plans.","63":"In this role you will be helping to grow the Rackspace Cloud data practice.\u202f You will be the expert in the region and support the delivery of our data projects on Azure.\u202f Our Data Architects are experienced technologists with technical depth and breadth, along with strong interpersonal skills. In this role, you will work directly with customers and our team to help enable innovation through continuous, hands-on, deployment across technology stacks, will serve as the Data SME for our customers and be the focal touchpoint in engagements.   As the expert you\u2019ll be involved in presenting to customers at events and promoting our capabilities to Azure.\u202f With a large Azure data team of over 200+ globally it is also an opportunity to mentor and shape the data practice during our growth phase.\u202f  More generally, Data Architect are the cornerstone of our delivery success, overseeing our most strategic accounts. They are empowered to make key delivery decisions and work closely with technical resources as well as our Engagement\/Project Managers to ensure our customers experience successful outcomes.\u202f\u202f  If you get a thrill from working with cutting-edge technology and love to help solve customers\u2019 problems, we\u2019d love to hear from you.  \nData Specialization:\nLead, define and implement end-to-end modern data platforms in support of analytics and AI use cases \nDesign and Drive reusable assets, growing Analytics and DevOps capabilities.\nSolution and deliver modern Data Platforms and Advanced Analytics solutions for clients.\nCollaborate with enterprise architects, data architects, ETL developers & engineers, data scientists, and information designers to lead identification and definition of required data structures, formats, pipelines, metadata, and workload orchestration capabilities \nAddress aspects such as data privacy & security, data ingestion & processing, data storage & compute, analytical & operational consumption, data modeling, data virtualization, self-service data preparation & analytics, AI enablement, and API integrations \nBe the technical liaison between customers and engineering teams \nBe a big data evangelist by educating a variety of customers on the value of cloud and data services \nHelp support in pre-sales.\nKey Requirements:\n5+ years' experience leading engagements from design to implementation of creative data solutions leveraging the latest in Spark based modern data platforms on public cloud\nAt least 4 full lifecycle data platform deployments on Azure using 1st party Services\nStrong Spark, SQL, Data Modeling, Data lakehouse concepts.\nStrong programming \/ scripting experience using python and scala.\nStrong experience using Data and AI tools such as Azure Storage, Stream Analytics, CosmosDB, SQL DW, Azure Databricks, Azure Data Catalog and Azure Data Factory.\n5+ years' experience architecting solutions for optimal extraction, transformation and loading of data from a wide variety of traditional and non-traditional sources such as structured, unstructured, and semi-structured using SQL, NoSQL and data pipelines for real-time, streaming, batch and on-demand workloads \n3+ years' experience with analytics\/data management strategy formulation, architectural blueprinting and effort estimation of analytics \n5+ years working in cloud or multi-server complex environments.  Extensive experience with Azure is required.\nAbility to simplify complex technical concepts into an easy-to-understand non-technical language to facilitate, communicate and interact with executives and business stakeholders \nAbility to deal with ambiguity by making the appropriate decisions considering the relative costs and benefits of potential actions.  \nExperience with Agile development methods in data-oriented projects \nExperience with Dashboarding and Reporting Tools used in the industry (Tableau, Power BI, Qlik, etc.) \nCertifications in architecture, data engineering and development from Azure.\nKnowledge of software configuration management environments and tools such as JIRA, Git, Jenkins, TFS, Shell, PowerShell, Bitbucket.\nEducation:\nBachelor's degree in Engineering, Computer Science, Information Systems, or Business required\nExperience may substitute for the degree requirement at a rate of 3 years\u2019 experience for 1 year of education.\nHigh school diploma or equivalent required\nThe following information is required by the\u202fColorado Equal Pay Transparency Act and applies only to individuals working in the state of Colorado. The anticipated starting pay range of Colorado applicants for this role is $117,000-$188,500.  \nActual compensation is influenced by a wide array of factors including but not limited to skill set, level of experience, licenses and certifications, and specific work location. Information on Benefits \u2013offered.\n#LI-VM1, #LI-Remote\nAbout Rackspace TechnologyWe are the multicloud solutions experts. We combine our expertise with the world\u2019s leading technologies \u2014 across applications, data and security \u2014 to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future. More on Rackspace TechnologyThough we\u2019re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.","64":"Company Description\nHitachi Solutions is a global Microsoft solutions integrator passionate about developing and delivering industry-focused solutions that support our clients to deliver on their business transformation goals. Our industry focus, expertise, and intellectual property is what truly sets us apart. We have earned, and continue to maintain, a strategic relationship with Microsoft. Recognized for our achievements - teaming with our clients to deliver innovative digital solutions and services - is how we have achieved year after year recognition.\nAs their trusted advisor, we support our clients to deliver on their strategic business initiatives as they unify, automate, and modernize their data and operations to increase efficiency, reduce costs, and enhance their customer\u2019s experience. Our over 3,000 team members across 14 countries, and our 18 years of 100% focus on Microsoft technologies and business applications, is how we deliver excellence through expert services and industry-focused cloud solutions. \nA part of Hitachi, Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world\u2019s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies.\nJob Description\nThis is a full-time role in our New Product organization for professionals with a proven history of execution, and a desire to rapidly expand a product organization.  Our team is seeking a Senior Data Architect, with a strong background in data definition, modeling, and implementation.  \nThis is a hands-on architect role where the individual will be responsible for the overall design of solutions within the data ecosystem serving our customers. This role will require someone who is experienced in designing data schemas using Kimball\/Dimensional modeling and pipelines in Databricks for data warehouses\/lakehouses and reporting systems, is able to evaluate multiple technologies and technical solutions, and be a hands-on contributor for engineering goals for multiple engineering teams. Additionally, as a technical leader within the team, you will mentor and coach your team members; therefore, top candidates have experience as either a team lead or manager. \nQualifications\nScope and execute with independence. Work with the product team to understand platform capabilities and leverage those capabilities to bring customer\u2019s data estate. \nIdentify and articulate technical and operational requirements for data pipelines and the models they populate; be able to optimize these pipelines for high performance\/resiliency workloads. \nInstill excellence into the processes, methodologies, standards and technology choices embraced by the team with customer teams, and junior staff. \nLead requirements discovery and delivery workshops \u2013 helping customers understand their options and guiding them to the best options. \nBe an advocate for the customer, and support delivery leadership (Director, VPs) in managing client expectations. \nDedicate time to continuous learning to keep the team and customers appraised of the latest developments in the space.\nA committed teacher and someone who enjoys developing technical maturity across the company. \nExperience supporting analytics, data science and\/or engineering teams and understand their unique needs and challenges.\nQualifications\n8+ overall years of professional experience including 4+ years\u2019 experience in designing high-scale Kimball\/Dimensional models is REQUIRED \n4+ years of experience with data modeling, schema design patterns and modern data access patterns (including API, streams, data lake) is REQUIRED\n2+ years as a proven leader interacting with customers (client facing) to collect requirements and manage a technical data backlog is REQUIRED; therefore you must have excellent interpersonal skills, both written and spoken, as well as a consultative\/collaborative style.\n2+ years with Databricks and Spark framework are REQUIRED\n2+ years of experience building data applications, microservices and\/or APIs using Python, Scala or an equivalent language is REQUIRED\n2+ years of experience with SQL, knowledgeable in complex queries and joins is REQUIRED; experience with UDF and\/or Stored Procedure development is HIGHLY DESIRED\n2 + years Azure Data Services including Azure Data Factory, ADLS, and Synapse is HIGHLY DESIRED; strong experience with AWS will be considered in lieu of.\nAdditional Information\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.\nAll your information will be kept confidential according to EEO guidelines.\n #LI-CC1","65":"Do you want the opportunity to leverage your skills to make a direct impact on the world\u2019s leading life sciences, consumer products, and retail companies? Join Clarkston Consulting as a Cloud Data Architect to help deliver creative business solutions to our market-leading clients as a part of our team of experienced professionals.\nWe are looking for motivated, self-driven leaders who are energized by team results and interested in joining a firm that values its culture and people as its biggest strengths. Together, we can help find the answers to our clients most challenging business problems.\nWhat You\u2019ll Do\nClarkston gives you the opportunity to deliver great solutions, become recognized as an industry expert, and help build a great practice.\nAs a Cloud Data Architect at Clarkston, you will:\nDesign and develop platforms for scalable solutions\nDesign, prototype, and develop Big Data Platforms utilizing Azure or AWS\nWork with all levels of staff, management, stakeholders, and vendors\nShowcase advanced analytical and conceptual skills to create original concepts\/theories for various projects\nProvide forward thinking technical expertise in current and emerging technologies, trends, and practices\nAnticipate internal and\/or external business challenges including regulatory; recommend process, product or service enhancements\nDesign\/drive architectural strategies with business and strategic goals\nTranslate business goals and objectives into IT capabilities and develop technical solutions\nHow You\u2019ll Grow\nAt Clarkston, we feel that we provide the greatest value to our clients through a combination of our industry expertise, business process knowledge, and consulting excellence.\nBeyond your day-to-day responsibilities, throughout your career at Clarkston you will:\nHave the support and mentorship of your Clarkston colleagues and leaders\nOwn your career \u2013 you'll be able to take charge of your career journey with diverse opportunities to lead and expand your skillset both at the client site and within the firm\nHave the opportunity to make a real and positive impact not only the clients you work with, but on the firm as well\n\nTravel Requirement\nTravel is an integral part of this role and is estimated to average 20-30%. This may vary based upon client and project needs. While travel is a requirement of the role, due to COVID-19 restrictions, all non-essential travel has been limited and any on-site requests are subject to review. When not traveling, consultants work from their home office. Relocation is not required.\nRequirements\nWhat We\u2019re Looking For:\nThe Cloud Data Architect will help support our client(s) by serving in a lead capacity on client initiatives, mentoring more junior data architects and data engineers in Clarkston\u2019s analytics team, assisting in defining client solutions, and support managing the delivery of those solutions.\nAn ideal candidate as a Cloud Data Architect would have the following qualifications and experience:\nExperience with data management solutions using data lake platform tools and technologies\nExperience with data architecture, specifically in support of data warehousing, business intelligence, master data management, and reference data management\nFamiliarity with delivering Data as a Service (DaaS) concepts from enterprise repositories using REST APIs\nFamiliarity with Azure or AWS-based data and data management tools, such as Azure SQL Azure Data Catalog, Azure Service Fabric, and microservices\nFamiliarity with data integration points for TOGAF (or other recognized architecture framework)\nWorking knowledge of development or operations framework methodologies, including Information Technology Infrastructure Library (ITIL), Systems Development Life Cycle (SDLC), etc.\nFamiliarity with developing data catalogues, and integrating with existing enterprise architecture\nFamiliarity with cloud data platforms and process automation\nExperience in using various data modeling techniques and their appropriate usage in data integration\nExperience in working with all levels of staff, management, stakeholders, and vendors\nSignificant experience in performing analysis of business processes and functions\nSignificant experience in work as an engineer or technical subject matter expert in two or more of the following areas: infrastructure; data; application; and\/or security related technology\nEffective skill creating system diagrams for review by both technical and non-technical audiences\nAdvanced analytical and conceptual skills to create original concepts\/theories for various projects\nDevelop and apply architectural governance based on business and information technology strategies\nEffective skill applying innovative approaches to solve technical design issue\nAnticipate internal and\/or external business challenges including regulatory; recommend process, product or service enhancements\nProvide forward thinking technical expertise in current and emerging technologies, trends and practices\nMinimum degree required: bachelor's degree from an accredited college or university\nBenefits\nOur benefits include:\nComprehensive Health and Wellness Benefits (Medical, Dental, Vision, and more)\n401k with company contributions\nPaid vacation, personal days, holidays, and sick leave\nPaid Parental Leave and Family Building Benefits (Adoption, Surrogacy, and Infertility Support)\nLife and Disability Insurance\nTraining and Professional Development investments, Tuition Assistance, and more\nVisit Careers at Clarkston to learn more about our culture, benefits, and opportunities. We hope you\u2019ll join us!\nCOVID-19 Vaccination Statement\nWhile Clarkston Consulting has not mandated vaccination at this time, COVID-19 vaccinations are required in order to access Clarkston Consulting facilities and those of many of our clients. With this in mind, all prospective hires will be required to provide their vaccination status.","66":"We are looking for a Data Architect to help define and improve our backend application architecture in terms of data location and work on general performance, scalability and robustness improvements.\n\nDevelop, align, and evolve the enterprise-wide data strategy to support delivery of corporate objectives.\nBuild a framework of principles to ensure data integrity across the business (including but not limited to ERP, CRM, BI, Data warehouse, external interfaces etc.).\nMaintain and shape appropriate Enterprise Architecture artefacts including; Entity Relationship Models, Data dictionary, taxonomy to aid data traceability.\nProvide technical oversight to solution delivery in creating business driven solutions adhering to the enterprise architecture and data governance standards.\nBe an advocate of data security principles and ensure appropriate security practices are embedded in any data strategy.\nContribute as to how the business evolves Data Governance practices and influence the adoption of data standards.\nDevelop key performance measures for data integration and quality.\nSupport third party data suppliers in developing specifications that are congruent with the Enterprise data architecture.\nRequirements\nProven experience in architecting and implementing Business Intelligence and Data warehouse platforms, Master data Management, data integration and OLTP database solutions.\nExtensive knowledge of industry best practices around data architecture in both cloud based and on prem solutions.\nComprehensive understanding of the principles of and best practices behind data engineering, and the supporting technologies such as RDBMS, NoSQL, Cache, Event Streaming & In-memory stores.\nDeep understanding of data warehousing and data transformation (extract, transform and load) processes and the supporting technologies such as Google Dataflow, Looker, Amazon Glue, EMR, Azure Data Factory, Data Lake, other analytics products.\nExcellent problem solving and data modelling skills (logical, physical, semantic and integration models) including; normalisation, OLAP \/ OLTP principles and entity relationship analysis.\nExperience mapping key Enterprise data entities to business capabilities and applications.\nA strong knowledge of horizontal data lineage from source to output.\nFluent in English, both written and spoken.\nBenefits\nVibrant modern multi city office spaces including barista, pool table, table tennis, and down time facilities.\nHybrid\/remote work arrangements.\nBi-Monthly company wide social and team building activities.\nLunch Vouchers.\nTraining and development opportunities\nPension scheme.\nPrivate medical and dental insurance.","67":"Company Description\nDans un monde o\u00f9 savoir se transformer est la cl\u00e9 du succ\u00e8s, Wavestone s'est donn\u00e9 pour mission d'\u00e9clairer et guider les grandes entreprises et organisations dans leurs transformations les plus critiques avec l'ambition de les rendre positives pour toutes les parties prenantes. C'est ce que nous appelons \u00ab The Positive Way \u00bb.\nWavestone rassemble plus de 3 000 collaborateurs dans 8 pays. Il figure parmi les leaders ind\u00e9pendants du conseil en Europe.\nWavestone est cot\u00e9 sur Euronext \u00e0 Paris et labellis\u00e9 Great Place To Work.\nPour plus d'informations, consulter www.wavestone.com.\nJob Description\nL\u2019exploitation num\u00e9rique des donn\u00e9es porte une formidable promesse de valeur pour les entreprises. Elle constitue un puissant levier d\u2019am\u00e9lioration de la performance op\u00e9rationnelle et d\u2019exploration de nouvelles sources de revenus.\nNous anticipons que les champions de demain seront les entreprises qui auront su placer au c\u0153ur de leurs m\u00e9tiers l\u2019exploitation de la data par l\u2019Intelligence Artificielle et le Machine Learning.      \nPour accompagner ses clients \u00e0 saisir les opportunit\u00e9s issues de la valorisation de la donn\u00e9e et \u00e0 engager leur transformation data, le cabinet Wavestone a d\u00e9cid\u00e9 de renforcer ses \u00e9quipes Suisse avec des collaborateurs \u00e0 m\u00eame de combiner de fortes comp\u00e9tences scientifiques, informatiques et m\u00e9tiers.\nRattach\u00e9(e) au bureau Suisse de Wavestone, vous serez amen\u00e9(e) \u00e0 travailler sur des projets centr\u00e9s sur la Data mais aussi sur les nouvelles technologies telles que le Cloud, le DevOps, les microservices, etc.\nVous accompagnerez des entreprises, leaders de leurs secteurs, dans leurs projets de valorisation et d\u2019exploitation de la donn\u00e9e. Vous int\u00e9grerez des \u00e9quipes combinant l'ensemble des comp\u00e9tences n\u00e9cessaires \u00e0 la r\u00e9alisation de ces projets.\nVous souhaitez avant tout devenir Consultant Senior Data ce qui signifie que vous pourrez traiter, gr\u00e2ce \u00e0 des comp\u00e9tences Data Architecture, Data Management, Data Science et de Data Engineering, un projet de bout en bout depuis la qualification du besoin m\u00e9tier jusqu\u2019\u00e0 l\u2019industrialisation des solutions mais aussi orienter nos clients dans leur grand choix de transformation Data.\n Vous serez donc amen\u00e9(e) \u00e0 contribuer aux activit\u00e9s suivantes :\n\u00b7       DATA STRATEGY : accompagner nos clients sur la construction et le d\u00e9veloppement de leur strat\u00e9gie IA sur toutes les fonctions de l\u2019entreprise\n\u00b7       DATA MANAGEMENT : accompagner nos clients dans la maitrise et la gestion du cycle de vie de leur patrimoine de donn\u00e9es\n\u00b7       DATA FOR BUSINESS : accompagner les d\u00e9marches de valorisation de la donn\u00e9e et la ma\u00eetrise des sujets data sur des sujets comme la d\u00e9tection de fraude, la maintenance pr\u00e9dictive ou encore la connaissance client par l'exp\u00e9rimentation et la r\u00e9alisation de Proof of Concept jusqu'\u00e0 l'industrialisation des solutions d\u00e9velopp\u00e9es\n\u00b7       TECH AND R&D FOR DATA&AI : r\u00e9aliser des \u00e9tudes de l'\u00e9tat de l'art autour de la Data et l'Intelligence Artificielle et la mise en application des d\u00e9couvertes issues des communaut\u00e9s Data du march\u00e9 chez nos clients\n En tant que Consultant(e) Confirm\u00e9(e) \/ Senior, nous vous proposons de :\n\u00b7       D\u00e9velopper\/am\u00e9liorer des comp\u00e9tences li\u00e9es au m\u00e9tier du conseil (formalisation, prise de recul, restitution, encadrement, partage de conviction, business d\u00e9veloppement\u2026)\n\u00b7       Porter la responsabilit\u00e9 de missions de conseil chez nos clients et encadrer des \u00e9quipes de consultants\n\u00b7       Explorer puis ma\u00eetriser en profondeur les m\u00e9thodologies et technologies qui se cachent derri\u00e8re les mouvements de transformation digitale en entreprise\n Vous devrez \u00e9galement participer activement \u00e0 la vie interne du cabinet \u00e0 travers :\n\u00b7       Le d\u00e9veloppement de notre offre Data\n\u00b7       La contribution au recrutement, relations \u00e9coles, r\u00e9ponses aux propositions commerciales, formations internes, \u00e9v\u00e9nements internes\u2026\nQualifications\nDipl\u00f4m\u00e9(e) en Master ou PhD d'une grande \u00e9cole d'ing\u00e9nieurs, de management ou d'une grande universit\u00e9, vous \u00eates attir\u00e9(e) par le conseil et avez une ou plusieurs exp\u00e9riences Data r\u00e9ussies.\n\nVos qualit\u00e9s font de vous un consultant aux multiples talents et vous avez : \n\n\u00b7       Des connaissances th\u00e9oriques et pratiques sur au moins deux des axes de comp\u00e9tences recherch\u00e9es (Strat\u00e9gie et Management de la donn\u00e9e, Architecture de donn\u00e9es et Data Engineering, Datascience et Machine Learning) et une curiosit\u00e9 autour des sujets de la Data et de l\u2019Intelligence Artificielle\n\u00b7       Une ouverture vers les sujets du digital au sens large\n\u00b7       Une curiosit\u00e9 intellectuelle, un esprit critique et analytique aiguis\u00e9 vous permettant de comprendre rapidement les sp\u00e9cificit\u00e9s de nos clients et de produire des livrables de qualit\u00e9\n\u00b7       Un tr\u00e8s bon relationnel, un sens prononc\u00e9 du service et une certaine pro-activit\u00e9 pour construire une relation de confiance avec vos clients et les guider jusqu'\u00e0 l'excellence dans leurs grands projets de transformation\n\u00b7       Un go\u00fbt pour l'entreprenariat et pour l'innovation\n\u00b7       Entre 2 et 5 ans d\u2019exp\u00e9rience sur des sujets data (une premi\u00e8re exp\u00e9rience dans le monde du conseil est un plus).\n\u00b7       Une certification Data (Architecture, Data Engineering, Machine Learning) sur l\u2019un des trois principaux fournisseurs Cloud du march\u00e9 est un plus\n Par ailleurs, vous souhaitez :\n\n\u00b7       \u00catre acteur d'un projet d'entreprise ambitieux en pleine croissance en Suisse et \u00e0 l'international.\n\u00b7       Relever des d\u00e9fis et mettre votre enthousiasme au service d'une entreprise qui saura vous proposer une prise de responsabilit\u00e9s rapide.\n\u00b7       \u00c9voluer dans un environnement propice \u00e0 l'\u00e9panouissement personnel et souhaitez int\u00e9grer des \u00e9quipes \u00e0 taille humaine favorisant la proximit\u00e9 et la transmission des savoirs.\nAdditional Information\nWavestone est un employeur inclusif qui s'engage pour l'\u00e9galit\u00e9 des chances. Dans le cadre de cette politique de diversit\u00e9 et inclusion, Wavestone accompagne les personnes en situation de handicap et\/ou n\u00e9cessitant un am\u00e9nagement durant leur process de recrutement et tout au long de leur prise de poste.","68":"What we are looking for\nHumble, hungry, and quick learners. As a data architect, you will need to have solid experience providing value to organizations with skills in the disciplines of Data Architecture, Data Modeling and Engineering, and Analytics. As well as having Azure experience across various disciplines. This senior data architect role is responsible for applying new technologies, so you must be decisive and show the ability to work with clients and assist their business and technology needs. In return, we offer an exciting position at a young startup, experiencing rapid growth and the opportunity to be part of creating a consulting firm that makes a difference for our clients.\nWhat you will do\nYou will work on various Big Data, Data Warehouse and Analytics projects for our world class clients. In addressing complex client needs, you will be integrated into appropriately sized and skilled teams. This will give you the opportunity to analyze requirements, design data and analytical solutions, present future-state visions to clients and execute as part of the project team, all while working with the latest tools, such as Azure Synapse Analytics and related Microsoft technologies.\nYour Duties and Responsibilities\nLead analysis, architecture, design, and development of Azure based data warehouses and business intelligence solutions. You will own the project and lead the team to success.\nHelp customers define their Azure focused data strategies\nMentor other Data & Analytics team members\nForm a trusted advisor relationship with the project and technology leaders\nLead the project delivery team\nRequirements\nWhat you must have to be considered\n4+ years of experience working as a customer facing consultant\n2+ years of experience in Analytics and Data Warehousing on the Microsoft platform\n2+ years of experience in Team and Project leadership\nExperience working with Azure based Data Services, such as:\nAzure Data Factory\nAzure Data Lake\nAzure Synapse Analytics\nAzure Analysis Services\nPower BI\nExperience in working with Microsoft SQL base Data Skills, such as:\nSSIS\nSQL Server\nSQL Server Analysis Services\nRequirement Analysis and Project Delivery methodologies\nProven track record with designing and building solutions in Azure\nStrong communication skills tying together technologies and architectures to business results\n\nWhat would be nice for you to have\nRequirement Analysis and Project Delivery methodologies\nProven track record with designing and building solutions in Azure\nStrong communication skills tying together technologies and architectures to business results\nBenefits\nHealth Coverage: 100% Employee Coverage (Up to a 1500 PPO Plan), 60% Coverage for dependents\nDental\/Vision\nLife Insurance, Aflac, Short\/Long term disability, HSA etc.\n9 Company holidays (Ability to use them as \u2018floating\u2019 Holidays)\nPaid time off (PTO) 15 days\nFlexible Sick Time\nMaternity\/Paternity Leave (Birth Parent: 3 months, Non-birth parent: 1 month\n401k - up to a 5% match. Eligibility to contribute the month after start date. Vests as soon as you are eligible for contribution.\nOpportunities for career growth and advancement, as well as helping to shape a young consulting firm\nAbility to learn from highly skilled consultants with years of industry experience\nExposure to the latest and greatest data warehousing, analytics, and cloud technologies\nFlexible schedules in a hybrid work environment\nBasic Life Insurance (50k)\nLT and ST Disability (paid by employee)\nFlexible Spending Account (FSA) and Healthcare Savings Account (HSA)\nEmployee Assistance Program (EAP)Mental health and substance abuse conditions are serious and sometimes require 24\/7 access to resources.\nEthics and Compliance Tool: We provide employees a safe space to speak through AllVoices\nEmployee Engagement & Cultural initiatives: Health & Wellness, Pulse Surveys, and Kolbe Instinctive Strengths\nCommuter Benefits\nWeWork office provision\n\nAbout OmniData\nOmniData is a Portland, Oregon based Data and Analytics focused consulting firm leveraging the Microsoft technology stack to help organizations build their Modern Data Estates, designed to serve their digital innovation needs for many years to come. To do this, we apply deep experience in Solution Architecture, Data, Analytics, and technology to simplify the complex.\nOmniData is offering you the opportunity to work with the entire lifecycle of large Data Projects, focused on next-generation data warehousing, with surface points to Analytics, Machine Learning and AI. We offer a collaborative work culture, that enables you to produce client results with a safety net from your team. You will get to work closely with very experienced consultants who will be able to provide mentorship and career guidance. At the same time, you will be rewarded for learning fast and executing within our teams to provide solutions for OmniData clients.\nOmniData Values\nWe build partnerships that last. We are ambitious and set aggressive goals. We embody professional humility. We are prepared. Visit www.omnidata.com\/AboutUs to learn more.\nOmniData is a Portland - based Data and Analytics focused consulting firm leveraging the Microsoft technology stack to help organizations build their Modern Data Estates, designed to serve their digital innovation needs for many years to come. To do this, we apply deep experience in Solution Architecture, Data, Analytics, and technology to simplify the complex.\nOmniData is offering you the opportunity to work with the entire lifecycle of large Data Projects, focused on next generation data warehousing, with surface points to Analytics, Machine Learning and AI. We offer a collaborative work culture, that enables you to produce client results with a safety net from your team. You will get to work closely with very experienced consultants who will be able to provide mentorship and career guidance. At the same time, you will be rewarded for learning fast and executing within our teams to provide solutions for OmniData clients.\n\nOmniData Is An Equal Opportunity Employer And All Qualified Applicants Will Receive Consideration For Employment Without Regard To Race, Color, Religion, Sex, National Origin, Disability Status, Protected Veteran Status, Or Any Other Characteristic Protected By Law.","69":"Company Description\nWe pledge \"to prove IT can make a real difference to our customer's businesses\". We work hard to ensure we understand what our customers need from their technology solutions and then we deliver.\n\nWe are an award-winning company who provide world class customer service; we think big and we hire great people. Version 1 are more than just another IT services company - we are leaders in implementing and supporting Oracle, Microsoft and AWS technologies.\n\nInvest in us and we\u2019ll invest in you; if you are driven, committed and up for a challenge, we want to meet you.\nJob Description\nWe are seeing unprecedented growth across several of our key practice areas. We are looking for talented individuals, who want a challenging, dynamic work environment with honesty & integrity, excellence and drive amongst our core values as well as a strong emphasis on our people and a work-life balance.\nIf you are interested in playing a key role in growing the Data Analytics practice, designing Data solutions for our customers and building the Data team within Version 1 read on.\nResponsibilities:\nTo provide technical and design leadership to a highly skilled and motivated expert technical team.\nTo design solutions that make use of the newest technologies and industry best practices.\nWorking alongside other teams to keep Data Architecture Models up to date.\nWork with data analysts, engineers and visualisation consultants to realise your designs\nTechnical ownership for a Data project, covering technology road-map alignment, estimation, project planning, user story\/requirement creation and full development lifecycle.\nMaintain and optimize the Data Warehouse and Data Lake \/ Data Brick solutions to maximize performance\nMarshall teams to ensure excellent quality and consistency.\nPull together estimates from teams for future work.\nDriving and implementing non-functional requirements for customers\nCommunicate technical designs in conversation, documentation and presentations to stakeholders of various technical abilities.\nMake effective decisions within fast-moving delivery.\nMentoring, coaching and developing members of your team and the wider community.\nIdentify opportunities to add value to the customer in the management and delivery of its Data landscape.\nWorking with business analysts and end-users to elicit requirements & assist in developing design specifications for short-, medium- and long-term future state architectures.\nIdentifying technology trends and deriving relevant IT proposals, including migration strategies.\nEngaging with the software development lifecycle, providing design and technical coaching to project business analysts, solutions architects, development teams, test management, and project managers.\nQualifications\nEssential criteria:\nStrong background in Data Engineering, Architecture and documentation\nStrong understanding of Microsoft SQL Server, Azure, PowerApps and Power BI\nStrong familiarity of the Azure DevOps toolset & Microsoft Azure related Certifications\nProven track record of implementing end-to-end data solutions and ELT\/ETL pipeline development skills\nExperience working with solutions in the Cloud specifically Microsoft's Azure platform\nStrong SQL experience both within the SQL Azure space and on prem\nAbility to communicate well with key stakeholders and non-technical audiences\nA strong level of TSQL language skills\nExperience in leading data engineering projects\nExperience working with large-scale data environments in a data engineering role\nA demonstrable track record in a similar role is a necessity for this role.\nAdditional Information\nHere's what else we offer:\nRemote\/hybrid working - your choice! Check out our office locations\nEmployee recognition in the form of Excellence Awards and CallOut\u202fwhich are awarded by your peers. Engagement is incredibly important with local engagement teams driving our engagement events! \nGreat Place to Work award winners - United Kingdom, Northern Ireland, Spain and India\nPrivate healthcare cover\nLife Assurance\nEmployer contributed pension scheme \nEmployee discount scheme\nPathways\u202fCareer Development Quarterly ","70":"Company Description\nWe pledge \"to prove IT can make a real difference to our customer's businesses\". We work hard to ensure we understand what our customers need from their technology solutions and then we deliver.\n\nWe are an award-winning company who provide world class customer service; we think big and we hire great people. Version 1 are more than just another IT services company - we are leaders in implementing and supporting Oracle, Microsoft and AWS technologies.\n6th Best Large Workplace in the UK\nBest place to work in Ireland #GPTW2022\n10th place in Glassdoor Top 50 UK companies\nUK & Ireland\u2019s premier Oracle, Microsoft & AWS partner\nMarket leader in Oracle ERP and Cloud Applications\nConsulting, implementation and support services\n3000 strong,\u20ac255m\/ \u00a3220m revenue business\nJob Description\nWe are seeing unprecedented growth across several of our key practice areas. We are looking for talented individuals, who want a challenging, dynamic work environment with honesty & integrity, excellence and drive amongst our core values as well as a strong emphasis on our people and a work-life balance.\nIf you are interested in playing a key role in growing the Data Analytics practice, designing Data solutions for our customers and building the Data team within Version 1 read on.\nTo provide technical and design leadership to a highly skilled and motivated expert technical team.\nTo design solutions that make use of the newest technologies and industry best practices.\nWorking alongside other teams to keep Data Architecture Models up to date.\nWork with data analysts, engineers and visualisation consultants to realise your designs\nTechnical ownership for a Data project, covering technology road-map alignment, estimation, project planning, user story\/requirement creation and full development lifecycle.\nMaintain and optimize the Data Warehouse and Data Lake \/ Data Brick solutions to maximize performance\nMarshall teams to ensure excellent quality and consistency.\nPull together estimates from teams for future work.\nDriving and implementing non-functional requirements for customers\nCommunicate technical designs in conversation, documentation and presentations to stakeholders of various technical abilities.\nMake effective decisions within fast-moving delivery.\nMentoring, coaching and developing members of your team and the wider community.\nIdentify opportunities to add value to the customer in the management and delivery of its Data landscape.\nWorking with business analysts and end-users to elicit requirements & assist in developing design specifications for short-, medium- and long-term future state architectures.\nIdentifying technology trends and deriving relevant IT proposals, including migration strategies.\nEngaging with the software development lifecycle, providing design and technical coaching to project business analysts, solutions architects, development teams, test management, and project managers.\nQualifications\nEssential criteria:\nStrong background in Data Engineering, Architecture and documentation\nStrong understanding of Microsoft SQL Server, Azure, PowerApps and Power BI\nStrong familiarity of the Azure DevOps toolset & Microsoft Azure related Certifications\nProven track record of implementing end-to-end data solutions and ELT\/ETL pipeline development skills\nExperience working with solutions in the Cloud specifically Microsoft's Azure platform\nStrong SQL experience both within the SQL Azure space and on prem\nAbility to communicate well with key stakeholders and non-technical audiences\nA strong level of TSQL language skills\nExperience in leading data engineering projects\nExperience working with large-scale data environments in a data engineering role\nA demonstrable track record in a similar role is a necessity for this role.\nMust have hands-on experience Architecting and delivering solutions using the AWS Analytics platform including some of the following: AWS S3, AWS RDS, AWS Glue, AWS Redshift, AWS Kinesis, AWS Lambda, AWS Managed Kafka, AWS Sagemaker, AWS Athena.\nAdditional Information\nBefore you apply, here are some of the benefits we offer:\nQuarterly Profit SharePrivate medical insurance\nFlexible working policy & Remote Working \nIncentives for accreditations and educational assistance for courses relevant to your role.\nEmployee recognition in the form of Excellence Awards and V1Ps which your peers award.\nPathways Career Development Quarterly\nEngagement is incredibly important! Our local teams drive our engagement events!\nand much more...","71":"Founded in 2003, IT Concepts\u2019 core values \u2013 customer-centricity, teamwork, driven to deliver, innovation, and integrity \u2013 ensure we work together to be the best, realize objectives, and make a positive impact in our communities. We intentionally created and sustain our ITC culture that embraces change, experimentation, continuous learning, and improvement. We bring our design thinking problem solving approach that challenges assumptions, prioritizes curiosity, and invites complexity to deliver innovative, efficient, and effective solutions. As we continue to grow in the support of our government customers, we are looking for driven and innovative individuals to join our team.IT Concepts Inc. is currently seeking a Senior Communications Specialist to support our Defense Intelligence Client in Washington, D.C.\nIT Concepts Inc. is currently seeking a qualified Data Architect to support the Office of Human Resources (OHR) at the Defense Intelligence Agency. The Data Architect will be responsible for researching, recommending, and implementing solutions across a wide range of technologies. Data Architect will work with Government lead to develop site concept, interfaces design, and architecture of Website.\nWork Location: Onsite- Joint Base Anacostia Bolling, DC. or Reston, VA\nRequirements\n7+ years working in the IT\/Sys Admin field with a broad field of knowledge\nBachelor\u2019s degree in related field\nExperience with Cloud (AWS\/Azure\/GCP) and rack infrastructure, Linux\/Windows\nData lake concepts and tools including storage, analytics, governance, security, ML, stream computing\nExperience with Data and Systems Architecture and design\nFamiliar with the RMF\/DecSecOps process\nExcellent at identifying and solving problems\nCapable of researching complex problems and finding solutions\nExperience conducting training sessions to all levels of capability\nExperience working with and briefing senior leadership\nExperience creating Quick Reference Guides, Job Aides, and other training material\nExperience with Microsoft tools and technologies to Include SharePoint (2013,2016, and 2019), Power BI, Visual Basic, and others\nFamiliarity with using and managing metadata\nMust be a U.S. Citizen\nPreferred:\nDoD IAT level II or higher certification such as CompTIA Security+\nExperience with Tableau or similar capability\nExperience implementing JavaScript, CAML queries, and REST services\nExperience with SQL or similar database capability\nSharePoint site collection administration experience\nExperience working in support of Government agencies\nClearance:\nTop Secret\/SCI security clearance and be willing to take and pass a CI polygraph\nBenefits\nThe Company:\nFounded in 2003, IT Concepts was established with a simple yet important promise to \u201cdeliver technology concepts that work.\u201d This founding principle, which permeates throughout our team and company culture, has propelled ITC to the upper echelons of the industry. With award-winning services and unflinching dedication to country and clients, ITC remains committed to teamwork, innovation, and collaboration.\nWe\u2019re an SBA 8(a) and CVE certified Service-Disabled Veteran Owned Small Business focused on providing best in class IT Services, Management Consulting, and Data Services Solutions to our clients.\nWe\u2019re ISO 27001:2013, ISO 20000-1:2011, and ISO 9001:2015 certified and have CMMI DEV and SVC ML3 ratings\nWe\u2019ve been named part of: Inc 5000\u2019s Fastest Growing Private Companies in 2016, 2018, 2020 and 2021; Washington Business Journal\u2019s Fastest Growing Companies in 2015, 2016, 2017 and 2019; Washington Business Journal\u2019s Best Places to Work in 2015, 2016, 2017 and 2019.\nThe Employer:\nWe offer great benefits \u2013 Competitive Paid Time Off, Medical, Dental and Vision Insurance, Identity Protection, Pet Insurance, 401(k) with company matching.\nWe invest in our employees \u2013 Every employee is provided with a stipend to invest in certifications, a master\u2019s degree, or even a doctorate.\nWe work hard, we play hard -Nationals Games, Happy Hours, Holiday events, philanthropic endeavors, etc\u2026at ITC we enjoy working together but also take time to connect with each other and our community through various events and activities.\nIT Concepts is an Affirmative Action\/Equal Opportunity employer. As such, any personnel decisions (hire, promotion, job status, etc.) on applicants and\/or employees are based on merit, qualifications, competence and business needs, not on race, color, citizenship status, national origin, ancestry, gender, sexual orientation, gender identity, age, religion, creed, physical or mental disability, pregnancy, childbirth or related medical condition, genetic information of the employee or family member of the employee, marital status, veteran status, political affiliation, or any other factor protected by federal, state or local law.\nTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. Reasonable Accommodations may be made to enable qualified individuals with disabilities to perform the essential functions.\nThe Company\nWe believe in generating success collaboratively, enabling long-term mission success, and building trust for the next challenge. With you as our partner, let\u2019s solve challenges, think innovatively, and maximize impact. As a valued member of our ITC community, you have the unique opportunity to work in a diverse range of technology and business career paths, all while supporting our nation and delivering innovative technology solutions. We are a close community of experts that pride ourselves on creating an environment defined by teamwork, dedication, and excellence.\nWe hold three ISO certifications (27001:2013, 20000-1:2011, 9001:2015) and two CMMI ML 3 ratings (DEV and SVC).\nIndustry Recognition\nGrowth | Inc 5000\u2019s Fastest Growing Private Companies, DC Metro List Fastest Growing; Washington Business Journal: Fastest Growing Companies, Top Performing Small Technology Companies in Greater D.C.\nCulture | Northern Virginia Technology Council Tech 100 Honoree; Virginia Best Place to Work; Washington Business Journal: Best Places to Work, Corporate Diversity Index Winner \u2013 Mid-Size Companies, Companies Owned by People of Color; Department of Labor\u2019s HireVets for our work helping veterans transition; SECAF Award of Excellence finalist; Viqtory Military Friendly Brand; Virginia Values Veterans (V3); Cystic Fibrosis Foundation Corporate Breath Award\nBenefits\nWe offer great benefits \u2013 Competitive Paid Time Off, Medical, Dental and Vision Insurance, Identity Protection, Pet Insurance, 401(k) with company matching.\nWe invest in our employees \u2013 Every employee is provided with a stipend to invest in certifications, a master\u2019s degree, or even a doctorate. We want you to grow as an expert and a leader and offer flexibility for you to take a course, a certification, or attend a conference. We are committed to supporting your curiosity and sustaining a culture that prioritizes commitment to continuous professional development.\nWe work hard, we play hard. ITC is committed to injecting fun into every day. We dedicate funds for activities \u2013 virtual and in-person \u2013 e.g., we have four season tickets to Nationals games that are available every month, we host happy hours, holiday events, fitness events, and annual celebrations. In alignment with our commitment to our communities, we host and attend charity galas\/events. We believe in appreciating your commitment and building a positive workspace for you to be creative, innovative, and happy.\nIT Concepts is an Affirmative Action\/Equal Opportunity employer. As such, any personnel decisions (hire, promotion, job status, etc.) on applicants and\/or employees are based on merit, qualifications, competence and business needs, not on race, color, citizenship status, national origin, ancestry, gender, sexual orientation, gender identity, age, religion, creed, physical or mental disability, pregnancy, childbirth or related medical condition, genetic information of the employee or family member of the employee, marital status, veteran status, political affiliation, or any other factor protected by federal, state or local law.\nTo perform this job successfully, an individual must be able to perform each essential duty satisfactorily. Reasonable Accommodations may be made to enable qualified individuals with disabilities to perform the essential functions.","72":"As a Solutions Architect (Analytics, AI, Big Data, Public Cloud), you will guide the technical evaluation phase in a hands-on environment throughout the sales process. You will be a technical advisor internally to the sales team, and work with the product team as an advocate of your customers in the field. You will help our customers to achieve tangible data-driven outcomes through the use of our Databricks Lakehouse Platform, helping data teams complete projects and integrate our platform into their enterprise Ecosystem. You'll grow as a leader in your field, while finding solutions to our customers' biggest challenges in big data, analytics, data engineering and data science problems. You will report to the Solutions Architect Manager.\nThe impact you will have:\nYou will be a Big Data Analytics expert on aspects of architecture and design\nLead your clients through evaluating and adopting Databricks including hands-on Spark programming and integration with the wider cloud ecosystem\nSupport your customers by authoring reference architectures, how-tos, and demo applications\nEngage with the technical community by leading workshops, seminars and meet-ups\nTogether with your Account Executive, you will form successful relationships with clients throughout your assigned territory to provide technical and business value\nWhat we look for:\nConsulting, Pre-sales or post-sales experience working with external clients across a variety of industry markets\nUnderstanding of customer-facing pre-sales or consulting role with a core strength in either data engineering or data science advantageous\n5+ years of experience demonstrating technical concepts, including demos, presenting and white-boarding\n5+ years of experience designing architectures within a public cloud (AWS, Azure or GCP)\n5+ years of experience with Big Data technologies, including Spark, AI, Data Science, Data Engineering, Hadoop, Cassandra, and others\nCoding experience in Python, R, Java, Spark or Scala\nBenefits :\nPrivate medical insurance\nAccident coverage\nEmployee's Provident Fund\nEquity awards\nPaid parental leave\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nBusiness travel insurance\nMental wellness resources\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.","73":"As a Solutions Architect (Analytics, AI, Big Data, Public Cloud), you will guide the technical evaluation phase in a hands-on environment throughout the sales process. You will be a technical advisor internally to the sales team, and work with the product team as an advocate of your customers in the field. You will help our customers to achieve tangible data-driven outcomes through the use of our Databricks Lakehouse Platform, helping data teams complete projects and integrate our platform into their enterprise Ecosystem. You'll grow as a leader in your field, while finding solutions to our customers' biggest challenges in big data, analytics, data engineering and data science problems.\nThe impact you will have:\nYou will be a Big Data Analytics expert on aspects of architecture and design\nLead your clients through evaluating and adopting Databricks including hands-on Spark programming and integration with the wider cloud ecosystem\nSupport your customers by authoring reference architectures, how-tos, and demo applications\nEngage with the technical community by leading workshops, seminars and meet-ups\nTogether with your Account Executive, you will form successful relationships with clients throughout your assigned territory to provide technical and business value\nWhat we look for:\nConsulting, Pre-sales or post-sales experience working with external clients across a variety of industry markets\nUnderstanding of customer-facing pre-sales or consulting role with a core strength in either data engineering or data science advantageous\n5+ years of experience demonstrating technical concepts, including demos, presenting and white-boarding\n5+ years of experience designing architectures within a public cloud (AWS, Azure or GCP)\n5+ years of experience with Big Data technologies, including Spark, AI, Data Science, Data Engineering, Hadoop, Cassandra, and others\nHands-on experience in Python, R, Java, Spark or Scala\nBenefits :\nPrivate medical insurance\nAccident coverage\nEmployee's Provident Fund\nEquity awards\nPaid parental leave\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nBusiness travel insurance\nMental wellness resources\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.","74":"Description de l'entreprise\nVous \u00eates passionn\u00e9 par le digital, la data, l\u2019ioT ou l\u2019IA et souhaitez rejoindre une \u00e9quipe dynamique et ambitieuse \u00e0 taille humaine ?  \nN\u2019attendez plus et rejoignez Talan !\nDepuis plus de 15 ans, nous conseillons les entreprises et les administrations et les accompagnons dans la mise en \u0153uvre leurs projets de transformation en Suisse et \u00e0 l'international.  \nPour ce faire, nous nous appuyons \u00e0 la fois sur le levier technologique et sur la force de notre ADN bas\u00e9 sur l\u2019intelligence collective, l'agilit\u00e9 et le go\u00fbt d\u2019entreprendre.  \nPr\u00e9sent sur cinq continents, avec plus de 3 500 collaborateurs notre objectif est de d\u00e9passer la barre du milliard d\u2019\u20ac de CA \u00e0 horizon 2024. L'innovation est au c\u0153ur de notre d\u00e9veloppement et nous intervenons dans les domaines li\u00e9s aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.\nNos valeurs & terrains de jeu :\nIntelligence collective\nAgilit\u00e9\nEntreprenariat \/Intrapreneuriat\nPromouvoir la diversit\u00e9\/mixit\u00e9 (Soutient \u00e0 la Fondation femmes@Numerique...)\nEngagement (employ\u00e9, partenaires, \u00e9coles, associations...)\nRespect de l\u2019humain et qualit\u00e9 de vie au travail\nOuverture d\u2019esprit et inclusivit\u00e9  \n Ensemble, construisons le futur de Talan !\nDescription du poste\nLe service DAM (Data Management) du d\u00e9partement informatique de notre client recherche un consultant avec le profil d\u2019Architecte Big Data pour nous assister sur divers projets dans l\u2019\u00e9cosyst\u00e8me Hadoop.\nLe consultant int\u00e9grera l\u2019\u00e9quipe DAM Modelisation et Administration (DADM) qui a comme r\u00f4les entre autres :\nLa gestion des bases de donn\u00e9es (DB2, MSSQL, Oracle).\nLa gestion des donn\u00e9es dans l\u2019\u00e9cosyst\u00e8mes Hadoop.\nOptimisation des performances.\nProtection de la donn\u00e9e\nMissions :\nAssistance dans la migration de HDP (HortonWorks data platform) vers CDP et s\u00e9curisation de l\u2019acc\u00e8s aux donn\u00e9es.\nRecueil des besoins fonctionnels aupr\u00e8s de diverses \u00e9quipes. Inventorier la donn\u00e9e brute (source DB2 Z\/os)\nMod\u00e9lisation des donn\u00e9es \u00e0 ing\u00e9rer dans hadoop. Design de la solution et des composants n\u00e9cessaires.\nMise en place de la proc\u00e9dure d\u2019alimentation hadoop avec r\u00e9cup\u00e9ration historique.\nSupport des \u00e9quipes qui vont consommer la donn\u00e9e.\nSous la responsabilit\u00e9 d'un chef de projet interne\nQualifications\nExp\u00e9rience d\u2019au moins 5 ans dans un poste d\u2019Architecte Big Data\nUne connaissance dans le domaine DB2 for Z\/os est un avantage\nMa\u00eetrise des technologies li\u00e9es au Big Data comme Hadoop & Spark id\u00e9alement dans l\u2019\u00e9cosyst\u00e8me CDP (cloudera data platform)\nFacilit\u00e9 d\u2019int\u00e9gration dans une \u00e9quipe de DBA & Data Scientist\nAisance de communication\nAutonomie dans la r\u00e9alisation des travaux demand\u00e9s\nLangues : fran\u00e7ais, anglais. Le luxembourgeois est consid\u00e9r\u00e9 comme un avantage.","75":"Data Head, Architect\nDegree or Masters' Degree from recognized university ideally in a computer related discipline\nMore than 10 years of working experience with at least 5 years leadership experience in delivery of Data Governance initiatives.\nProficient in defining Data Strategy, Target Data Architecture, Data Classification, Reference Data Architecture\nProven experience in designing, evaluating, and implementing large Data solutions and delivering large scale change\nProven experience of providing strategic and technical leadership (experience managing multi geography and multi-disciplinary teams is an advantage)\nKnowledge of the contemporary digital landscape of organizations and experience of working in multi-disciplinary teams to drive sustainable improvements in business performance\nExperience working at senior level leading large scale technology projects (including engineering, solution design and complex implementations)\nWork with various CDO units to build a common Solution and integration architecture and roadmap for CDO\nBuild and assurance method on how design concepts (e.g., reference data usage) are enforced in the solutions developed by CDO.\nProvide Guidelines and principles for Data Usage across the Bank.\nFS\/ Banking domain expertise\n  Preferred\nStrong work background in Data related or technology role within international financial services\nDetailed understanding of Information Security, Data Privacy, Metadata, Data Taxonomy including working knowledge of global data protection laws and practices\nExperience with SDLC and Agile working methodologies\/environment\nSelf-starter with strong self-management skills, Team Leader, Strong oral and written communications skills\nAble to creatively apply analytical solutions to business problems and adapting to changes per requirement\/standards\nAbility to work under constant pressure to tight deadlines and deliver high quality output\n ","76":"As a Solutions Architect (Analytics, AI, Big Data, Public Cloud), you will guide the technical evaluation phase in a hands-on environment throughout the sales process. You will be a technical advisor internally to the sales team, and work with the product team as an advocate of your customers in the field. You will help our customers to achieve tangible data-driven outcomes through the use of our Databricks Lakehouse Platform, helping data teams complete projects and integrate our platform into their enterprise Ecosystem. You'll grow as a leader in your field, while finding solutions to our customers' biggest challenges in big data, analytics, data engineering and data science problems. You will report to the Solutions Architect Manager.\nThe impact you will have:\nYou will be a Big Data Analytics expert on aspects of architecture and design\nLead your clients through evaluating and adopting Databricks including hands-on Spark programming and integration with the wider cloud ecosystem\nSupport your customers by authoring reference architectures, how-tos, and demo applications\nIntegrate Databricks with 3rd-party applications to support customer architectures\nEngage with the technical community by leading workshops, seminars and meet-ups\nTogether with your Account Executive, you will form successful relationships with clients throughout your assigned territory to provide technical and business value\nWhat we look for:\nConsulting, Pre-sales or post-sales experience working with external clients across a variety of industry markets\nUnderstanding of customer-facing pre-sales or consulting role with a core strength in either data engineering or data science advantageous\n5+ years of experience demonstrating technical concepts, including demos, presenting and white-boarding\n8+ years of experience designing architectures within a public cloud (AWS, Azure or GCP)\n5+ years of experience with Big Data technologies, including Spark, AI, Data Science, Data Engineering, Hadoop, Cassandra, and others\nCoding experience in Python, R, Java, Spark or Scala\nBachelor's degree in Computer Science, Information Systems, Engineering, or equivalent experience through work experience\nBenefits :\nPrivate medical insurance\nAccident coverage\nEmployee's Provident Fund\nEquity awards\nPaid parental leave\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nBusiness travel insurance\nMental wellness resources\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.","77":"At Lightmatter, we are building chips for artificial intelligence computing. Our architecture leverages unique properties of light to enable fast and efficient inference and training engines. If you're a collaborative engineer or scientist who has a passion for innovation, solving challenging technical problems and doing impactful work...work like building the world's first optical computers, consider joining the team at Lightmatter!\nWe are seeking a motivated and dedicated hands-on Architect to help develop an ASIC for our next-generation artificial intelligence computing architecture alongside a team of world-class scientists and engineers.\nIn this role, you will be defining the architecture components for a ground-breaking AI accelerator with emphasis on delivering a high performance while maintaining a low power consumption. You will be part of a team that integrates our high performance photonics compute core into a custom machine learning accelerator SoC. You will also work closely with our software and analog teams to define and optimize the features needed to accelerate the next generation of machine learning algorithms.\nJoin a tight-knit team where each individual\u2019s contributions directly influence the success of the company and product. You'll have the opportunity to build a new kind of computer from the ground up and to solve groundbreaking challenges along the way. Work with people who love to build and who thrive in technically diverse environments where great ideas are prioritized.\nResponsibilities\nDefine the hardware architecture for Lightmatter's AI products, including memory systems, data movement systems, and compute engines.\nAuthor, review, and validate architectural specifications.\nActively collaborate with the hardware and software teams to perform trade-off analysis between power and performance for AI workloads.\nWith other architects, engage in problem solving and contributing with novel architectural ideas.\nCollaborate with design, verification and implementation teams to realize and validate the functionality, performance and power of Lightmatter\u2019s AI products.\nRequirements\n8+ years of experience in ASIC architecture with emphasis on compute performance\nDeep knowledge of memory hierarchies, data movement and their impact on performance\nExperience in mapping software algorithms to hardware accelerators, including ISA definition\nStrong teamwork skills with the ability to collaborate with multiple functional teams across a variety of fields\nAbility to react to change and thrive in a fast-paced (startup) environment\nExperience influencing decisions in a matrix environment\nMeaningful deep knowledge of processor design, accelerators, networks, and\/or memory hierarchies\nDemonstrate strong problem solving skills in problems that do not have obvious solutions\n\nPreferred Qualifications\nMS or PhD degree in Computer Science, Computer Engineering, or Electrical Engineering\nExperience in leading a complex architecture project from start to commercial volume chip production in an advanced node\nExperience in making power\/performance tradeoffs\nExperience implementing functional or performance models\nDemonstrated technical innovations with impact on AI or high-performance computing\nBenefits\nHealth Care Plan (Medical, Dental & Vision)\nRetirement Plan (401k, IRA)\nLife Insurance (Basic, Voluntary & AD&D)\nPaid Time Off (Vacation, Sick & Public Holidays)\nFamily Leave (Maternity, Paternity)\nShort Term & Long Term Disability\nTraining & Development\nWork From Home\nFree Food & Snacks\nWellness Resources\nStock Option Plan\n\nBase Compensation Range: $231,000 - $254,000. In accordance with the Colorado, California and New York law, the range provided is Lightmatter's reasonable estimate of the compensation for this role. Actual pay will be based on several factors including work experience, location and education.\nLightmatter recruits, employs, trains, compensates and promotes regardless of race, religion, color, national origin, sex, disability, age, veteran status, and other protected status as required by applicable law.","78":"About UsEvery small business journey is different, filled with its own twists and turns. Mineral is with them every step of the way, taking the guesswork out of HR and compliance so that they\u2019re always ready for whatever lies ahead.\nMineral brings together the best of two HR and compliance powerhouses: ThinkHR and Mammoth. By combining certified HR experts with tech-enabled tools, Mineral takes the guesswork out of HR.  Our innovative platform is a one-stop resource for small businesses, filled with everything they need to tackle even the trickiest workplace issues with confidence.  \nHumble brag alert: Mineral has been consistently recognized for our award-winning culture, and we\u2019re especially proud of our 2022 Great Places to Work certification. Simply put, Mineral is a place where people want to be, which could explain why we\u2019ve also been ranked among the nation\u2019s fastest-growing private companies. \nAs a company, Mineral is also made up of incredibly diverse, vibrant individuals, working together for the greater good.  We\u2019re here to help our clients build healthy, thriving organizations, and we\u2019re looking for some like-minded people to help us do it.\nThe Senior Data Architect will define the vision for the future state data architecture, implement, own, and govern the advanced data analytics capabilities at Mineral to realize our vision of becoming a data-forward organization. This leader will report to the Senior Director of Data Management and will manage the definition and implementation of capabilities necessary to modernize our data platforms and analytics services. The capabilities will cut across our internal operational data and analytics as well as customer facing data products so this leader will architect, manage, and deliver both over the next 12 to 24 months.\nYou will:\nDefine the future state data and advanced analytics architecture to realize our data strategy, enable business growth targets, and support organizational growth\nIdentify and develop\/evolve data and analytics capabilities required to achieve self-service analytics, AI\/ML driven decision making, data product incubation, and overall vision to be a data forward organization\nDefine and manage initiatives to design and implement data and analytics capabilities\nCollaborate with our Digital Operations (IT), Product, and Engineering teams to define frameworks, design patterns, and best practices for managing end to end data value chain from creation\/ingestion to consumption and decision making\nCollaborate with business leaders and system owners to implement architectural and system level changes necessary to institutionalize consistent data exchange and governance\nCreate a diverse and inclusive environment, emphasizing Mineral\u2019s core values\nPerform other duties as assigned\n\nYou have:\n8+ years of experience in data and analytics and 3+ years of experience in architecting and implementing modern cloud data analytics stack, preferably on AWS or Databricks\nStrong experience in establishing Data Science capability, implementing advanced analytics use-cases building and training models, and operationalizing ML Ops is needed\nExperience delivering self-service analytics and driving business adoption including training and literacy is preferred\nDemonstrated success developing and leading a team including setting the direction for hiring, goal setting, coaching and development\nProven effective project management skills to enable and ensure projects are delivered in service of the business strategy and requirements\nProven effective communication and presentation skills\nCompensation Range   At Mineral, our compensation philosophy and practices are aligned with our commitment to pay equity and transparency. We determine total compensation packages with an intentional analysis of a candidate\u2019s skills, experience, qualifications, and job-related competencies, and consideration of internal equity. In order to offer competitive, market-based pay, our pay ranges are informed by geographic location.   Target Hiring Range: Geo G - (Examples: San Francisco, CA; Los Angeles, CA; New York City, NY; Chicago, IL; Seattle, WA): $150,000 - $180,000Geo E -  (Examples: Portland, OR; Austin, TX; Charlotte, NC; Denver, CO): $132,000 - $158,400 Geo M - (Examples: Milwaukee, WI; Orlando, FL; Nashville, TN; San Antonio, TX): $120,000 - $144,000  We believe that meaningful total compensation also includes competitive benefits offerings that support the well-being of every Mineralist. In addition to the target hiring range, this position is eligible for annual corporate bonus and benefits offerings. \nBenefits and PerksGenerous Medical, Dental, and Vision Insurance Coverage401k + Company MatchFlexible Vacation + Paid Sick Time + Company HolidaysCorporate Bonus ProgramPaid Family LeaveLifestyle Spending AccountPet InsuranceOther market competitive perks and benefits Equal opportunities, accessibility for allMineral values diversity and is proud to be an Equal Employment Opportunity employer. All individuals seeking employment at Mineral are considered without regard to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, sexual orientation, or any other legally protected characteristic.\nWe\u2019re also committed to providing reasonable accommodations for qualified applicants with disabilities in our job application and recruitment process. If you need assistance or an accommodation, don\u2019t hesitate to reach out to us at careers@trustmineral.com\nSecurity Alert We\u2019re aware of phishing scams targeting job candidates. Mineral will never ask you to do anything that puts your privacy at risk. Verify that your recruiter\u2019s contact information is from the trustmineral.com domain. If you encounter suspicious activity, please notify us at careers@trustmineral.com","79":"Company Description\nBosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it\u2019s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.\nJob Description\nJob Description\nJob Description\nMinimum of 8+ years of experience working with large data sets or do large scale quantitative analysis\nWill be responsible for leading architecture, design and implementation of AI\/ML and MLOps solutions across team of Data Scientists, Data Engineers, ML Engineers, Cloud, Analytics, DevOps and Visualization teams\nExperience in analyzing complex problems and translating them to data science algorithms with due attention to computational efficiency and testing at scale.\nAuthoritative experience in the field of Data Science to influence stake holders across varied work streams and geographical locations, ability to challenge the status quo to improve the base line models and the models which are already productionized.\nExperience in machine learning, supervised and unsupervised: Forecasting, Classification, Data\/Text Mining, NLP, Search Algorithms, Deep Learning Algorithms.\nExperience in using MLOps frameworks like Kubeflow, MLFlow, Airflow Pipelines for building, deploying, and managing multi-step ML workflows based on Docker containers and Kubernetes.\nExperience with workflow orchestration tools like Kubeflow, Airflow, Argo or similar tools\nExposure to deep learning approaches and modeling frameworks (PyTorch, Tensorflow, Keras, etc.)\nExperience in frameworks to depict interpretability of models using libraries like Lime, Shap etc.\nExperience working with big data - identifying trends, patterns, and outliers in large volumes of data.\nStrong implementation experience with Python, and familiarity with Linux\/Unix\/Shell environments\nStrong hands-on skills in sourcing, cleaning, manipulating and analyzing large volumes of data using distributed computing platform\nExperience with Hive \/ Spark \/ Teradata and NOSQL databases\nExperience in using code versioning tools like GIT, bit bucket; building CI\/CD pipelines for ML projects\nExperience in productionizing ML models in any of the cloud platforms - AWS\/GCP\/Azure\nGood to have experience in building automated\/semi-automated model retraining pipelines.\nSuperior verbal, visual and written communication skills to educate and work with cross functional teams on controlled experiments.\nCandidates with prior publications in the field of Data Science are highly preferred.\nTech savy and willing to work with open-Source Tools\nWillingness to learn IoT, Edge AI and keep up to date with technologies\nQualifications\nQualifications\nPhd related to AI\/ML\nAdditional Information\nAdditional information\nGood to have \nWhitepaper submissions and IP filings","80":"Company Description\nCompany Overview\nHitachi Solutions is a global solutions integrator passionate about designing, developing, and delivering cutting edge cloud solutions to help our clients innovative across their entire business.  Our firm develops the business services and technology powering some of the products you use every day \u2013 and is closely aligned with Microsoft and other leaders in the cloud computing space.  \nWhat sets Hitachi Solutions apart is both our industry focus, and the intellectual property that we bring to our customers.  Recognized for our achievements year after year, we strive to be the trusted advisor of large and medium sized enterprises alike \u2013 helping them move fast to achieve strategic business initiatives with distinguished engineering, hard work, and compassion.  With over 3,000 team members across 14 countries, in our 18 years of focus our company has seen explosive growth and high customer satisfaction.  This has allowed us to offer exceptionally compelling salaries, 401k match, family leave, and health benefits.  And no \u2013 we will not make you come into an office or ask for an inflexible work schedule. \nA part of Hitachi, Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world\u2019s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies\nJob Description\nNEW PRODUCT DEVELOPMENT AND INNOVATIONS TEAM \nThis position is housed in our New Product Development team formed in 2021.  Joining this team represents an opportunity to fast-track your career and to work with a team of fun and nerdy colleagues in a disruptive startup atmosphere: focused on hypergrowth, moving quickly, and making mistakes in the furtherance of innovation and sound engineering.  \n\nArmed with an existing book of business, and a stable financial parent \u2013 it is the goal of this group to transform our company into a billion-dollar product company, by focusing on engineering excellence and making the cloud easier for our customers. \nSpark Solution Architect (Databricks, Python, Spark) \nThis is a full-time role on the Empower product team, our Platform-as-a-Service (PaaS) \/ Software-as-a-Service (SaaS) Datalakehouse and Business Intelligence subscription-based Intellectual Property, architecting Big Data solutions.\nIndividuals in this role will architect complex data pipelines products that manage business critical operations, and large-scale analytics pipelines.   Qualified applicants will have expert Spark data engineering expertise and have robust Python software engineering experience.  \nResponsibilities:\nScope business problems and architect Big Data pipeline solutions \u2013 for structured, unstructured and live streaming data \u2013 in Spark and Databricks platforms\nDesign complex data pipeline products which manage business-critical operations and large-scale analytics applications\nUtilize Airflow, Dbt, Data Factory, or similar DAG Tools for orchestration of robust data pipelines\nSupport analytics, data science and\/or engineering teams and understand their unique needs and challenges\nDesign & POC integration of new features into proprietary Spark package(s)\nPartner with Product Management team to identify user stories and maintain prioritized backlog\nAn owner of Empower's Spark repository; review & approve pull requests\nEnforce code standards: formatting, comments, documentation, unit tests, etc.\nInstill excellence into the processes, methodologies, standards, and technology choices embraced by the team\nMentor developers in Spark and Python best practices\nIdentify opportunities for continued improvement of existing proprietary Spark package(s)\nDedicate time to continuous learning to keep the team appraised of the latest developments in the space\nCommitment to developing technical maturity across the company\nQualifications\nPlease note: Although our position is remote \/ virtual \/ work-from-home, you MUST reside, and be authorized to work, in the US.\n10+ years of Data Engineering expertise including 6+ years designing and building data pipelines for batch and streaming data is REQUIRED\n6+ years of experience with Spark\/PySpark is REQUIRED\n4+ years of experience with Databricks is REQUIRED\n4+ years of hands-on experience implementing Big Data solutions in a cloud ecosystem, including Data\/Delta Lakes, is REQUIRED\n2+ years of experience with DAG Tools (Airflow, Dbt, Data Factory, or similar) is REQUIRED\nAzure cloud experience preferred; will consider AWS, GCP or other cloud platform experience in lieu of\n2+ years of experience with Kafka or other live streaming technology is REQUIRED\nExperience with unit testing or data quality frameworks is REQUIRED\n2+ years of experience with source control (git) on the command line is REQUIRED\n5+ years of SQL experience, specifically writing complex, highly optimized queries across large volumes of data is REQUIRED\nExperience with CI\/CD deployment pipelines\nKnowledge of software design patterns\n   #LI-CA1\n#REMOTE\n#DATABRICKS\n#SPARK\n#PYTHON\n#DATALAKEHOUSE\nAdditional Information\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.","81":"Company Description\nWelcome to Bosch\nCars drive autonomously, machines speak to each other, and houses become smarter. At Bosch, we turn these visions into reality to improve the quality of life for people all over the world. Start something big and become a part of forward thinkers where you can create something remarkable: Invented for life.\nWith over 300 specialized associates and around 15 nationalities, Bosch activities in Lisbon are focusing on sales, marketing, communication, training, nearshoring services and shared support for human resources services to Europe. The diversity, commitment and know-how of the team are the key success factors of this organization.\nBosch Service Solutions develops and delivers Customer Experience, Mobility and Monitoring solutions for companies and their customers. Our teams find fast and efficient solutions for thousands of people on a daily basis \u2013 from claim management to life-saving emergency calls, among other services. Define the standards and become a pioneer together with around 9000 associates worldwide.\nJob Description\nCustomer master data management is processing all of the information related to a company's customers in a central system. This information can include personal and contact details, such as names, addresses, categorizations and relationships, and any other data related to the customer's interactions with the company. Having accurate, complete, and up-to-date customer information is a business critical requirement for every company .\nAs the data architect Customer Data Management you are responsible for the design and implementation of customer master data management systems. This includes the definition of the overall data architecture, designing the data model, and ensuring that the system meets the organization's business requirements.\nEvaluation and Selection of Next Generation Repository Tool as successor of SAP-MDS Platform\nDefine solution Architecture for Next Generation Repository\nDefinition of Business and Technical Data Modell  for Organizations and Person Objects\nModelling and specification of creation\/update and maintenance processes cross ECO system\nCo-ordination of development and testing ressources\nAlignment with Business Owner and Product Owner of integrated Customer Profile Management solution\nConsulting of Consumers and Providers in regards of Business and Technical integration Architecture \nTurning business problems into data design\nQualifications\nStrong logical, analytical and Problem solving working method\nOpen and transparent communication and collaboration style\nWorking in \/Understanding of Business Processes in a big global company\nData engineering and modelling with complex data modells\nDeep IT Architecture and Tool experience e.g. SAP middleware, Stibo STEP,  Solace \u2026.\nData Governance and Standardization\nProject Management\nAdditional Information\nWhat we offer you:\nChallenges in an international environment | career opportunities in one of the best companies in the world | flexible hours | medical services | discounts for employees | sports and health related activities | canteen | good access to public transports | space for creativity.\nSuccess stories don\u00b4t just happen. They are made...\nMake it happen! We are looking forward to your application!","82":"Company Description\nBlend360 is a world class marketing, analytics, and technology company that delivers the best results for our clients. Our primary focus is Data Sciences; leveraging data and applied mathematics to solve our clients\u2019 business challenges. Blend360 is known for our exceptional people, our get-it-done mentality, and delivering high impact and sustainable results. If you love to solve difficult problems and deliver results; if you like to learn new things and apply innovative, state-of-the-art methodology, join us at Blend360.\nJob Description\nBlend360 is looking for a technology industry professional with a combination of business acumen and technical insight to maximize the value of our clients\u2019 technology assets.  You will understand the business problem, align stakeholders on your vision, develop a technical strategy, and oversee the implementation of critical technology products that drive our clients\u2019 organization. \n Job Duties\nDevelops and maintains a vision and plan for technical assets and oversees the execution of that plan to maximize the value of the technology to the organization.\nKnows how to identify key client initiatives, refine and manage stakeholders as it relates to the larger project\nDetermines operational objectives by studying business functions; gathering information; evaluating output requirements and formats\nAbility to conduct an enterprise analysis of tools and processes while building relationships with various levels of a client organization to help develop and drive a clear vision\nUnderstands business strategy as it relates to technologies used within client engagements\nCan conduct market analyses for tools and functionality available in the marketplace.\nUnderstanding product releases as it relates to requirements and deadlines\nDesigns and defines new technical programs and requirements\nImproves systems and processes by studying current practices; designing modifications, recommending controls by identifying problems; writing improved procedure\n Qualifications\n Required Skills\nBackground in Data Science or Data Engineering\n5+ years of experience\nStrong written documentation skills\nStrong verbal and client facing communication skills\nA critical thinker with a consultative mindset\nStrong understanding of the data industry as a whole, including tools, best practices, and functionality\nHands-on Experience across 2 or more of the following technologies:\nETL processes (Cloud Native, DataBricks, Spark, Airflow)  \nMultiple coding languages (JavaScript, Python, Java, .Net)  \nExperience with Database Designs & Administration (SQL, noSQL, Cache, DataLakes, Cluster)  \nCloud Native Engineering (AWS, Azure, GCP, WAF)  \nCloud Development \/ (CI\/CD) \/ DevOps \nMust have Certification in Databricks  or Snowflake \nThe starting pay range for this role is $100k - $145k. Actual compensation within the range will be dependent on several factors including but not limited to relevant experience, skills, certifications, training, and location. It is not typical for an individual to be hired at or near the top of the range and determining factors for compensation are considered for each individual circumstance. BLEND360 also offers a competitive benefits program to meet the health and financial well-being of our team and their families. You can look forward to a range of benefits including medical, dental, vision, 401K, PTO, paid holidays, commuter benefits, spending accounts, life insurance, disability coverage, and EAPs. \nAdditional Information\n All your information will be kept confidential according to EEO guidelines.","83":"Company Description\n6th Best Large Workplace in the UK\n1st Best place to work in Ireland #GPTW2023\nUK & Ireland\u2019s premier Oracle partner\nMarket leader in Oracle ERP and HCM Applications\nConsulting, implementation and support services\n3000 strong,\u20ac255m\/ \u00a3220m revenue business\nERP Partner of the Year\nWon 7 Gold awards out of 7 nominations at this last year's virtually held OUG Partner awards.\nWe pledge \"to prove IT can make a real difference to our customer's businesses\". We work hard to ensure we understand what our customers need from their technology solutions and then we deliver.\nJob Description\nWe are seeing unprecedented growth across several of our key practice areas. We are looking for talented individuals, who want a challenging, dynamic work environment with honesty & integrity, excellence, and drive amongst our core values as well as a strong emphasis on our people and a work-life balance.\nIf you are interested in playing a key role in growing the Ireland Data Analytics practice, designing Data solutions for our customers, and building the Data team within Version 1 read on.\nResponsibilities:\nTo provide technical and design leadership to a highly skilled and motivated expert technical team.\nTo design solutions that make use of the newest technologies and industry best practices.\nWorking alongside other teams to keep Data Architecture Models up to date.\nWork with data analysts, engineers, and visualisation consultants to realise your designs\nWorking closely with the Sales\/Commercial team to support them with new Data customer opportunities.\nTechnical ownership for a Data project, covering technology road-map alignment, estimation, project planning, user story\/requirement creation and full development lifecycle.\nMaintain and optimize the Data Warehouse and Data Lake \/ Data Brick solutions to maximize performance\nMarshall teams to ensure excellent quality and consistency.\nPull together estimates from teams for future work.\nDriving and implementing non-functional requirements for customers\nCommunicate technical designs in conversation, documentation, and presentations to stakeholders of various technical abilities.\nMake effective decisions within fast-moving delivery.\nMentoring, coaching, and developing members of your team and the wider community.\nIdentify opportunities to add value to the customer in the management and delivery of its Data landscape.\nWorking with business analysts and end-users to elicit requirements & assist in developing design specifications for short-, medium- and long-term future state architectures.\nIdentifying technology trends and deriving relevant IT proposals, including migration strategies.\nEngaging with the software development lifecycle, providing design and technical coaching to project business analysts, solutions architects, development teams, test management, and project managers.\nQualifications\nEssential criteria:\nStrong background in Data Engineering, Architecture, Solution Design, and documentation\nStrong understanding of Microsoft SQL Server, Azure, PowerApps and Power BI\nStrong familiarity of the Azure DevOps toolset & Microsoft Azure related Certifications\nProven track record of implementing end-to-end data solutions and ELT\/ETL pipeline development skills\nExperience working with solutions in the Cloud specifically Microsoft's Azure platform\nStrong SQL experience both within the SQL Azure space and on prem\nAbility to communicate well with key stakeholders and non-technical audiences\nExperience in leading data engineering projects\nExperience working with large-scale data environments in a data engineering role\nA demonstrable track record in a similar role is a necessity for this role.\nAdditional Information\nBefore you apply, here are some of the benefits we offer:\nQuarterly Profit Share\nPrivate medical insurance\nFlexible working policy & Remote Working \nIncentives for accreditations and educational assistance for courses relevant to your role.\nEmployee recognition in the form of Excellence Awards and CallOut which your peers award.\nPathways Career Development Quarterly\nEngagement is incredibly important! Our local teams drive our engagement events!\nand much more...","84":"In this role you will be helping to grow the Rackspace Cloud data practice.\u202f You will be the expert in the region and support the delivery of our data projects on Azure.\u202f Our Data Architects are experienced technologists with technical depth and breadth, along with strong interpersonal skills. In this role, you will work directly with customers and our team to help enable innovation through continuous, hands-on, deployment across technology stacks, will serve as the Data SME for our customers and be the focal touchpoint in engagements.   As the expert you\u2019ll be involved in presenting to customers at events and promoting our capabilities to Azure.\u202f With a large Azure data team of over 200+ globally it is also an opportunity to mentor and shape the data practice during our growth phase.\u202f  More generally, Data Architect are the cornerstone of our delivery success, overseeing our most strategic accounts. They are empowered to make key delivery decisions and work closely with technical resources as well as our Engagement\/Project Managers to ensure our customers experience successful outcomes.\u202f\u202f  If you get a thrill from working with cutting-edge technology and love to help solve customers\u2019 problems, we\u2019d love to hear from you.   Data Specialization:\u00b7       Lead, define and implement end-to-end modern data platforms in support of analytics and AI use cases \u00b7       Design and Drive reusable assets, growing Analytics and DevOps capabilities.\u00b7      Solution and deliver modern Data Platforms and Advanced Analytics solutions for clients.\u00b7       Collaborate with enterprise architects, data architects, ETL developers & engineers, data scientists, and information designers to lead identification and definition of required data structures, formats, pipelines, metadata, and workload orchestration capabilities \u00b7       Address aspects such as data privacy & security, data ingestion & processing, data storage & compute, analytical & operational consumption, data modeling, data virtualization, self-service data preparation & analytics, AI enablement, and API integrations \u00b7       Be the technical liaison between customers and engineering teams \u00b7       Be a big data evangelist by educating a variety of customers on the value of cloud and data services \u00b7       Help support in pre-sales.\n Key Requirements:\u00b7       5+ years' experience leading engagements from design to implementation of creative data solutions leveraging the latest in Spark based modern data platforms on public cloud \u00b7       At least 4 full lifecycle data platform deployments on Azure using 1st party Services \u00b7       Strong Spark, SQL, Data Modeling, Data lakehouse concepts. \u00b7       Strong programming \/ scripting experience using python and scala.\u00b7       Strong experience using Data and AI tools such as Azure Storage, Stream Analytics, CosmosDB, SQL DW, Azure Databricks, Azure Data Catalog and Azure Data Factory.\u00b7       5+ years' experience architecting solutions for optimal extraction, transformation and loading of data from a wide variety of traditional and non-traditional sources such as structured, unstructured, and semi-structured using SQL, NoSQL and data pipelines for real-time, streaming, batch and on-demand workloads \u00b7       3+ years' experience with analytics\/data management strategy formulation, architectural blueprinting and effort estimation of analytics \u00b7       5+ years working in cloud or multi-server complex environments.  Extensive experience with Azure is required. \u00b7       Ability to simplify complex technical concepts into an easy-to-understand non-technical language to facilitate, communicate and interact with executives and business stakeholders \u00b7       Ability to deal with ambiguity by making the appropriate decisions considering the relative costs and benefits of potential actions.   \u00b7       Experience with Agile development methods in data-oriented projects \u00b7       Experience with Dashboarding and Reporting Tools used in the industry (Tableau, Power BI, Qlik, etc.) \u00b7       Certifications in architecture, data engineering and development from Azure.\u00b7       Knowledge of software configuration management environments and tools such as JIRA, Git, Jenkins, TFS, Shell, PowerShell, Bitbucket.#LI-VM1#LI-USA#LI-Canada\n\n\nAbout Rackspace TechnologyWe are the multicloud solutions experts. We combine our expertise with the world\u2019s leading technologies \u2014 across applications, data and security \u2014 to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.  More on Rackspace TechnologyThough we\u2019re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.","85":"Our client is looking for a Senior Data Architect, with strong technical background as well as leadership qualities, to fill in as the leader of the data platform. Provide centralized data services for Digital solutions teams \u2013 data scientists, business users with NoSQL and Big Data platforms, hybrid cloud, and BI tools.\nExperience level: Mid-senior, Experience required: 10 Years, Education level: Bachelor\u2019s degree\nJob Function: Information Technology, Industry: Financial Services\nRelocation assistance: No\n\nJOB DESCRIPTION AND RESPONSIBILITIES:\nThe client is looking for a senior data architect, with strong technical background as well as leadership qualities, to fill in as the leader of the data platform.\nOversee the development and maintenance of a centralized data platform with the latest big data and advanced analytics technology deployed globally on-premise and on major public clouds.\nOversee a pool of 50+ contingent data professionals developing and supporting 20+ projects and products on the platform.\nDefine and maintain operational standards on the platform.\nImprove the way data assets are managed and work with businesses to find new ways to monetize data.\nProvide centralized data services for Digital solutions teams \u2013 data scientists, and business users with NoSQL and Big Data platforms, hybrid cloud, and BI tools.\nThis position will cover multiple data-driven projects encompassing data requirements gathering, discovery, pipeline design, data modeling, DDL release, and query tuning.\nMust be able to work independently, acting as the lead expert in data, and work with business analysts, project managers, architects, app developers, and data engineers to deliver the results on time and with quality.\nRequirements\nGC Holder or US Citizen,\nDirect hire (W2 role),\n10+ years of experience working with Data,\n7+ years as a Data Architect,\nAbility to lead projects on a platform level,\nExperience in Architectural Concepts at the Enterprise Level,\nExperience with relational, NoSQL, and Big Data concepts, environments, and common products\nSolid background in SQL and SQL-like query languages, as well as various types of schema.\n(Relational, JSON, AVRO, etc.),\nData Modeling tools, such as Erwin, and conversion between various types of schema,\nExpertise in Big Data (knowledge and background) is required, including the Hadoop platform (HDFS, Hive, etc.),\nQuery engines, such as Presto,\nAbility to deliver data solutions in the cloud (AWS \/ Azure),\nBenefits\nOur client offers top-notch benefits: multiple medical, dental, and vision plans with choices to fit all needs and budgets - benefits coverage starting Day 1\nFlexible work opportunities for work\/life balance\nA culture of internal mobility, diversity, inclusion, and collaboration\n\nABOUT THE CLIENT:\nOur client is the world\u2019s leading professional services firm in the areas of risk, strategy, and people. The Company\u2019s 76,000 colleagues advise clients in 130 countries. With annual revenue of over $17 billion. Our client helps clients navigate an increasingly dynamic and complex environment through four market-leading businesses. The client advises individual and commercial clients of all sizes on insurance broking and innovative risk management solutions.","86":"Company Description\nMerkle is a leading data-driven, technology-enabled, global performance marketing agency that specializes in the delivery of unique, personalized customer experiences across platforms and devices. For more than 30 years, Fortune 1000 companies and leading nonprofit organizations have partnered with Merkle to maximize the value of their customer portfolios. The agency\u2019s heritage in data, technology, and analytics forms the foundation for its unmatched skills in understanding consumer insights that drive people-based marketing strategies. Its combined strengths in performance media, customer experience, customer relationship management, loyalty, and enterprise marketing technology drive improved marketing results and competitive advantage. With 9,600+ employees, Merkle is headquartered in Columbia, Maryland, with 50+ additional offices throughout the US, EMEA, and APAC. In 2016, the agency joined the Dentsu Aegis Network. For more information, contact Merkle at 1-877-9-Merkle or visit www.merkleinc.com.\nJob Description\nThe purpose of this role is to take database implementation projects through the entire development life cycle.  This role will work as the solution lead and will be directly involved in the architecture, solution design, development, testing and deployment of the solution. This role serves as the technical subject matter expert for the solution.\nKey responsibilities:\nArticulates feasible technology choices that meet the requirements; ability to put forth a viable, scalable technology point of view; be knowledgeable and conversant with the offline and online (digital) marketing technology landscape\nBridges business and technical requirements to provide a cohesive, seamless solution to scale and perform\nHas the ability to wear multiple technology hats across systems integration, technology consulting and technology solution design and architecture\nParticipates and leads technology discussions with prospects (RFP support)\nLeads large-scale technology implementations including understanding of scoping, estimation and managing timeline\/budget\nHas experience in legacy migration and re-platform of technology solutions\nLeads technology conversations with senior management (be an internal and external technology solutions evangelist) and be the technology voice of the solution\nIs responsible and accountable for the underlying client technology solution architecture\nLeads CRM platform development programs and roadmap Data warehouse architecture and ETL design\nHas experience in DB integration and execution, data architecture, database, process (ETL and services), identity Management, open source (GNU, Apache, Java, Linux, HDFS et al) tools and technologies, real-time application integration (web services)\n Additional Information\nDentsu (the \"Company\") is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant or employee of the Company, on the basis of age, sex, sexual orientation, race, color, creed, religion, ethnicity, national origin, alienage or citizenship, disability, marital status, veteran or military status, genetic information, or any other legally recognized protected basis under federal, state or local laws, regulations or ordinances. Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and\/or certain state or local laws. A reasonable accommodation is a change in the way things are normally done that will ensure an equal employment opportunity without imposing an undue hardship on the Company. Please contact recruiting@dentsuaegis.com if you need assistance completing any forms or to otherwise participate in the application process or to request or discuss an accommodation in connection with a job at the Company to which you are applying.\nThe anticipated salary range for this position is $113,000-$130,000. Salary is based on a range of factors that include relevant experience, knowledge, skills, other job-related qualifications, and geography.  \n#LI-DB2\nAbout dentsu \nDentsu is the network designed for what\u2019s next, helping clients predict and plan for disruptive future opportunities in the sustainable economy. Taking a people-centered approach to business transformation, dentsu combines Japanese innovation with a diverse, global perspective to drive client growth and to shape society www.dentsu.com. \nWe are champions for meaningful progress and we strive to be a force for good\u2014for our people, for our clients, for the industry and for our society. We keep our people at the center, creating space for growth, understanding and learning so they can thrive. We embed diversity, in our mindset, in our solutions and in our teams to empower an inclusive, equitable and culturally fluent environment. Building this culture within our teams makes us better collaborators with each other and with our clients, driving better outcomes for all.\nDentsu (the \"Company\") is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant or employee of the Company, on the basis of age, sex, sexual orientation, race, color, creed, religion, ethnicity, national origin, alienage or citizenship, disability, marital status, veteran or military status, genetic information, or any other legally-recognized protected basis under federal, state or local laws, regulations or ordinances. Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and\/or certain state or local laws. A reasonable accommodation is a change in the way things are normally done that will ensure an equal employment opportunity without imposing an undue hardship on the Company. Please contact recruitingops@dentsu.com if you need assistance completing any forms or to otherwise participate in the application process or to request or discuss an accommodation in connection with a job at the Company to which you are applying. ","87":"At Yohana, we\u2019re finding new ways for technology and design to lighten our loads, reclaim our time, and improve our well-being. We want it all. A career and home. Family and friends. Health and wellness. But actually having it all can leave us feeling overloaded. And research shows it. 43% of people struggle with decision-making. 66% say overload affects their work, and 62%, their interpersonal relationships.  \nTechnology was supposed to help by making us more efficient. But the faster we get things done, the more we take on, and our well-being falls to the bottom of the list. Yohana is on a mission to make balance a priority \u2013 and do it joyfully.\n It\u2019s a meaningful product challenge: helping society reclaim time and make space for joy through technology and design. That\u2019s what the team at Yohana is solving for every day, and we have a lot of fun doing it. With leadership from big tech like Google, Apple, Microsoft, and hypergrowth startups like Nest, Waymo, TaskRabbit, and Casper, we\u2019re motivated to make the world a happier place. Join us!\nYohana is a wholly owned subsidiary of Panasonic Inc. Our unique positioning as a start-up within a global Consumer Electronics and Services company makes this opportunity one that is rich with world-class capability and game-changing possibilities. \nAbout The Role:\nWe are seeking a highly motivated and experienced Architect and Tech Lead for AI\/ML\/Data to join our team. The ideal candidate will be responsible for leading the design, development and deployment of cutting-edge AI\/ML systems. The candidate will also be accountable for overseeing data architecture and data management to ensure high data quality, accuracy and consistency. \nWhat You\u2019ll Get To Do: \nDevelop and implement Data and AI\/ML strategies, architectures, and solutions to meet business requirements in a fast-paced startup environment \nCollaborate with cross-functional teams including data scientists, engineers, and business stakeholders to ensure data and AI\/ML solutions align with business goals \nMentor and lead a team of Data and AI\/ML engineers, providing technical guidance and promoting best practices in a constantly evolving startup environment \nDesign, develop, deploy and maintain data pipelines, data storage, data processing, AI\/ML system\/infrastructure \nDesign and implement data governance and data management policies, ensure data quality, accuracy and consistency \nStay current with the latest developments in the field and incorporate them into the development process \nCollaborate with stakeholders to understand business requirements and translate them into technical solutions\nWork with limited resources and be comfortable with ambiguity and uncertainty, with the ability to make informed decisions quickly \nWhat You\u2019ll Bring:\nMaster's degree in Computer Science, Mathematics, Statistics or related field\n8+ years of experiences in data engineering, machine learning, and artificial intelligence\nExtensive experience in designing, developing and deploying automated system using machine learning and artificial intelligence at scale \nStrong understanding of data architecture and data management principles\nStrong leadership skills and experience leading and mentoring engineering teams\nExcellent communication, collaboration and interpersonal skills \nAbility to work effectively with cross-functional teams, can be very hands on when needed\nExpertise in Python, SQL, and data processing technologies, experience with Snowflake is a big plus \nA passion for working in a fast-paced and constantly evolving startup environment \nIf you are passionate about technology and have a proven track record in AI\/ML\/Data architecture, we would love to hear from you. Please apply with your updated resume. \nWhat We Offer:\nThe future of work at Yohana is flexibility. Like many other leading Silicon Valley based businesses, we follow a hybrid workplace model post-pandemic. We believe this model is consistent with our goals of fostering a highly collaborative culture, promoting employee well-being, and developing a workplace that is engaging, equitable, and innovative. \nLocal (Bay Area) employees are expected to come into the office on Mondays & Wednesdays and optional on the other days of the week. Fully remote (Work From Home) employment may be available for select positions. \nEmployee benefits include: \nOpportunity to join a hyper-growth startup on a mission to make well-being attainable for modern families \nCompetitive compensation \nComprehensive benefits (Medical, Dental, Vision, HSA, FSA) \n401(k) with employer match \nLife & Short Term Disability Insurance \nSupplemental Medical Coverage \nUnlimited PTO \n12 Company Holidays \nPaid Maternity & Parental Leave \nPaid Caregiver Leave \nEmployee Assistance Program \nGroup and 1-on-1 Career Coaching \nPet Insurance\nCasual Dress Code \nCatered Lunch & Snacks \nDiscounts on Panasonic products \nCompany Social Events \nWe are proud to be an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender identity, sex, sexual orientation, national origin, disability status, protected veteran status, and any other characteristic protected by law or company policy. All qualified individuals are required to perform the essential functions of the job with or without reasonable accommodation. Pre-employment drug testing is required for safety sensitive positions or as may otherwise be required by contract or law. All candidates must have valid authorization to work in the U.S. Thank you for your interest.","88":"Do you enjoy being a part of the data revolution and constantly look for new solutions? Do you want to join an agile, international company and help businesses in different industries to innovate in the data arena, create new opportunities and bring their operations to a whole new level?\nWe are now looking for an experienced Azure Data Architect, who is ready to be an essential part of Nortal\u2019s growth in data competence. We are building a Data and IoT Center of Excellence in Finland, so now is a perfect time to join and contribute to the development of the new CoE. You will get to work side-by-side with our experts in data and IoT development in Finland, closely collaborating with our data and software delivery teams around the globe.  \nYour role involves identifying the data needs of the customer, and designing and maintaining the master blueprints to meet those needs. You build data architectures, guide data integration and data modeling, control data assets, and align data investments with the customer\u2019s strategy.\nYou will at the same time be setting up the standards for data related offering, services, and architecture across Nortal Finland. You are proactive in seeking new ways of working in the data arena, but you are never alone, as the team loves to support one another and bounce ideas. You enjoy communicating with different stakeholders and network easily. You embrace leading people by example and enjoy hands-on work to make an impact.\nNortal\u2019s offices are located in Helsinki, Turku, Oulu, Uusikaupunki and, Jyv\u00e4skyl\u00e4. This position can be worked from any of the previous, but we are pretty flexible with remote work as well. \nYou are likely to succeed if you have:\nExperience in envisioning and designing solid data architectures as part of overall enterprise architecture\nStrong working experience on enterprise data strategies and data warehouse solutions\nExperience in various types of data architectures like data lakes, data warehouse and lakehouses\nUp-to-date understanding of the data mesh paradigm\nExperience in Azure and on-premise data solutions\nLove to innovate, demonstrate thought leadership and enjoy supporting pre-sales as a solution architect \nAdditionally it is beneficial if you:\nHave background in software engineering\nHave work experience on data infrastructures and networking\nAre familiar with Snowflake\nMicrosoft certificates are a big plus (Azure Solutions Architect Expert, Azure Data Engineer Associate, Azure Database Administrator Associate) \nOn top of everything else, here are a few other perks why to join Nortal. We are waiting for you! \ud83d\ude0a\nFlexible working in general; flexible hours, working either at our office downtown or remotely when you like. We even have a nomad program that enables you to work from almost anywhere in the world!\nNice benefits such as support for learning (free digital library, opportunities for mentoring, participating in courses, support for gaining certificates etc.), massage, holiday apartment in Northern Finland\nGreat colleagues to have lunch with, sing karaoke, go walking in the forest or even try archery. You are more than welcome to suggest any fun activities to do together!\nInterested?\nApply here or contact our recruiter Virpi directly: +358 40 6616 338 or virpi.kivinen(at)nortal.com. Feel free to call, text me, send a voice message, or then let\u2019s grab a coffee. Whatever works for you!\nVirpi Kivinen","89":"Company Description\nTransforming businesses, driving success: SmarTek21\nSmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev\/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients\nJob Description\nSmarTek21 is looking for a hands-on Big Data Solution Architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.  \nQualifications\n\u2022 Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python.\n\u2022 Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks.\n\u2022 Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP).\n\u2022 Solid understanding of enterprise strategies for data security and data governance.\n\u2022 Experience in practice development, architecture, and consulting or product development.\n\u2022 Experience delivering data analytics projects and architecture guidelines.\n\u2022 Experience in engaging with enterprise architects. Non-technical Skills:\n\u2022 Excellent oral and written communication and presentation skills.\n\u2022 Ability to handle ambiguous situations and take trade-off decisions.\n\u2022 Strong problem solving and analytical skills to break down complex problems into smaller components.\n\u2022 Ability and willingness to perform in a team environment.\nRequirements:\n\u2022 Understand prospect\/customer\/partner technology landscape.\n\u2022 Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation.\n\u2022 Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers\/partners.\n\u2022 Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints.\n\u2022 Collaborate with the engineering team to create proof-of-concepts (POCs).\n\u2022 Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices.\n\u2022 Demonstrate business value of proposed solutions or current products to prospects and customers.\nSalary Range: $200,000-$215,000 (may be subject to change outside of WA State)\nAdditional Information\nWhat Is in It for You:\nPaid Time off \u2013 start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service.\nPaid Holidays - 8 paid holiday a year in addition to your PTO.\nHealth Insurance for FT employees \u2013 we pay 100 % premium of medical, dental and vision.\nHealth Insurance for FT employee\u2019s family \u2013 we pay 50% of premium for medical, dental and vision for dependents.\n401(k) \u2013 we administer 401(K) retirement contribution for FT employees.\nLife Insurance\/Short Term and Long-Term Disability \u2013 at no cost to you\nOpportunities for internal promotions\/career advancement\nFamily friendly work hours (closed on weekends and paid holidays)\nSmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and\/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class.","90":"Title: Big Data Solution Architect\nType: Full-time\nLocation: Switzerland (Lausanne or Zurich)\n\ud83e\uddec About us\nVisium is a fast-growing Swiss AI technology consultancy company founded in 20218. At Visium, we develop customized AI-powered solutions for our clients in order to help them achieve their business goals.\nWith a team of 55+ Visiumees dedicated to accelerating the adoption of state-of-the-art Artificial Intelligence in traditional industries. We are the strategic AI partner of world-leading companies and we contribute to them with ethical AI solutions that have a massive positive impact on their business, customers and employees.\n\ud83e\udded Role\nYou will be our clients Data Engineering expert, helping them identify their opportunities and designing the projects we will develop for them.\nAs the first point of contact for many of our prospects, you will establish a close, impactful, and long-lasting relationship with our clients and partners. More importantly, you will be the main technical reference when it comes to supporting the growth team in the design of Data Engineering solutions and during client meetings.\n\n\ud83d\udca1 What you will be responsible for\nAs a Big Data Solution Architect you will be:\nOur technical expert to support our Sales team:\nCooperate with our Sales team and senior stakeholders, during pre-sales stage, to construct a total solutioning proposal, including offering and pricing, high level scope of both functional and technical requirements, data and security.\nIdentify potential Data Engineering use-cases and evaluate the value they would bring to our clients.\nPrepare proposal presentations for clients\u2019 projects.\nA trusted technical advisor to clients and project members:\nParticipate in or drive deep architectural discussions to build trust and rapport with clients during the implementation stage.\nProvide technological and architectural consulting to our clients, create strategic roadmaps, and advise on their execution.\nSolve complex technical challenges, and build deep relationships with senior technical individuals within internal and client organizations.\nGuide teams through the end-to-end project lifecycle, covering the initial conception, business requirements, software architecture, implementation, and delivery.\nAct as a technical lead and coach for the more junior team members.\nA resourceful leader to bring our Data Engineering practices to the next level:\nPromote the adoption of new initiatives on client side or internally.\nRun group-wide thought leadership initiatives to advance our architectural practices and sustain our technical excellence.\nDepending on your previous experiences and appetite to grow, you will have the opportunity to gain more responsibilities.\nRequirements\n\ud83d\udd27 What we are looking for\nA trustful expert in Data Engineering with a strong technical knowledge that can be put at the best-use of our clients\u2019 project.\nA client-centric person with strong consultative selling capabilities and commercial awareness to be a winning partner to close deals.\nA resourcefulness and a self-starter leader, always looking for constant self and collective improvements in his\/her areas of expertise and beyond.\nRequired qualifications:\n2-5 years of experience in designing and implementing large scale data engineering projects, preferable from a consulting background.\nStrong expertise on data management and cloud architecture.\nExcellent leadership, stakeholder management and communication skills to speak and present in front of senior executives.\nGood communication skills, fluent in English, French or German is a plus.\nBenefits\n\ud83d\udce6 What we offer\nA yearly education budget to steep your learning curve\nA yearly sport budget because a fit body leads to a fit mind\nA position that enables you to have an impact on 1\u2019000s of people\nA welcoming, international, and diverse team with a fun and dynamic spirit\nOpportunity to join a talented and experienced startup with proven traction in its journey\nOpen and transparent culture\nOur culture\nThe family culture we have built in our company is something we are very proud of. We truly value our people and encourage them to work and express themselves in the best possible way. You can always count on the people around you to help you get back on track. We always strive to do the right thing. Open discussion is welcomed and everyone is encouraged to share new ideas. We believe everyone can make a valuable impact no matter their role. We are united through the passion with which we approach our goals. 'Good-enough' is missing from our vocabulary because we stretch for amazing.\nCheck our LinkedIn and Instagram to learn more about us & don\u2019t hesitate to contact us if you have any questions.","91":"About PriceHubble\nPriceHubble is a PropTech company with over 200 employees, set to radically improve the understanding and transparency of real estate markets based on data-supported insights. We aggregate and analyze a wide variety of large scale datasets, and apply state-of-the-art machine learning to generate high-quality valuations and predictive analytics for the real estate market. We are headquartered in Z\u00fcrich, with offices in Berlin, Hamburg, Paris, Vienna, Prague and Tokyo.\nWhy us?\nWe have a startup environment, low bureaucracy, an international team and business, and are backed by world-class investors.\nWe focus on building good products, well engineered, that make a difference to our customers. To achieve this, we believe in accountability, empowering our teams, and an empathetic, honest and transparent work environment.\nWe believe in the market possibilities unlocked by digitalization in the real estate industry, as well as the strong beneficial impact it can have on people\u2019s lives and the environment, and we want to be a major actor of that change.\nYour role\nYou will be part of the Data team, responsible for designing and improving the architecture, and guiding the engineering of several of the team\u2019s data products. As Data Architect, you will have a key role in helping to design and deliver efficient and scalable data products. These products will directly integrate into our customer workflows as well as support key functions of the applications we offer them, and you will have a direct hand in ensuring they are trustworthy, versatile, and fit for purpose.\nYour mindset\nYou enjoy working on a wide range of technical domains and use cases, in an international and multi disciplinary team. You are passionate about learning new things and transferring this knowledge to others. You are an empathetic team player and speak your mind, you measure success by what is accomplished and how others have been enabled by your work.\nYou will strive at PriceHubble and in the Data team if you deeply care about the impact your work has on other teams, the customers your products serve and the real-estate industry, and if you take pride in simple, elegant and well crafted solutions, and derive great satisfaction from delivering reliable and usable systems.\nYour responsibilities\nDesign, model and specify datasets that will act as the source-of-truth for PriceHubble\u2019s processes and the activities of PriceHubble\u2019s customers\nArchitect, scale and optimize data pipelines and data management systems to deliver those data products\nTrack, monitor and improve the performance of these products, and optimize their trustworthiness for their use cases\nStay at the cutting edge of the industry\u2019s best practices in data design and management, and evangelize these towards the larger technical organization\nDrive the consensus between teams on data standards, methodologies and technology choices, and support peers and more junior engineers on their application\nRequirements\nBSc or MSc in computer science or related fields\n5+ years practice of agile methodologies and devops methods\n5+ years of experience in the Python data engineering ecosystem\nExperience working with public cloud platforms (AWS, Azure or GCP)\nFamiliar with data design and specification techniques and languages (ORM, UML, XSD, JsonSchema \/ OpenAPI\u2026)\nExtensive experience with data systems, ML and ML ops in production, at scale (K8s, Kubeflow, Dataproc, Airflow, Spark\u2026)\nYour abilities\nExcellent skills in object-oriented programming, data structures and algorithms\nExcellent skills designing distributed service architectures in a cloud environment\nStrong ability to speak with layman leaders, and other engineers or scientists with a specialized profile\nStructured, didactic communicator and able to mentor other engineers and scientists\nStrong oral, written and presentation skills with ability to explain complex concepts clearly to a variety of audiences\n\n* We are interested in every qualified candidate who is eligible to work in the European Union and UK but we are not able to sponsor visas.\nBenefits\nJoin an ambitious and hungry team and enjoy the following benefits:\n\ud83d\udcb0 Competitive salary because we always want to attract the best talents.\n\ud83d\udcd8 Learning & Development program - We want you to feel happy, confident about improving your skills, experience level as well as your personal development success.\n\ud83c\udfe2 Very well-located offices with a great remote work policy and the possibility to work from different places.\n\ud83d\udd53 Flexible working hours and work life balance","92":"OANDA is a global leader in online multi-asset trading services, currency data, corporate payments and FX services.\nEveryone at OANDA is focused on our vision to transform how our customers can meet all their currency needs. From our roots in 1996 that provided free currency exchange information to launching a multi-award winning global FX and CFD trading business to our recent new venture of money transfer. OANDA is now a major global player.\n  Join us and: \nWork on an award-winning platform that processes billions of dollars every day.\nBe on a team that\u2019s responsible for company-wide top priority projects.\nDeliver reliable software on an agile team striving for continuous integration, automated testing, and code reviews.\nContribute innovative ideas to improve the daily trading experience of thousands of customers.\nImprove yourself and your team through education and continuous learning.\nData Engineering team is  looking for a Data Architect to help reshape the culture of data throughout the organization. You\u2019ll have the opportunity to transform the way our business teams, technical teams and applications communicate with one another through the common language of data, unifying our data models and driving the architecture of the next generation of our big data platform as we move fully into the cloud. You will drive strategies to democratize data and establish a data-first culture to supercharge our ability to make data-driven decisions at all levels of the enterprise.\nDuties and Responsibilities\nApply domain-driven design principles to create unified data models that standardize how data is produced, consumed and interpreted across the enterprise\nEnable data discovery through metadata management, establishing our data catalog, data dictionaries and business glossaries\nCreate data vaults, data marts and semantic layers to target the unique needs of the different areas of the business\nDevelop a comprehensive understanding of all facets of OANDA\u2019s business, analyze data requirements and provide data solutions to serve business and technology teams throughout the company\nSolve MDM challenges to ensure a consistent, accurate and verifiable representation of data across all of our systems\nArchitect the underlying data transformations required for OANDA to integrate companies we have or may acquire\nDrive the migration from on-prem data systems to a cloud-native GCP architecture, building out our cloud data lake and data warehouse, while developing roadmaps and defining transitional states on the way to achieving long-term objectives\nArchitect data pipelines through batch and stream processing techniques using technologies like Kafka, Google Cloud Dataflow and Mule to deliver data where it is needed, when it is needed\nProduce APIs with data models that allow our internal application teams, customers, regulators and third-party partners to effectively leverage our data\nOwn data governance - ensure teams across the enterprise are meeting design standards for data security, privacy, quality, scalability, retention, extensibility and performance, and act as a leader within the organization in promoting best practices\nAssess, select and implement best-in-class tooling, applications and systems to support data technology goals\nQualifications\nDeep industry experience in data architecture, data strategy and end-to-end data management systems including hands-on implementations using appropriate tools\nExperience working with a variety of SAAS and third-party tools to manage data quality, profiling, governance, archival and accelerate the buildout of the cloud platform\nDeep industry experience in building and operationalizing public cloud data platforms, especially in Google Cloud Platform\nExperience in data API design\nBonus skills\nDomain experience in forex or financial markets \nExperience with time-series databases like KDB to store tick data\nExperience in real-time, high-frequency trading platforms \nOANDA Global Corporation is a diverse and global team with offices around the world. We value the unique skills and experiences each individual brings to OANDA. We are committed to creating and sustaining a collegial work environment in which all individuals are treated with dignity and respect and one which reflects the diversity of the community in which we operate. We provide an inclusive and accessible environment for everyone.\nCandidates selected for an interview will be contacted directly. If you require accommodation during the recruitment and selection process, please let us know. We will work with you to provide as seamless a recruitment experience as possible.\n     ","93":"Accenture Federal Services delivers a range of innovative, tech-enabled services for the U.S. Federal Government to address the complex, sensitive challenges of national security and intelligence missions.\nRefer a qualified candidate and earn up to $20K. Learn more here >\nJob Description: \nAccenture Federal Services is seeking a Geospatial Analyst who wants to develop innovative solutions for customers and internal product teams. We look to rapidly prototype solutions and deploy the most promising of them. We identify and leverage the latest techniques so that our customers can stay one step ahead. On every project you\u2019ll learn something new (and likely teach us something as well). If that sounds appealing to you - we\u2019d love to chat.\nResponsibilities include:\nDefine the data requirements and structure for the application. Model and design the application data structure, storage, and integration.\nHere's what you need:\nMinimum 5 years of experience with PostgreSQL or PostGIS databases with the ability to insert, process, and run SQL queries.\nMinimum 5 years of experience using ESRI software\nMinimum 5 years of experience with GIS products\nMinimum 5 years conducing geospatial and statistical analysis\nBonus points if you have:\nGeographic Information Systems (GIS) \/ P3 \u2013 Advanced\nPostgreSQL \/ P3 - Advanced\nSecurity Clearance:\nAn active TS\/SCI with Polygraph is required to start\nCompensation for roles at Accenture Federal Services varies depending on a wide array of factors including but not limited to the specific office location, role, skill set and level of experience.\u202fAs required by local law, Accenture Federal Services provides a reasonable range of compensation for roles that may be hired in California, Colorado, New York City or Washington as set forth below and\u202finformation on benefits offered is here.\u202f\u202f\u202f\u202f \n  Role Location: Range of Starting Pay for role\u202f\u202f \nCalifornia: $105,200 - $168,400\u202f \nColorado: $105,200 - $145,500\u202f \nNew York City: $121,700 - $168,400 \nWashington: $112,100 - $154,900 \nEligibility Requirements\nUS Citizenship required.\nImportant information\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture Federal Services\nAccenture Federal Services is an EEO and Affirmative Action Employer of Females\/Minorities\/Veterans\/Individuals with Disabilities. An active security clearance or the ability to obtain one may be required for this role. Accenture Federal Services is committed to providing veteran employment opportunities to our service men and women. Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.\n  What We Believe\nWe have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment. Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities. Read more here\nEqual Employment Opportunity Statement\nAccenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.\nAccenture is committed to providing veteran employment opportunities to our service men and women.\nFor details, view a copy of the Accenture Equal Opportunity and Affirmative Action Policy Statement.\nRequesting An Accommodation\nAccenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.\nIf you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an email or speak with your recruiter.\nOther Employment Statements\nThe Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.","94":"!099 or Corp to Corp 6 month plus contract\n\nWhat You'll Do Here:\nOwn & build design, develop, test, deploy, maintain and enhance full-stack data engineering solutions for the Data Pipelines, Data Lake & Data Mart encompassing the Data Warehouse.\nIdentify, evaluate and validate the right AWS technologies for each layer of the existing analytical platform, including technologies for ingestion layer, data processing layer and data consumption layer.\nIdentify optimal strategies for migrating data across cloud platforms (from GCP to AWS).\nInspect existing data platform components and solutions and evangelize through data-based evidence improvements in terms of data processing and storage.\nWith your technical expertise, own and manage project priorities, deadlines and deliverables.\nWork closely with Data Operations to improve CI\/CD pipelines, as well as continually improve the operations, monitoring and performance of the Data Warehouse\nWork across multiple teams in high visibility roles and own solutions end-to-end\nRequirements\nThe Skills You'll Bring:\nExpert knowledge Java, Python, Spark and SQL scripting, working knowledge of R or similar statistical computing packages.\nexperience in building data & feature engineering applications, including design, implementation, debugging, and support\nExperience working in the AWS Services Ecosystem or relevant Cloud Infrastructures such as Google Cloud or Azure\nHands-on experience with AWS Glue, AWS Redshift, AWS Athena and other AWS data related technologies is required.\nDeep understanding of data integration to support analytics & feature engineering for Machine learning algorithms\nStrong at applying data structures, algorithms, and object-oriented design, to solve challenging data integration problems\nExperience with Databricks technologies as a compute environment is a plus\nBachelor\u2019s \/ Master\u2019s degree in Computer Science or equivalent\nMust have 3 plus years experience","95":"Location: Delhi, Gurgaon, Bangalore, Chennai,Indore, Ahmedabad, Jaipur, Kolkata,Pune.,None,None\nAbout Material\nMaterial is a global strategy, insights, design, and technology partner to companies striving for true customer centricity and ongoing relevance in a digital first, customer-led world. By leveraging proprietary, science-based tools that enable human understanding, we inform and create customer-centric business models and experiences + deploy measurement systems \u2013 to build transformational relationships between businesses and the people they serve.\nAbout Srijan\nSrijan is a global engineering firm that builds transformative digital paths to better futures for Fortune 500 enterprises to nonprofits all over the world. Srijan brings advanced engineering capabilities and agile practices to some of the biggest names across FMCG, Aviation, Telecom, Technology, and others. We help businesses embrace the digital future with cloud, data, API and platform centric technologies and adapt to changing business models and market demands. Srijan leads in Drupal with 350+ Drupal engineers, 80+ Acquia certifications. Srijan is also a Drupal Enterprise Partner & Diamond Certified\n Job description\nExperience in service architecture, development, and high performance and scalability.\nExperience in Spark, SQL performance tuning, and optimization.\nExperience with architectural design and development of large-scale data platforms and data applications.\nGood hands-on experience in AWS\nIn-depth understanding of Spark Hive Frameworks and their internal architecture\nStrong programming background with Java \/ Python.\nPractical exposure to end-to-end design and implementation process of Near-Real-Time and Batch Data Pipelines.\nStrong SQL (Hive\/Spark) skills and experience tuning complex queries\nExcellent understanding of AWS storage, and its compute services. Able to effectively use of AWS managed services - Step function, EMR, Lambda, Glue and Athena.\nHands-on experience on Data Lake and ETL pipeline development\nExpertise on designing and building new Cloud Data platform and its optimization at organization level.\nHands-on experience in Big Data technologies - Hadoop, Sqoop, Hive and Spark including DevOps.\nMust Have:\n10-12 years of big data technologies or data platform architecture experience with deep technology expertise in Hive, HDFS, Spark, Kafka, Java, or Scala,Python, Pyspark etc.\nExperience in service architecture, development, and high performance and scalability.\nExperience in Spark, SQL performance tuning, and optimization.\nExperience with architectural design and development of large-scale data platforms and data applications.\nExpertise in design and management of complex data structures and data processes like ETL\/ELT.\nExpertise in managing and operating distributed big data systems, including but not limited to the Hadoop ecosystem.\nA deep understanding of issues in multiple areas such as data acquisition and processing, data management, distributed processing, and high availability is required.\nKnowledge of Teradata.\nExpertise on designing and building new Cloud Data platform and it s optimization at organization level.\nStrong past experience on designing AWS data lake and surrounding ecosystem development.\nGood to have\nUnderstanding of sage maker and ML algorithms\nExperience in migrating workloads from on-premise to cloud and cloud to cloud migrations\nExperience on AWS services like RDS, DynamoDB, Redshift\nAbility to drive the deployment of the customers workloads into AWS and provide guidance, cloud adoption model, service integrations, appropriate recommendations to overcome blockers and technical road-maps for AWS cloud implementations.\nExtensive, real-world experience designing technology components for enterprise solutions and defining solution architectures and reference architectures with a focus on cloud technologies.\nAct as a subject-matter expert OR developer around AWS and become a trusted advisor to multiple teams.\nCoach and mentor engineers to raise the technical ability of the rest of the team, and\/or to become certified in required AWS technical certifications\n What you will get:\nCompetitive Salaries with flexi benefits \nGroup Mediclaim Insurance and Personal Accidental Policy\n30+ Paid Leaves in a year \nLearning and Development of quarterly budgets for certification\nApply to this job","96":"Company Description\nHitachi Solutions is a global Microsoft solutions integrator passionate about developing and delivering industry-focused solutions that support our clients to deliver on their business transformation goals. Our industry focus, expertise, and intellectual property is what truly sets us apart. We have earned, and continue to maintain, a strategic relationship with Microsoft. Recognized for our achievements - teaming with our clients to deliver innovative digital solutions and services - is how we have achieved year after year recognition.\nAs their trusted advisor, we support our clients to deliver on their strategic business initiatives as they unify, automate, and modernize their data and operations to increase efficiency, reduce costs, and enhance their customer\u2019s experience. Our over 3,000 team members across 14 countries, and our 18 years of 100% focus on Microsoft technologies and business applications, is how we deliver excellence through expert services and industry-focused cloud solutions. \nA part of Hitachi, Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world\u2019s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies.\nJob Description\nPlease note:  Although this is a Remote \/ Virtual \/ Work-From-Home career opportunity, candidates MUST reside, and be authorized to work without sponsorship, in the US.\n This is a full-time role in our New Product organization for professionals with a proven history of execution, and a desire to rapidly expand a product organization.  Our team is seeking a Senior Data Architect, with a strong background in data definition, modeling, and implementation.  \n This is a hands-on architect role where the individual will be responsible for the overall design of solutions within the data ecosystem serving our customers. This role will require someone who is experienced in designing data schemas using Kimball\/Dimensional modeling and pipelines in Databricks for data warehouses\/lakehouses and reporting systems, is able to evaluate multiple technologies and technical solutions, and be a hands-on contributor for engineering goals for multiple engineering teams. Additionally, as a technical leader within the team, you will mentor and coach your team members; therefore, top candidates have experience as either a team lead or manager. \n Responsibilities\nScope and execute with independence. Work with the product team to understand platform capabilities and leverage those capabilities to bring customer\u2019s data estate. \nIdentify and articulate technical and operational requirements for data pipelines and the models they populate; be able to optimize these pipelines for high performance\/resiliency workloads. \nInstill excellence into the processes, methodologies, standards and technology choices embraced by the team with customer teams, and junior staff. \nLead requirements discovery and delivery workshops \u2013 helping customers understand their options and guiding them to the best options. \nBe an advocate for the customer, and support delivery leadership (Director, VPs) in managing client expectations. \nDedicate time to continuous learning to keep the team and customers appraised of the latest developments in the space.\nA committed teacher and someone who enjoys developing technical maturity across the company. \nExperience supporting analytics, data science and\/or engineering teams and understand their unique needs and challenges.\nQualifications\n8+ overall years of professional experience including 4+ years\u2019 experience in designing high-scale Kimball\/Dimensional models is REQUIRED \n4+ years of experience with data modeling, schema design patterns and modern data access patterns (including API, streams, data lake) is REQUIRED\n2+ years as a proven leader interacting with customers (client facing) to collect requirements and manage a technical data backlog is REQUIRED; therefore you must have excellent interpersonal skills, both written and spoken, as well as a consultative\/collaborative style.\n2+ years with Databricks and Spark framework are REQUIRED\n2+ years of experience building data applications, microservices and\/or APIs using Python, Scala or an equivalent language is REQUIRED\n2+ years of experience with SQL, knowledgeable in complex queries and joins is REQUIRED; experience with UDF and\/or Stored Procedure development is HIGHLY DESIRED\n2 + years Azure Data Services including Azure Data Factory, ADLS, and Synapse is HIGHLY DESIRED; strong experience with AWS will be considered in lieu of.\n  #REMOTE\n#LI-CA1\n#azure\n#databricks\n#datalakehouse\n#datamodeling\nAdditional Information\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.","97":"Company Description\nBlend360 is a world class marketing, analytics, and technology company that delivers the best results for our clients. Our primary focus is Data Sciences; leveraging data and applied mathematics to solve our clients\u2019 business challenges. Blend360 is known for our exceptional people, our get-it-done mentality, and delivering high impact and sustainable results. If you love to solve difficult problems and deliver results; if you like to learn new things and apply innovative, state-of-the-art methodology, join us at Blend360.\nJob Description\nBlend360 is looking for a technology industry professional with a combination of business acumen and technical insight to maximize the value of our clients\u2019 technology assets.  You will understand the business problem, align stakeholders on your vision, develop a technical strategy, and oversee the implementation of critical technology products that drive our clients\u2019 organization. \n Job Duties\nDevelops and maintains a vision and plan for technical assets and oversees the execution of that plan to maximize the value of the technology to the organization.\nKnows how to identify key client initiatives, refine and manage stakeholders as it relates to the larger project\nDetermines operational objectives by studying business functions; gathering information; evaluating output requirements and formats\nAbility to conduct an enterprise analysis of tools and processes while building relationships with various levels of a client organization to help develop and drive a clear vision\nUnderstands business strategy as it relates to technologies used within client engagements\nCan conduct market analyses for tools and functionality available in the marketplace.\nUnderstanding product releases as it relates to requirements and deadlines\nDesigns and defines new technical programs and requirements\nImproves systems and processes by studying current practices; designing modifications, recommending controls by identifying problems; writing improved procedure\n Qualifications\n Required Skills\nBackground in Data Science or Data Engineering\n5+ years of experience\nStrong written documentation skills\nStrong verbal and client facing communication skills\nA critical thinker with a consultative mindset\nStrong understanding of the data industry as a whole, including tools, best practices, and functionality\nHands-on Experience across 2 or more of the following technologies:\nETL processes (Cloud Native, DataBricks, Spark, Airflow)  \nMultiple coding languages (JavaScript, Python, Java, .Net)  \nExperience with Database Designs & Administration (SQL, noSQL, Cache, DataLakes, Cluster)  \nCloud Native Engineering (AWS, Azure, GCP, WAF)  \nCloud Development \/ (CI\/CD) \/ DevOps \nMust have Certification in Databricks  or Snowflake \nThe starting pay range for this role is $100k - $145k. Actual compensation within the range will be dependent on several factors including but not limited to relevant experience, skills, certifications, training, and location. It is not typical for an individual to be hired at or near the top of the range and determining factors for compensation are considered for each individual circumstance. BLEND360 also offers a competitive benefits program to meet the health and financial well-being of our team and their families. You can look forward to a range of benefits including medical, dental, vision, 401K, PTO, paid holidays, commuter benefits, spending accounts, life insurance, disability coverage, and EAPs. \nAdditional Information\n All your information will be kept confidential according to EEO guidelines.","98":"Company Description\nTransforming businesses, driving success: SmarTek21\nSmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev\/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients\nJob Description\nSmarTek21 is looking for a hands-on architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.  \nQualifications\n\u2022 Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python.\n\u2022 Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks.\n\u2022 Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP).\n\u2022 Solid understanding of enterprise strategies for data security and data governance.\n\u2022 Experience in practice development, architecture, and consulting or product development.\n\u2022 Experience delivering data analytics projects and architecture guidelines.\n\u2022 Experience in engaging with enterprise architects. Non-technical Skills:\n\u2022 Excellent oral and written communication and presentation skills.\n\u2022 Ability to handle ambiguous situations and take trade-off decisions.\n\u2022 Strong problem solving and analytical skills to break down complex problems into smaller components.\n\u2022 Ability and willingness to perform in a team environment.\nRequirements:\n\u2022 Understand prospect\/customer\/partner technology landscape.\n\u2022 Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation.\n\u2022 Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers\/partners.\n\u2022 Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints.\n\u2022 Collaborate with the engineering team to create proof-of-concepts (POCs).\n\u2022 Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices.\n\u2022 Demonstrate business value of proposed solutions or current products to prospects and customers.\nSalary Range: $200,000-$215,000 (may be subject to change outside of WA State)\nAdditional Information\nWhat Is in It for You:\nPaid Time off \u2013 start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service.\nPaid Holidays - 8 paid holiday a year in addition to your PTO.\nHealth Insurance for FT employees \u2013 we pay 100 % premium of medical, dental and vision.\nHealth Insurance for FT employee\u2019s family \u2013 we pay 50% of premium for medical, dental and vision for dependents.\n401(k) \u2013 we administer 401(K) retirement contribution for FT employees.\nLife Insurance\/Short Term and Long-Term Disability \u2013 at no cost to you\nOpportunities for internal promotions\/career advancement\nFamily friendly work hours (closed on weekends and paid holidays)\nSmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and\/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class.","99":"Company Description\nMerkle is a leading data-driven, technology-enabled, global performance marketing agency that specializes in the delivery of unique, personalized customer experiences across platforms and devices. For more than 30 years, Fortune 1000 companies and leading nonprofit organizations have partnered with Merkle to maximize the value of their customer portfolios. The agency\u2019s heritage in data, technology, and analytics forms the foundation for its unmatched skills in understanding consumer insights that drive people-based marketing strategies. Its combined strengths in performance media, customer experience, customer relationship management, loyalty, and enterprise marketing technology drive improved marketing results and competitive advantage. With 9,600+ employees, Merkle is headquartered in Columbia, Maryland, with 50+ additional offices throughout the US, EMEA, and APAC. In 2016, the agency joined the Dentsu Aegis Network. For more information, contact Merkle at 1-877-9-Merkle or visit www.merkleinc.com.\nJob Description\nThe purpose of this role is to take database implementation projects through the entire development life cycle.  This role will work as the solution lead and will be directly involved in the architecture, solution design, development, testing and deployment of the solution. This role serves as the technical subject matter expert for the solution.\nKey responsibilities:\nArticulates feasible technology choices that meet the requirements; ability to put forth a viable, scalable technology point of view; be knowledgeable and conversant with the offline and online (digital) marketing technology landscape\nBridges business and technical requirements to provide a cohesive, seamless solution to scale and perform\nHas the ability to wear multiple technology hats across systems integration, technology consulting and technology solution design and architecture\nParticipates and leads technology discussions with prospects (RFP support)\nLeads large-scale technology implementations including understanding of scoping, estimation and managing timeline\/budget\nHas experience in legacy migration and re-platform of technology solutions\nLeads technology conversations with senior management (be an internal and external technology solutions evangelist) and be the technology voice of the solution\nIs responsible and accountable for the underlying client technology solution architecture\nLeads CRM platform development programs and roadmap Data warehouse architecture and ETL design\nHas experience in DB integration and execution, data architecture, database, process (ETL and services), identity Management, open source (GNU, Apache, Java, Linux, HDFS et al) tools and technologies, real-time application integration (web services)\n Additional Information\nDentsu (the \"Company\") is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant or employee of the Company, on the basis of age, sex, sexual orientation, race, color, creed, religion, ethnicity, national origin, alienage or citizenship, disability, marital status, veteran or military status, genetic information, or any other legally recognized protected basis under federal, state or local laws, regulations or ordinances. Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and\/or certain state or local laws. A reasonable accommodation is a change in the way things are normally done that will ensure an equal employment opportunity without imposing an undue hardship on the Company. Please contact recruiting@dentsuaegis.com if you need assistance completing any forms or to otherwise participate in the application process or to request or discuss an accommodation in connection with a job at the Company to which you are applying.\nThe anticipated salary range for this position is $113,000-$130,000. Salary is based on a range of factors that include relevant experience, knowledge, skills, other job-related qualifications, and geography.  \n#LI-DB2\nAbout dentsu \nDentsu is the network designed for what\u2019s next, helping clients predict and plan for disruptive future opportunities in the sustainable economy. Taking a people-centered approach to business transformation, dentsu combines Japanese innovation with a diverse, global perspective to drive client growth and to shape society www.dentsu.com. \nWe are champions for meaningful progress and we strive to be a force for good\u2014for our people, for our clients, for the industry and for our society. We keep our people at the center, creating space for growth, understanding and learning so they can thrive. We embed diversity, in our mindset, in our solutions and in our teams to empower an inclusive, equitable and culturally fluent environment. Building this culture within our teams makes us better collaborators with each other and with our clients, driving better outcomes for all.\nDentsu (the \"Company\") is committed to a policy of Equal Employment Opportunity and will not discriminate against an applicant or employee of the Company, on the basis of age, sex, sexual orientation, race, color, creed, religion, ethnicity, national origin, alienage or citizenship, disability, marital status, veteran or military status, genetic information, or any other legally-recognized protected basis under federal, state or local laws, regulations or ordinances. Applicants with disabilities may be entitled to reasonable accommodation under the terms of the Americans with Disabilities Act and\/or certain state or local laws. A reasonable accommodation is a change in the way things are normally done that will ensure an equal employment opportunity without imposing an undue hardship on the Company. Please contact recruitingops@dentsu.com if you need assistance completing any forms or to otherwise participate in the application process or to request or discuss an accommodation in connection with a job at the Company to which you are applying. ","100":"Company Description\nBosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it\u2019s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.\nJob Description\nRequired Experience:\n10+ years of in-depth experience in enterprise level IT environments supporting SDLC\/Agile, 5+ years as Solution Architect with proficiency working in environments supporting solutions design\nProven expertise in Design and architect multi layered Cloud only \/ Hybrid network for Microsoft azure cloud\nAbility to understand and delivery of Security and compliance solutions to meet business standards\nAbility to architect and integrate on-premises applications, cloud providers or other platforms with Azure\nProven ability in analyzing, designing, and delivering full-stack technical solutions to customers leveraging Cloud services (Azure)\nAzure Integration Services (Logic Apps, API Management, Service Bus & Event Grid) Azure SQL Database, SQL Server, SQL Server IaaS, firewalls, Web App proxies, Bash, BGP, Chef, Puppet, OSS Technologies, PowerShell scripting, Azure Monitor and Application Insights\nAzure Security and Identity services (e.g., Security Center, Azure Active Directory, RBAC, NSGs \/ ASGs)\nAzure Networking services (e.g., VNETs, Load Balancers, Front Door, ExpressRoute, Traffic Manager, Content Delivery Network)\nWorking experience in the areas of Data Engineering (Azure Data Factory, Azure Synapse, Data Lake)\nDesigning and Deploying Azure IaaS and PaaS solutions\nExperience with Cloud-based infrastructure systems, BigData platforms, Data processing, data verification, ETL pipelines & Data Visualization\nKnowledge on implementing DevOps as a culture and with strategies and tools to implement DevSecOps practices as part of a new\/existing delivery engagement\nExperience with build, design, implementation, and maintenance of solutions, products, and services in Onprem & Cloud environments\nGood to have understanding and demonstrated working experience in hybrid cloud\nExperience in managing cross-functional team, day-to-day relationships with clients, and stakeholders supporting clients to achieve better outcomes\nExtensive client account and project management experience with demonstrated ability to plan and manage the execution and implementation projects\nRole Exposure:\nBuilding cloud integration framework architecture; and Kubernetes for containerized deployment\nUse problem-solving creativity to design, architect, and develop high-end technology solutions that solve our clients' most complex and challenging problems across different industries on Microsoft Azure\nExplore different tech stacks and architecture design\nDocument supporting evidence with KPIs for decision on solution design and document product guideline and protocols to seamlessly utilize the framework\nPrior experience with ETL & Big Data to set up scalable pipeline to process data in real time and batch\nDevelop configurable solutions to support cross functional requirements and support multiple platforms\nQualifications\nQualifications\/Certifications:\nEducation qualification: BE \/B Tech (IT\/CS\/Electronics) \/ MCA \/ MSc Computer science\nLocation\n123, Hosur Rd, 7th Block, Koramangala, Bengaluru, Karnataka 560095\nFull-time\nAdditional Information\nGood To have:\nShould have Azure Solutions Architect Expert or DevOps Engineer Expert Microsoft Certification\nAny certifications or whitepapers.","101":"TetraScience is the Scientific Data Cloud company with a mission to accelerate scientific discovery and improve and extend human life. The Scientific Data Cloud is the only open, cloud-native platform purpose-built for science that connects lab instruments, informatics software, and data apps across the biopharma value chain and delivers the foundation of harmonized, actionable scientific data necessary to transform raw data into accelerated and improved scientific outcomes. Through the Tetra Partner Network, market-leading vendors access the power of our cloud to help customers maximize the value of their data.\nOur core values are designed to guide our behaviors, actions, and decisions such that we operate as one. We are looking to add high performance team members that authentically and unconditionally embrace the our values:\nTransparency and Context - We trust our people will make the right decisions and overcome any challenges when given data and context.\nTrust and Collaboration - We believe there can only be trust when there is transparency. We are committed to always communicating openly and honestly.\nFearlessness and Resilience - We proactively run toward challenges of all types. We embrace uncertainty and we take calculated risks.\nAlignment with Customers - We are completely committed to ensuring our customers and partners achieve their missions and treat them with respect and humility.\nCommitment to Craft - We are passionate missionaries. We sweat the details, as the small things enable the big things.\nEquality of Opportunity - We seek out the best of the best regardless of gender, ethnicity, race, or age; We seek out those who embody our common values but bring unique and invaluable perspectives, talents and advantages.\nWho You Are\nYou love to collaborate with fellow engineers, managers, designers, user researchers, executives, and customers, and inspire them to do their best. You relentlessly strive to excel in your craft and take pride in your craft. You are passionate about continuously improving what we deliver and how we deliver our products to customers. You take ownership of all the aspects of software design and architecture deliverables you are working on. You consistently seek understanding and clarity. You look at every interaction as an opportunity to educate, inspire, and learn. You aren\u2019t afraid to ask questions. You have the humility and confidence to not be the smartest person in the room.\nIn this critical leadership role you will own the data architecture for the TetraScience Scientific Data Cloud, devising both the short and long term architectural strategies to achieve the vision of harmonized data, bridging the gap between heterogeneous instrument and software vendors and repeatable scientific data usage in integration, analytics, and AI \/ ML.\nYou will work closely with product leadership and the executive staff to ensure that the overall architecture plan and execution are in concert with the product strategy. This role will lead by example with a small team of architects to form and prototype architecture decisions and partner with engineering teams to implement. You will have come from a strong technical background and be able to demonstrate in code, and drive the technical direction of the data product and architecture around the use cases that we are solving for.\nYou are the steward of the world\u2019s most consequential and valuable data - the very scientific data that is necessary to solve humanity\u2019s grand challenges.\nWhat You Will Do\nOwn, define, communicate, and drive our technical vision, architectural strategy for TetraScience Scientific Data Cloud.\nDevise the strategy to support very diverse data domains and evolve the product to support high scale and downstream, analytics, and AI\/ML use cases especially on harmonizing data from heterogenous instruments and software to accelerate data exploration and analysis.\nSupport and advise executive leadership regarding technical and architectural feasibility, implications, readiness, and data integrity.\nProvide key inputs into technology evaluation and technology planning activities.\nDrive innovations with tangible examples to improve the consistency, usability, ease of maintenance of our data architecture, and minimize impact to our data customers.\nCommunicate the architecture to the engineering and product teams, customers, and stakeholders.\nMentor and train other team members of the Tetra Data team on design techniques, data modeling, data query and processing technologies, systems architecture and coding standards.\nStay on the cutting edge of emerging technology, forging key relationships with peers.\nProvide thought leadership and represent TetraScience at industry and technology conferences.\nRequirements\n\n15+ years\u2019 experience designing and building highly scalable, mission-critical distributed software systems, focused on analytical data processing.\nDeep understanding of Data Architecture, Data Modelling, Schema design, Data Integration.\nUnderstanding of modeling strategies (dimensional, snowflake, relational, unstructured).\nSignificant experience with ETL \/ data orchestration, data integration, data lakes, data warehouses, and data science\/machine learning tooling.\nDemonstrated ability to drive architectural vision for a company or highly scalable line of products.\nProven track-record of success evolving and informing product strategy within a start-up environment through prototypes and working code.\nHands on experience in building data warehouses, platform architecture, and\/or production-grade machine learning technologies.\nProficient in SQL, Python, and web scale technologies.\nDemonstrable curiosity and drive to learn, with the ability to translate these qualities into tangible results.\nExcellent problem solving, collaboration and communication skills, both verbal and written.\nAbility and desire for transparent communication and influence at the executive level.\nHave an entrepreneurial spirit and bring ideas to the table.\nExperience in Life Sciences domain a big plus but not necessary.\nBenefits\n\n100% employer paid benefits for all eligible employees and immediate family members.\n401K.\nUnlimited paid time off (PTO).\nFlexible working arrangements.\nCompany paid Life Insurance, LTD\/STD.\n\nNo visa sponsorship is available for this position","102":"Riverside Research is an independent National Security Nonprofit dedicated to research and development in the national interest. We provide high-end technical services, research and development, and prototype solutions to some of the country\u2019s most challenging technical problems.\n Job Number: 1080\nRiverside Research is seeking full-time Senior Data Architects to support Director, Air Force Chief Data Office (SAF\/CO) sponsored activities across the Air Force Enterprise to ensure the visibility, accessibility, understanding, sharing, and trustworthiness of data across air, space, and cyberspace domains. Candidates will provide subject matter expertise in and perform on multidisciplinary teams that support data preparation and architecture, development of agile algorithmic solutions, evaluate and\/or execute data governance and data maturity models; and conduct data analytics using state of the art mathematical and machine learning\/artificial intelligence techniques and other data analytic lines of research\/effort. Positions will be at various CONUS Air Force installations and the National Capital Region.\nAll Riverside Research opportunities require U.S. Citizenship\nJob Duties\nApplies a wide set of statistical, programming and\/or engineering disciplines for planning, design, analysis, and specification development for systems and databases to support the end user analysis process.\nResponsible for, or assists in the recommendations of platform, end user Business Intelligence tools, design, quality assurance standards, and performance standards.\nDetermines benefit of tradeoffs in recommended options.\nWorks with consultants, programmers, data scientists and analysts assigned to the project. \nRequired Qualifications:\nTop Secret clearance with SCI adjudication\nEducation and Experience:\nBachelor\u2019s Degree in Computer Science, Information Systems or other related scientific or technical discipline \n9 or more years of increasingly more complex relevant experience in a field relevant to the task order.\nMaster's degree or an advanced certification in data analytics may be substituted for 4 years of experience.  \nFamiliarity with the manipulation of unstructured data in a data analytics environment, and the use of open-source tools, cloud computing, machine learning and data visualization as applicable.  \nThe ability to use\/code in  a language applicable to the project or task order such as Apache Hadoop, Python, and advanced knowledge of machine learning.\n  Riverside Research does not mandate COVID vaccination as a condition of employment. However, proof of vaccination or negative test may be required to enter certain government facilities and sites. Vaccination requirements will depend on the status of the federal contractor mandate and customer site-specific requirements. To protect the health and safety of its employees, their families, and to comply with customer requirements, the company requires all employees to disclose vaccination status (upon hire). \nRiverside Research strives to be one of America's premier providers of independent, trusted technical and scientific expertise. We continue to add experienced and technically astute staff who are highly motivated to help our DoD and Intelligence Community (IC) customers deliver world class programs. As a not-for-profit, technology-oriented defense company, we believe service to customers and support of our staff is our mission. Our goal is to serve as a destination company by providing an industry-leading, positive, and rewarding employee experience for all who join us. We aspire to be a valued partner to our customers and to earn their trust through our unwavering commitment to achieve timely, innovative, cost-effective and mission-focused solutions.\nAll positions at Riverside Research are subject to background investigations. Employment is contingent upon successful completion of a background investigation including criminal history and identity check.\nOur EEO Policy\nRiverside Research is an equal opportunity employer. We recruit, employ, train, compensate and promote without regard to race, religion, sex, color, national origin, age, gender identity, sexual orientation, marital status, disability\/veteran, status as a protected veteran, or any other basis protected by applicable federal, state and local law.\nIf you need assistance at any time in our application or interview process, please contact Recruiting at email Recruiting@RiversideResearch.org. A member of the Recruiting team will be available to assist.\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-741.5(a). This regulation prohibits discrimination against qualified individuals on the basis of disability and requires affirmative action by covered prime contractors and subcontractors to employ and advance in employment qualified individuals with disabilities.\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-300.5(a). This regulation prohibits discrimination against qualified protected veterans and requires affirmative action by covered contractors and subcontractors to employ and advance in employment qualified protected veterans.\nFor more information on \"EEO is the Law,\" please visit:\nhttp:\/\/www.dol.gov\/ofccp\/regs\/compliance\/posters\/pdf\/eeopost.pdf\nhttps:\/\/www.dol.gov\/sites\/dolgov\/files\/ofccp\/regs\/compliance\/posters\/pdf\/eeopost.pdf","103":"Riverside Research is an independent National Security Nonprofit dedicated to research and development in the national interest. We provide high-end technical services, research and development, and prototype solutions to some of the country\u2019s most challenging technical problems.\n Job Number: 1073\nRiverside Research is seeking full-time Data Architect to support Director, Air Force Chief Data Office (SAF\/CO) sponsored activities across the Air Force Enterprise to ensure the visibility, accessibility, understanding, sharing, and trustworthiness of data across air, space, and cyberspace domains. Candidates will provide subject matter expertise in and perform on multidisciplinary teams that support data preparation and architecture, development of agile algorithmic solutions, evaluate and\/or execute data governance and data maturity models; and conduct data analytics using state of the art mathematical and machine learning\/artificial intelligence techniques and other data analytic lines of research\/effort.  Positions will be at various CONUS Air Force installations and the National Capital Region.\nAll Riverside Research opportunities require U.S. Citizenship\nJob Duties\nApplies a wide set of statistical, programming and\/or engineering disciplines for planning, design, analysis, and specification development for systems and databases to support the end user analysis process.\nResponsible for, or assists in the recommendations of platform, end user Business Intelligence tools, design, quality assurance standards, and performance standards. Determines benefit of tradeoffs in recommended options.\nWorks with consultants, programmers, data scientists and analysts assigned to the project. \nRequired Qualifications:\nTop Secret clearance with SCI adjudication\nA Bachelor\u2019s Degree in Computer Science, Information Systems or other related scientific or technical discipline \nMinimum of 5 years\u2019 experience in data analysis, design, and implementation of databases and analytics in support of mission\/business processes.\nWork experience in a data analytics environment, and the use of open-source tools, cloud computing, machine learning and data visualization as applicable.\nThe ability to use\/code in a language applicable to the project or task order. \n   Riverside Research does not mandate COVID vaccination as a condition of employment. However, proof of vaccination or negative test may be required to enter certain government facilities and sites. Vaccination requirements will depend on the status of the federal contractor mandate and customer site-specific requirements. To protect the health and safety of its employees, their families, and to comply with customer requirements, the company requires all employees to disclose vaccination status (upon hire). \nRiverside Research strives to be one of America's premier providers of independent, trusted technical and scientific expertise. We continue to add experienced and technically astute staff who are highly motivated to help our DoD and Intelligence Community (IC) customers deliver world class programs. As a not-for-profit, technology-oriented defense company, we believe service to customers and support of our staff is our mission. Our goal is to serve as a destination company by providing an industry-leading, positive, and rewarding employee experience for all who join us. We aspire to be a valued partner to our customers and to earn their trust through our unwavering commitment to achieve timely, innovative, cost-effective and mission-focused solutions.\nAll positions at Riverside Research are subject to background investigations. Employment is contingent upon successful completion of a background investigation including criminal history and identity check.\nOur EEO Policy\nRiverside Research is an equal opportunity employer. We recruit, employ, train, compensate and promote without regard to race, religion, sex, color, national origin, age, gender identity, sexual orientation, marital status, disability\/veteran, status as a protected veteran, or any other basis protected by applicable federal, state and local law.\nIf you need assistance at any time in our application or interview process, please contact Recruiting at email Recruiting@RiversideResearch.org. A member of the Recruiting team will be available to assist.\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-741.5(a). This regulation prohibits discrimination against qualified individuals on the basis of disability and requires affirmative action by covered prime contractors and subcontractors to employ and advance in employment qualified individuals with disabilities.\nThis contractor and subcontractor shall abide by the requirements of 41 CFR 60-300.5(a). This regulation prohibits discrimination against qualified protected veterans and requires affirmative action by covered contractors and subcontractors to employ and advance in employment qualified protected veterans.\nFor more information on \"EEO is the Law,\" please visit:\nhttp:\/\/www.dol.gov\/ofccp\/regs\/compliance\/posters\/pdf\/eeopost.pdf\nhttps:\/\/www.dol.gov\/sites\/dolgov\/files\/ofccp\/regs\/compliance\/posters\/pdf\/eeopost.pdf","104":"Company Description\nWNS (Holdings) Limited (NYSE: WNS), is a leading Business Process Management (BPM) company. We combine our deep industry knowledge with technology and analytics expertise to co-create innovative, digital-led transformational solutions with clients across 10 industries. We enable businesses in Travel, Insurance, Banking and Financial Services, Manufacturing, Retail and Consumer Packaged Goods, Shipping and Logistics, Healthcare, and Utilities to re-imagine their digital future and transform their outcomes with operational excellence.\n\nWe deliver an entire spectrum of BPM services in finance and accounting, procurement, customer interaction services and human resources leveraging collaborative models that are tailored to address the unique business challenges of each client. We co-create and execute the future vision of 400+ clients with the help of our 44,000+ employees. \nWNS Triange\nThe Research & Analytics (R&A) journey for WNS began in 2003. The initial years saw strong organic growth in the areas of customer analytics, marketing analytics, research and subsequently diversified in more industry specific specialisms such as actuarial, claims, risk, and loyalty analytics. These served as a platform for its growth which got further bolstered by investments in multiple acquisitions and continuous capability developments in line with market trends. Today WNS is recognized as a major research & analytics service provider in the industry.\nOur R&A business unit is currently a 3,000+ strong team comprising of consultants, data scientists, data engineers, visualization experts, researchers as well as experienced industry practitioners servicing 100+ clients.\nSome of Triange offerings:\nEnd to end Unified analytics offerings from data to insights including data engineering, visualization, and cloud-based services.\nEnable Process-embedded analytics solutions to drive digital transformation goals for our clients.\nLeverage our scalable AI\/ML based cognitive products and platforms to deliver non-linear benefits.\nWide repertoire of industry and domain specific bespoke analytics solutions help achieve clients\u2019 business goals.\nConsulting services to our clients to help them tap into their data assets and enable business decision making.\nDelivered phenomenal business outcomes to clients across all verticals using proprietary analytics embedded products\nWe continuously develop innovative solutions through our Analytics Innovation Center to address critical business problems for clients. We are aggressively building out our technology-enabled advanced analytics capabilities such as machine learning, cognitive, and artificial intelligence. We have a dedicated products team that works on developing new, cutting-edge products, relevant to our client needs. We currently have 20+ productized solutions with multiple developments in the pipeline. In the recent past, we have won more than 20 awards in various international forums in recognition of our quality of products, innovation, and service delivery.\nWe are also developing a steady stream of future-ready next gen analytics talent through multiple avenues including partnerships with educational institutes such as Wharton, NIIT, ISME etc.\nWe are leveraging partnerships with niche vendors and cloud service providers to experiment with new product and service lines in a cost-effective manner helping to develop new business models and offer newer solutions to clients. \u00a9 Copyright 2022 WNS (Holdings) Ltd. All rights reserved 2\nSome of our leading clients include:\nLeading global multi-category CPG company\nWorld\u2019s largest multinational hotel chain\nLeading global beverage brand\nTop 2 global food major\nTop 3 diversified technology major\nTop 3 global media & entertainment company\nGlobal multi-line insurance company\nUS headquartered life insurance Company\nUS headquartered life insurance and Financial\nServices Company\nLeading global customer insights company\nTop 10 North American retail bank\nTop 20 Global Pharmaceutical Major\nTop 3 global airline\nTop 3 global travel agency\nLeading European retail chain\nGlobal P&C insurance and reinsurance\nGlobal P&C insurance company\nWNS Triange \u2013 Data, Analytics and AI Powering Business Growth & Innovation\n WNS Triange enables organizations from 10+ industries to articulate their business\u2019 data needs, distill the insights and interventions required, develop a data strategy and then translate it into action. Our domain expertise, co-creation labs, strategic partnerships, skin-in-the-game approach, and proven track record of delivering high-end tech solutions make us the ideal Data, Analytics and AI partner for our clients.\n At WNS Triange, we believe it is the performance that matters \u2014 not just creative data sets, interesting patterns, or killer algorithms. Our team of 4000+ analysts, data scientists and domain experts combine 20+ years of experience and 25+ productized solutions and accelerators to deliver outcomes that matter most to 120+ global clients, at speed and scale.\nBuilt on three core pillars \u2013 Triange Consult, Triange NxT and Triange CoE, WNS Triange supports clients at every stage of their data journey, powering their transformation to \u201cIntelligent Enterprises.\u201d  \n Job Description\nJob Description\nSnowflake Architect is responsible for designing, developing and maintaining data warehouse and analytics solutions to meet enterprise's business analysis and reporting needs\nCreate data models (dimensional, relational), data marts in Snowflake to deliver performant solutions\ncreate end-to end data  architecture which involves snowflake\nDevelop tables, views, SQL, stored procedures and snow pipe\nDevelop pipe lines using spark API\u2019s\nDevelop continues data pipelines, real-time replication solutions into Snowflake\nWork with large data volumes including structured and unstructured data\nInteract with stake holders in developing the complete data solution on snowflake\nMust have good communication & able to handle the respective stake holders.\nQualifications\nQualifications & Requirements\n12+ years of experience in the Data warehouse, ETL, BI projects and 5+ years working as Data Architect and at least 5 years of Snowflake hand-on experience\nExcellent knowledge in Business Intelligence and Visualisation\nExcellent knowledge of RDBMS , SQL, OLAP, OLTP, NO-SQL databases, JSON\nMust have hands-on experience in SnowSQL, JavaScript Stored Procedures, performance tuning and Streaming Ingestion\nExpertise and excellent understanding of Snowflake Internals and Integration \nHands-on experience with programming in Python or Java, scala , Pyspark\nWell versed with  spark technologies\nWell versed with cloud (AWS\/Azure\/GCP).\nWell versed in creating or fine-tuning snowpipes. Hands-on experience with snowspark API's.\nWell-versed with security concepts in handling the data from source to storage and reporting\nWorking knowledge of CI\/CD, git pipelines\nKnowledge of data engineering python libraries\nMust have strong business process knowledge in healthcare\nProficiency in data modeling, very good understanding of data management concepts such as 3NF, multi-dimensional and data marts\nUnderstanding of performance tuning and troubleshooting end-to-end\nAbility to suggest innovative solutions based on new technologies and latest trends\nStrong oral and written communication skills\nExpertise with snowflake object-level, column and row level access controls\nExpertise in parsing various file formats like JSON, Parquet, Avro and xml\nWell versed with handling batch, micro batch & real-time data ingestion into the snowflake\nGood understanding of snowflake virtual warehouse, data sharing and optimization\nGood to have snowflake certification","105":"We are looking for a Data Architect to help define and improve our backend application architecture in terms of data location and work on general performance, scalability and robustness improvements.\n\nDevelop, align, and evolve the enterprise-wide data strategy to support delivery of corporate objectives.\nBuild a framework of principles to ensure data integrity across the business (including but not limited to ERP, CRM, BI, Data warehouse, external interfaces etc.).\nMaintain and shape appropriate Enterprise Architecture artefacts including; Entity Relationship Models, Data dictionary, taxonomy to aid data traceability.\nProvide technical oversight to solution delivery in creating business driven solutions adhering to the enterprise architecture and data governance standards.\nBe an advocate of data security principles and ensure appropriate security practices are embedded in any data strategy.\nContribute as to how the business evolves Data Governance practices and influence the adoption of data standards.\nDevelop key performance measures for data integration and quality.\nSupport third party data suppliers in developing specifications that are congruent with the Enterprise data architecture.\nRequirements\nProven experience in architecting and implementing Business Intelligence and Data warehouse platforms, Master data Management, data integration and OLTP database solutions.\nExtensive knowledge of industry best practices around data architecture in both cloud based and on prem solutions.\nComprehensive understanding of the principles of and best practices behind data engineering, and the supporting technologies such as RDBMS, NoSQL, Cache, Event Streaming & In-memory stores.\nDeep understanding of data warehousing and data transformation (extract, transform and load) processes and the supporting technologies such as Google Dataflow, Looker, Amazon Glue, EMR, Azure Data Factory, Data Lake, other analytics products.\nExcellent problem solving and data modelling skills (logical, physical, semantic and integration models) including; normalisation, OLAP \/ OLTP principles and entity relationship analysis.\nExperience mapping key Enterprise data entities to business capabilities and applications.\nA strong knowledge of horizontal data lineage from source to output.\nFluent in English, both written and spoken.\nBenefits\nHybrid & Remote work arrangements;\nLunch vouchers;\nHealth Insurance;\nFlexible working hours;\nBi-monthly company wide social and team building events;\nTraining and Development opportunities.","106":"Project Description\nWe occupy a unique position in the market because we are vertically integrated. We have both a PBM platform (RxAgile) that provides enterprise solutions to B2B players in the healthcare space and a direct to consumer product with a mission to make prescription medication more affordable.\nResponsibilities\nMust have ability to filter data and identify cleansing methodologies and provide performance indicators and recommendations to correct any code problems.\nMust have experience combining data from multiple different sources (such as OLE\/ODBC sources, Excel, delimited and fixed-width text files etc.)\nMinimum of five (7) years overall Qlik experience.\nMinimum of five (5) years of Data modeling experience.\nCheck efficiency of the data collection processes in place and ability to determine business impact due to data quality issues.\nMust be able to script load scripts with deep understanding of Qlik load script and data modeling best practices.\nMust be able to proactively identify system\/app performance issues and resolve by working with the Qlik developers.\nSupport for release-night activities, including (but not limited to) starting\/stopping scheduled tasks and monitoring database schema changes\nRequirements\nMust have a deep understanding of the overall Qlik Sense or (QlikView) and Qlik NPrinting architecture on a single and multi-node platform.\nExperience in large-scale datasets highly desired.\nShould have experience working in Data Warehouse environments.\nMust be a critical thinker who can successfully troubleshoot and solve data quality\/performance issues.\nShould have a deep understanding of business needs and translate into technology solutions.\nAbility to manage key project milestones with limited direct supervision. Ability to work in a fast-paced and self-managed environment and quickly switch priorities based of project needs.\nMust be able to create Qlik QVDs from source systems.\nMust have a strong SQL background. Experience with Microsoft SQL Server preferred.\nMust have experience working with Cloud-based technologies like Snowflake, AWS.\nQlik Sense Enterprise strongly preferred, but will consider QlikView Enterprise experience.\nPowerShell experience desired, but not necessary.\nSingle-sign-on (SSO) configuration experience desired.\nExperience with Qlik Web Connectors is a plus.\nQlik Management Console (QMC) experience desired.\nGeoAnalytics experience is a plus.\nQlik Associative Big Data Index (QABDI) experience is a big plus\nRewards\nPayment in USD.\nFree credentials for e-learning platforms.\nRemote workshops & activities.\n ","107":"Company Description\nPublicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients\u2019 businesses through creating the products and services their customers expect.\nJob Description\nAs Senior Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.\n\nYour role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.\n\nAs a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration.\nQualifications\n Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS \/ Azure \/ GCP)\nExperience delivering end to end Big Data solutions on premise and\/or on Cloud\nKnowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases\nExpertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions\nProficiency in Java and Scala programming languages (Python a plus)\nExpertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.)\nExperience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub\/Sub etc.)\nExpertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc.\nKnowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding\nKnowledge of performance tuning, optimization and scaling solutions from a storage\/processing standpoint\nExperience building DevOps pipelines for data solutions, including automated testing\nYou\u2019ll Also Likely Have Some Of The Following\n Knowledge of containerization, orchestration and Kubernetes engine\nAn understanding of how to setup Big data cluster security (Authorization\/ Authentication, Security for data at rest, data in transit)\nA basic understanding of how to manage and setup Monitoring and alerting for Big data clusters\nExperience of orchestration tools \u2013 Oozie , Airflow , Ctr-M or similar\nExperience of MPP style query engines like Impala, Presto, Athena etc.\nKnowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\nExposure to data governance, catalog, lineage and associated tools would be an added advantage\nA certification in one or more cloud platforms or big data technologies\nAny active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV\/POC, hackathon)\nAdditional Information\nThere is a superb package of benefits waiting for you at Publicis Sapient.\nWe cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension.\nThe learning opportunities here are endless. Most importantly, of course, there\u2019s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine.\nFlexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services.","108":"Company Description\nPublicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients\u2019 businesses through creating the products and services their customers expect.\nJob Description\nAs a  Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.\n\nYour role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.\n\nAs a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration.\nQualifications\n Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS \/ Azure \/ GCP)\nExperience delivering end to end Big Data solutions on premise and\/or on Cloud\nKnowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases\nExpertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions\nProficiency in Java and Scala programming languages (Python a plus)\nExpertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.)\nExperience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub\/Sub etc.)\nExpertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc.\nKnowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding\nKnowledge of performance tuning, optimization and scaling solutions from a storage\/processing standpoint\nExperience building DevOps pipelines for data solutions, including automated testing\nYou\u2019ll Also Likely Have Some Of The Following\nKnowledge of containerization, orchestration and Kubernetes engine\nAn understanding of how to setup Big data cluster security (Authorization\/ Authentication, Security for data at rest, data in transit)\nA basic understanding of how to manage and setup Monitoring and alerting for Big data clusters\nExperience of orchestration tools \u2013 Oozie , Airflow , Ctr-M or similar\nExperience of MPP style query engines like Impala, Presto, Athena etc.\nKnowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models\nExposure to data governance, catalog, lineage and associated tools would be an added advantage\nA certification in one or more cloud platforms or big data technologies\nAny active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV\/POC, hackathon)\nAdditional Information\nThere is a superb package of benefits waiting for you at Publicis Sapient.\nWe cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension.\nThe learning opportunities here are endless. Most importantly, of course, there\u2019s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine.\nFlexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services.","109":"Description de l'entreprise\nAvec pr\u00e8s de 8000 collaborateurs \u00e0 travers le monde, nous accompagnons les entreprises dans leur transformation num\u00e9rique. Nous imaginons et concr\u00e9tisons leurs ambitions gr\u00e2ce aux possibilit\u00e9s infinies des plateformes digitales, pour faire \u00e9voluer leur culture et leur mode de travail, et cr\u00e9er de la valeur dans leurs organisations.\nPr\u00e9sent dans 18 pays d\u2019Europe et du Moyen-Orient et fort de 25 ans d\u2019exp\u00e9rience, nous mettons la \u201cTechnologie au service de l\u2019Homme\u201d afin de construire un monde plus humain et plus durable.\nTravailler chez Devoteam, c\u2019est : \ntravailler aux c\u00f4t\u00e9s de partenaires comme Google, Microsoft, AWS ou Salesforce dont nous impl\u00e9mentons les solutions chez nos clients.\n\u00e9voluer dans un groupe international qui vous accompagne dans le d\u00e9veloppement de votre carri\u00e8re avec des parcours de formation et de certification adapt\u00e9s.\nrejoindre une \u00e9quipe sp\u00e9cialis\u00e9e, accompagn\u00e9 par un manager de proximit\u00e9 qui saura vous guider dans vos choix et favoriser les \u00e9changes avec vos pairs, que ce soit lors d'\u00e9v\u00e9nements techniques ou conviviaux.\ngrandir dans une entreprise qui challenge ses \u00e9quipes en \u00e9tant agile et ambitieuse, s\u2019adaptant pour permettre les succ\u00e8s individuels et collectifs.\nDescription du poste\nGarance et son \u00e9quipe n\u2019attendent que vous pour relever de nouveaux d\u00e9fis autour de l\u2019\u00e9cosyst\u00e8me Data.\nEnsemble vous accompagnerez nos clients dans la transformation de leur Syst\u00e8me d\u2019information et la mise en place de solutions BIG DATA.\nPour  nos clients, la transformation digitale induit une modification profonde des processus m\u00e9tier pouss\u00e9e par le d\u00e9veloppement des nouvelles technologies. Ce changement de mod\u00e8le \u00e0 plusieurs objectifs : accro\u00eetre l'efficacit\u00e9, optimiser les co\u00fbts et cr\u00e9er de nouveaux produits et services innovants pour les clients.\nNotre offre data se d\u00e9compose en deux offres distinctes: une offre orient\u00e9e Data Foundation en amont de la pipeline data et une offre Data for Business qui se positionne sur l\u2019analyse de donn\u00e9es au profit du m\u00e9tier.  \nQue vous soyez Data Architect ou Data Engineer, nous vous proposons d\u2019int\u00e9grer une \u00e9quipe d\u2019ing\u00e9nieurs exp\u00e9riment\u00e9s et multi-comp\u00e9tences.\nAu sein de nos clients issus de diff\u00e9rents secteurs d'activit\u00e9 (Industrie, Services, Transport, Banque, Assurances, \u00c9nergie) et en fonction de vos comp\u00e9tences, les missions que vous serez amen\u00e9(e) \u00e0 r\u00e9aliser pourront concerner:\n- La conception et mise en place de cha\u00eene de processing Big Data\n- La conception et le d\u00e9veloppement des modules de traitements de donn\u00e9es - ETL  (transformation, extraction, stockage)\n- Le d\u00e9veloppement d\u2019API\n- La participation aux d\u00e9ploiements des solutions dans une d\u00e9marche Agile \/ DevOps\n- La mise en place de solutions d\u2019automatisation\n- etc.  \nPour r\u00e9ussir ces diff\u00e9rents challenges, nous vous proposerons des actions de formation, des parrainages, des certifications sur les outils concern\u00e9s et un dispositif d\u2019\u00e9valuation personnel r\u00e9gulier.\nQualifications\nDipl\u00f4m\u00e9(e) d\u2019une \u00e9cole d\u2019ing\u00e9nieurs ou d\u2019un Master 2 en informatique, vous \u00eates dot\u00e9(e) d\u2019un excellent relationnel, d\u2019un sens prononc\u00e9 du service et de la qualit\u00e9. Vous aimez travailler en \u00e9quipe, and you are fluent in english, of course !  \nVous poss\u00e9dez id\u00e9alement un minimum de deux ans d\u2019exp\u00e9rience professionnelle dans le domaine.\nVous ma\u00eetrisez \u00e0 minima SQL, Python et Git, et vous \u00eates \u00e0 l'aise avec au moins 2 technologies de la liste suivante:\nMongoDB \/ Snowflake \/ Databricks \/ Hadoop \/ Spark \/ Scala \/ Apache \/ Matillion \/ Talend \/ Kafka \/ SAP \/ Power BI \/ Kubernetes \/ Docker \/ Cloudera \/ Cloud (AWS, GCP, Azure)\nVous \u00eates d\u00e9sireux.se de vous investir dans des projets challengeants et gagner rapidement en responsabilit\u00e9s et en comp\u00e9tences.\nUne activit\u00e9 sur des projets Open Source serait un plus.\nAlors n\u2019h\u00e9sitez plus ! \nVous vous sentez plus proche de l\u2019analyse ? On a aussi besoin de vous par ici\nInformations suppl\u00e9mentaires\nLe Groupe Devoteam \u0153uvre pour l'\u00e9galit\u00e9 des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m\u00e9rite et lutte activement contre toute forme de discrimination. Nous sommes persuad\u00e9s que la diversit\u00e9 contribue \u00e0 la cr\u00e9ativit\u00e9, au dynamisme et \u00e0 l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.","110":"Who We Are:\n\nAND Digital are a tech company focused on accelerating digital delivery and dedicated to closing the digital skills gap. We\u2019ve been helping organisations build better digital products and stronger digital teams since 2014.\nWe believe our work should always leave a legacy for the client. We do this through close relationships with our offices (or \u2018Clubs\u2019) so that our partners are always prioritised by a regional team close to them.\nThis unique model has driven success for our clients and ourselves, evidenced by our remarkable organic growth since 2014. Today we number more than 1,300 people with Clubs all over the UK and Europe with plans for global expansion in the next couple of years.\n\nJoin us - and help us fulfil our mission to close the world\u2019s digital skills gap.\n\nWhat you\u2019ll bring to the table:\nAs a Data Engineering Principal for a newer club, you will be a hands on, senior data technologist. Working within a team that has high impact and importance for the business, providing team support, driving technical excellence, fostering a culture of innovation while delivering customer value at pace and insisting on high quality and simplicity.\nYou\u2019ll also make a real impact by taking an active role in the team\u2019s Agile Development practices, technical decision making and development, generating value and continuously striving to improve the quality and reliability of our data and processes.\nYou will spend the majority of your time helping deliver client data engineering opportunities, building our data engineering capabilities, growing our technologists and influencing how we think about data, both within AND and for our clients.\n\nTo do that, it\u2019s essential you bring the following:\nProven track record of leadership of teams and problem solving at the enterprise scale in the field of Data Architecture, Science or Analytics. With hands-on technical delivery of client-facing data projects across the full SDLC from design to migration, integration and live service in a multi-vendor environment\nStrong skills in languages such as Python, R, SQL or Scala, alongside experience of using modern and traditional data technologies including: ElasticSearch, MongoDB, PostgreSQL, mySQL\/mariaDB, Oracle, SQL Server, Hadoop, Kafka, Splunk\/ELK or other logging and monitoring tools, BI and Data Warehousing solutions and ETL and migration technologies. This should be backed with strong cloud-native data engineering skills e.g. AWS RDS, Aurora, Redshift, Kinesis, Glue or Azure CosmosDB, DataFactory, DataWarehouse, SQL DB etc.\nProven experience in quality assuring data programmes, including non-functional testing and performance tuning\nHands-on experience of modern software delivery, including CI\/CD and DevOps practices with a deep understanding and extensive track record of delivering complex data solutions using Agile methods including Scrum, SAFe etc.\nA keen understanding of industry best-practice around standards, quality and continuous improvement in the field of Data Engineering\nExperience in conducting large scale enterprise batch and real-time processing from varying sources\nExperience in building and designing scalable and extensible enterprise data architectures\n\nWhy join AND Digital?\nWe have three values: wonder, share, and delight. These values inform how we work with clients, and our culture: what it feels like to work for AND. We believe collaboration, ambition, curiosity and fun can drive innovation by creating a better environment for problem-solving.\n\nBy joining AND, we\u2019ll provide:\nOpportunities to work on projects with big clients and the chance to produce meaningful work that makes a difference to people\u2019s lives.\nA \u201cBlended Working\u201d model, meaning you will be able to work in a range of locations from; your home, in your clubhouse, on a client, as well as just a change of scenery.\nA dedicated career scrum team, designed to help you reach your career goals and develop the skills you need to be your best self.\nAn annual budget for training and upskilling, including allocated days off so you don\u2019t have to study in your own free time.\nMonthly and quarterly team socials - on us - ranging from after work drinks, to driving experience days with your fellow club members.\nA safe environment for you to be yourself and challenge yourself.\n\nBenefits\n26 days holiday allowance + bank holidays\n13 days per year for innovation or upskilling\n2 days per year for volunteering\nShare scheme\nA \u00a31000 flexifund to use on a personalised list of benefits such Gym membership, Cycle to Work Scheme, Health, dental and optical cash plan\nPLUS many more\nFor a full list of benefits - click here\n\n\nEqual Opportunities Statement\nAt AND Digital we embrace diversity and are committed to equal opportunities. We are actively recruiting for a diverse and inclusive workforce so want to ensure we do everything we can to support your application.\n\nWe want you to feel safe and empowered to let us know if you require any adjustments to be made to your application or interview process so please speak to our recruitment team.","111":"Note for Applicants: \nThe requirements listed in the below description are simply guidelines, and you do not need to satisfy every requirement or meet every qualification listed.  We encourage you to apply if you feel your experience is transferable to what our company is looking for.  Applying gives you the opportunity to be considered and we look forward to reviewing your application!\nOfferFit was founded by ex-McKinsey and BCG math PhDs, and we\u2019re funded by leading Silicon Valley VCs. OfferFit replaces A\/B testing with automated experimentation, powered by self-learning AI. This allows lifecycle marketers to test & improve the performance of their campaigns much faster than before. Customers include leading brands like Brinks Home (leading home security company) and Engie (multinational electric utility), among many others.\nThe Machine Learning Solutions Architect is a critical individual contributor role on our growing Implementation & Customer Success team. In this role, you will work with our enterprise customers to deploy OfferFit in the context of their complex and evolving tech stacks. You will be responsible for designing scalable, secure, and efficient solutions that meet the technical requirements of our customers, and then advising implementation teams and partners as they deliver the solutions into production.\nAdditionally, you will play a key role in sales pursuits by leading discussions of a highly technical nature (e.g., deep dives into product functionality, possible integration approaches) fielded by technical stakeholders (architecture SMEs, data platform SMEs, data scientists). Clearly demonstrating your expertise in this context is critical to establishing the credibility needed to close deals with highly sophisticated companies.\nFinally, you will collaborate with OfferFit\u2019s engineering team to improve the architecture of our own products and services, leveraging your architecture design expertise and hands-on capabilities.\nAn ideal candidate for this role is experienced working directly with enterprise customers (in particular, architecture SMEs), and is very familiar with common architecture patterns and tools (e.g., common cloud platforms, data platforms, CDPs, activation platforms). Additionally, the ideal candidate is very comfortable being \u201chands-on\u201d in a broad range of areas including cloud architecture, ETL, security, performance analysis, and analytics.\nIn particular, you will:\nBe a technical expert on all aspects of OfferFit\nWork with customers, OfferFit teams and integration partners to successfully position and deploy OfferFit in customer environments, in the context of their current and future state IT landscape\nAssist in enterprise sales pursuits by lead conversations with highly technical stakeholders (e.g., architecture, data platform, data science)\nMaintain deep understanding of competitive and complementary technologies and vendors and how to position OfferFit in relation to them\nWork hands-on with OfferFit\u2019s engineering team to improve our infrastructure\nCollaborate cross-functionally (e.g., product, engineering) to continuously improve OfferFit\u2019s products and externally facing materials\nSupport other members of the Implementation, Sales and Engineering teams to develop their expertise\nWhy is it great:\nBe the face of the company, working alongside our customers to help them succeed.\nLead the AI transformation happening in marketing technology today \u2014 OfferFit is at the forefront, so you\u2019ll be in the middle of the action.\nGet in at an early stage to help define the vision, shape culture, and hire more awesome people across all engineering teams.\nWork in a team that not only talks the talk of development best practices, but walks the walk \u2014 unit & integration tests, modular design, CI\/CD, pair programming, code reviews \u2014 the works.\nJoin OfferFit\u2019s fast-paced, supportive, and professional team. We make sure all of our team members are empowered and receive great mentorship and coaching.\nWho\u2019s a fit: \nEntrepreneurial: you take initiative, work around obstacles, and always seek creative ways to get to the next level\nTechnology enthusiast: you are passionate about new technologies and their potential to impact business-as-usual\nPeople person: you build trust-based relationships with external partners, and combine empathy with a willingness to have direct, challenging conversations\nAnalytically-driven: You are able to draw insights from raw data and perform analysis that is helpful and clear to customers\nStructured and organized: you can structure a plan, align stakeholders, and see it through to execution\nClear communicator: you are able to express yourself clearly and persuasively, both in writing and speech\nThe base salary range for this position in the United States is $207,000 - 287,000 per year;  Eligibility for an end of year performance bonus, commissions (when applicable) and\/or equity options may be provided as part of the compensation package, in addition to a full range of medical, financial, and\/or other benefits, depending on the position offered. For non-US based candidates, base pay and overall compensation packages will be adjusted based on location.  Applicants should apply via OfferFit\u2019s internal or external careers site.\nCompany Benefits and Perks\nGenerous PTO policy (starting at 25 days PTO per year)\n100% remote work environment with flexible hours \nQuarterly gatherings where we meet in person in a different city to work together, bond as a team and celebrate our progress\nWeekly team events (lunch and learns, trivia, virtual escape rooms, town hall and team health \u201cbarometer\u201d meetings)\nAbility to learn and develop from an experienced leadership team (ex-Amazon, McKinsey, BCG, and IBM, among others) who are focused on building a talented, diverse, and inclusive team\nDedication to building a strong culture (e.g., employee resource groups, weekly employee recognitions, major life event celebrations, mental health\/sustainability days off, etc.)\nCompetitive Employee benefits (major medical, vision, dental, LTD and parental leave) and 401K matching program\nOfferFit is committed to a diverse and inclusive workplace. OfferFit is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.","112":"All offices are currently open, and our employees are back 4 or 5 days a week in Hudson Yards, NY and 3 days a week in all other offices. If you have questions on this policy or the application process, please contact recruiting@gafg.com.\n  COMPANY OVERVIEW\nGlobal Atlantic Financial Group is a leader in the U.S. life insurance and annuity industry, serving the needs of individuals and institutions. Global Atlantic is a majority-owned subsidiary of KKR, a leading global investment firm that offers alternative asset management across multiple strategies and capital markets solutions.\n\nGlobal Atlantic is looking for a diverse team of talented individuals who reinforce our culture of collaboration and innovation. We are dedicated to the career development of our people because we know they are critical to our long-term success. Join our team and come grow with us. \nWe use Greenhouse as our scheduling tool and communicate through their systems. At times, your email may block our communications. Please be sure to check your SPAM so that you do not miss critical information about our process, including scheduling. \nPOSITION OVERVIEW\nSummary: The IT Senior Data Architect will expand and optimize the data and data pipeline architecture, as well as optimize data flow and collection for cross functional teams. The senior data architect will perform data architecture analysis, design, development and testing to deliver data applications, services, interfaces, ETL processes, reporting and other workflow and management initiatives. The role will work closely with the business, data analysts and IT teams to support on data strategy initiatives and will ensure optimal data delivery architecture is consistent throughout the strategy. The role also will follow modern SDLC principles, test driven development and source code reviews and change control standards in order to maintain compliance with policies. This role requires a highly motivated individual with strong leadership capability, technical ability, data capability, excellent communication and collaboration skills including the ability to develop and troubleshoot a diverse range of problems.\nResponsibilities\nDesign and develop enterprise data \/ data architecture solutions using Hadoop and other data technologies like Spark, Scala, Python, SQL etc.\nAssemble large, complex data sets that meet functional \/ non-functional business requirements.\nCreate and maintain optimal data pipeline architecture.\nDevise, Lead and execute continual improvement initiatives in all Data Management Service delivery and technology, with a focus on delivery velocity and quality.\nPartner with business leaders to determine and prioritize delivery initiatives.\nDefine or influence system, technical and application architectures for major areas of development.\nDevise, Lead and execute in software development life cycle including requirements gathering, development, testing, release management, and maintenance.\nEngage with business partners to report (formally and informally) on technology strengths, weaknesses, successes, and challenges on a regular basis.\nAbility to do analytical programming in EDW architecture to bridge the gap between a traditional DB architecture and a Hadoop centric architecture.\nHighly organized and analytic, capable of solving business problems using technology.\nEnsure appropriate change management and other technology methodologies are carried out on a consistent basis over time.\nShould be an individual with in-depth technical knowledge and hands-on experience in the areas of Data Management, BI Architecture, Product Development, RDBMS and non-RDBMS platforms.\nShould have excellent analytical skills, able to recognize data patterns and troubleshoot the data.\nWill be responsible for design and delivery of data solutions to empower data migration initiatives, BI initiatives, dashboards development etc.\nQUALIFICATIONS\nUndergraduate degree required, MBA or other advanced degree preferred.\n12+ years of experience as a member of an information technology team.\nMinimum of 3-5 years of relevant experience architecting the complete end to end design of enterprise-wide solution using latest technologies \u2013 Hadoop, Spring boot\/Spring Cloud, Rest API, SQL\nMinimum of 5-7 experience in SQL Python, Core Java, Cloudera, AWS, Rest API, Microservices, Spring Boot, Spring cloud etc.\nIdeally a strong Life Insurance background.\nExperience with data modeling, complex data structures, data processing, and data quality and data lifecycle\nAdvanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.\nExperience building and optimizing \u2018big data\u2019 data pipelines, architectures and data sets.\nExperience performing root cause analysis on internal and external data and processes to provide solution for specific business requirements.\nExperience building solutions for streaming applications.\nShould be able to lead critical aspects of the data management and application management.\nExperience in UNIX shell scripting, batch scheduling and version control tools.\nExperience in large scale server-side application development that includes the design and implementation of high-volume data processing jobs.\nCultural awareness with excellent interpersonal and relationship building skills.\nPassion and drive for continuous improvement and transformational change, with a business owner mentality.\nStrong written and verbal communication skills.\nVarious jurisdictions have passed pay transparency laws that require companies provide salary ranges for any positions for which they are accepting applications. Global Atlantic has offices in Atlanta, Batesville, Bermuda, Boston, Des Moines, Hartford, Indianapolis, and New York City. The base salary range posted below is inclusive of the lowest cost of living geography to the highest in which we have a Global Atlantic office. \nGlobal Atlantic\u2019s base salary range is determined through an analysis of similar positions in the external labor market. Base pay is just one component of Global Atlantic\u2019s total compensation package for employees and at times we hire outside the boundaries of the salary range. Other rewards may include annual cash bonuses, long-term incentives (equity), generous benefits (including immediate vesting on employee contributions to a 401(k), as well as a company match on your contributions), and sales incentives.  Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and\/or skill level and will be finalized at the time of offer. Compensation for our more senior positions have a larger component of short-term cash bonus and long-term incentives.  The base salary range for this role is $120,000 to $228,000.\n  #LI-CA1\n   TOTAL REWARDS STATEMENT  \nGlobal Atlantic\u2019s total rewards package is reflective of our corporate values, particularly diversity, excellence and innovation, with a focus on inclusion, pay equity, and flexibility. We are proud to support your personal and professional growth and well-being through programs such as educational assistance, virtual physical therapy, remote\/onsite fitness reimbursement, a medical second opinion program, pet insurance, military leave, parental leave, adoption assistance, fertility and family planning coverage. We strive to foster a culture of total well-being through community outreach and charitable giving programs.\nWe are active in our communities-\nNew York: Red Hook Conservancy, Girls Who Invest and The Bowery Mission\nBoston: Cradles to Crayons, Project Bread, Let\u2019s Get Ready, Rise Against Hunger, Salvation Army and many other local volunteer organizations in around the Boston area\nHartford: Habitat for Humanity, Foodshare, Humane Society, Hands on Hartford, Mercy Shelter and Dog Star Rescue\nIndianapolis: Elevate Indianapolis, Gleaners Food Bank and the Juvenile Diabetes Research Foundation\nBatesville: American Cancer Society Relay for Life, Angels of Giving, Margaret Mary Health Foundation, Ripley County Community Foundation, Safe Passage, Batesville High School Sponsorships, local area youth sports and food pantries, as well as many others\nDes Moines: United Way, Central Iowa Shelter & Services, Junior Achievement of Central Iowa and Make a Wish Foundation\nBerwyn: Food drive and will be planning an event to help a local family over the holidays\nAtlanta: Packaged Good Organization, which helps the most vulnerable community members with providing personalized care packages for people in need including the elderly, our armed forces, the homeless and hospitalized kids\nBermuda: Sponsor of a weekly feeding program operated by The Hamilton Seventh-Day Adventist Church\nSocial platforms provide an environment to collaborate with others and participate in friendly competitions towards achieving physical, emotional and financial well-being. Our highly competitive health, retirement, life and disability plans can be tailored to best suit your needs and those of your whole family.\nGlobal Atlantic is committed to creating an inclusive environment where everyone can meaningfully contribute to our success. We are proud to be an equal opportunity employer and we do not discriminate in employment on any basis that is prohibited by federal, state or local laws.  More than that, we strive to be inclusive of all backgrounds and experiences, which we feel gives us a competitive advantage in the market and within our firm.  All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, or veteran status.\nEmployees who require an accommodation to perform the essential functions of their job will participate in an interactive process which may include providing documentation. If you are hired and require an accommodation for any protected status, please email benefits@gafg.com.\nPlease click on the links below to learn more about Global Atlantic.\nGlobal Atlantic Financial Company Employee Candidate Privacy Notice","113":"Join a Challenger\nBeing a traditional bank just isn\u2019t our thing. We are big believers in innovating the banking experience because we believe Canadians deserve better options, and we challenge ourselves and our teams to creatively transform what\u2019s possible in banking. Our team is made up of inquisitive and agile minds that find smarter ways of doing things. If you\u2019re not afraid of taking on big challenges and redefining the future, you belong with us. You\u2019ll get to work with people who will encourage you to reach new heights. We like to keep things fun, ask questions and learn together. We are a big (and growing!) family. Overall we serve more than 370,000 people across Canada through Equitable Bank, Canada's Challenger Bank\u2122 and have been around for more than 50 years. Equitable Bank's wholly owned subsidiary, Concentra Bank, supports credit unions across Canada that serve more than 5 million members. Together we have over $100 billion in combined assets under management and administration, with a clear mandate to drive change in Canadian banking to enrich people's lives. Our EQ Bank platform (eqbank.ca) has been named the top Schedule I Bank in Canada on the Forbes World's Best Banks 2022 and 2021 lists. \n\nThe Work\nThe Data Architect (\u201cDA\u201d) reports to the Director, Enterprise Risk Operations (\u201cDERO\u201d) and supports the DERO and other Senior Management with respect to designing, developing, and implementing data models and the related database structures and processes for all credit risk models within Equitable Bank (the \u201cBank\u201d) as a part of the Bank\u2019s Basel operations and programs. This includes but is not limited to developing, implementing, and maintaining data models related to credit risk models under the Advanced Internal Ratings Based (\u201cAIRB\u201d) approach, International Financial Reporting Standards (\u201cIFRS\u201d) 9 and Internal Capital Adequacy Assessment Process \u201c(ICAAP\u201d). These models must meet Basel Pillar 1 and Pillar 2 qualifying criteria established by the Office of the Superintendent for Financial Institutions Canada (\u201cOSFI\u201d). The incumbent will assist the DERO in ensuring the successful development, implementation, documentation, and operationalization of data models under the Basel Committee for Banking Supervision (\u201cBCBS\u201d)-239 and OSFI AIRB standards. The incumbent will also be responsible for ensuring data quality best practices are put in place and executed in compliance with internal policies, procedures, and regulatory requirements. \nThe core parts of your role would be to:\nData Modeling and Architecture (50%):\nDesign and develop scalable data models, database structures for all in-scope credit risk models covering AIRB, ICAAP, and IFRS 9 models to establish a single source of truth.\nEvaluate current data setup and architect new and efficient solution to streamline operational processes.\nCreate detailed and clear data model diagrams and related documentation.\nProvide ongoing support to DERO during internal (Risk, Audit, Finance) and external (OSFI, vendors, etc.) requests and audits.\nEnsure model documentation is clear and provide third party reviewers (e.g., External Audit or OSFI) the ability to replicate model data.\n\nData Models Implementation & Automation (50%):\nAssess database implementation procedures to ensure they comply with Bank polices and applicable regulations.\nAutomate monthly data feeds to generate reliable single source of truth for model data.\nEnsure solution adheres to internal information\/cyber security & privacy policy and procedures.\nIdentify and document Business Continuity, Disaster Recovery (DR) and backup procedures.\nPrepare CDE and lineage documentation and DQ reports for the data models.\nDesign and implement operational processes for the data models.\nSupport the DERO to ensure model data governance, and to enforce appropriate controls from a model data perspective.\nSupport the DERO in developing, documenting, and implementing Risk Data Management Best Practices within the department and across the enterprise.\nProvide regular project status updates to DERO for tracking and monitoring ERO projects.\nLet\u2019s Talk About You\nRequired:\nMinimum post-secondary level education (diploma\/degree) in Computer Science, Software\/Database Engineering, Information Systems\/Technology, or related disciplines.\n7+ years of experience in database architecture, modeling, and management.\nAdvanced knowledge of data modeling in relational, dimensional, multidimensional, and non-structured environments.\nAdvanced knowledge of data integration patterns and procedures.\nExpert knowledge of an industry standard financial data model.\nDeep understanding of data governance principles and BCBS-239 standards.\nA strong understanding of the overall Banking Industry, particularly the Credit Risk Management Lifecycle for mortgages and similar products.\nStrong development skills in Python, MS Azure Data Studio (SQL) and\/or related programming languages.\n\nNice to Have:\nUnix shell scripting\nMS Azure cloud certifications\nProgramming skills in Power BI, R, SAS, MATLAB\n\nGeneral skills\nStrong desire to learn, innovate and develop into a strong contributor in Risk Management Technology space.\nStrong analytical abilities, with a keen attention to detail and an aptitude for problem solving.\nExcellent organizational and time management skills, with the ability to multi-task and to orchestrate and prioritize tasks.\nExcellent communication and presentation skills (written and verbal); producing grammatically correct\/error-free project documentation, conveying issues\/requirements clearly and concisely.\nExperience with Business and Technical Writing for audiences of varying roles and experience.\nProficiency in the use of Microsoft Office applications (i.e., Excel, PowerPoint, Outlook, Word).\nSkilled in the use of collaborative technologies such as Teams, SharePoint, Confluence, JIRA, etc.\n\n\nWhat we offer [For full-time permanent roles] \ud83d\udcb0 Competitive discretionary bonus \u2728 Market leading RRSP match program\ud83e\ude7a  Medical, dental, vision, life, and disability benefits\ud83d\udcdd  Employee Share Purchase Plan\ud83d\udc76\ud83c\udffd Maternity\/Parental top-up while you care for your little one\ud83c\udfdd Generous vacation policy, personal days and even a moving day \ud83d\udda5  Virtual events to connect with your fellow colleagues\ud83c\udf93  Annual professional development allowance and a comprehensive Career Development program\ud83d\udc9b  A fulfilling opportunity to join one of the top FinTechs and help create a new kind of banking experience\n  Equitable Bank is deeply committed to inclusion. Our organization is stronger and our employees thrive when we honour and celebrate everyone\u2019s diverse experiences and perspectives. In tandem with that commitment, we support and encourage our staff to grow not just in their career path, but personally as well. \nWe commit to providing a barrier-free recruitment process and work environment for all applicants. Please let us know of any accommodations needed so that you can bring your best self to the application process and beyond. All candidates considered for hire must successfully pass a criminal background check and credit check to qualify for hire. While we appreciate your interest in applying, an Equitable recruiter will only contact leading candidates whose skills and qualifications closely match the requirements of the position.  We can\u2019t wait to get to know you!","114":"Company Description\nHitachi Solutions is a global Microsoft solutions integrator passionate about developing and delivering industry-focused solutions that support our clients to deliver on their business transformation goals. Our industry focus, expertise, and intellectual property is what truly sets us apart. We have earned, and continue to maintain, a strategic relationship with Microsoft. Recognized for our achievements - teaming with our clients to deliver innovative digital solutions and services - is how we have achieved year after year recognition.\nAs their trusted advisor, we support our clients to deliver on their strategic business initiatives as they unify, automate, and modernize their data and operations to increase efficiency, reduce costs, and enhance their customer\u2019s experience. Our over 3,000 team members across 14 countries, and our 18 years of 100% focus on Microsoft technologies and business applications, is how we deliver excellence through expert services and industry-focused cloud solutions. \nA part of Hitachi, Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world\u2019s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies.\nJob Description\nPlease note:  Although this is a Remote \/ Virtual \/ Work-From-Home career opportunity, candidates MUST reside, and be authorized to work without sponsorship, in the US.\n This is a full-time role in our New Product organization for professionals with a proven history of execution, and a desire to rapidly expand a product organization.  Our team is seeking a Senior Data Architect, with a strong background in data definition, modeling, and implementation.  \n This is a hands-on architect role where the individual will be responsible for the overall design of solutions within the data ecosystem serving our customers. This role will require someone who is experienced in designing data schemas using Kimball\/Dimensional modeling and pipelines in Databricks for data warehouses\/lakehouses and reporting systems, is able to evaluate multiple technologies and technical solutions, and be a hands-on contributor for engineering goals for multiple engineering teams. Additionally, as a technical leader within the team, you will mentor and coach your team members; therefore, top candidates have experience as either a team lead or manager. \n Responsibilities\nScope and execute with independence. Work with the product team to understand platform capabilities and leverage those capabilities to bring customer\u2019s data estate. \nIdentify and articulate technical and operational requirements for data pipelines and the models they populate; be able to optimize these pipelines for high performance\/resiliency workloads. \nInstill excellence into the processes, methodologies, standards and technology choices embraced by the team with customer teams, and junior staff. \nLead requirements discovery and delivery workshops \u2013 helping customers understand their options and guiding them to the best options. \nBe an advocate for the customer, and support delivery leadership (Director, VPs) in managing client expectations. \nDedicate time to continuous learning to keep the team and customers appraised of the latest developments in the space.\nA committed teacher and someone who enjoys developing technical maturity across the company. \nExperience supporting analytics, data science and\/or engineering teams and understand their unique needs and challenges.\nQualifications\n8+ overall years of professional experience including 4+ years\u2019 experience in designing high-scale Kimball\/Dimensional models is REQUIRED \n4+ years of experience with data modeling, schema design patterns and modern data access patterns (including API, streams, data lake) is REQUIRED\n2+ years as a proven leader interacting with customers (client facing) to collect requirements and manage a technical data backlog is REQUIRED; therefore you must have excellent interpersonal skills, both written and spoken, as well as a consultative\/collaborative style.\n2+ years with Databricks and Spark framework are REQUIRED\n2+ years of experience building data applications, microservices and\/or APIs using Python, Scala or an equivalent language is REQUIRED\n2+ years of experience with SQL, knowledgeable in complex queries and joins is REQUIRED; experience with UDF and\/or Stored Procedure development is HIGHLY DESIRED\n2 + years Azure Data Services including Azure Data Factory, ADLS, and Synapse is HIGHLY DESIRED; strong experience with AWS will be considered in lieu of.\n  #REMOTE\n#LI-CA1\n#azure\n#databricks\n#datalakehouse\n#datamodeling\nAdditional Information\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.","115":"Company Description\nTransforming businesses, driving success: SmarTek21\nSmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev\/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients\nJob Description\nSmarTek21 is looking for a hands-on architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.  \nQualifications\n\u2022 Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python.\n\u2022 Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks.\n\u2022 Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP).\n\u2022 Solid understanding of enterprise strategies for data security and data governance.\n\u2022 Experience in practice development, architecture, and consulting or product development.\n\u2022 Experience delivering data analytics projects and architecture guidelines.\n\u2022 Experience in engaging with enterprise architects. Non-technical Skills:\n\u2022 Excellent oral and written communication and presentation skills.\n\u2022 Ability to handle ambiguous situations and take trade-off decisions.\n\u2022 Strong problem solving and analytical skills to break down complex problems into smaller components.\n\u2022 Ability and willingness to perform in a team environment.\nRequirements:\n\u2022 Understand prospect\/customer\/partner technology landscape.\n\u2022 Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation.\n\u2022 Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers\/partners.\n\u2022 Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints.\n\u2022 Collaborate with the engineering team to create proof-of-concepts (POCs).\n\u2022 Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices.\n\u2022 Demonstrate business value of proposed solutions or current products to prospects and customers.\nSalary Range: $200,000-$215,000 (may be subject to change outside of WA State)\nAdditional Information\nWhat Is in It for You:\nPaid Time off \u2013 start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service.\nPaid Holidays - 8 paid holiday a year in addition to your PTO.\nHealth Insurance for FT employees \u2013 we pay 100 % premium of medical, dental and vision.\nHealth Insurance for FT employee\u2019s family \u2013 we pay 50% of premium for medical, dental and vision for dependents.\n401(k) \u2013 we administer 401(K) retirement contribution for FT employees.\nLife Insurance\/Short Term and Long-Term Disability \u2013 at no cost to you\nOpportunities for internal promotions\/career advancement\nFamily friendly work hours (closed on weekends and paid holidays)\nSmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and\/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class.","116":"Company Description\nBlend360 is a world class marketing, analytics, and technology company that delivers the best results for our clients. Our primary focus is Data Sciences; leveraging data and applied mathematics to solve our clients\u2019 business challenges. Blend360 is known for our exceptional people, our get-it-done mentality, and delivering high impact and sustainable results. If you love to solve difficult problems and deliver results; if you like to learn new things and apply innovative, state-of-the-art methodology, join us at Blend360.\nJob Description\nBlend360 is looking for a technology industry professional with a combination of business acumen and technical insight to maximize the value of our clients\u2019 technology assets.  You will understand the business problem, align stakeholders on your vision, develop a technical strategy, and oversee the implementation of critical technology products that drive our clients\u2019 organization. \n Job Duties\nDevelops and maintains a vision and plan for technical assets and oversees the execution of that plan to maximize the value of the technology to the organization.\nKnows how to identify key client initiatives, refine and manage stakeholders as it relates to the larger project\nDetermines operational objectives by studying business functions; gathering information; evaluating output requirements and formats\nAbility to conduct an enterprise analysis of tools and processes while building relationships with various levels of a client organization to help develop and drive a clear vision\nUnderstands business strategy as it relates to technologies used within client engagements\nCan conduct market analyses for tools and functionality available in the marketplace.\nUnderstanding product releases as it relates to requirements and deadlines\nDesigns and defines new technical programs and requirements\nImproves systems and processes by studying current practices; designing modifications, recommending controls by identifying problems; writing improved procedure\n Qualifications\n Required Skills\nBackground in Data Science or Data Engineering\n5+ years of experience\nStrong written documentation skills\nStrong verbal and client facing communication skills\nA critical thinker with a consultative mindset\nStrong understanding of the data industry as a whole, including tools, best practices, and functionality\nHands-on Experience across 2 or more of the following technologies:\nETL processes (Cloud Native, DataBricks, Spark, Airflow)  \nMultiple coding languages (JavaScript, Python, Java, .Net)  \nExperience with Database Designs & Administration (SQL, noSQL, Cache, DataLakes, Cluster)  \nCloud Native Engineering (AWS, Azure, GCP, WAF)  \nCloud Development \/ (CI\/CD) \/ DevOps \nCertification in Databricks or GCP or AWS or Snowflake \nThe starting pay range for this role is $100k - $145k. Actual compensation within the range will be dependent on several factors including but not limited to relevant experience, skills, certifications, training, and location. It is not typical for an individual to be hired at or near the top of the range and determining factors for compensation are considered for each individual circumstance. BLEND360 also offers a competitive benefits program to meet the health and financial well-being of our team and their families. You can look forward to a range of benefits including medical, dental, vision, 401K, PTO, paid holidays, commuter benefits, spending accounts, life insurance, disability coverage, and EAPs. \nAdditional Information\n All your information will be kept confidential according to EEO guidelines.","117":"Prominence is looking for a data architect with strong experience with SQL to help us build and deploy analytics solutions in partnership with some of the nation\u2019s leading healthcare providers. Our ideal candidate has deep familiarity with Microsoft SQL Server and\/or cloud technologies such as Azure Synapse, AWS Redshift, Snowflake, Databricks, Apache Spark or similar tools.\nYou should be able to work at the data level to transform raw sources into meaningful and actionable information and at the architectural level to design data models that can scale both in size and complexity. More important than experience with any particular technology or platform is the demonstrated desire and ability to tackle new and unfamiliar technical challenges.\nRequirements\nDesired Skills Required\nStrong experience reading and writing SQL\nDeep knowledge of relational data modeling\nExperience with one or more of the following\nMicrosoft SQL Server\nApache Spark (Spark SQL, pyspark etc.)\nAzure Synapse\nAWS Redshift\nDatabricks\nSnowflake\nSimilar cloud or big data technology\nAbility to write, debug and tune SQL queries\nAbility to think at an architectural level in creating, growing, maintaining, and documenting scalable data models\nStrongly Preferred\nExperience with the AWS or Azure cloud\nHealthcare industry knowledge and experience\nProgramming experience (Python, C#, etc.)\nKnowledge of Microsoft SQL Server hardware and software configuration best practices\nExperience with reporting tools such as Tableau, QlikView, Qlik Sense\nBonus Skills\nExperience working with source control software (git, svn, TFS)\nBenefits\nProminence is dedicated to hiring the best and brightest minds in healthcare, and maintaining a culture that rewards our employees for following their passion. You\u2019ll join a team of highly motivated and passionate people who do great work for the nation\u2019s leading healthcare organizations, including 7 of the top 10 academic medical centers. In the past 5 years, we\u2019ve received 20+ Best Places to Work Awards and are highly rated in KLAS, reflecting the quality work from our team of A-players who move mountains daily for our customers. We strive to create the best working environment with the best team, so that we can continue to drive innovation in healthcare faster.\nOur 3 nodes of business - Strategy, Deployment, and Analytics - offer you a diversified career path, stability in a rapidly changing market, and opportunities for growth within Prominence.\nProminence is a fully remote company, with no requirements on where you live or work within the US and flexibility to manage your schedule.\nWe offer 15 days PTO and up to 16 paid Holidays each year for full-time staff.\nWe offer a diverse healthcare offering, including low and high deductible health plans, HSAs, LTD\/STD Insurance, Health and Dependent Savings Accounts, Vision, Dental, 401k offering, an annual Professional Development fund, Technology stipend, and Signing Bonuses.","118":"C3.ai, Inc. (NYSE:AI) is a leading provider of Enterprise AI software for accelerating digital transformation. The proven C3 AI Suite provides comprehensive services to build enterprise-scale AI applications more efficiently and cost-effectively than alternative approaches. The core of the C3 AI offering is an open, data-driven AI architecture that dramatically simplifies data science and application development. Learn more at: www.c3.ai\nC3 AI is looking for experienced data and analytics professionals to join our AI Solution Architecture team (presales). You will be applying your analytics platform experience to design, recommend, and validate solution designs to help our prospective customers deliver high-value, high-impact projects driven by AI\/ML.\nAI Solution Architects are data and analytics professionals with at least 5 years of experience with knowledge of data lake architectures, data integration, and data governance, and at least 2 years of experience with cloud-based AI\/ML technologies (such as tools from AWS, Azure, Google, and Databricks).\nResponsibilities:\nDevelop and maintain expertise on the latest technologies relating to cloud, IoT, big data, and artificial intelligence to provide thought leadership to our prospects, customers, and within the company.\nProvide technical leadership in the delivery of trials and proofs-of-concept.\nCollaborate with application engineers, product managers, and data scientists to deliver solutions that solve real-world problems.\nDrive discussions on architecture and engineering to articulate the capabilities of the C3 AI Application Platform and its interoperability with existing systems.\nDeliver technical deep dives, demonstrations, and training in support of sales.\nQualifications:\n5 years of experience in developing solutions for data and analytics (such as Data Warehousing, Hadoop, and BI Tools), with proficiency in JavaScript and\/or Python.\nFamiliarity with cloud technologies and machine learning concepts.\nUndergraduate degree in Science, Technology, Engineering, or Mathematics (STEM), or a comparable area of study.\nStrong verbal and written communication and presentation skills.\nExperience with object-oriented programming.\nPassionate learner and ability to apply new skills rapidly.\nPassion for teaching, storytelling, and presenting.\nExperience driving client-facing architecture sessions \/ technical workshops.\nAbility to travel, up to 50%.\nPreferred Qualifications:\nApplied experience with machine learning and data science.\nFamiliarity with AI\/ML-related technologies and tools such as MLFlow, KubeFlow, Kubernetes, AWS SageMaker, Azure MLStudio, DataRobot, and Databricks.\n2+ years of experience demonstrating software products and presenting technical materials.\nExperience working with large enterprises across multiple industries.\nExperience with Information, Network, & Infrastructure Security concepts.\nC3 AI provides excellent benefits and a competitive compensation package, which include:  \nGenerous equity plan.\nSalary range: $129,000 - $149,000 USD.\nCandidates must be authorized to work in the United States without the need for current or future company sponsorship.\nC3 AI is proud to be an Equal Opportunity and Affirmative Action Employer. We do not discriminate on the basis of any legally protected characteristics, including disabled and veteran status. ","119":"We partner with the world\u2019s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience and drive operational efficiency.\n\nDescri\u00e7\u00e3o geral \nProcuramos um Arquiteto de Dados para ajudar um dos nossos clientes norte-americanos a construir uma plataforma Data Mesh do zero. Nesta posi\u00e7\u00e3o, voc\u00ea projetar\u00e1 e implementar\u00e1 cargas de trabalho de dados, definir\u00e1 estrat\u00e9gias de hospedagem e entrega para uma plataforma DaaP (dados como produto) de ponta a ponta em um ambiente de nuvem. \nSua miss\u00e3o:  - Trabalhar em estreita colabora\u00e7\u00e3o com arquitetos e engenheiros da CI&T e do cliente, selecionando ferramentas e frameworks, definindo e implementando solu\u00e7\u00f5es de dados end-to-end;- Compreender problemas de neg\u00f3cios complexos e traduzi-los em problemas e estruturas de dados estruturados;  - Conceituar, visualizar e construir um Enterprise Data Platform Framework para apoiar os objetivos de neg\u00f3cios e ci\u00eancia de dados do cliente. Portanto, visualize, projete e prepare dados em uma estrutura que possa ser utilizada por engenheiros de dados, cientistas de dados e analistas de dados;  - Como parte da estrutura, defina uma arquitetura\/ambiente de dados de estado de destino para dar suporte \u00e0 implementa\u00e7\u00e3o de pipelines de dados e modelos de aprendizado de m\u00e1quina com t\u00e9cnicas de ci\u00eancia de dados de ponta. Portanto, identificando e resolvendo as lacunas arquitet\u00f4nicas conforme necess\u00e1rias;- Explorar conjuntos de dados para determinar a melhor forma de capturar, integrar e preparar dados para casos de uso de an\u00e1lise\/aprendizado de m\u00e1quina;   - Colaborar com o Analista de Dados para entender requisitos e casos de uso;- Comunicar descobertas de forma eficaz para um p\u00fablico de partes interessadas de neg\u00f3cios, engenheiros de dados e analistas de dados; \nRequisitos para este desafio:\n- Engenharia de dados em ambiente cloud;  - AWS;  - DataOps;  - Pipelines de CI\/CD aplicados a cargas de trabalho de dados;  - Projeto e implementa\u00e7\u00e3o de Data Lake\/Data Warehouse para dados estruturados e n\u00e3o estruturados (Snowflake, Redshift, BigQuery, DataBricks ou outros);- Projetar, construir e entregar pipelines de dados de alta qualidade (processamento em lote e em tempo real);- Bancos de dados SQL (MySQL, PostGres, etc) e No-SQL (Neo4J, MongoDb, Cassandra, etc); - Preven\u00e7\u00e3o de perda de dados; - Gest\u00e3o de dados;  - Dados privados;- Profici\u00eancia em ingl\u00eas para comunica\u00e7\u00e3o\n#LI-PM1\nCI&T is an equal opportunity employer. We celebrate and appreciate the diversity of our CI&Ters\u2019 identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow. \nAt CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas. We strongly encourage Black, Indigenous, and People of Color (BIPOC), immigrants, candidates with a disability, women, and LGBTQIA+ candidates to apply to our vacancies.","120":"Description de l'entreprise\nQui sommes-nous ? Devoteam Data Driven est l\u2019\u00e9quipe sp\u00e9cialiste de la Data du Groupe Devoteam, leader du conseil en strat\u00e9gie digitale, plateformes technologiques, data, et cybers\u00e9curit\u00e9. Nous sommes pr\u00e9sents dans 8 pays et comptons plus de 800 collaborateurs EMEA dont 300 en France.  \nDans un univers en constante \u00e9volution, notre ambition est d\u2019accompagner les organisations qui ont d\u00e9cid\u00e9 de placer les donn\u00e9es au c\u0153ur de leur strat\u00e9gie. Nous les aidons \u00e0 transformer la valeur de leurs donn\u00e9es en succ\u00e8s durable.\n90% des donn\u00e9es mondiales ont \u00e9t\u00e9 g\u00e9n\u00e9r\u00e9es au cours des deux derni\u00e8res ann\u00e9es.. Chaque organisation est engag\u00e9e dans cette opportunit\u00e9 de passer \u00e0 la vitesse sup\u00e9rieure.\nC\u2019est l\u00e0 que nous intervenons. Nos partenaires 100% Cloud et Data (Databricks, Dataiku, Snowflake et Tableau) et nos 3 domaines d\u2019expertise ( Data Strategy, Data for Business, Data Foundation) nous permettent d\u2019aider nos clients dans leur qu\u00eate d'agilit\u00e9, de comp\u00e9titivit\u00e9 et de croissance.\nDans le cadre de notre d\u00e9veloppement, nous renfor\u00e7ons nos \u00e9quipes ! Pourquoi nous rejoindre ? \u00catre form\u00e9(e) en continu : Devoteam Data Driven a d\u00e9velopp\u00e9 un programme solide de formations & certifications (partenariats avec Databricks, Snowflake, Tableau, Dataiku, \u2026), notamment sur les technologies cloud (GCP, AWS, Azure, \u2026) Intervenir sur des sujets vari\u00e9s et pointus : Devoteam Data Driven intervient dans de nombreux secteurs d\u2019activit\u00e9 (Retail, luxe, m\u00e9dia, t\u00e9l\u00e9coms, banque, industrie, \u2026) pour des grands comptes internationaux Rejoindre une soci\u00e9t\u00e9 sp\u00e9cialis\u00e9e : Devoteam Data Driven ne fait que de la data \ud83d\ude09 La garantie d\u2019intervenir sur des sujets pr\u00e9cis au c\u0153ur de votre expertise Int\u00e9grer une \u00e9quipe : Devoteam Data Driven c\u2019est avant tout une \u00e9quipe \u00e0 taille humaine b\u00e9n\u00e9ficiant de l\u2019\u00e9cosyst\u00e8me d\u2019un grand groupe Le Groupe Devoteam oeuvre pour l'\u00e9galit\u00e9 des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m\u00e9rite et lutte activement contre toute forme de discrimination. Nous sommes persuad\u00e9s que la diversit\u00e9 contribue \u00e0 la cr\u00e9ativit\u00e9, au dynamisme et \u00e0 l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap .\nDescription du poste\n@S\u00e9bastien et son \u00e9quipe n\u2019attendent que vous pour relever de nouveaux d\u00e9fis autour de l\u2019\u00e9cosyst\u00e8me Cloud Data.\nEn tant que Data Architect, votre m\u00e9tier sera d\u2019accompagner nos clients grands comptes en veillant \u00e0 ce qu'ils tirent toute la valeur des technologies\/m\u00e9thodologies data. \nVous accompagnerez nos clients dans la transformation de leur Syst\u00e8me d\u2019information, par le design de plateformes Data Cloud Native ainsi que lors des projets de migration vers ces plateformes.. \nLes missions que vous serez amen\u00e9 \u00e0 r\u00e9aliser concerneront :\nD\u00e9finir, choisir et d\u00e9fendre vos choix d\u2019architectures Data Cloud\nConcevoir une architecture en ad\u00e9quation avec les besoins m\u00e9tier,\nTenir compte des probl\u00e9matiques de performance et de s\u00e9curit\u00e9,\nInt\u00e9grer les solutions au sein du reste du SI\nConcevoir des mod\u00e8les de donn\u00e9es permettant le versionning et l\u2019\u00e9volution\nMettre en place ou accompagner l'industrialisation et l'automatisation des t\u00e2ches r\u00e9currentes\nTravailler en \u00e9troite collaboration avec notre panel d\u2019experts: Cloud Architects, Data Engineer, Data Scientists, PO\u2026\nParticiper et piloter les phases de POC (proof-of-concept) pour s\u2019assurer de l\u2019ad\u00e9quation des sc\u00e9narios et des d\u00e9cisions d\u2019architecture ;\nAssurer le suivi et mise \u00e0 jour du r\u00e9f\u00e9rentiel d\u2019architecture ;\nAssurer une Veille technologique\nAvoir une posture conseil et d\u2019expertise aupr\u00e8s de nos clients du CAC 40\nCe que nous attendons de vous:\nEmbarquer, coacher, animer une communaut\u00e9 de passionn\u00e9s Data\nEtre force de proposition chez votre client, en proposant des choix d\u2019architectures\nAccompagner le Practice Manager sur les sujets: AVV, recrutement, formation etc\u2026, pour les communaut\u00e9s Data chez Devoteam\nQuid de la r\u00e9mun\u00e9ration ? Nous aborderons ouvertement le sujet lors de nos \u00e9changes !\nDe vos qualifications :\nEn sommes, si vous cochez les 3 crit\u00e8res ci-dessous (pas un de moins :D).... :\nPassionn\u00e9 : vous vous impliquez dans les communaut\u00e9s, vous \u00eates ravis de partager votre exp\u00e9rience et vous vous positionnez naturellement en tant que mentor\nAmbitieux : vous participez \u00e0 la performance de l\u2019entreprise\nCourageux : vous repoussez les limites de votre champ d\u2019action et embarquez les \u00e9quipes\n... Alors vous \u00eates peut-\u00eatre un futur #TalentMaker Expert big data sur une ou plusieurs solutions, issu d\u2019\u00e9cole d\u2019ing\u00e9nieurs ou en Master 2 en informatique, vous \u00eates dot\u00e9 d\u2019un excellent relationnel, d\u2019un sens prononc\u00e9 du service et de la qualit\u00e9. Vous aimez travailler en \u00e9quipe, and you are fluent in english, indeed !\n Vous poss\u00e9dez id\u00e9alement cinq ans d'exp\u00e9rience professionnelle en tant qu'architecte, dont une premi\u00e8re exp\u00e9rience sur des solutions Data\/Big Data. Vous disposez de comp\u00e9tences sur les solution Cloud majeures du march\u00e9, voire les distributions Hadoop. La ma\u00eetrise en particulier de Spark Streaming, KAFKA et les applications orient\u00e9es \u00e9v\u00e9nements serait un plus.\nVous avez de tr\u00e8s bonnes connaissances sur les services Cloud et les architectures serverless ; Vous maitrisez des processus d\u2019Industrialisation, d\u00e9veloppements & d\u00e9ploiement (DevOps, FinOps, DataOps)\nVous avez des connaissances concernant les normes et r\u00e9f\u00e9rentiels d\u2019architecture ainsi qu\u2019une connaissance des m\u00e9thodes agiles Scrum, Kanban, Safe, \u2026\nVous \u00eates d\u00e9sireux de vous investir dans des projets challengeants et gagner rapidement en responsabilit\u00e9s. Vous \u00eates p\u00e9dagogue, soucieux de collaborer avec diverses \u00e9quipes (PO, Data Scientists, Scrum Masters, D\u00e9veloppeurs etc\u2026).\nQualifications\nAlors n\u2019h\u00e9sitez plus \u00e0 r\u00e9pondre \u00e0 l\u2019annonce de @Oumaima et rejoignez la communaut\u00e9 des One Devoteam. \nLe Groupe Devoteam \u0153uvre pour l'\u00e9galit\u00e9 des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m\u00e9rite et lutte contre toute forme de discrimination. Nous sommes persuad\u00e9s que la diversit\u00e9 contribue \u00e0 la cr\u00e9ativit\u00e9, au dynamisme et \u00e0 l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.\nPoste bas\u00e9 en IDF et ouvert uniquement en CDI.\nEn rejoignant Devoteam, vous aurez la possibilit\u00e9 de vous connecter avec vos pairs, de partager leur exp\u00e9rience et de d\u00e9velopper vos comp\u00e9tences en rejoignant la communaut\u00e9 Big Data partag\u00e9e par nos 18 pays.\nTu veux en savoir plus? Viens \u00e9changer directement avec nos ambassadeurs.","121":"About Coalfire\nCoalfire is on a mission to make the world a safer place by solving our clients\u2019 toughest cybersecurity challenges. We work at the cutting edge of technology to advise, assess, automate, and ultimately help companies navigate the ever-changing cybersecurity landscape. We are headquartered in Denver, Colorado with offices across the U.S. and U.K., and we support clients around the world.\nBut that\u2019s not who we are \u2013 that\u2019s just what we do.\nWe are thought leaders, consultants, and cybersecurity experts, but above all else, we are a team of passionate problem-solvers who are hungry to learn, grow, and make a difference. \nAnd we\u2019re growing fast.\nWe\u2019re looking for a Director of Business Systems & Data Architecture to support our team.\nPosition Summary\nCoalfire Business Technology organization is seeking to add a Director of Business Systems & Data Architecture reporting to Chief Information Officer with specific focus on Sales, Marketing, Professional Services, Finance, Engineering and Operations teams. Salesforce Sales Cloud, Revenue Cloud\/CPQ, Financial Force, and Sales tools. This leader will be responsible for ensuring a strong and effective partnership with the assigned business functions in order to implement, enhance and support all existing systems and, in addition, plan for and execute new technology solutions that will enable growth and support their assigned business function along with enhancing the current Data Architecture and leading Master Data Management program.\nWhat You'll Do\nEffectively lead the technology and data architecture, keeping long term vision and scalability while working with cross-functional teams in a hyper-growth fast-paced environment.\nKnowledgeable on complex business solutions, trends in IT and experience implementing complex tools and solutions, along with Integrations, to ensure end to end flow\nOwn and drive the strategy, roadmap, technical health, and management of key business systems, including Salesforce CRM, Financial Force & NetSuite in collaboration with Business Stakeholders.\nExperience with Agile Scrums, Customer management and project management experience is required\nLead business requirement gathering sessions in collaboration with business stakeholders and provide best practices and ensure a long term best-fit solution.\nEnvision and lead system architecture around customer life cycle, solving business problems, ensuring data quality, scale, security, reliability and availability\nEstablish Data Governance model and MDM processes and ensure basic architecture and data governance principles are followed across the board.\nMaintain accurate program estimates, timelines, project plans, and status reports.\nDevelop and maintain the current state of business processes and systems.\nExecute roadmaps, solution architecture, release planning, preparation, validation, post-release monitoring, performance, and maintenance.\nResponsible for complex technical management coordination with multiple vendors and staff.\nManage and appropriately escalate delivery impediments, risks, issues, and changes associated to the project development initiatives.\nAssign and monitor work of technical personnel, ensuring that application development and deployment is done in the best possible way.\nImplement quality control and review systems throughout the development and deployment processes.\nProvide process improvement recommendations based on best practices and industry standards.\nKnowledge and experience with Agile project methodologies\nRun daily stand ups, sprint management & leading scrums effectively\nExceptional analytical and quantitative skills, with great attention to detail\nAbility to conceptualize current requirements to align with future roadmaps\nStrong aptitude for quickly understanding program work processes and identifying technical integration opportunities\nAttention to detail with organization, and multi-tasking abilities are key to be successful in this role\nCollaborates with management and user community to develop strategies for enhancement, improvement, or replacement of systems to improve productivity, efficiency, and quality of data.\nDrive vision, mission and technology strategy, buy vs build decisions, balancing competitive advantage with time to market\nStrong verbal and written communication skills, including executive presentation skills\nAbility to make order out of chaos and make effective decisions\nBe an advocate for security and performance standards in the organization.\nWhat You'll Bring\n10+ experience working with business systems technology is required\n3-5 years of experience in sales, marketing, and finance systems is ideal\nExperience with middleware such as MuleSoft or Dell Boomi would be Ideal\nExperience with leading SaaS platforms, and other forms of service-based computing models\nAbility to lead large teams and work in a matrix environment supporting business partners.\nKnowledgeable on IT solutions, trends in IT and experience evaluating\/implementing new tools and solutions\nStrong track record in planning and prioritizing work with the business well in advance (rolling 12 month plan)\nProven ability to build strong relationships across the enterprise to ensure IT Business System delivery expectations are met and priorities are set at the appropriate level.\nDemonstrated analysis, troubleshooting and problem-solving skills\nStrong executive presence and ability to work with all levels\nShould have an \u201cautomation first\u201d mindset.\nAbility to quickly identify and drive to the optimal solution considering possible constraints.\nGood understanding of agile scrum principles.\nExcellent judgment, analytical-thinking, and problem-solving skills.\nPrevious experience working in the Tech\/SaaS industries.\nSelf-motivated, possessing excellent time-management and organizational skills.\nStrong cross-functional collaboration skills, relationship-building skills, and ability to achieve results without direct reporting relationships.\nStrong sense of personal responsibility and accountability for delivering high quality work, both personally and at a team level\nProven ability to design, optimize, and integrate business processes across systems\nKnowledge and experience with Agile project methodologies\nProven ability leveraging analytical and problem-solving skills in a fast-paced environment\nExperience collaborating with business stakeholders, business process owners, technical project managers and technical teams to execute business analysis tasks\nDrive and desire to learn and grow both technical and functional skill sets\nInquisitive and continuously focused on identifying inefficiencies and improving business processes\nExcellent interpersonal skills and ability to thrive in a collaborative environment\nGoal-orientated, self-motivated and adapts to changing situations\nStrong presentation, communication (written and verbal) skills, and interpersonal skills; must be detail orientated\nWhy You'll Want to Join Us\nAt Coalfire, you\u2019ll find the support you need to thrive personally and professionally. In many cases, we provide a flexible work model that empowers you to choose when and where you\u2019ll work most effectively \u2013 whether you\u2019re at home or an office.\nRegardless of location, you\u2019ll experience a company that prioritizes connection and wellbeing and be part of a team where people care about each other and our communities. You\u2019ll have opportunities to join employee resource groups, participate in in-person and virtual events, and more. And you\u2019ll enjoy competitive perks and benefits to support you and your family, like flexible time off, certification and training reimbursement, and comprehensive insurance options.\nAt Coalfire, equal opportunity and pay equity is integral to the way we do business. A reasonable estimate of the compensation range for this role is $114,000 to $198,000 based on national salary averages. The actual salary offer to the successful candidate will be based on job-related education, geographic location, training, licensure and certifications and other factors. You may also be eligible to participate in annual incentive, commission, and\/or recognition programs.","122":"Company Description\nAt Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people\u2019s lives. Our promise to our associates is rock-solid: We grow together, we enjoy our work, and we inspire each other. Welcome to Bosch.\nThe Robert Bosch GmbH is looking forward to your application!\nJob Description\nAs AI Software Architect you will be responsible for defining and driving architecture for AI and software projects within Bosch Digital.\nPart of your work involves defining overall architectural principles, frameworks and technology.\nThe development of codes excites you and you enjoy working hands-on in the process of software development.\nYou are able to consult other Bosch organizations in the field of AI and software.\nLastly, you train other experts on AI and Software Architecture and Development.\nQualifications\nEducation: completed university studies in Computer Science, Information Technology, Computational Linguistics or related fields\nPersonality: communicative, responsible\nWorking Practice: resilient, initiative\nExperience and Knowledge: several years of experience in AI, data, cloud and micro-service architecture; experience in agile Software development; programming knowledge in Python & Java\nEnthusiasm: passion for AI and software combined with a personality that inspires people\nLanguages: fluent English and German\nAdditional Information\nYou want to work remotely or part-time - we offer great opportunities for mobile working as well as different part-time models or job-sharing. Feel free to contact us.\nDiversity and inclusion are not just trends for us but are firmly anchored in our corporate culture. Therefore, we welcome all applications, regardless of gender, age, disability, religion, ethnic origin or sexual identity.\nNeed support during your application?\n Anna Haas (Human Resources)\n+49 711 811 27525\nNeed further information about the job?\nJohannes Epple (Functional Department)\n+49 711 811 14417","123":"Are you passionate about Artificial Intelligence, Machine Learning and Deep Learning? Are you passionate about helping customers build solutions leveraging the state-of-the-art AI\/ML\/DL tools on Amazon Web Service (AWS)? Come join us!\n\nAt Amazon, we\u2019ve been investing deeply in artificial intelligence for over 20 years, and many of the capabilities customers experience in our products are driven by machine learning. Amazon.com\u2019s recommendations engine is driven by machine learning (ML), as are the paths that optimize robotic picking routes in our fulfillment centers. Our supply chain, forecasting, and capacity planning are also informed by ML algorithms. Alexa is fueled by Natural Language Understanding and Automated Speech Recognition deep learning; as is Prime Air, and the computer vision technology in our new retail experience, Amazon Go. We have thousands of engineers at Amazon committed to machine learning and deep learning, and it\u2019s a big part of our heritage.\n\nWithin AWS, we\u2019re focused on bringing that knowledge and capability to customers through three layers of the AI stack: 1) Frameworks and Infrastructure with tools like Apache MxNet and TensorFlow, 2) Machine Learning Platforms such as Amazon SageMaker for data scientists, and, 3) API-driven Services like Amazon Lex, Amazon Polly, Amazon Transcribe, Amazon Comprehend, and Amazon Rekognition to quickly add intelligence to applications with a simple API call.\n\nAWS is looking for a Machine Learning Solutions Architect (ML SA), who will be the Subject Matter Expert (SME) for helping technology customers (ISVs, Digital Native Businesses, Gaming, etc.) design solutions that leverage our ML services. As part of the team, you will work closely with customers to enable large-scale use cases, design ML pipelines, and drive the adoption of AWS for the AI\/ML platforms. You will interact with other SAs in the field, providing guidance on their customer engagements, and you will develop white papers, blogs, reference implementations, and presentations to enable customers to fully leverage AI\/ML on AWS. Additionally, as the voice of the customer, you will work closely with the service teams, and submit product feature requests to drive the platform forward.\n\nYou must have deep technical experience working with technologies related to artificial intelligence, machine learning and\/or deep learning. A strong mathematics and statistics background is preferred in addition to experience building complex machine learning models. You will be familiar with the ecosystem of software vendors in the AI\/ML space, and will leverage this knowledge to help AWS customers in their selection process.\n\nRoles and Responsibilities - Working with customers\u2019 development and data science teams to deeply understand their business and technical needs. After understanding their needs, you will design solutions that make the best use of the AWS cloud platform and AWS AI\/ML Services including SageMaker, Amazon Comprehend, Amazon Rekognition, Amazon Transcribe, Amazon Lex, Amazon Polly, Amazon Forecast, Amazon Personalize, and the other AI\/ML services.\nPartner with SAs, Sales, Business Development and the AI\/ML Service teams to accelerate customer adoption and revenue attainment in the AMERICAS for Amazon SageMaker.\nThought Leadership \u2013 Evangelize AWS ML services and share best practices through forums such as AWS blogs, whitepapers, reference architectures and public-speaking events such as AWS Summit, AWS re:Invent, etc.\nAct as a technical liaison between customers and the AWS SageMaker services teams to provide customer driven product improvement feedback.\nDevelop and support an AWS internal community of ML related subject matter experts in the AMERICAS.\n\n\nAbout the team\nInclusive Team Culture\nHere at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon\u2019s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.\n\nWork\/Life Balance\nOur team puts a high value on work-life balance. It isn\u2019t about how many hours you spend at home or at work; it\u2019s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.\n\nMentorship & Career Growth\nOur team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we\u2019re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.\nBasic Qualifications\n\n8+ years of specific technology domain areas (e.g. software development, cloud computing, systems engineering, infrastructure, security, networking, data & analytics) experience\n3+ years of design, implementation, or consulting in applications and infrastructures experience\n\nPreferred Qualifications\nBachelor's degree in computer science, engineering, mathematics or equivalent\n\n\nAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https:\/\/www.amazon.jobs\/en\/disability\/us.","124":"TruRating \u2013 be part of something which will change the world.\nTake the plunge. Live the dream. Do something which you know will touch the lives of millions of people the world over every single day and will change the way businesses and consumers think. Get out of bed in the morning for that adrenalin hit, love the pace, love the challenge, love doing what has never been done before \u2013 and love being the best you\u2019ve ever been. And what\u2019s more, owning part of what you\u2019ve created.\nTruRating is a hypergrowth software as a service (SaaS) company that improves businesses, benefits consumers, and donates to charities. Our starting point is using patented technology to collect feedback from 80%+ of customers at the point of payment and linking this to transaction and product data to provide unique mass, real-time insight to merchants.\nThis feedback can also be pointed towards consumers - providing transparent, representative, and validated information to help us all make better decisions. whilst we also \u2018do our bit\u2019 as for every question we ask, TruRating donates to children\u2019s charities.\nWorking with our retail partners we can also provide data & insights to 3rd parties including FMCGs via ground-breaking \u2018intelligent questions\u2019 which allow us to send questions in real time that relate to specific products or behaviours.\nWe partner with the biggest payment companies in the world, and our unique integrations mean we are delivering an unprecedented dataset. No other business in the world is combining online and offline sentiment and consumer behaviour data in huge volumes, at near to real time.\nOur customers include some of the best performing and highest-profile retailers in the world \u2013 and the group is growing all the time. We are collecting nearly 5 million ratings and 250m data points every week now and are \u2018live\u2019 in the UK, Europe, North America, Australia, and NZ. With almost 400m ratings under our belt and global patents granted \/ registered, the world is there for the taking.\nWe need to grow our passionate team to help us live out the dream and deliver on our incredible opportunity. TruRating is a global organization with US headquarters in Atlanta GA, UK headquarters in London and ANZ headquarters in Sydney. We are actively growing our team and invite you to check us out!\nThe Role\nThe role of the Data Architect is critical to TruRating\u2019s continued growth and success. The role will help us continue to build on our data and insight capabilities and ensure we deliver uniquely powerful insights to our clients as we extend our reach and process huge volumes of near real time data.\nThe emphasis is on making our data work for us and to set us up to scale our data and insight services as we work with more and more major retailers. Your work will allow us to maximise value from the data, allowing us to process hundreds of millions of daily data points, funneling them into simple, meaningful insights.\nThe right candidate will have deep experience of working with the Azure BI stack, designing and maintaining complex ETL processes, working with third party platforms such as Snowflake, will love solving complex challenges and be up to date on new technology advances in the big data and insight space.\nThe role requires a talented and highly motivated individual who fits well into the team, has excellent communication skills and a keen eye for the detail. The successful candidate will need to quickly understand our data assets and immediately add value.\nRequirements\nKey Responsibilities\nSet the strategic vision for designing our data schemas, managing our data architecture, and scaling and enhancing our data platform\nArchitect, develop and deliver end-to-end data processing from raw storage to front-end analytics solutions\nProvide exceptional leadership and support to the Data Services team\nManage all data infrastructure services\nWork with our Product, Insights, and Development Teams to enhance data availability, deliver technical projects, and advise on how best to deliver and present data within the merchant facing analytics platform, open data deliverables, and client reporting\nSupport data platforms to internal users for deep dive analytical activity and internal reporting requirements\nContribute to wider architecture group\u2019s work (Solutions Architects working with our payment partners and merchants around data capture etc.) including creating\/reviewing their designs and specifications.\nWe would love to bring on board someone who\u2026\nIs comfortable leading the architecture, governance, design and development of systems which enable the analysis of data from multiple diverse internal and external sources\nHas great experience with the design and build of modern data warehouse solutions in the cloud\nDesigns and documents solutions using data schemas, flowcharts, layouts, diagrams, charts and code comments\nIs a team player with excellent interpersonal skills; able to collaborate across the organization and has a hands on-approach to development\nHas a strong BI background and assists with design and development of Tabular cubes, Snowflake tables, and other data structures which provide reporting to internal and external users\nIs experienced working with Agile and Rapid Application Development methodologies, using an Agile approach\nCan evaluate 3rd party software solutions\nHas excellent written, verbal communication and presentation skills\nIs self-reliant, resilient and proactive with a high motivation to make things happen, deliver effectively and efficiently.\nTechnical Skills\nEnterprise data warehouse design, star\/snowflake schemas and ETL design\nCurrent experience of working with third party data platforms, such as the Snowflake Platform\nAzure Platform: Azure SQL DB, Azure Azure SQL DW, Azure Analysis Services, Azure Data Factory, Azure Function Apps\nMSSQL BI Stack, SSAS, SSIS, SSRS. Power BI desirable\nSource control with git and experience using CI\/CD solutions\n\nLocation: Lite - hybrid model \u2013 at present largely at home with 2 days a month with the team, which could extend to once\/twice a week in the future to a central london location (on consultation with team).\nBenefits\nTruRewards\nIn addition to our enviable company culture at TruRating, we offer 25 days holiday, Private Medical Healthcare with BUPA (medical history disregarded), a SMART pension, a great Wellbeing support package with \"WeCare\" and group life insurance with Canada Life.\nAs with everyone in the team, you will have share options and therefore own a part of the company and benefit directly from its success.\nApplication process\nAs well as your CV please include a brief introduction that helps us understand why you would be a great fit for the role.\nIf you are excited about this role but your experience doesn't align perfectly with every qualification in the job description, please apply anyway :-) Studies in this area report that some groups of us \u2013 like people of colour, people with disabilities and people from LGBTQ2+ communities, women etc. \u202fare less likely to apply to jobs unless we meet every single qualification. Here at TruRating we are committed to providing the most welcoming and inclusive work environment - free from any form of discrimination and inequality.\nWhat makes TruRating is us all thriving as part of a diverse and supportive culture \u2013 and we would love to welcome you to it :-)","125":"Join a global community united on a mission to radically shift science-led innovation.\nWe are looking for a Data Architect to join the Eagle Genomics Architecture Team on our journey as we collaborate with some of the world\u2019s most exciting, blue-chip companies. Using cutting-edge technologies, we\u2019re reinventing research, enabling data-driven discovery, and unlocking meaningful change in the fields of sustainable agriculture, food, pharma, personal care, and cosmetics.\nThe Data Architect will play an active role in architecting, implementing, and managing enterprise solutions around big data especially in cloud environments with distributed, scalable, fault tolerant and secure data storage, data ingestion, integration, retrieval, and data analysis. To succeed in this role a person must be an organised self-starter, a clear communicator and be comfortable working with ambiguity in an unstructured workplace environment and has strong experience in providing robust solutions in data and information architecture and management from conceptual to physical implementation.\n\nYou will:\nCollaborate:\nWith SMEs to catalogue and organise data sources across the business by domain\nWith SME\u2019s and data modeller to build a generic and systematic data modelling approach and solution that cater for diverse data sources\nWorking with the data engineers to ingest, transform, and onboard the identified data sources\nWith SME\u2019s, Data governance, Security leads to evolve the Data management policies and security around data usage\nTo supervise & guide development teams during the data management implementation\nCollaborate with Architecture team to build the Data Management Roadmap\nDesign:\nDesigning cloud agnostic data management and engineering solutions for big data, data-intensive and data analytics systems\nDefining best practices, patterns and architectural styles for data fabric management and engineering (data ingestion, transformation, and integration)\nMapping the data product vision to the required data solutions and technologies by ensuring genericity, performance, reliability, resilience and security models and sources\nRecommend and implement secure and regulatory compliant data practices and solution\nStakeholder management:\nActing as the data design authority within the engineering team and the platform development for data considerations\nEffective communication in keeping stakeholders for current technical problems and solutions\nProvide business impacts based on the assessment of technical choices\nChampioning a Data-as-an-Asset mindset across the engineering team\nChampioning the Data governance and process across the organization\nScale:\nContinuously searching for advanced technical and data architectural methods, practices and technologies and champion these practices across the organization\nAbility to mentor and build high performing data engineers\nRequirements\nYou will need:\n8+ years of experience in data architect and design of data management solutions,\nExperience in architecting, designing, integrating, and understanding the characteristics and specificities of data-intensive systems (aka Big Data, Data analytics)\nKnowledge in Data modelling at Conceptual, logical, and Physical based on domain and business needs\nExperience in building and managing Data Technology Roadmaps\nExperience in influencing or championing data governance and policies\nExperience in Data security concepts and implementations\nProficiency and understanding of relational, non-relational and graph database technologies\nExperience in handling large and varied data sets, data preparation, data processing and data analytics of large data sets\nExperience in designing and implementing effective solutions for \/managing data governance and data policies\nExperience in ETL\/ELT, Data Migration, Data import and Export from\nKnowledge in various licensed or open ETL\/ELT technologies like Azure data factory, AWS glue, or Apache NiFi\nDistributed systems to relational or graph databases from concepts to implementations\nExperience in implementing Enterprise data management solution in a Cloud Agnostic model\nA bonus if you have:\nExperience in any of the data architecture like kappa, lambda or delta is a big plus\nExperience in SQL (Oracle or MS SQL), no-SQL (MongoDB)\nExperience in implementing security policies or standards like ISO, GDPR or Hi-Trust\nExperience in Graph databases (neo4j or grakn) is an advantage\nExperience Microsoft Azure Databricks, Data factory, HDInsight, Hadoop, HBase\nExperience in implementing Azure or Aws Data lakes and analytics\nUnderstanding \/Experience in Apache Spark SQL, GraphX, Streaming\nExperience in any Program language Python or Scala or Go or .NET\nExperience in implementing cloud infrastructure, cloud data storages (blobs or buckets), be it Azure or Aws or both\nExperience in using Azure or Aws provided ML engines, Power BI to implement analytics\nCertifications or accreditations related to database design, Azure or Aws data architect is desirable\nBenefits\nWhat you will love about Eagle Genomics:\nWorking for impact. Teaming up with smart and engaging people united by a shared purpose.\nCollaborating with industry shaping clients to tackle complex, real-world challenges, sparking discoveries that affect the world around us.\nBe an active part of our growth story with the freedom to test, learn, experiment, and explore innovative ideas.\nOpenness. Our monthly All Hands meetings bring our global teams together and encourage discussion.\nThe opportunity to lead, learn and grow with continuous encouragement, professional development, and support.\nFlexible working:\nOur roles offer flexible working practices that support your, and the team\u2019s, best delivery. We have co-working spaces in London, Cambridge, Berlin, Paris, Kyiv, Manhattan, and Hyderabad.\nDiversity, equity & inclusion:\nWe strive to create and foster a working environment where everyone is free to be themselves. A commitment to diversity, equity and inclusion is in our DNA and spans everything we do, including our recruitment process.\nMore about Eagle Genomics:\nDigitally reinventing life sciences to solve some of the grand challenges of our age.\nEagle Genomics is a pioneering company working at the intersection of two exciting areas: life sciences and data science. Our AI (Artificial Intelligence) augmented platform is revolutionising how scientists conduct life sciences research and is bridging the gap between data and new insights in a rapid, systematic, and traceable way. We are putting data science at the fingertips of biologists to drastically reduce the time and cost of research, enabling customers to achieve radical productivity improvements and true data driven discovery. We are also partnering with research leaders such as the Earlham Institute to bring together open science and commercial R&D to help society.\nWe are proud to have an active information security program across all business areas, based on the ISO\/IEC ISO 27001 standard. We require all our colleagues to contribute to the effectiveness of the ISMS (Information Security Management System) by accepting and understanding their duty of confidentiality to keep Eagle Genomics data secure.","126":"Als globale Unternehmensberatung mit Fokus auf die Finanzdienstleistungsbranche kombinieren wir bei Capco innovatives Denken mit einzigartigem Know-How. So divers wie unsere Mitarbeiter*, sind auch unsere L\u00f6sungen, die wir unseren Kunden anbieten. Bringe Dich ein und setze Deine Ideen bei Capco in die Tat um als\u2026\nSenior Consultant\/Manager* - Data Architecture\nIn Frankfurt am Main, D\u00fcsseldorf, M\u00fcnchen, Berlin oder Wien\nDeine Capco Benefits\nDu bist uns wichtig! Daher bekommst Du einen pers\u00f6nlichen Coach an Deine Seite gestellt, der Dich individuell f\u00f6rdert und unterst\u00fctzt. Zudem bieten wir Dir ein umfangreiches Trainingsangebot sowie anerkannte Zertifizierungen. Mit unserer Start-Up-Mentalit\u00e4t und unseren flachen Hierarchien, stehen Dir alle M\u00f6glichkeiten offen. Nach Feierabend hast Du bei Teamevents oder gemeinsamen Aktivit\u00e4ten die Chance, Dein Netzwerk zu erweitern und Deine Hobbies mit Kollegen* zu teilen.\nCapco Benefits Card mit monatlicher Gutschrift\nBike Leasing Programm und gef\u00f6rderte Gesundheitschecks\nAttraktives Mitarbeiterempfehlungsprogramm\nFlexible Arbeitsmodelle\nUnser Office Management in der City in FFM, direkt am Opernplatz, h\u00e4lt immer Erfrischungen und \u00dcberraschungen bereit\nDeine Capco Aufgaben\nDu begleitest herausfordernde agile Beratungsprojekte hinsichtlich konzeptionellem und technischem Aufbau, Entwicklung und Optimierung der Datenarchitektur von der Business Analyse und Fachkonzeption bis hin zur Implementierung\nDabei setzt Du auf modernen Verfahren und Technologien, um hocheffiziente, transparente und qualitativ hochwertige Datenarchitekturl\u00f6sungen zu konzipieren\nDu \u00fcbernimmst Verantwortung f\u00fcr Deine Themen sowie die F\u00fchrung von (Teil-) Projekten und Projektteams\nNeben der Projektarbeit hast Du die M\u00f6glichkeit, Dich in verschiedenen internen Themen mit einzubringen, diese zu entwickeln und eigene Ideen umzusetzen\nDein Capco Profil\nDu hast ein erfolgreich abgeschlossenes Hochschulstudium, beispielsweise mit dem Schwerpunkt (Wirtschafts-) Informatik, Ingenieur- oder Naturwissenschaften\nDu verf\u00fcgst \u00fcber mehrj\u00e4hrige Projekterfahrung in den relevanten Vorgehensweisen, Architekturen und Technologien in einem oder mehreren der folgenden Themen:\nDesign und Umsetzung von Datenarchitekturen und -technologien (On-Prem, Cloud; SQL, No-SQL)\nDesign und Umsetzung von Data-Lake- und Cloud-Konzepten und \u2013technologien\nEinf\u00fchrung von Datenverarbeitungstechnologien und -tools (Ab Initio, Informatica, AWS Glue, Spark)\nKonzepte der Datenmodellierung und des Datenmanagements\nDesign von Events und Datenfl\u00fcssen in Event-Driven-Architecture Konzepten, z.B. mit Kafka\nEigenschaften wie Teamf\u00e4higkeit, sehr gute analytische und konzeptionelle F\u00e4higkeiten zeichnen Dich aus\nDeine flie\u00dfenden Deutsch- und Englischkenntnisse sowie eine uneingeschr\u00e4nkte Mobilit\u00e4t im (inter-)nationalen Raum runden Dein Profil ab\nBewirb Dich jetzt! Dauert nur 5 Min. Versprochen!\nDein Capco Recruiter*\nAylin Han erreichst Du am besten unter: aylin.han@capco.com\n*Wichtig ist nur, dass wir zueinander passen (m\/w\/d) #beyourselfatwork","127":"Enterprise Horizon Consulting Group is seeking a Data Architect to join our team to support a Navy Business Intelligence and Data Modeling project. The project is based in Mechanicsburg, PA and remote work is available based on client approval. The successful candidate will need Extract Transform and Load (ETL), data modeling, and computer programming related skills. The Data Architect will be expected to:\nTake initiative in an environment involving diverse sets of data, documents, and materials.\nWork closely with clients to translate user functional requirements into a system requirement specification by learning and understanding their business processes, business requirements, interpreting requirements and assisting in the solution design.\nSupport project teams and interface with clients.\nFunction as a business intelligence developer to include \u201cExtract, Transform and Load\u201d processing, data modeling, interface design, report development, and report visualization.\nPerform Netezza and Informatica administration tasks such as supporting user account tickets, user account lockouts, and other user date issues.\n\nWork Schedule: Work can be performed remotely with client approval. The project is based in Mechanicsburg, PA.\nRequirements\nActive Secret Security clearance is required.\nSecurity+ and Linux+ certifications are required.\nBachelor\u2019s degree, with a technical major, such as mathematics, statistics, engineering, data computer information systems or computer science is required.\n5-10 years of related work experience is required.\nBusiness intelligence development experience which should include ETL processing, data modeling, interface design, report development, and report visualization.\nWorking knowledge of some (not all) of the following technologies:\nPrimary: Yellowbrick, Netezza, Informatica, IBM Pure Data for Analytics, SQL, Data Stage, Attunity\nSecondary: COGNOS, SAS, Business Objects, Oracle\nHighly Desired Qualifications:\nSAP data structures\nNavy and DoD Supply Chain functional business process\nData lifecycle management and interface design\nUnix\/Linux Scripting\nApplication installation, configuration and administration in Linux and Widows Environments\nMilitary Installation Access:\nActive Secret Security Clearance is required.\nU.S. Citizenship required.\nMust be able to qualify for and obtain a base access pass in a timely manner.\nMust be able to obtain a favorable National Security Agency Check (NACI) including an FBI fingerprint check.\n\n\nEnterprise Horizon Consulting Group complies with federal, state, and local mandates regarding COVID-19. Many of our business partners (including the federal government) are requiring all employees working on or in connection with their projects to be fully vaccinated. Accordingly, you acknowledge that you may be required to prove that you have received the COVID-19 vaccine as a condition for ongoing employment. The Company will consider requests for reasonable accommodations for employees who are unable to be vaccinated due to a disability\/medical condition or a sincerely held religious belief, but please note that accommodations may not be possible.\nPay Scale\n$160,000 to $180,000 commensurate with experience and qualifications.\nBenefits\nWe offer full-time salaried employees competitive salaries with a range of benefits, including medical, dental, vision, life insurance, simple IRA with company match, federal holidays, vacation time, and sick leave.\n\nAnother Way to Put $500 in Your Pocket\nIf this position is not a perfect fit for you, but you know someone who would be a great match, please refer them to us via our Candidate Referral Program using the following link: www.enterprisehorizon.com\/candidatereferrals. If we hire them, you could receive $500! See the link for further details.\n\nEnterprise Horizon Consulting Group does not discriminate against any employee or applicant for employment on the basis of race, color, religion, sex, marital status, sexual orientation, gender identity, national origin, ancestry, age (40 and over), physical or mental disability, or protected veteran status, or any other protected status in accordance with all applicable federal, state and local laws. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, marital status, sexual orientation, gender identity, national origin, ancestry, age (40 and over), physical or mental disability, or protected veteran status, or any other protected status in accordance with all applicable federal, state and local laws.","128":"Als globale Unternehmensberatung mit Fokus auf die Finanzdienstleistungsbranche kombinieren wir bei Capco innovatives Denken mit einzigartigem Know-How. So divers wie unsere Mitarbeiter*, sind auch unsere L\u00f6sungen, die wir unseren Kunden anbieten. Bringe Dich ein und setze Deine Ideen bei Capco in die Tat um als\u2026\n(Junior) Consultant* \u2013 Data Architecture\nIn Frankfurt am Main, D\u00fcsseldorf, M\u00fcnchen, Berlin oder Wien\nDeine Capco Benefits\nDu bist uns wichtig! Daher bekommst Du einen pers\u00f6nlichen Coach an Deine Seite gestellt, der Dich individuell f\u00f6rdert und unterst\u00fctzt. Zudem bieten wir Dir ein umfangreiches Trainingsangebot sowie anerkannte Zertifizierungen. Mit unserer Start-Up-Mentalit\u00e4t und unseren flachen Hierarchien, stehen Dir alle M\u00f6glichkeiten offen. Nach Feierabend hast Du bei Teamevents oder gemeinsamen Aktivit\u00e4ten die Chance, Dein Netzwerk zu erweitern und Deine Hobbies mit Kollegen* zu teilen.\nCapco Benefits Card mit monatlicher Gutschrift\nBike Leasing Programm und gef\u00f6rderte Gesundheitschecks\nAttraktives Mitarbeiterempfehlungsprogramm\nFlexible Arbeitsmodelle\nUnser Office Management in der City in FFM, direkt am Opernplatz, h\u00e4lt immer Erfrischungen und \u00dcberraschungen bereit\nDeine Capco Aufgaben\nDu begleitest herausfordernde agile Beratungsprojekte hinsichtlich konzeptionellem und technischem Aufbau, Entwicklung und Optimierung der Datenarchitektur von der Business Analyse und Fachkonzeption bis hin zur Implementierung\nDu \u00fcbernimmst Aufgaben im Bereich Data Engineering, Business Analyse und Konzeption und lernst die verschiedenen Aspekte im Umfeld von Datenarchitekturen auf dem Projekt und in internen Schulungen kennen\nDabei setzt Du auf modernen Verfahren und Technologien, um hocheffiziente, transparente und qualitativ hochwertige Datenarchitekturl\u00f6sungen aufzubauen\nSchrittweise \u00fcbernimmst Du mehr Verantwortung f\u00fcr Deine Themen und \u00fcbernimmst verst\u00e4rkt konzeptionelle und architektonische Aufgaben\nNeben der Projektarbeit hast Du die M\u00f6glichkeit, Dich in verschiedenen internen Themen mit einzubringen, diese zu entwickeln und eigene Ideen umzusetzen\nDein Capco Profil\nDu hast ein erfolgreich abgeschlossenes Hochschulstudium, beispielsweise mit dem Schwerpunkt (Wirtschafts-) Informatik, Ingenieur- oder Naturwissenschaften\nDu verf\u00fcgst \u00fcber Kenntnisse und idealerweise Projekterfahrung in den relevanten Vorgehensweisen, Architekturen und Technologien in einem oder mehreren der folgenden Themen:\nDesign und Umsetzung von Data-Lake- und Cloud-Konzepten und \u2013technologien\nNutzung von Datenverarbeitungstechnologien und -tools (z.B. Ab Initio, Informatica, AWS Glue, Spark)\nKonzepte der Datenmodellierung und des Datenmanagements\nGute Kenntnisse von Datenbanken und SQL\nEigenschaften wie Teamf\u00e4higkeit, sehr gute analytische und konzeptionelle F\u00e4higkeiten zeichnen Dich aus\nDeine flie\u00dfenden Deutsch- und Englischkenntnisse sowie eine uneingeschr\u00e4nkte Mobilit\u00e4t im (inter-)nationalen Raum runden Dein Profil ab\nBewirb Dich jetzt! Dauert nur 5 Min. Versprochen!\nDein Capco Recruiter*\nAylin Han erreichst Du am besten unter: aylin.han@capco.com\n*Wichtig ist nur, dass wir zueinander passen (m\/w\/d) #beyourselfatwork","129":"Company Description\nArthur Grand Technologies (www.arthurgrand.com) is in the business of providing staffing and technology consulting services. We have doubled our revenue year over year for the past 5 years. This speaks to the long-lasting relationship and customer satisfaction that we have built in this short span of time. Our company is managed by a team of professionals who worked for big 5 consulting firms for 20+ years. \nWe are a minority owned staff augmentation and technology consulting company\nTo keep our valued employees, we need to keep them engaged in challenging, interesting work, offer market-relevant benefits and provide continued opportunities for professional growth.\nJob Description\nRole: Azure Data Architect\nLocation: Washington, DC [Hybrid Onsite \u2013 2 Days\/Week]\nDuration: Long term contract\n Roles and Responsibilities:\nCandidate with experience as Data Architect, Data Engineering, or any related role to Data solutions.\nCandidate should have a proven track record in leading and delivering Azure Data Analytics solutions.\nGood experience in Developing Advanced Analytics solutions, Applying Data Visualization.\nHands-on experience solutioning and implementing analytical capabilities using the Azure Data Analytics platform including, Azure Data Factory, Azure Logic Apps, Azure Functions, Azure Storage, Azure SQL Data Warehouse\/Synapse, Azure Data Lake.\nCandidate should be capable to support in all the phases of Analytical Development from identification of key business questions, through Data Collection and ETL.\nStrong knowledge of Data Modelling and Data Design is required for the role.\nRole requires interplay between data and business process. Candidates who have performed this Role would be preferred.\nExperience in the design of reporting & data visualization solutions such as Power BI or Tableau is a plus.\nKnowledge and implementation in financial institutions is a plus.\nKnowledge in Statistical Programming languages is a plus.\nKnowledge in Machine Learning is a plus.\nMicrosoft Data Certification is a plus.\nAdditional Information\nAll your information will be kept confidential according to EEO guidelines."}}