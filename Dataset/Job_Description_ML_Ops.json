{"Job Description":{"0":"Hala Systems, Inc. is a social enterprise working to transform the nature of protection and accountability in the world\u2019s toughest places by democratizing advanced defense, sensing, and artificial intelligence technology. Hala is currently saving lives, reducing trauma, and improving resilience for millions of people.\n\nOur team works across the globe and hails from over 15 countries. We speak over 20 languages and have studied and worked in leading educational, business, research and government institutions. We are mission-driven thinkers, and we share a deep respect for each other and for the communities that partner with us.\n  We believe in innovation with purpose, focusing on developing real and applicable technology solutions to the challenges facing the planet. We believe in working ethically and collaboratively, and making decisions with transparency. We value flexibility, adaptability, and a good sense of humor.\n  The MLOps Engineer will be a part of a high-performing Data Science team developing and implementing AI algorithms to help address global challenges. They will develop and use modern software engineering practices to deploy AI\/ML solutions; Identify and evaluate new technologies to improve the performance, maintainability, and reliability of Hala\u2019s learning systems. The MLOps Engineer will contribute to the technical work program of Hala\u2019s projects, providing expert guidance and strong technical mentorship, reporting to the Director of Analytics.\n  This position remote position is open to candidates based in Europe with a yearly gross salary range of 48.000\u20ac - 58.000\u20ac. This position is also open to candidates based on the East Coast of the United States, with a yearly gross salary range of 124,000$ - 134,000$\n  We\u2019ll trust you to: \nThese are the responsibilities of the position\nBe part of a high-performing team developing and implementing AI algorithms to help address critical global challenges.\nDevelop and use modern software engineering practices to deploy AI\/ML solutions at scale.\nMaintain knowledge of advances of AI and scalable computing in industry and academia.\nEvaluate AI architecture solutions and compare to external stakeholders\u2019 requirements and needs.\nContribute to the technical work program of one or more projects, providing expert guidance and high-quality technical products focused on successful outcomes, strong technical leadership, and transition of research to operations.\nProvide caring mentorship and collaborative technical advice to staff.\nDesign the data pipelines and engineering infrastructure to support our clients\u2019 enterprise machine learning systems at scale.\nTake offline models data scientists build and turn them into a real machine learning production system.\nDevelop and deploy scalable tools and services for our clients to handle machine learning training and inference.\nIdentify and evaluate new technologies to improve performance, maintainability, and reliability of Hala\u2019s learning systems.\nApply software engineering rigor and best practices to machine learning, including CI\/CD, automation, etc.\nSupport model development, with an emphasis on auditability, versioning, and data security.\nFacilitate the development and deployment of proof-of-concept machine learning systems.\nCommunicate with clients to build requirements and track progress.\n  Who you are:\nA highly collaborative, well-rounded professional.\nAn exemplary diplomat with exceptional interpersonal skills.\nA visionary and strategist.\nAn excellent communicator who is able to provide appropriate and data-driven recommendations. \nA creative problem-solver,\nA highly driven, results-oriented person.\n  We\u2019d love to see:\nThese are the technical skills and qualifications\nBachelor's Degree in Computer Science, Engineering, Cybersecurity, or related technical field\nAdvanced degree in related field of study.\n2\u20135 years experience building production-quality software.\n4+ years\u2019 work experience with Machine Learning, DevOps, Deep Learning, Computer Vision, high-performance computing (HPC), software engineering and\/or related fields.\nHands-on experience using tools such as: Python, C\/C++, and database languages.\nExperience supporting efforts training & deploying AI\/ML models.\nOutstanding written and oral presentation skills are required for both internal and stakeholder-facing communications.\nHands-on experience managing or provisioning GPU\/CPU clusters, or other large-scale cloud or Linux\/Unix systems.\nHands on experience developing and training AI\/ML models.\nProven experience implementing CI\/CD on large-scale operational AI pipelines.\nOperational experience deploying across cross-provider, cross-domain cloud computing environments.\nAbility to translate business needs to technical requirements.\nStrong understanding of software testing, benchmarking, and continuous integration.\nExposure to machine learning methodology and best practices.\nExposure to deep learning approaches and modeling frameworks (PyTorch, Tensorflow, Keras, etc.).\n  What Hala offers you:\nLife-saving social impact.\nCompetitive salaries.\nUnlimited vacation policy and flexible holidays so you can take time off when you need it. All staff take a minimum of 22 days off plus holidays, including a mandatory 2 week vacation.\nComprehensive, world-wide healthcare, dental and vision insurance for you and your family at no cost to you.\nPaid parental leave.\nFlexible working policy, including the ability to work from home. \nComputer and other office equipment to help you get your job done.\nRelocation assistance for you, your family, and your pets for eligible positions.\nA diverse, international community of dedicated, hardworking team players committed to interdisciplinary collaboration and a thriving workplace culture. \nOpportunities for international travel, including to program locations and satellite offices. \n  If there\u2019s something important to you that isn\u2019t on this list, please ask!\n  What happens next:\nWe will review applications and reach out to candidates advancing to the interview stage by October 15th. You should expect a phone screen, followed by several interviews with team members and the supervisor for this role, concluding with the opportunity to speak with both of our co-founders.\nYou will receive a confirmation that your application was received, and you\u2019ll also hear back from us whether you\u2019re selected for an interview or not. Please note that we are unable to offer individualized feedback before the first interview round due to the volume of applications we receive.","1":"Machine Learning (ML) and Artificial Intelligence(AI) are revolutionizing the way of doing business at a global scale. sennder is a European digital freight forwarder with a data-centric problem-solving approach to build the next generation of supply chain and road logistics services. Do you want to help us to shape the future?\nWe are looking for a (Senior) Machine Learning Engineer (MLOps) to join our central ML Recommendations team - as part of sennAI department. The department\u2019s mission is to achieve \u201cAutomated & Data-Driven Road Logistics\u201d. We\u2019re a large, diverse and multidiscplinary group of ML&AI engineers, data scientists, backend\/frontend engineers and technical product people that are passionate by the new AI-empowered digitalization wave that is changing our world. We want to attract and train world-class talent to form a incredible group that can provide you the most productive and growth-friendly time of your career.\nsennAI goal is to build proprietary technology that can automate sales, brokerage and other business-related activities which can enable a flywheel where data acquisition and revenues grow exponentially with one another. The scope of our teams is creating best-in-class predictive analytics services while approaching ML Engineering in an holistic, end-to-end fashion: from best practices in ML modelling until engineering excellence around our MLOps Platform that lifts our developers experience to a different realm.   Every day, we acquire 3M+ new real-time data points (augmenting by the day!) about the road logistics industry in Europe. This data is used to build the future of logistics marketplaces where pricing optimization, load-to-carrier recommendation, load search and network optimization happen in an automated fashion.\nCan you even imagine where we can go with your help? Let\u2019s #keepOnTrucking... together!\n  YOUR MISSION:\nDesign and maintain scalable ETL data pipelines;\nDesign and develop health and performance monitoring tools (MLOps) of data pipelines and the machine learning services in production;\nDesign and improve heterogeneous, asynchronous and high-performance large-data processing pipelines from\/to multiple sources\/destinations;\nOperationalize innovative, data-intensive, end-to-end machine-learning(ML)-based decision engines;\n  YOUR PROFILE:\nYou are someone who\nHas extensive experience with one or more orchestration tools (e.g Airflow, Flyte, Kubeflow)\nHas experience working with MLOps tools like experiment tracking, model registry tools and feature stores (e.g MLFlow, Sagemaker, Azure)\nHas extensive experience with DevOps focused around data intensive applications. You are comfortable with infrastructure-as-code, you have used the likes of Terraform, Kubernetes extensively. \nHas experience building and scaling model serving tools, i.e building APIs with tight SLAs.\nAdheres to best coding practices. You find joy in beautifully written code. \nWorks the best in Agile teams.\nHas experience with a programming language (Python preferred).\n  BONUS:\nExperience in the digital logistics industry.\nExperience in Machine Learning modelling, especially in Pricing, Recommendations.\nMentoring experience.\n  ABOUT sennder:\nsennder is moving trucks with the power of data to unlock endless and sustainable capacity at unparalleled quality. Through our proprietary transportation operating system, built by our in-house tech teams, we not only connect shippers to our fleet of thousands of trucks, but also improve how they move products in sustainable, cost-efficient, and transparent ways - making the logistics industry fit for the future. In a traditional industry, we\u2019re growing and moving fast to digitally automate all road logistics processes. \nWe are building a curious team that is driven by an ambitious desire to solve the toughest logistics puzzles. What others may consider uncertainty, we see as an opportunity to learn and be proactive. We invite you to go on this journey with us and be part of one of Europe\u2019s inspiring growth stories as we fast-forward road logistics into digitalization. \n  Get to know us, our culture, green business, funding history, and more on our blog here.\n  Why Us?\nAt sennder, we want to maximize the individual\u2019s potential for all employees and reinforce an inclusive culture and environment of continuous learning that empowers people to succeed as a team. In addition to humility, we value commitment, team spirit, respect, and kindness to build trusted relationships across teams. Learn more on our career site. \nA fast-growing, start-up-oriented international team of 1000+ people with 65+ nationalities spread across 8 country offices with English as our company language.\nContinuous feedback and bi-annual review process for personal development, professional growth, and career opportunities. We also use \u201cObjectives and Key Results\u201d for company goals.\nA structured promotion process, providing everyone with fair and transparent career growth.\nLearning and development opportunities on the job and through conversations with your manager.\nVarious opportunities to connect with colleagues, formally and informally, digitally or in-person (when allowed), through regular team events, company get-togethers, and partnership events with other companies and local organizers.\nFlex\/hybrid remote working options.\nWhen in office: unlimited snacks, drinks, and fruits.\nAll interviews are currently conducted on a remote basis.\nPlease send your application in English and help us reduce negative unconscious bias by leaving out your picture, age, address, and other unnecessary information in your CV. We only want to know the merits on which you\u2019d be great for this role.\nWe value humility and we're as interested in your character as we are in your talent. Please apply, even if you feel you only meet part of our listed criteria. Diversity drives our innovation and we offer a collaborative, dynamic and international work environment. Just be yourself. We are excited to meet you and for you to join us in shaping the future of the logistics industry in Europe.\nIf you have any questions or problems please reach out to us at ta@sennder.com. We do not accept applications via email.\n#LI-MS1","2":"Manage a team of engineers delivering a world-class machine learning operations platform that can be deployed on any Kubernetes. We're building the most robust, well-integrated and sustainable way of operating a comprehensive MLOps platform on Kubernetes, powered by Juju and Charmed Operators.\nLocation: Remote role for candidates in AMER and EMEA.\nWhat your day will look like\nLead a world-class rigorous software engineering process\nLead the design and implementation of Charmed Operators\nCollaborate with other leaders to develop best practices\nWork with partners and the open source community\nCoach, mentor and develop engineers across the business\nWhat we are looking for in you\n Exceptional academic track record in maths and the sciences\n Demonstrated ability to design and build high quality software\n High level of proficiency in Python and with Kubernetes\n Demonstrated ability to build and lead engineering teams\n Willingness to travel up to 4 times a year for internal events\nAdditional skills that you might also bring\nExperienced in Machine Learning tooling\nExperienced in the operation of Machine Learning tooling at scale\nCompetency in Go programming\nExperience with working in and contributing to open source communities\nWhat we offer you\nYour base pay will depend on various factors including your geographical location, level of experience, knowledge and skills. In addition to the benefits above, certain roles are also eligible for additional benefits and rewards including annual bonuses and sales incentives based on revenue or utilisation. Our compensation philosophy is to ensure equity right across our global workforce.  \nIn addition to a competitive base pay, we provide all team members with additional benefits, which reflect our values and ideals. Please note that additional benefits may apply depending on the work location and, for more information on these, please ask your Talent Partner.\nFully remote working environment - we\u2019ve been working remotely since 2004!\nPersonal learning and development budget of 2,000USD per annum\nAnnual compensation review\nRecognition rewards\nAnnual holiday leave\nParental Leave\nEmployee Assistance Programme\nOpportunity to travel to new locations to meet colleagues at \u2018sprints\u2019\nPriority Pass for travel and travel upgrades for long haul company events\nAbout Canonical\nCanonical is a pioneering tech firm that is at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world on a daily basis. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do.\nCanonical has been a remote-first company since its inception in 2004. Work at Canonical is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical provides a unique window into the world of 21st-century digital business.\nCanonical is an equal opportunity employer\nWe are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.\n#LI-remote ","3":"We are Leaf\nLeaf is on a mission to upend the way companies buy and sell transportation. Every year, billions of dollars, hundreds of megatons of carbon and millions of person-hours are wasted because the companies who ship goods and the companies who carry them aren\u2019t upfront about their needs and abilities. Our platform finds ways for buyers and sellers to contract binding commitments for plannable and predictable freight and allows those contracts to be traded when needs change. In time, Leaf will become the hub through which the trillion-dollar American freight market is managed.\nWe are a team of experienced, smart, and mildly disagreeable troublemakers who like taking on unreasonably big challenges; we know how to build things, we\u2019ve lived what\u2019s broken in this industry, and we\u2019re looking for bright, ambitious people to help us drag the transportation world kicking and screaming into the 21st century.\n\n\nWhat does a Data Operations (DataOps) Engineer do at Leaf?\nAs a DataOps Engineer, you will work cross-functionally to ensure continuous access to clean, accurate, and usable data through the company, and to bridge the data gaps between Leaf's technical, operational, and customer-facing teams. This is a highly interdisciplinary role that combines aspects of data science, data engineering, UI\/UX design, business consulting, and project management.\nAs a DataOps Engineer, you....\nMonitor Leaf's internal analytics software and data pipelines for quality and accuracy\nDevelop automated data validation and testing tools to proactively identify and resolve issues before they reach end users\nBuild, audit, and tune SQL queries, reports, and dashboards\nOptimize Leaf's database architecture to support a range of business applications and analytics use cases\nDesign and implement processes for data ingestion, ETL, reporting, and governance\nManage data integrations between Leaf and various external sources\nWho makes a DatOps Engineer?\nBachelor's degree or higher (or equivalent experience) in a highly analytical and detail-oriented field such as computer science, engineering, economics, or law\nExcellent command of Python, clean code principles, and the Python data ecosystem (Pandas, Jupyter, etc.)\nIntermediate to advanced SQL skills, and familiarity with NoSQL systems\nWorking knowledge of RESTful web services and backend API development\nComfortable with Git and other standard Unix command-line tools\nStrong basic statistical literacy and the ability to translate those concepts into simple terms\nDemonstrated ability to work independently while managing competing priorities in a startup or similar fast-paced environment\nNice-to-haves: Prior experience in the logistics industry, familiarity with electronic data interchange (EDI) protocols, working knowledge of frontend development, experience with (or interest in learning) a strongly typed modern programming language such as Rust\nCompensation\nCash compensation range: $140,000-$160,000 USD annually.\nThe cash compensation above reflects the annual base salary. In addition to base salary, our total cash compensation may include additional compensation for employees in eligible roles. All Leaf employees are also eligible to participate in Leaf\u2019s equity plan to receive Incentive Stock Options (ISOs). Individual compensation packages are based on a few different factors unique to each candidate, including their skills, experience, qualifications, and other job-related reasons.\nWe know that benefits are also an important piece of your total compensation package. We offer the following benefits:\u25cf      Equity: Incentive Stock Options\u25cf      Medical, dental, and vision insurance options at low group rates\u25cf      16 company observed US holidays in 2023 plus unlimited PTO\u25cf      401K plan\u25cf      Up to 12 weeks of fully-paid parental leave after 6 months of employment\u25cf      Stipend toward home office necessities and monthly phone bill or internet\nLeaf Logistics is an equal-opportunity employer and we welcome applicants from all backgrounds. If you\u2019re a passionate team player who wants to have an outsized impact on a diverse and dynamic team, we\u2019d love to hear from you!\n#LI-Remote","4":"Company Description\nDigitas is the Connected Marketing agency, built on the principle that there are better ways for brands to connect with people. We leverage comprehensive data, technology, creative, media and strategy capabilities to deliver Media-Fueled Creativity via connected Solutions that include Connected Campaigns, Social Marketing, Brand Experience, CRM & Loyalty, and Marketing Transformation. A Leader in Gartner\u2019s Magic Quadrant for Global Marketing Agencies for six consecutive years, Digitas serves the world\u2019s leading brands through a global network comprised of more than 4,000 employees across over 30 countries and 50 offices. For more information visit www.digitas.com.\nJob Description\nVice President Director, Data Operations\nWe are the connected marketing agency, a full-service agency with modern creative & media, data, and technology services all under one roof. \nWe are connected in the way we think and the way we work. At the heart of our company are great people that we call Unicorns. Our Unicorns are open, bold, and curious and love to solve complex problems for clients in unique ways.\nOur Data & Analysis team is a group of curious, agile, and collaborative strategic analysts.  We collect, connect, and analyze data, transforming it into meaningful stories that drive overall marketing strategy and smarter business decisions.\nTo help with this, we\u2019re looking for an outstanding Vice President Director, Data Operations \u2014 someone who leads a team of experienced Data Ops team members, aligns solutions with client goals, directs ongoing client relationships, thinks critically and strategically, has a passion for connecting people and processes more efficiently, provides innovative automation solutions and motivates internal teams to drive operational efficiencies with data.\nSound like you? Read on.\nDay-to-day, your role includes:\nLeading a Data Ops team, ensuring their growth as they progress through their career\nActing as a key partner for the client and internal teams by architecting data flows and developing strategies for ensuring marketing data is democratized, reliable and delivered efficiently\nExpanding current client work, consulting on client-side Data Ops, and helping clients realize the value of a dedicated team managing Data Ops\nAssisting clients in defining data automation and democratization needs and developing solutions to solve those challenges\nCreating frameworks and methodologies for deploying Data Ops solutions, leveraging existing Digitas intellectual capital and developing innovation solutions to fill any gaps\nLeading evaluations and opportunities with new platforms and solutions for simplifying and\/or automating media and site data processes\nEnsuring projects are managed and executed efficiently\nLeading documentation and sharing best practices gained from other Data Ops projects\nBuilding a collaborative team environment, including participation in department-wide training efforts, and fostering employee career growth\nLeading development of roadmaps for deploying automation solutions and Data Ops projects\nPlaying a key role in defining the technology strategy for data management\nEmpowering your team to live the Digitas values to be open, bold, and curious\nContributing to the vision and strategy for the Data Ops practice, including setting development roadmaps, participating in new business, and identifying growth or efficiency opportunities\nDetermining new opportunities among existing clients and participating in broader new business and growth initiatives\nLeading, driving, and promoting a culture of process documentation, strong data governance and operational efficiencies\nCoaching and mentoring team members\nQualifications\nWe\u2019re looking for strong, impactful experience, which typically includes:\n10-12 years of applicable experience in analytics with an advertising agency, management consulting company, or ad tech company\nStrong client relationship and communication skills, experience managing multiple projects across teams\nExperience managing and mentoring a team, an empathetic leader\nProven leadership ability with strong client relationship skills\nA four-year college degree; advanced degree is a plus\nStrong attention to detail, critical thinking, and problem-solving skills\nExcellent oral and written communication skills\nPassion for digital marketing, eagerness to learn in a constantly changing space, and a natural curiosity\nProficient with SQL and data visualization tools (i.e. Tableau, PowerBI, Google Data Studio)\nKnowledge of digital data technologies (Google Analytics, Google Marketing Platforms, etc.)\nKnowledge and experience with Python and\/or R a plus\nExperience with tools like Alteryx\nExperience working with Google Cloud and AWS\nComfortable in a fast-paced and deadline-driven environment\nGot what it takes? We\u2019d love to hear from you!\n23-2808\nAbout Digitas:\nDigitas is the Connected Marketing agency, built on the principle that there are better ways for brands to connect with people. We leverage comprehensive data, technology, creative, media and strategy capabilities to deliver Media-Fueled Creativity via connected Solutions that include Connected Campaigns, Social Marketing, Brand Experience, CRM & Loyalty, and Marketing Transformation. A Leader in Gartner\u2019s Magic Quadrant for Global Marketing Agencies for six consecutive years, Digitas serves the world\u2019s leading brands through a global network comprised of more than 4,000 employees across over 30 countries and 50 offices. For more information visit www.digitas.com.\nAdditional Information\nDigitas is an equal opportunity employer. All your information will be kept confidential according to EEO guidelines.","5":"About Us:\nWe are a team of physicians, healthcare executives, data scientists, and Tech experts committed to empowering anyone, anywhere with the insights they need to make well-informed healthcare decisions. Through the combined power of AI and big data, we have created the first all-in-one solution that provides our users with everything they need to know about medical professionals and facilities. RYTE transforms the comprehensive data we collect on millions of healthcare providers and medical experts worldwide into knowledge that helps individuals and organizations navigate healthcare systems. Headquartered in Toronto (Canada) and having operations in Canada, France, Kazakhstan, and the Philippines, you will join a truly international, multi-cultural, and dynamic workforce driven toward building something unique and that affects Life and Healthcare on a global scale. For more information about Us, please connect with us at www.ryte.ai.\nWe are looking for a junior Data Scientist to join the Research and Development team who is willing to learn about the complexities of structured, semi-structured and non-structured text data and have a significant impact on the Healthcare Analytics sector.\nThis is an internship (alternance) position (that might evolve to a CDI contract) in France.\nThe Position: Junior MLOps Engineer.\nThe Role:\nAs part of the AI and data engineering department, you will work side to side with a team of AI engineers, architects and data scientists located in multiple countries to perform research and development on AI-based technologies applied to Healthcare Analytics.\nRequirements\nExpected Tasks:\nWork with Product Managers and Engineers and dive deep into Ryte\u2019s collection of structured and non-structured data.\nActively collaborate in the design of an end-to-end strategy and implementation of scalable machine learning operations to production.\nMaximize productivity, process efficiency and quality through streamlined workflows, process standardization, documentation and investigations on a periodic basis, including:\nExperimentation tracking\nPipelining\nCI\/CD\nMonitoring\nTrack, document and report quality metrics to ensure our models optimal performance and determine its limitations.\nRequirements and Qualifications:\nCurrently pursuing a Master of Science degree in Computer Engineering, Computer Science, or related discipline.\nGood understanding of Python and\/or R.\nKnowledge of SQL and (Azure) Databricks.\nExperience working with tools such as MLflow or Azure ML will be a plus.\nExperience with at least one Deep Learning framework such as TensorFlow, Keras, Azure ML Studio, or PyTorch.\n1 year of relevant experience with the above-mentioned frameworks will be a plus.\nGood written and verbal communication skills in English are a must.\n\nWe would like to thank all Applicants for their interest in this position. Please note that only Applicants selected for an interview will be contacted. Ryte Corp. is an equal opportunity employer. If selected for an interview, please advise our Human Resources team if you require accommodation during the interview and assessment process. We will work with Applicants to accommodate all accessibility needs.\nBenefits","6":"Company Description\nPublicis Media harnesses the power of modern media through global agency brands Performics, Spark Foundry, Starcom and Zenith. A key business solution of Publicis Groupe ([Euronext Paris FR0000130577, CAC 40], Publicis Media\u2019s digital-first, data-driven global practices deliver client value and drive growth in a platform-powered world. It is present in more than sixty countries with over 23,000 employees worldwide.\nJob Description\nThis role offers an opportunity to work on Publicis Media\u2019s best-in-class data infrastructure platform where we ingest, process, and enable access to data from major media platforms across categories including search, social, ad serving, and more.  In this role, the Platform Success Lead will coordinate closely with various Publicis agency stakeholders and the Data Infrastructure team to ensure successful delivery of data used to power various agency analytics products and deliverables.  This role will be responsible for coordinating with agency contacts to ensure successful onboarding and enablement of data specific to their media platforms and use cases. Additionally, the role will have responsibility for defining engineering requirements specific to the success of various agency use cases.\nResponsibilities:\nPrepare specs and requirements for data sources and data source features required by agency client teams\nResearch, and where needed, coordinate with vendors to ensure data availability to meet Agency client use cases\nWork closely with Product Manager to help prepare stories for grooming and to help the grooming process with Engineers\nCoordinate with Product Peers, Engineering Team and Scrum Master to ensure delivery of Data Infrastructure features and data sources required to achieve Agency client product vision\nAct as Data Infrastructure Product SME with a focus on the DSP and Social data, data access procedures, and data certification practices.\nCoordinate closely with global contacts and maintain ongoing communications to help ensure success using Data Products\nOwn relationships with Data Source vendors\nQualifications\n5-7 years of related work experience\n5-7 years of digital media experience, particularly experience working in ad tech industry with a data-centric role\nHands-on analytics-based query experience in SQL and ability to articulate technical ETL requirements\nStrong written and verbal communication, including technical writing skills\nUnderstanding of systems engineering concepts\nRequirements gathering, analysis, translation, organization, documentation and communication experience\nPractical experience in scrum-based Agile development methodology\nExperience working with JIRA, Confluence, or equivalent\nB.S. in Engineering, Information Management, or Computer Sciences preferred\nHands-on experience working in Business Intelligence platform, preferably Tableau, is a plus\nAdditional Information\nPublicis Media provides benefits and resources designed to support all of our employees. With comprehensive health and dental benefits, 401K match program, generous time off, and flexibility to work remotely we strive to support work life balance. We encourage participation in the over 13 Business Resource Groups, including groups for Women, People of Color, Veterans, LGTBQ community and allies, Parents, and more.\nPlease let your Publicis Recruiter know if there are any particular adjustments we can consider to make the interview more accessible and comfortable.\nAll your information will be kept confidential according to EEO guidelines.\nCompensation Range: $130,000-$204,500 annually. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. For this role, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off.","7":"Company Description\nSyngenta Group is a $28B leading science-based agtech company, operating in more than 100 countries, with more than 50\u2019000 employees. We are proud to stand at the forefront of the tech revolution in agriculture. Using the latest digital innovations, data, and cutting-edge technologies we want to transform the way that crops are managed and enable farmers and agronomists to enhance efficiency and sustainable food production.\nOur business success reflects the quality and skill of our people. We recognize that human diversity is as important to our business as biodiversity. Embracing the unique perspectives and capabilities of our employees helps us continue to catalyze innovation, maximize performance, and create business value. Join us and help shape the future of agriculture.\nJob Description\nMake a difference\nIn this role you will work within a multidisciplinary global team to discover, define, and design experiences that empower farmers to work more effectively and efficiently by utilizing our data-driven solutions.\nThe ideal candidate will work collaboratively with Data Scientists, Data engineers, and Cloud Engineers to deploy and operate ML systems. You will help automate and streamline our ML operations and processes from discovery to deployment. You\u2019ll build and maintain tools for deployment, monitoring, and operations. You will also troubleshoot and resolve issues in development, testing, and production environments\nWe all have a critical role to play and add value. Here is how this role will help:\nBuild out our ML Ops platform in partnership with data scientists, data engineers, and cloud engineers\nOperate and maintain systems supporting the provisioning of new clients, applications, and features.\nSoftware deployment and configuration management in both QA and Production environments.\nCollaborate with Data Scientists and Data Engineers on product teams to containerize and build out deployment pipelines for new capabilities and services\nDesign, build and optimize applications containerization and orchestration with Docker and Kubernetes within a cloud environment\nAutomate applications and infrastructure deployments.\nSupport development, experimentation, verification\/validation and monitoring of AI\/ML models\nProduce build and deployment automation scripts to integrate between services\nBe a subject matter expert and an evangelist on DevOps practices, CI\/CD, Configuration Management and Cloud Computing Assess current level of maturity of the teams you are interacting with and prepare a technology adoption plan.\nContribute to a team culture that values effective collaboration, technical excellence, and innovation\nQualifications\nWe are highly people-focused \u2013 we look for professionals who are engaged, collaborative and excellent in execution. Leaders are expected to communicate effectively, develop teams and lead by example. Our industry and our function are changing rapidly so we are looking for new team members with a strong desire to develop themselves. You will be a great fit if you have:\nMinimum 5 years\u2019 post-academic experience working with cloud-base services and DevOps concepts, tools and practices\nExperience with the cloud computing platforms: AWS, GCP, Azure \nExperience in MLFlow, Kubeflow, Sagemaker, Vertex AI, or equivalent\nExperience with containerization using Docker and Singularity\nKnowledge and experience of machine learning frameworks: Tensorflow, Pytorch, or Keras\nExperience working in cross-functional Agile engineering teams\nProficiency with standard concepts and technologies used in CI\/CD build, deployment pipelines.\nExperience with pipeline automation tools, such as ArgoCD, Tekton, Gitlab CI\/CD, Jenkins\nExperience with scripting and coding using Python, R, Shell\nExperience with logging tools such as Splunk, ElasticSearch, Kibana, Logstash\nExperience with monitoring tools such as Prometheus, Grafana, AlertManager, PagerDuty\nBig data technical stack experience is a plus such as HDFS, Spark, Kafka\nExcellent Written and Verbal Communication Skills\nAbility to collaborate effectively with highly technical resources in a fast-paced environment\nAbility to solve complex challenges\/problems and rapidly deliver innovative solutions\nProficiency with feature stores, Graph databases, SQL, NoSQL, Data Lakes and other data storage technologies \nExperience with data visualization tools\nStrong overall software development approach. You deliver clean, well-tested code.\nAdditional Information\nWhat We Offer:\nFull Benefit Package (Medical, Dental & Vision) that starts the same day you do\n401k plan with company match, Profit Sharing & Retirement Savings Contribution \nPaid Vacation, 9 Paid Holidays, Maternity and Paternity Leave, Education Assistance, Wellness Programs, Corporate Discounts among others\nA culture that promotes work\/life balance, celebrates diversity and offers numerous family-oriented events throughout the year\nSyngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, marital or veteran status, disability, or any other legally protected status.\nFamily and Medical Leave Act (FMLA) \n(http:\/\/www.dol.gov\/whd\/regs\/compliance\/posters\/fmla.htm)\nEqual Employment Opportunity Commission's (EEOC)\n(http:\/\/webapps.dol.gov\/elaws\/firststep\/poster_direct.htm)\nEmployee Polygraph Protection Act (EPPA)\n(http:\/\/www.dol.gov\/whd\/regs\/compliance\/posters\/eppa.htm)\n        #LI-DO1\n ","8":"Company at a GlanceOpenX is focused on unleashing the full economic potential of digital media companies. We do this by making digital advertising markets and technologies that are designed to deliver optimal value to publishers and advertisers on every ad served across all screens.\nAt OpenX, we have built a team that is uniquely experienced in designing and operating high-scale ad marketplaces, and we are constantly on the lookout for thoughtful, creative executors who are as fascinated as we are about finding new ways to apply a blend of market design, technical innovation, operational excellence, and empathetic partner service to the frontiers of digital advertising.\nWith some of the best minds in adtech under our global roof, we bring industry-leading technology, a tradition of great service to our clients, and huge scale \u2014 across every format, from mobile to CTV. This allows us to build products that lead to greater reach for buyers and higher revenue for publishers \u2014 while solving some of the most intricate problems in digital marketing at large. That's the power of OpenX.\nAbout YouYou enjoy solving complex quantitative problems and are eager to work with tools and technologies that may be outside your comfort zone. You enjoy working in an open and collaborative environment. You are highly communicative, presenting relevant, concise, and empirically-driven information.You have the self-motivation to work independently but also know when to ask for help or guidance.You are highly driven but recognize when compromises are a more efficient solution.You are a dedicated software craftsperson who cares deeply about best practices and what it takes to write and maintain great code.\nKey Responsibilities\nDevelop, maintain, and monitor the infrastructure responsible for training and serving the Machine Learning models and scale it to support over 350 billion requests a day.\nMaintain ML model training at scale using infrastructure available on Google Cloud Platform\nCollaborate with engineers and scientists to deploy and serve our models at scale\nBuild monitoring tools that can provide real-time analysis of ML models in production\nSupport development teams and the data science team in building products based on machine learning.\nRequirements\nActively pursuing a BS or MS in Computer Science or a related major\nExperience with machine learning technologies such as PyTorch, TensorFlow, etc.\nExperience in serving a trained ML model\nExperience in using AWS, GCP, Azure, or other cloud platforms\nKnowledge of current principles and frameworks for ML Ops\nProficiency in Docker containerization or Kubernetes orchestration\nA willingness to learn new tools and deliver proof of concept implementations\nExcellent communication and the ability to collaborate with multiple teams \n#li-ac\nOpenX VALUESOur five company values form a solid bedrock serving to define us as a group and guide the company. Our values remind us that how we do things often matters as much as what we do.\nWE ARE ONEWe are one team. There are no exceptions. We are a group of strong and diverse individuals unified by a shared mission. We embrace challenges and win together as a team. We respect and care about our colleagues and cultivate an inclusive culture\nWE ARE CUSTOMER CENTRICWe innovate on behalf of our customers. We understand, respect, and listen carefully to our customers. We build great products to solve our customers\u2019 problems. We manage our customers\u2019 expectations clearly and honestly. We are a trusted partner to all of our customers - we act with integrity at all times. We care.\nOPENX IS OURSWe innovate on behalf of our customers. We understand, respect, and listen carefully to our customers. We build great products to solve our customers\u2019 problems. We manage our customers\u2019 expectations clearly and honestly. We are a trusted partner to all of our customers - we act with integrity at all times. We care.\nWE ARE AN OPEN BOOKWe understand and respect what each of us does. We are eager to teach and share what we know with others, both internally and externally. We are eager to learn from others and we ask questions internally and externally. \nWE EVOLVE FASTWe take responsible risks and own and learn from our mistakes. We recognize and repeat success. We actively seek out and provide constructive feedback. We adapt quickly and embrace change. We tackle growth and learning with real urgency. We are endlessly curious.\nOpenX is committed to equal employment opportunities. It is a fundamental principle at OpenX not to discriminate against employees or applicants for employment on any legally-recognized basis including, but not limited to: age, race, creed, color, religion, national origin, sexual orientation, sex, disability, predisposing genetic characteristics, genetic information, military or veteran status, marital status, gender identity\/transgender status, pregnancy, childbirth or related medical condition, and other protected characteristic as established by law.\nOpenX Applicant Privacy PolicyApplicants can review our Applicant Privacy Policy at any time by visiting the following link: https:\/\/www.openx.com\/privacy-center\/applicant-privacy-policy\/.\nEffective Date: March 1, 2022","9":"Fuel50 is growing rapidly, and we are seeking an experienced Machine Learning Operations (ML Ops) Engineer to join our team! As an ML Ops Engineer, you will be developing the Fuel50 SaaS application as part of the in-house development team using a range of technologies. You will be responsible for building, deploying, and maintaining machine learning models in production environments that power our platform. Working closely with data scientists, software engineers, and product managers you will ensure that our production machine-learning models are scalable, reliable, and performant. You will also be responsible for monitoring and troubleshooting models to ensure that they are meeting business requirements. This role requires a strong technical background in machine learning, software engineering, and DevOps.\nYou will be a champion of ML Ops best practices and provide technical and thought leadership to ensure that we follow industry best practices and develop solutions that are simple, scalable and achieve engineering excellence. Your exceptional communication skills will enable you to articulate challenges effectively to your team and to the wider engineering practice while working synergistically and efficiently in a cross-functional Agile environment with others to achieve shared objectives.\nThis role will be involved creating a world-class product with involvement in all aspects of the product lifecycle, from gathering requirements, brainstorming ideas, market analysis, and MVP definition, to building an MVP and working with your team to deliver the MVP into production.\nResponsibilities:\nManage the production machine learning systems that power our platform.\nBuild, deploy, and maintain new machine-learning models in production environments.\nCollaborate with data scientists and engineers to deploy and monitor machine learning models.\nWork closely with data scientists and software engineers to ensure scalable, reliable, and performant models.\nDevelop and maintain infrastructure for model training, testing, and deployment.\nCreate and manage data pipelines to ensure that models have access to high-quality data.\nImplement and maintain automated testing and deployment processes.\nMonitor and troubleshoot system performance and resolve issues as needed.\nMonitor and troubleshoot models to ensure that they are meeting business requirements.\nImplement and maintain continuous integration and continuous deployment (CI\/CD) pipelines.\nCollaborate with cross-functional teams to drive projects to completion.\nWillingness to learn and stay up to date with emerging trends and technologies in AI, ML Ops and DevOps.\nRequirements\nGraduate or post-graduate degree in Computer Science, Engineering, Mathematics, Statistics, Data Science, or a related field.\n3+ years of experience in software engineering or DevOps.\n2+ years of experience in machine learning or data science.\nExperience with containerization technologies such as Docker and Kubernetes.\nExperience with cloud computing platforms and tools such as Amazon Web Services (AWS), Terraform, Microsoft Azure, Google Cloud Platform (GCP), IBM Cloud and other similar technologies.\nFamiliarity with ML libraries such as TensorFlow, Keras, PyTorch, or Scikit-Learn.\nStrong programming skills in Python, Java, or another relevant language.\nKnowledge of data engineering and pipeline development.\nExcellent problem-solving, communication and collaboration skills.\nAbility to work independently and in a team environment.\nUnderstanding ML and data pipelines and management tools such as Apache Airflow or Databricks will be beneficial.\nAbout Fuel50\nFuel50 is an international, high-growth tech company. Our award-winning AI talent marketplace platform exists to improve the lives and careers of people everywhere by empowering forward-thinking companies to deploy career growth and talent mobility initiatives to attract and retain talent while boosting engagement and productivity. In other words, we are at the forefront of changing how people work and how organizations empower their people.\nOur tech is global and has touched careers across 100+ companies in 13+ languages and 25+ countries. Our clients are some of the biggest brands in their respective industries. And, most importantly, we practice what we preach and believe everyone should be in a job they love (including you!).\nFuel50 is immensely proud of our strong team culture, where our people (or \u201cFuellies\u201d) come first. Our vision and values are inclusive and transparent and built upon quarterly business objectives that drive our growth, encourage goal setting, and celebrate milestones every step of the way.\nThe Fuel50 vision has resonated with investors across NZ, Australia, UK, and the USA - supporting our global growth and helping us become the pioneers in this fast-growing talent space.\nWe are also a socially responsible company. We work with charities that help women and minority groups land on their feet through career coaching and support.\nBenefits\nThe chance to work in a fast growing organisation that supports global businesses to mobilize their talent and create high employee engagement and outstanding workplaces.\nOpportunity to use Fuel50 platform to understand and shape future career pathway.\nBe based at our unique and cool HQ in Takapuna, with coffee, snacks, pool, pingpong and pizza!\nChance to work on some innovative People & Culture solutions as part of the People Strategy.\nAs well as our day-to-day responsibilities, all Fuellies play an integral part in growing our culture with us and ensuring that Fuel50 remains an inspirational and amazing place to work. Some additional benefits are:\nDay off on your birthday, your Fuel50 anniversary and an annual companywide celebration day.\nRefuel days - a chance to take a day off once a quarter to rest, relax and refuel yourself.\nEmployee Stock Options Plan (ESOP).\nFlexible working times and remote working (as above) - we're very supportive of school commitments, traveling in off-peak hours, looking after the kids, and all that jazz.\nInvesting in you with career and development planning, using our very own Fuel50 software and online Fuellie University.\nA very progressive parental leave policy - get extra flexibility and time off on top of what your local government already mandates.\nFully subsidised medical insurance with Southern Cross.\nWhat is it like to be a Fuellie?\nWe know that having the right people with the right attitude and behaviour is a big part of what makes us successful. Living our values is an important part of being successful in this role.\nWe have a culture around continuous (but super friendly) feedback and recognition - be part of a family-like team that is working towards a common goal and helping each other every step of the way.\nWe have #SuperheroAwards at every quarterly sprint meeting and every weekly team meeting includes spontaneous recognition and shout-outs across the business.\nWe'll have your back when you need help - your colleagues want to see you succeed and work hard to help you do so.\nWe work hard and deliver amazing results to our clients - when you see our amazing feedback, you'll be proud to be a Fuellie.\nApplication Process\nIf this sounds like you, then please apply. If you\u2019re not sure you're ready or perhaps you don't meet all requirements yet, please apply anyway. We'll review every application that we get.\nThis role is based in New Zealand, as a result candidates must hold the relevant right to work in NZ i.e. Citizenship or a work visa at time of application.","10":"Company Description\nAbout us and our team\nDoes working at one of Europe\u2019s largest fin-tech companies sound interesting to you? Are you keen to join a rapidly growing team, in an international environment where you\u2019ll get tons of opportunities to develop yourself, and collaborate with colleagues from all over Europe? If so, you are in the right place!\n\nNets is part of the Nexi group. As a group, we come from the merger and integration of Nexi, Nets and Sia; with a presence in more than 25 countries, more than 10,000 employees across Europe and experience on the market for more than 80 years. We provide limitless growth opportunities for our employees.\nJob Description\nWhy join us in 2023?\nJust think of all the virtual shopping platforms, online stores, digital wallets, QR code payments and the contactless payment technology that stands behind them; this is all technology we use daily, the technology that will mark our future. By joining our team, you will be shaping the future of digital banking with us, working in a modern, innovative, and ever-changing environment. As we come from the merger of numerous companies globally, the opportunity to grow, learn and share expertise with colleagues across the whole organization, is enormous.\n\nIf you join us in the role of Team Lead & Product Owner, this is what you can expect from us:\nAttractive salary and an overall good package\nWell-structured training for the job and constant support from your manager\nHybrid way of working\nFlexible work hours\nEquipment needed for the role (laptop and mobile phone, including monthly mobile phone subscription)\nGroup life and health insurance\nFull time illness and accident insurance\nReferral bonuses for recommending new team members to join the company\n\nAbout your future role\nAre you a data value proposition enthusiast?\n\nThen take this opportunity at Nets as a Team lead and product owner in one of the biggest payment companies in the fintech domain across Europe.\nAs Team lead and product owner, you will be part of a newly established team of data engineers managing and operating data products across our Issuing solutions, taking ownership of the team\u2019s successes and failures and contributing to securing the operations of data products for our customers.\nYou will be powering Data & Insights department, with key responsibility to be the focal point between product management and technology. This means owning the backlog, facilitating the creation of features and stories, participating in PI planning, ensuring the delivery of prioritized stories and performing reviews. \nWorking location can be wither Oslo or Copenhagen.\nOur data platform includes Informatica, Oracle, Cloudera Hadoop data lake, Talend and Automic, with SAP business objects & Power BI for self-service reporting and dashboards.\nYou will be a vital part of Data Productivity in Issuer solutions, and your key responsibilities in this role will be:\nOwn, maintain and further develop our data products and reporting solutions\nOperations, monitoring and securing our data flows and data deliveries to customers\nIdentifying weak spots in the data flows and implementing continuous improvements to secure our data products for the future\nQualifications\nWhat makes you the best person for this job?\nNow when you read about the role, are you curious to discover more? If your answer is yes, check what qualifications make you the right candidate to apply. But keep in mind one thing - on top of your skillset, knowledge and experience, it's your potential that makes a difference for you to achieve your goals in everyday work.\nWe are in the process of establishing an agile team and best practices around data operations.  To do this, we are looking for a person who is a leader, team builder, learner, motivator, committed, analytical and structured. \n\nQualifications needed to be successful in this role:\nYou have a solution-oriented and analytical mindset, and you thrive working with complex end-to-end solutions and processes.\nYou are a team-oriented person with good communication skills.\nOpen to new ideas, approaches, opportunities, and environments with the ability to handle multiple tasks and meet deadlines.\nVerbal and written communication skills in English are necessary, as our business language is English.\nVerbal knowledge of Norwegian, Danish, or Finnish in a work context will be an advantage for our team.\n3+ years of experience engaging with business stakeholders to understand their business requirements.\nYou have working experience with some of these technologies and tools:\nSQL and RDBMS like Oracle, SQL server\nInformatica Power Center\nSAP Business Objects reporting tools\nBig Data technologies including Apache Hive, Apache Spark, Hbase, Sqoop etc.\nPower BI & SQL Server Analysis Services\nExperience from the financial industry is beneficial but not a pre-requisite.\nAdditional Information\nApply now!\nBy simplifying payments and enabling people and businesses to build closer relationships and grow together, we bring change to the lives of everyone around us. Joining us means becoming part of the international team that actively creates an easier tomorrow for every citizen, bank, and business. By reading about this job opening, you are one step closer to getting there.\n\nIf this is the right job for you, we would love to hear from you! Please apply as soon as possible. We will review all applications ongoing and close the position as soon as a new team member has been found.\n\nIf you are curious about working with us, but feel this is not the right role for you at this time, please join one of our communities following this link, so that we can stay in touch for future job openings. We look forward to getting to know you!","11":"Reddit is a community of communities where people can dive into anything through experiences built around their interests, hobbies, and passions. Our mission is to bring community, belonging, and empowerment to everyone in the world. Reddit users submit, vote, and comment on content, stories, and discussions about the topics they care about the most. From pets to parenting, there\u2019s a community for everybody on Reddit and with over 50 million daily active users, it is home to the most open and authentic conversations on the internet. For more information, visit redditinc.com.\n\u201cThe front page of the internet,\" Reddit brings over 430 million people together each month through their common interests, inviting them to share, vote, comment, and create across thousands of communities. \nThe Machine Learning Platform team at Reddit is a high impact team that owns the infrastructure that powers recommendations, content discovery, user and content quantification, while directly impacting other teams such as Growth, Ads, Feeds, and Core Machine Learning teams.\nHow You'll Have Impact:\nAs the 6th largest site on the internet, Reddit generates billions of events and terabytes of data in a day. You will own projects from ideation to production instead of being stuck making small incremental gains on enterprise systems. We are looking for the best and the brightest Machine Learning Platform Engineers to join us in solving hard problems in order to enable products that millions of users will love, and ultimately bring community and belonging to Reddit\u2019s users. We are a team of builders that value impact, personal growth, openness and kindness.\nWhat You\u2019ll Do\nYou will be instrumental in architecting, implementing, and maintaining foundational Machine Learning (ML) infrastructure that powers Feeds Ranking, Content Understanding, Recommendations and much more to fulfill Reddit\u2019s mission of bringing community and belonging to everyone in the world. You will build systems and tools that enable machine learning engineers (MLEs) and data scientists (DSs) and continuously improve the ML software development lifecycle.  You will deliver a self service ML platform that enables the continuous iteration and improvement of systems that use ML techniques including Deep Learning, Natural Language Processing, Recommendation Systems, Representation Learning and Computer Vision.\nResponsibilities:\nProvide technical leadership through engineering lifecycle \nServe as top escalation point to resolve complex technical issues \nIdentify and lead strategic initiatives to advance the ML infrastructure at Reddit\nGuide other engineers in resolving complex technical designs \nBe the go-to expert in the design and building the high-performance ML platform solutions that address bottlenecks in the model development lifecycle\nCollaborate with other teams and translate requirements into reliable, scalable platform solutions\nSet high-standards for a rigorous DevOps approach to maintain and\/or improve ML platform components and services health and quality\nRequirements:\n7+ years of work experience in software development and ML or data infrastructure\n5+ years of experience building production-quality code incorporating testing, evaluation, and monitoring using object oriented programming, e.g. Python, Scala, etc.\n2+ years acting as leader and architect in the computation and data storage domains to evolve and refine ML infrastructure\nAbility to lead, coach, and mentor other engineers \nSuperior organizational skills and cross-functional collaboration\nSuperior communication skills\nPluses:\nExpert on relevant technology stack, e.g. Go, Python, AWS, GCP, Kubernetes, Kubeflow, Airflow, and Ray\nExperience designing and developing applications using large-scale data stack, e.g, BigQuery, GraphQL, Kafka, Flink, Cassandra, Redis\nExperience is recommendation, search engines, or content classification systems\nInterest in advancing infrastructure for Deep Learning, NLP, or Computer Vision\nInterest in open source development and working with applied researchers in the advancement of ML Systems\nBenefits: \nComprehensive Health benefits\n401k Matching \nWorkspace benefits for your home office\nPersonal & Professional development funds\nFamily Planning Support\nFlexible Vacation & Reddit Global Days Off\n4+ months paid Parental Leave  \nPaid Volunteer time off\nPay Transparency:\nThis job posting may span more than one career level.\nIn addition to base salary, this job is eligible to receive equity in the form of restricted stock units, and depending on the position offered, it may also be eligible to receive a commission. Additionally, Reddit offers a wide range of benefits to U.S.-based employees, including medical, dental, and vision insurance, 401(k) program with employer match, generous time off for vacation, and parental leave. To learn more, please visit https:\/\/www.redditinc.com\/careers\/.\nTo provide greater transparency to candidates, we share base pay ranges for all US-based job postings regardless of state. We set standard base pay ranges for all roles based on function, level, and country location, benchmarked against similar stage growth companies. Final offer amounts are determined by multiple factors including, skills, depth of work experience and relevant licenses\/credentials, and may vary from the amounts listed below.\nThe base pay range for this position is: $198,200 - $297,300.\n#LI-SV1\n#LI-Remote\nReddit is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, please contact us at ApplicationAssistance@Reddit.com.","12":"The health insurance and benefits industry is undergoing rapid digital transformation. Today, most people choose, enroll, and utilize their benefits not by calling insurance carriers or reviewing paper forms, but by using HR and benefits software. Behind the scenes, Ideon\u2019s APIs make this modern benefits experience possible. We\u2019re powering an entire industry forward, delivering the speed, transparency, and efficiency that today\u2019s consumers expect.\nThe Network Operations team uses our in-house technology to support the aggregation, ingestion, and production of our Provider Network Data Sets. Our Data Coordinators are responsible for the accuracy, completeness, and timeliness of Ideon\u2019s healthcare provider data and for enhancing the value of data by increasing the breadth and depth of the dataset. Additionally, by collaborating on new tooling and workflows, you have the opportunity to engage in creating foundational building blocks used to grow this company. Our team\u2019s culture is one of curiosity, collaboration, and growth and we sit uniquely at the intersection of technical and business teams in order to drive results.\nFor this role, we are open to remote candidates anywhere in the U.S. Ideon is headquartered in NYC with a second office in Omaha, NE. This role reports to the Director of Data Operations.\nIn this role you will:\nHelp maintain standards for data integrity and quality assurance\nCreate and maintain data acquisition processes, keeping quality and scalability in mind\nWork with internal and external data partners to acquire and maintain datasets\nIdentify and implement changes to managed data elements, creating\/managing top-notch documentation along the way\nIdentify gaps in the current dataset and determine the steps to fill them\nWe would love to hear from you if you:\nHave 1+ years experience working with large datasets (think >1 million rows!)\nHave an eye for detail and exceptional critical thinking skills\nHave intermediate experience with MS Excel, including filtering, formatting, and utilizing basic functions and formulas\nHave a desire to increase your data analysis skills using tools such as SQL and\/or Tableau\nHave experience in the Healthcare\/Insurance industries (not a must, but a plus!)\nHave project management experience (not a must, but a plus!)\nSalary Range: $24 - $28\/hr\nAbout Ideon\nWhat we do:Ideon is the way health insurance carriers and employee benefits providers connect with new technology partners to deliver seamless consumer experiences at every stage of the member journey. We are not the websites or apps you use to choose a plan or find a doctor. We are the infrastructure, the \u2018pipes,\u2019 that allows InsurTech platforms and health insurance and benefits carriers to exchange data accurately, efficiently, securely, and at scale\u2014improving the way benefits are quoted, sold, enrolled, managed, and utilized. Our APIs transmit billions of data points, powering an amazing benefits experience for all. Faster. Better. Awesomely.\nWho we are:We are a group of people who love a good API and all it can do. We are insurance geeks, systems gurus, data wonks, sales & marketing execs, product leads, finance whizzes, and admin pros\u2014all determined to bring efficiency, transparency, and connectivity to the health insurance and benefits industry.\nOur benefits include:- 100% company-paid medical and dental for you and your dependents.- Healthcare and dependent care FSA (Flexible Spending Account).- 401(k) with company matching and immediate vesting.- Flexible PTO policy: take time off without worrying about accruals or carryovers.- Pre-tax commuting benefits.- Home office allowance so you can work comfortably wherever you are.\nWe are an equal opportunity employer. We encourage  people of different backgrounds, experiences, abilities and perspectives to apply. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status.\nAll offers of employment are contingent upon successful reference and background checks.","13":"Company Description\nWe\u2019re the world\u2019s leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business.\nJob Description\n\nAs a Sport Data Operator you will work with data journalists all over the world turning sporting events into the highest quality sports data. You will monitor various sports across the globe and are responsible for the overall coverage quality.\n\nWhether football, basketball, rugby or F1, our global Data Monitoring team ensures seamless data collection of more than 20 sports via our tailor-made systems that guarantee a fast and accurate data entry.\nYour profile\nYou talk sports and have a large Sporting knowledge and interest.\nIt\u2019s a great start if You know who won the last Champions League final or the recent Grand Slam tournament.\nThere is some tech geek in you and you like working with new technologies.\nYou tackle challenges with ease and will easily adapt to working with different teams and nationalities.\nGood English both written and oral, any other language is an advantage.\nBasic understanding of the betting world is a plus.\nFlexibility to work around the sporting calendar (we work when sport happens).\nCareer path and self-development\nLaunching or building a career in sports and betting industry\nOn-site training team to ensure a smooth onboarding\nInternational recognition for your skills\nPossibility to work with innovative in-house technology\nCompetent hands-on managers\nCourses via our eAcademy\nWork environment\nSports 24\/7: live footage TV's streaming the world's biggest events\nHigh-end workstations with 3-4 monitors\nFree drinks in the office\nFruit Wednesdays\nWeekend lunches\nCompany benefits to support your well-being\nReferral bonus to extend the team\nCompany events and fun with your colleagues at free basketball or soccer practice\nThis is your chance to be more than a fan, a real player in the sports industry!\nAdditional Information\nSportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences ","14":"Company Description\nWe\u2019re the world\u2019s leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business.\nJob Description\n\nOVERVIEW:\nAccuracy is key within the Production team at Sportradar. In order to realize high-quality products, we are seeking applicants who contribute within our successful team of professional and highly motivated employees. You will be responsible to maintain the data collection and guarantee the highest quality.\nTHE CHALLENGE:\nResearch and verify fixture content for all Sportradar products and platforms\nMatch creation during ongoing tournaments \/ events\nPost-match Result confirmation (Resulting)\nSports data research\nOutright Resulting\nCommunication with global scout and freelancer network\nCreativity and innovation throughout the daily business\nYOUR PROFILE:\nHave a high interest and knowledge in a variety of sports\nWillingness to work in shifts (we work when sports happens)\nAccuracy and focusing within all working processes\nHigh routine and pressure tolerance\nGood computer skills\nGood English both written and oral\nHighly self-motivated, leading by example and enthusiasm\nA team player, with the ability to work with new teams immediately\nFlexibility to adapt to changing priorities as well as product environments and able to work to tight deadlines\nOUR OFFER:\nBe part of one of the fastest-growing digital sports companies in the world at the intersection of sports, media, and video\nWork together with an international team of highly motivated and enthusiastic people\nExciting job field with the opportunity for personal development\nEducation and training, like German and English courses and Sportradar eAcademy\nAs much flexibility as working in shifts allows\nPossibility of reimbursement for childcare\nHealth Care, company pension scheme and 24 days paid holidays\nComplimentary fresh fruit and coffee in the office\nTeam activities, like summer party and Christmas party\nAdditional Information\nSportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences ","15":"Binance is the global blockchain company behind the world\u2019s largest digital asset exchange by trading volume and users, serving a greater mission to accelerate cryptocurrency adoption and increase the freedom of money.\nAre you looking to be a part of the most influential company in the blockchain industry and contribute to the crypto-currency revolution that is changing the world?\nAbout Binance Accelerator Programme Binance Accelerator Programme is a concise 3 - 6 months programme designed to have an immersive experience in the rapidly expanding Web3 space.  You will be given the opportunity to experience life at Binance and understand what goes on behind the scenes of the worlds\u2019 leading blockchain ecosystem. Alongside your job, there will also be a focus on networking and development, which will expand your professional network and build transferable skills to propel you forward in your career. \nWho may applyCurrent students, fresh graduates, and candidates who are mid-career switchers.\nData driven based business is the core in helping  to use cloud native platform to serve tens of millions of crypto-currency users. Engineers and Data Scientists across the company use the data platform to do interesting and impactful analysis for continuous innovations.\nAs a data scientist, you will have the opportunity to leverage rich data (PB-level scalability) and state-of-art machine learning infrastructure to develop data products which are used by our tens of millions of crypto-currency users.\nYou will collaborate with a strong team of engineers, data analysts, business operation and product\/marketing managers to define and build solutions, features, algorithms and products based off our rich data and cutting-edge machine learning technology.\nResponsibilities:\nFacilitate data collection that will allow the identification of crypto address owners\nWork closely with the Data Science team, who will guide your data collection strategy\nRequirements:\nExperience in making transactions on the blockchain\nBroad understanding of blockchain technology and existing ecosystem\nExperience in investigation of blockchain cyber crimes is plus\nKnowledge of DeFi ecosystem (DEX, Lending Platform, etc) is plus","16":"Company Description\nWe are Flink - your online supermarket revolutionizing the way you do your grocery shopping. With a wide selection of over 2,400 high-quality products, we aim to deliver to your door in minutes. We put our customers first and ensure all products delivered are fresh and nutritious. Additionally, we can customize our national assortment to be able to offer you unique local products in every city. Our delivery hubs are located in densely populated inner-city locations and we strive to be sustainable by delivering on electric bikes and using packaging that can be recycled.\nIf you want to be part of this exciting journey\u2026 read on!\nJob Description\nYou take care of tasks arising in the operative day-to-day business on your own responsibility\nYou support individual teams and employees in the area of Supply Chain, ERP & Finance Systems and take on various special tasks\nYou monitor compliance with various processes and proactively look for improvement opportunities\nYou work together with various teams to optimize our processes, support the development of solutions and prepare process documentation\nQualifications\nYou are detail oriented\nBusiness professional English and German - French is a big plus \nWorking to strict timelines is nothing new to you \nGood understanding for IT systems, workflows \nYou are systematic and organized\nAdditional Information\nA \u20ac1000 annual L&D budget as well as individual coaching options to ensure you have plenty of opportunities to learn, grow and achieve your goals\n26 days of vacation, +1 day every year up to a maximum of 30 days\nA mobility budget of 30 EUR per month with RYDES, which you can use individually for Uber, BVG and many other providers \nA cool discount on your Urban Sports Club membership\nAttractive company pension options\nUnlimited access to an e-learning and development platform, MyAcademy, including online German courses\nOnline discounts with Corporate Benefits and Future Bens\nA cool discount off your personal Flink orders; be the first to test out new products!\nA modern and dog-friendly office in the heart of Berlin - lots of delicious lunch spots available within short walking distance\n  We pride ourselves in being an inclusive and equal opportunities employer with a diverse and multicultural team. It is our commitment that every applicant will be evaluated according to their skills regardless of age, gender identity, ethnicity, sexual orientation, disability status, or religion.","17":"Who we are \nTractable is an Artificial Intelligence company bringing the speed and insight of Applied AI to visual assessment. Trained on millions of data points, our AI-powered solutions connect everyone involved in insurance, repairs, and sales of homes and cars \u2013 helping people work faster and smarter, while reducing friction and waste.\nFounded in 2014, Tractable is now the AI tool of choice for world-leading insurance and automotive companies. Our solutions unlock the potential of Applied AI to transform the whole recovery ecosystem, from assessing damage and accelerating claims and repairs to recycling parts. They help make response to recovery up to ten times faster \u2013 even after full-scale disasters like floods and hurricanes. \nTractable has a world-class culture, backed up by our team, who have rated us 4.9\/5 on Glassdoor, making us a global employer of choice!\nWe're a diverse team, uniting individuals of over 40 different nationalities and from varied backgrounds, with machine learning researchers and motor engineers collaborating together on a daily basis. We empower each team member to have tangible impact and grow their own scope by intentionally building a culture centred around collaboration, transparency, autonomy and continuous learning.\n About Tractable\nTractable is an Artificial Intelligence company bringing the speed and insight of Applied AI to visual assessment. Trained on millions of data points, our AI-powered solutions connect everyone involved in insurance, repairs, and sales of homes and cars \u2013 helping people work faster and smarter, while reducing friction and waste.\n  Founded in 2014, Tractable is now the AI tool of choice for world-leading insurance and automotive companies. Our solutions unlock the potential of Applied AI to transform the whole recovery ecosystem, from assessing damage and accelerating claims and repairs to recycling parts. They help make response to recovery up to ten times faster \u2013 even after full-scale disasters like floods and hurricanes. \n  We're a diverse team, uniting individuals of over 40 different nationalities and from varied backgrounds, with machine learning researchers and motor engineers collaborating together on a daily basis. We empower each team member to have tangible impact and grow their own scope by intentionally building a culture centred around collaboration, transparency, autonomy and continuous learning.\n  What you will do\n  The MLOps team belongs to a larger group - Platform Engineering, which is focused on building tools and services for our internal customers within Tractable: researchers, product engineers, ops specialists, etc. We have several teams in the Platforms group tackling different aspects of the space including Infrastructure, Business Intelligence, Data Platform, Dev tools and engineering efficiency, MLOps. As a ML OPS Engineer on the MLOps team, you will be collaborating with the fellow Platform and Research teams. \n  We are looking for an MLOps Engineer to build and support systems that enable the core mission of Tractable - to make applied AI possible - by optimising the end-to-end Machine Learning life cycle. The vision of the MLOps team is to enable researchers to spend 80%+ of their time solving tricky ML problems rather than dealing with engineering\/infra\/ops challenges. \n  You'll play a key role in developing our MLOps platform from pretty much ground up, as part of a bigger Platforms group. You will influence the scope and technical direction as well as champion best practices within the team. You have a relentless focus on user experience (Researchers and Data Scientists in this case) and you care deeply about what your team is building to make sure it will have the biggest impact on your users. You will be a strong mentor, nurturing an encouraging and supportive environment to enable the team to do their best work.\n  The role: \nYou'll play a key role in developing our MLOps platform from ground up, as part of a small but high-performing team. You will influence the scope and technical direction as well as champion best practices within the team. You will continuously pursue clean code practices and contribute towards overall platform architecture collaborating with our other Engineering and Product team. \nYou will be:\nWorking with engineers and data scientists to build the next generation of MLOps platform in Tractable\nBuilding various platform capabilities in the Machine Learning lifecycle to massively speed up efficiency in bringing research to production. From dataset management, model training to monitoring models performance in production\nSolving lots of scalability problems in both model training and model serving in production\nAdopting open-source technologies to best leverage our in-house resources\nPromoting engineering best practices throughout the team\nSuggesting, collecting and synthesising requirements and creating effective feature roadmap with Product Manager\nTech Stack:\nWe rely heavily on the following tools and technologies below \u2013 but we are likely to explore new technologies \/ frameworks as we are building the platform from ground up hence you don't need to have prior experience in all of them. We\u2019re just keen to know that you're willing to break things, fix things, learn fast and carry on building a great team that is capable of building awesome platforms customers love! \nMain Infrastructure: AWS (EC2, S3, MSK, Lambda, StepFunctions, Glue, IAM, Cognito, Systems Manager, CloudWatch, SQS, Route 53, Sagemaker), Apache Kafka (AWS MSK), Kubernetes, Datadog (Metrics, Logs, Synthetics), Pagerduty\nMain CI\/CD: Terraform, Docker, Harness\nMain Databases: Postgres \/ RDS, Redis, DynamoDB\nMain Languages: Python, Node + Typescript\nMain ML stack:  Triton, TFServing, KServe\nWe encourage you to drop us a line even if you don\u2019t have all the points above. That\u2019s a lot of different areas of responsibility! We will help you pick them up because we believe that great people come from all walks of life.\n  What you need to be successful:\nA strong ML Engineer who is passionate about building platforms to massively reduce lead time from bringing Machine Learning research to production. You would have a solid background in software engineering as well as a good understanding of the difficulties faced by data scientists. A few things we are particularly interested in seeing from you:\nGreat communication skills and collaborative mindset\n1 year of experience in building scalable Machine Learning Platforms. Experience working with open source ML frameworks such as MLFlow \/ Kubeflow would be a plus.\nStrong programming experience, from self-contained algorithms to complex object modelling design\nWorked with Python in a professional environment for 2+ years\nCares about team practices \/ pairing \/ advocate of CICD\nExperience in building Data Pipelines\nBonus for: Experience working with GPUs \/ Tensorflow\nBonus for: distributed system experience\nBonus for: basic ML knowledge\nBonus if you have trained a few deep learning models\n What\u2019s in it for you\nCompetitive salary\n6 month salary reviews\nVisa sponsorship (if required)\nEquity\nPension scheme\nBupa private healthcare (full coverage)\nFlexible hours & WFH\/hybrid setups \nLearning and Development budget\nCompetitive maternity + paternity leave\nDaily office snacks & soft drinks \nRegular company office events such as Games Nights, Movie Nights, Lunch & Learns, Monthly Brunch and more\nDiversity commitment\nAt Tractable, we are committed to building a diverse team and inclusive workplace where people\u2019s varied backgrounds and experiences are valued and recognised. \nWe encourage applications from candidates of all backgrounds and offer equal opportunities without discrimination.\n#LI-HM1\nDiversity commitment\nAt Tractable, we are committed to building a diverse team and inclusive workplace where people\u2019s varied backgrounds and experiences are valued and recognised. \nWe encourage applications from candidates of all backgrounds and offer equal opportunities without discrimination.","18":"Job Description\nAbout This Role\nYou will ensure master data and reference data availability for daily commercial operations and business initiatives for the supported affiliates including but not limited to processing requests , data quality, ensuring alignment of data among tools, business users support, testing.\nWhat you will do\ncoordinatie withing the team the daily processing of healthcare related Data Change Requests coming from different sources (identification and solving complex issues, preparation and deliver bulk updates, monitor auto-rejected DCRs)\ncoordinate the effort to get the primary affiliation flag in place. Analyze healthcare related data and maximize Orange records by finding the applicable pairs of respective records and run match and merge process for them.\ndesign and deliver data quality reporting for the affiliate in healtcare master data and reference data area (periodic DQ checks, provide insight into data quality issues, ensure data alignment between Open Data, MDM and CRM systems and other applicable systems and apps.\nprovide expertise and coordinate delivery of the tasks to Business Stakeholders regarding master data, reference data, their presence and usage in CRM system\nprovide expertise with Support business users with CRM reports delivery incl desing and development of reports for multiple countries and locations considering local differences.  Drive cooperation within the team and Business Users in healthcare data questions and issues resolution.\ncoordinate the testing, adoption and roll-out of new systems\/system releases. Develop and analyse error reports and data for the purpose of testing, integrating, and connecting new systems\/system releases. Transfer knowledge and carry out new system\/system release trainings including reporting, reviewing and taking actions to solve the issues, identifying training needs, etc. for rejected and auto-rejected DCRs.\npropose and socialize requirements to governance processes. Develop and implement data policies and procedures. Act as gatekeeper for local healthacare master data governance process. Ensure that the Customer Master Data Management policies and procedures are implemented and complied with.\nQualifications\nRequired skills\nEducation or strong interest in data analysis or data management related function\n1 year experience in data management would be an advantage\n1 year experience in MS Office (Excel, Office, Power Point)\nUnderstanding of CRM system, Business Intelligence concept and solutions.\nCRM or data base experience is a strong plus: Salesforce or Veeva preferred\nLogical thinking capabilities with strong focus on details and data quality.\nBasic knowledge of data management, data governance, data structures, data analysis.\nEnglish - good level is a must,\nGerman language would be a great asset, any other European language is a plus\nAdditional Information\nJoin our Global Business Services Center in Poland!\nThe vision of GBS at Biogen is to be recognized as a world-class Global Business Services organization driven by the desire for excellence in its people, business solutions, execution and partnerships with internal and external customers.\nWe offer:\nRole in a dynamic and one of the oldest biotechnology company in the world \nCompany mission you can be really proud of\nWork with diverse and knowledgeable multinational teams\nOpportunities to learn and grow with GBS site in Poland\nStructured onboarding program\nCustomized benefit package, e.g. MyBenefits cafeteria, annual bonus eligibility, medical care, hybrid work\nMore details: https:\/\/www.biogen.com\/en_us\/careers.html\nWhy Biogen?\nOur mission to find therapies for neurological and rare diseases is a unique focus within our industry and this shared purpose is what connects us as a team. We work together to overcome obstacles and to follow the science. We are resilient as we strive to make an impact on our patients\u2019 lives and on changing the course of medicine. Together, we pioneer. Together, we thrive.\nAt Biogen, we are committed to building on our culture of inclusion and belonging that reflects the communities where we operate and the patients we serve. We know that diverse backgrounds, cultures, and perspectives make us a stronger and more innovative company, and we are focused on building teams where every employee feels empowered and inspired. Read on to learn more about our DE&I efforts","19":"Company Description\nSnke OS\u2122 is a universally deployable digital B2B platform, founded in 2020 & headquartered in Munich. Emerging technologies continue to drive a digital transformation in the healthcare economy. Our founders recognized the potential for value creation by decoupling & deploying their best-in-class platform & team so that other companies can scale up & innovate efficiently. Fueled by AI & big data analytics, Snke OS delivers the platform & infrastructure that enables partners across the healthcare industry to deploy digital solutions for safer & more efficient interventions.\n\nThe 150-person Snke OS team brings a wealth of experience to the new company with backgrounds in large platforms, digital health & software-driven medical technology. Let\u2019s impact the industry together! We are looking for pioneers to lead fast & lead first with Snke OS.\nJob Description\nFor our ambitious and growing Data Intelligence department, we are looking for a machine learning platform engineer with a strong background in building state-of-the-art MLOps infrastructure.\nIn this position, you will\nShape the development and productization of AI-based solutions for medical use-cases\nDesign, build, and maintain systems to enable complex development workflows throughout the machine learning life cycle (from data processing to experimentation, model training, and ultimately deployment of solutions)\nSet up and operate complex computing environments based on local and cloud resources, using modern DevOps \/ MLOps techniques\nWork closely with our machine learning engineers to establish new standards in development efficiency, automation, and reproducibility\nSet up processing pipelines to make complex medical data accessible in the best possible way\nQualifications\nEducation in Computer Science, natural sciences, or similar background\nDemonstrated experience in designing complex computing environments based on Linux and ideally Windows, including solid understanding of networking, storage, and authentication concepts as well as infrastructure-as-code technologies\nProven experience setting up and maintaining container orchestration tools (in particular Kubernetes) and container management.\nGood knowledge in the setup and operation of cloud-based computing environments (ideally AWS)\nSolid programming experience in Python; C++ is a plus\nGood understanding of the success factors for modern software development (ideally in the context of machine learning) and a strong agile DevOps mindset\nBroad knowledge of the ML\/DL development process and data pipelines\nFluent in English, German is a plus\nAdditional Information\nCentrally located, modern work spaces\n30 days of vacation plus 24.12. and 31.12.\nFlexible working hours as well as hybrid work model within Germany\nSecure bicycle storage room\nRegular after-work, team & company events\nGreat 212m\u00b2 roof terrace\nInternational team of supportive colleagues\nComprehensive training and continuing education opportunities\nInterested? Then we are looking forward to receiving your online application!\nContact person: Daniel Sypli","20":"Who we are \nTractable is an Artificial Intelligence company bringing the speed and insight of Applied AI to visual assessment. Trained on millions of data points, our AI-powered solutions connect everyone involved in insurance, repairs, and sales of homes and cars \u2013 helping people work faster and smarter, while reducing friction and waste.\nFounded in 2014, Tractable is now the AI tool of choice for world-leading insurance and automotive companies. Our solutions unlock the potential of Applied AI to transform the whole recovery ecosystem, from assessing damage and accelerating claims and repairs to recycling parts. They help make response to recovery up to ten times faster \u2013 even after full-scale disasters like floods and hurricanes. \nTractable has a world-class culture, backed up by our team, who have rated us 4.9\/5 on Glassdoor, making us a global employer of choice!\nWe're a diverse team, uniting individuals of over 40 different nationalities and from varied backgrounds, with machine learning researchers and motor engineers collaborating together on a daily basis. We empower each team member to have tangible impact and grow their own scope by intentionally building a culture centred around collaboration, transparency, autonomy and continuous learning.\n What you will do\nThe MLOps team belongs to a larger group - Platform Engineering, which is focused on building tools and services for our internal customers within Tractable: AI researchers, data scientists, product engineers, operations specialists, etc. We have several teams in the Platforms group tackling different aspects of the space including Infrastructure, Business Intelligence, Data Platform, Dev tools and engineering efficiency, MLOps. As an Engineering Manager on the MLOps team, you will be collaborating with the fellow Platform teams. \nWe are looking for an experienced Engineering Manager to build and support a team of extremely talented MLOps engineers. This team enables the core mission of Tractable - to make applied AI possible - by optimising the end-to-end Machine Learning life cycle. The goal of the MLOps team is to enable researchers to spend 80%+ of their time solving tricky ML problems rather than dealing with engineering\/infra\/ops challenges. \nYou'll play a key role in developing our MLOps platform from pretty much ground up. You will influence the scope and technical direction as well as champion best practices within the team. You have a relentless focus on user experience (Researchers and Data Scientists in this case) and you care deeply about what your team is building to make sure it will have the biggest impact on your users. You will be a strong mentor, nurturing an encouraging and supportive environment to enable the team to do their best work.\nYou will be:\nPlaying a pivotal role in building and shaping the vision of our machine learning platform and infrastructure\nGrowing and scaling a team of best-in-class Machine Learning Engineers \nIntroducing and driving best practices into the team\nHelping your team define the technical architecture of the machine learning platform\nManaging a team of Engineers and being responsible for their career growth and execution of the roadmap\nMentoring more junior members of the team and provide technical guidance\nReviewing design and architecture proposals on your team, giving feedback and advising on best practices.\nYou are an ideal candidate if you are interested in a leadership role because it allows you to work closely with others to help them achieve their best. Ideally, you have led teams of more than three people and are looking for an opportunity to take on more responsibility and lead a larger team\nWhat you need to be successful:\n2+ years of experience in supporting teams building and maintaining scalable Machine Learning Platforms. We don\u2019t expect you to write code in this role but in order to be successful, prior hands-on experience with Data\/ML engineering is key. Bonus if you have trained a few deep learning models! \nYou\u2019ve seen several examples of various ML Platforms over the course of your career, you know what a successful ML Platform looks like, what works in production, where typical pitfalls are; you\u2019re familiar with the AI infrastructure landscape and what vendors are out there, so you can make an informed build vs. buy decision.\nExceptional communication skills and collaborative mindset. You will be working closely with your customers - researchers and data scientists - and making sure the tools your team is building are user friendly and tackle the unmet needs of your customers.\nHave empathy towards your customers and product sense. As a manager in the Platforms group, you are excited about wearing the PM hat and think about ML Platform as a product. You enjoy working alongside other managers to craft a shared vision and roadmap for your team.\nThe ability to plan and track timelines for your team, ensuring efficient execution and communicating to relevant partners when things change.\nBe able to have technical conversations with your team about the design\/system architecture and help your team think through trade-offs (distributed system experience is a plus!). Ability to advocate for best practices in the engineering\/MLOps space.\nBe able to  build a high performing team with emphasis on team health and psychological safety.\nHave experience with building hiring processes for your team, ability to work closely with your talent acquisition\/people ops partners to attract and retain amazing talent from a diverse set of backgrounds\nWe rely heavily on the following tools and technologies below \u2013 but we are likely to explore new technologies \/ frameworks as we are building the platform from ground up hence you don't need to have prior experience in all of them. We\u2019re just keen to know that you're willing to break things, fix things, learn fast and carry on building a great team that is capable of building awesome platforms customers love! \nMain Infrastructure: AWS (EC2, S3, MSK, Lambda, StepFunctions, Glue, IAM, Cognito, Systems Manager, CloudWatch, SQS, Route 53, Sagemaker), Apache Kafka (AWS MSK), Kubernetes, Datadog (Metrics, Logs, Synthetics), Pagerduty\nMain CI\/CD: Terraform, Docker, Harness\nMain Databases: Postgres \/ RDS, Redis, DynamoDB\nMain Languages: Python, Node + Typescript\nMain ML stack: Triton, TFServing, KServe\nWe encourage you to drop us a line even if you don\u2019t have all the points above. That\u2019s a lot of different areas of responsibility! We will help you pick them up because we believe that great people come from all walks of life.\nWhat\u2019s in it for you\nCompetitive salary\n6 month salary reviews\nVisa sponsorship (if required)\nEquity\nPension scheme\nBupa private healthcare (full coverage)\nFlexible hours & WFH\/hybrid setups \nLearning and Development budget\nCompetitive maternity + paternity leave\nDaily office snacks & soft drinks \nRegular company office events such as Games Nights, Movie Nights, Lunch & Learns, Monthly Brunch and more\nDiversity commitment\nAt Tractable, we are committed to building a diverse team and inclusive workplace where people\u2019s varied backgrounds and experiences are valued and recognised. \nWe encourage applications from candidates of all backgrounds and offer equal opportunities without discrimination.\n#LI-HM1\nDiversity commitment\nAt Tractable, we are committed to building a diverse team and inclusive workplace where people\u2019s varied backgrounds and experiences are valued and recognised. \nWe encourage applications from candidates of all backgrounds and offer equal opportunities without discrimination.","21":"The AdTech & Data Operations Lead reports to the Head of AdTech & Solutions and is responsible for owning, managing, and maintaining data operations and adtech partner relations for Insider\u2019s Advertising business while partnering with Revenue Operations\u2019 Department Heads, Solutions Engineering, Product & Tech, & Editorial in a multi-faceted capacity.\nResponsibilities:\nPlan, design, and build audience segments in line with IAB standards, 1st Party Readership consumption & behaviors, engagement, intent, contextual, psychographics, demographics, Google\u2019s Topics, FLEDGE, and other future solutions via Insider\u2019s DMP and supplemental tools\nInvestigate, test, and prove the success or failures of alternative identifiers and solutions in the adtech ecosystem with our SSP partners to help address anonymous users\nOwn all ad tech and data provider relationships in conjunction with the Head of AdTech & Solutions\nVetting of net new data providers for data enrichment opportunities, audience profiling, and additional opportunities and solutions\nBuild relationships with key stakeholders across Revenue, Product, Technology, & Editorial teams to improve and automate workflows and processes, including but not limited to: content tagging,\nPartner with Data Products, Data Engineering, Solutions Engineering, & Tech teams on data centralization, data visualization,  data modeling, data manipulation, data visualization, platform integrations, and overall data-based innovation and data innovation projects leveraging cloud provider services (Snowflake, AWS, GCP)\nQualifications:\nUnderstanding how ad operations, programmatic buying, and audience segmentation works in the Buying (Brand\/Advertisers & Agencies) and Selling (Publishers) sectors\nKnowledge of relational databases, data schemas, data joins, data modeling, data science, and data manipulation\nProficient experience working with SQL for data querying, and more\nExperience working with Snowflake, Google Cloud Platform, AWS, or similar data warehouse technologies\nBuilding relationships with internal and external stakeholders, clients, and team members\nAlways curious and willing to learn, try new things, and not be afraid to fail\nPersonable with everybody, even-keeled, and analytical thinker\nSalary & Benefits:\nSalary: $95,000. - $115,000. (dependent on skills, experience, and competencies)\nMedical, health, and vision\nUnlimited PTO, paid holidays, and parental leave\nMatched 401k plan\nAdditional benefits include commuter benefits, phone reimbursement, gym membership discounts, etc.\n Are you passionate about this opportunity, but worried that you don\u2019t have 100% of the experience we\u2019re looking for? We still want to hear from you! Apply online and let us know why you would make a great addition to the Insider community.\nAbout Us: Insider Inc. is the global media company behind Insider and an ever-growing family of brands. Our mission is to inform and inspire the digital generation and become the most influential journalism brand in the world. We reach an audience of more than 375 million users with our stories, which command attention and inspire action.\nOur core value is effectiveness. We make things happen. We listen to each other, learn from each other, and take risks together. We understand that a diverse set of perspectives and an inclusive environment are critical to our success. All of this helps us get better every day. Check out our mission, values, and culture page to learn more.\nInsider Inc supports a distributed workforce that allows for varied work locations. Many roles are eligible for 100% remote or hybrid remote\/office work unless otherwise noted.","22":"Successful applicants for this position must be fully vaccinated against COVID-19 as a condition of employment. Vaccine verification will be required.\n  POSITION SUMMARY:\nClinical Data Operator accessions patient samples according to standard operating procedures (SOP) with high efficiency and accuracy. Shift is: Tuesday - Saturday, either Day Shift 830am-5pm or Swing Shift 530pm-2am.  Hourly pay starts at $18, with an added swing and Saturday shift differential.       Natera requires successful applicants for this position must be fully vaccinated against COVID-19 as a condition of employment. Vaccine verification will be required.    PRIMARY RESPONSIBILITIES:\nCreate new orders on Laboratory Inventory Management System (LIMS) and perform necessary checks to ensure proper accessioning.\nAccession samples with high accuracy and efficiency.\nAccurately enter patient data into the Laboratory Inventory Management System (LIMS).\nEnsure that the information in LIMS is up-to-date.\nScan test requisition forms and attached paperwork.  Ensure that all paperwork belong to patient and upload to case.\nProtect patient health information (PHI) at all times to ensure compliance with HIPAA and privacy policies.\nPerform safe and proper handling of samples (blood, buccal, and tissue).\nMaintain tidiness of workstations and lab.\nMaintain familiarity with standard operating procedures (SOP) and quality standards determined by the clinical laboratory.\nPerform safe and proper handling of tools provided to open packages and kit boxes.\nSort packages at the dock upon arrival of packages and bring packages up to the lab.\nThis role works with PHI on a regular basis both in paper and electronic form and have an access to various technologies to access PHI (paper and electronic) in order to perform the job.\nEmployee must complete training relating to HIPAA\/PHI privacy, General Policies and Procedure Compliance training and security training as soon as possible but not later than the first 30 days of hire.\nMust maintain a current status on Natera training requirements.\nPerforms other duties as assigned.\nQUALIFICATIONS:\nHigh School Diploma (or equivalent) required.\n0 - 1 year of industry related experience.\nPrevious computer experience is required.\nPrevious data entry experience is preferred\nKNOWLEDGE, SKILLS, AND ABILITIES:\nTrained on all product types and able to accession with accuracy and efficiency.\nTyping speed of at least 45wpm with high accuracy.\nGood oral and written communication skills.\nEffective critical thinking skills and the ability to use good judgment.\nAbility to perform required duties with a high degree of accuracy and attention to detail.\nPositive attitude and ability to work well with others.\n  #LI-LS1\nOUR OPPORTUNITY\nNatera\u2122 is a global leader in cell-free DNA (cfDNA) testing, dedicated to oncology, women\u2019s health, and organ health. Our aim is to make personalized genetic testing and diagnostics part of the standard of care to protect health and enable earlier and more targeted interventions that lead to longer, healthier lives.\nThe Natera team consists of highly dedicated statisticians, geneticists, doctors, laboratory scientists, business professionals, software engineers and many other professionals from world-class institutions, who care deeply for our work and each other. When you join Natera, you\u2019ll work hard and grow quickly. Working alongside the elite of the industry, you\u2019ll be stretched and challenged, and take pride in being part of a company that is changing the landscape of genetic disease management.\nWHAT WE OFFER\nCompetitive Benefits - Employee benefits include comprehensive medical, dental, vision, life and disability plans for eligible employees and their dependents. Additionally, Natera employees and their immediate families receive free testing in addition to fertility care benefits. Other benefits include pregnancy and baby bonding leave, 401k benefits, commuter benefits and much more. We also offer a generous employee referral program!\nFor more information, visit www.natera.com.\nNatera is proud to be an Equal Opportunity Employer. We are committed to ensuring a diverse and inclusive workplace environment, and welcome people of different backgrounds, experiences, abilities and perspectives. Inclusive collaboration benefits our employees, our community and our patients, and is critical to our mission of changing the management of disease worldwide.\nAll qualified applicants are encouraged to apply, and will be considered without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, disability or any other legally protected status. We also consider qualified applicants regardless of criminal histories, consistent with applicable laws.\nIf you are based in California, we encourage you to read this important information for California residents. \nLink: https:\/\/www.natera.com\/notice-of-data-collection-california-residents\/\nPlease be advised that Natera will reach out to candidates with a @natera.com email domain ONLY. Email communications from all other domain names are not from Natera or its employees and are fraudulent. Natera does not request interviews via text messages and does not ask for personal information until a candidate has engaged with the company and has spoken to a recruiter and the hiring team. Natera takes cyber crimes seriously, and will collaborate with law enforcement authorities to prosecute any related cyber crimes.\nFor more information:\n- BBB announcement on job scams \n- FBI Cyber Crime resource page ","23":"Who we are \nTractable is an Artificial Intelligence company bringing the speed and insight of Applied AI to visual assessment. Trained on millions of data points, our AI-powered solutions connect everyone involved in insurance, repairs, and sales of homes and cars \u2013 helping people work faster and smarter, while reducing friction and waste.\nFounded in 2014, Tractable is now the AI tool of choice for world-leading insurance and automotive companies. Our solutions unlock the potential of Applied AI to transform the whole recovery ecosystem, from assessing damage and accelerating claims and repairs to recycling parts. They help make response to recovery up to ten times faster \u2013 even after full-scale disasters like floods and hurricanes. \nTractable has a world-class culture, backed up by our team, who have rated us 4.9\/5 on Glassdoor, making us a global employer of choice!\nWe're a diverse team, uniting individuals of over 40 different nationalities and from varied backgrounds, with machine learning researchers and motor engineers collaborating together on a daily basis. We empower each team member to have tangible impact and grow their own scope by intentionally building a culture centred around collaboration, transparency, autonomy and continuous learning.\n What you will do\nThe MLOps team belongs to a larger group - Platform Engineering, which is focused on building tools and services for our internal customers within Tractable: researchers, product engineers, ops specialists, etc. We have several teams in the Platforms group tackling different aspects of the space including Infrastructure, Business Intelligence, Data Platform, Dev tools and engineering efficiency, MLOps. As a Senior ML OPS Engineer on the MLOps team, you will be collaborating with the fellow Platform and Research teams. \nWe are looking for a Senior MLOps Engineer to build and support systems that enable the core mission of Tractable - to make applied AI possible - by optimising the end-to-end Machine Learning life cycle. The vision of the MLOps team is to enable researchers to spend 80%+ of their time solving tricky ML problems rather than dealing with engineering\/infra\/ops challenges. \nYou'll play a key role in developing our MLOps platform from pretty much ground up, as part of a bigger Platforms group. You will influence the scope and technical direction as well as champion best practices within the team. You have a relentless focus on user experience (Researchers and Data Scientists in this case) and you care deeply about what your team is building to make sure it will have the biggest impact on your users. You will be a strong mentor, nurturing an encouraging and supportive environment to enable the team to do their best work.\n  The role: \nYou'll play a key role in developing our MLOps platform from ground up, as part of a small but high-performing team. You will influence the scope and technical direction as well as champion best practices within the team. You will continuously pursue clean code practices and contribute towards overall platform architecture collaborating with our other Engineering and Product team. \nYou will be:\nWorking with engineers and data scientists to build the next generation of MLOps platform in Tractable\nBuilding various platform capabilities in the Machine Learning lifecycle to massively speed up efficiency in bringing research to production. From dataset management, model training to monitoring models performance in production\nSolving lots of scalability problems in both model training and model serving in production\nAdopting open-source technologies to best leverage our in-house resources\nPromoting engineering best practices throughout the team\nSuggesting, collecting and synthesising requirements and creating effective feature roadmap with Product Manager\nTech Stack:\nWe rely heavily on the following tools and technologies below \u2013 but we are likely to explore new technologies \/ frameworks as we are building the platform from ground up hence you don't need to have prior experience in all of them. We\u2019re just keen to know that you're willing to break things, fix things, learn fast and carry on building a great team that is capable of building awesome platforms customers love! \nMain Infrastructure: AWS (EC2, S3, MSK, Lambda, StepFunctions, Glue, IAM, Cognito, Systems Manager, CloudWatch, SQS, Route 53, Sagemaker), Apache Kafka (AWS MSK), Kubernetes, Datadog (Metrics, Logs, Synthetics), Pagerduty\nMain CI\/CD: Terraform, Docker, Harness\nMain Databases: Postgres \/ RDS, Redis, DynamoDB\nMain Languages: Python, Node + Typescript\nMain ML stack:  Triton, TFServing, KServe\nWe encourage you to drop us a line even if you don\u2019t have all the points above. That\u2019s a lot of different areas of responsibility! We will help you pick them up because we believe that great people come from all walks of life.\nWhat you need to be successful:\nA strong ML Engineer who is passionate about building platforms to massively reduce lead time from bringing Machine Learning research to production. You would have a solid background in software engineering as well as a good understanding of the difficulties faced by data scientists. A few things we are particularly interested in seeing from you:\nGreat communication skills and collaborative mindset\n2+ years of experience in building scalable Machine Learning Platform. Experience working with open source ML frameworks such as MLFlow \/ Kubeflow would be a plus.\nStrong programming experience, from self-contained algorithms to complex object modelling design\nWorked with Python in a professional environment for 2+ years\nExperience working with GPUs \/ Tensorflow\nExperience in building Data Pipeline\nAble to design good system architecture and compare trade-offs (distributed system experience a plus)\nNumerical computing experience\nCares about team practices \/ pairing \/ advocate of CICD\nBasic ML knowledge, bonus if you have trained a few deep learning models\n What\u2019s in it for you\nCompetitive salary\n6 month salary reviews\nVisa sponsorship (if required)\nEquity\nPension scheme\nBupa private healthcare (full coverage)\nFlexible hours & WFH\/hybrid setups \nLearning and Development budget\nCompetitive maternity + paternity leave\nDaily office snacks & soft drinks \nRegular company office events such as Games Nights, Movie Nights, Lunch & Learns, Monthly Brunch and more\nDiversity commitment\nAt Tractable, we are committed to building a diverse team and inclusive workplace where people\u2019s varied backgrounds and experiences are valued and recognised. \nWe encourage applications from candidates of all backgrounds and offer equal opportunities without discrimination.\n  #LI-HM1\nDiversity commitment\nAt Tractable, we are committed to building a diverse team and inclusive workplace where people\u2019s varied backgrounds and experiences are valued and recognised. \nWe encourage applications from candidates of all backgrounds and offer equal opportunities without discrimination.","24":"nSight Surgical is the first machine learning platform that ensures hospital patient safety, and streamlines operative workflow. By recognizing patient safety moments in the operating room, the platform improves both patient safety, and increases efficiency across the entire hospital ecosystem.\nAs the MLOps Data Engineer, you will be responsible for designing and building the MLOps pipelines. You enjoy automating tasks and documenting your work to benefit others. From monitoring the complex ML models in production to improving best practices, prioritizing multiple issues, and troubleshooting complex problems, you\u2019re ready to contribute to the architecture of a unified infrastructure system.\nOur platform focuses on managing different components of the machine learning application development life cycle, starting from data ingestion, annotation, and exploration to model training, deployment, and monitoring.\nOur engineers are self-motivated problem solvers who enjoy being versatile. We adore diversity and encourage healthy debate and discussion.\nWhat We Need Your Help With:\nDesign and build MLOps pipelines for data ingestion, selection, auto-ml, experimentation, optimization, continuous integration, deployment, verification, validation, and monitoring of ML models in production while following best practices of automation, monitoring, scale, and safety.\nContribute to the architecture of a unified infrastructure system that bridges the gap between Data, ML, CI\/CD, and Evaluation frameworks, improving the stability, security, efficiency, and scalability of the system.\nEvaluate the latest tools and frameworks in the ML ecosystem and help improve code quality through writing unit tests, automation, and performing code reviews.\nIdentify patterns of data ingestion and pipeline issues and propose short and long-term solutions while working collaboratively with the computer vision team.\nEnable the CV teams to continuously experiment with new data and provide data and infrastructure support.\nWhat We Look For:\nMasters or Ph.D. in Computer Science, Electrical Engineering, Statistics, or related technical field with at least 2+ years experience after graduation.\nPassion for automation by creating tools using Python.\nExpertise in MLOps infrastructure, machine learning model development, and deployment lifecycle.\nExperience with MLOps Frameworks like MLFlow, Kubeflow, DataRobot, Airflow, etc.\nStrong programming skills in Python or C\/C++, with relevant experience in building AI applications using deep learning platforms like PyTorch or TensorFlow on GPUs\nKnowledge of basic statistical techniques (t-tests, confidence intervals, p-value, etc.).\nExperience building ML pipelines in a high-impact role, with years of AWS experience.\nAbility to design and implement cloud solutions, including building MLOps pipelines on cloud platforms such as AWS, MS Azure, or GCP.\nKnowledge of professional enterprise software development and practices, including software lifecycle, best coding practices, version control, architecture, testing, and deployment.\nNice to Have:\nExperience working with medical data.\nUnderstanding of healthcare or HIPAA-compliant systems.\nExperience with Docker, CI\/CD build systems like Jenkins\/Team City, and AWS services like S3, DynamoDB, EC2, ECR, lambda, etc.\nProficiency in data visualization and dashboarding tools such as Superset, Elasticsearch and Kibana, Grafana, and Tableau\nAt nSight SurgicalnSight embraces diversity. We believe an inclusive and diverse workforce is an innovative one. We are an EEO employer and welcome all gender, race, culture, age, sexual orientation, and abilities to our team. If you require special accommodations throughout the process please reach out to alison@nsightsurgical.ai.","25":"Company Description\nSyngenta Seeds is one of the world\u2019s largest developers and producers of seed for farmers, commercial growers, retailers and small seed companies. Syngenta seeds improve the quality and yields of crops. High-quality seeds ensure better and more productive crops, which is why farmers invest in them. Advanced seeds help mitigate risks such as disease and drought and allow farmers to grow food using less land, less water and fewer inputs.\nSyngenta Seeds brings farmers more vigorous, stronger, resistant plants, including innovative hybrid varieties and biotech crops that can thrive even in challenging growing conditions.\nSyngenta Seeds is headquartered in the United States.\nJob Description\nThe ML OPS Engineer will be responsible for designing, implementing, and maintaining machine learning infrastructure, pipelines, and workflows. This role will require a deep understanding of data management, software development, and cloud computing. The successful candidate will work closely with data scientists, software engineers, and other stakeholders to ensure that machine learning models are deployed, monitored, and updated efficiently and effectively\nDevelop, deploy and maintain machine learning models, pipelines and workflows in production environment.\nBuild and maintain machine learning infrastructure that is scalable, reliable and efficient.\nCollaborate with data scientists and software engineers to design and implement machine learning workflows.\nImplement monitoring and logging tools to ensure that machine learning models are performing optimally.\nContinuously improve the performance, scalability and reliability of machine learning systems.\nWork with DevOps team to deploy and manage infrastructure for machine learning services.\nCreate and maintain technical documentation for machine learning infrastructure and workflows.\nStay up to date with the latest developments in machine learning and cloud computing technologies.\nThis person will work in our Durham, NC location in a hybrid work setting\nQualifications\nRequired Skills\nBachelor's or Master's degree in computer science, engineering or related field.\n5+ years of experience in software development, machine learning engineering or related field.\nStrong understanding of machine learning concepts and frameworks, including TensorFlow, PyTorch, Scikit-learn, etc.\nExperience with ML Ops in AWS preferred including Sagemaker.\nFamiliarity with DevOps practices and tools such as Kubernetes, Docker, Jenkins, Git.\nExperience in developing and deploying machine learning models in a production environment.\nStrong analytical and problem-solving skills\nPreferred Skills\nExperience with data lake technologies such as S3 and Snowflake\nExperience in a genetics\/genomics life science setting\nExperience with time-series data and forecasting models.\nExperience with data streaming technologies such as Kafka, Kinesis, etc.\nExperience with MLOps platforms such as Kubeflow, MLFlow, Sagemaker etc.\nFamiliarity with database technologies such as SQL, NoSQL, etc.\nAdditional Information\nWhat we Offer\nA culture that celebrates diversity & inclusion, promotes professional development, and strives for a work-life balance that supports the team members\nWe offer flexible work options to support your work and personal needs\nFull Benefit Package (Medical, Dental & Vision) that starts your first day\n401k plan with company match, Profit Sharing & Retirement Savings Contribution\nPaid Vacation, 9 Paid Holidays, Maternity and Paternity Leave, Education Assistance, Wellness Programs, Corporate Discounts, among other benefits\nSyngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, marital or veteran status, disability, or any other legally protected status\nFamily and Medical Leave Act (FMLA)\n(http:\/\/www.dol.gov\/whd\/regs\/compliance\/posters\/fmla.htm)\nEqual Employment Opportunity Commission's (EEOC)\n(http:\/\/webapps.dol.gov\/elaws\/firststep\/poster_direct.htm)\nEmployee Polygraph Protection Act (EPPA)\n(http:\/\/www.dol.gov\/whd\/regs\/compliance\/posters\/eppa.htm)\n #LI-SB2","26":"The Company\nEgon Zehnder\nEgon Zehnder (www.egonzehnder.com) is trusted advisor to many of the world\u2019s most respected organizations and a leading Executive Search firm, with more than 400 consultants and 69 offices in 41 countries spanning Europe, the Americas, Asia Pacific, the Middle East and Africa. Our clients range from the largest corporations to emerging growth companies, government and regulatory bodies, and major educational and cultural institutions. The firm is a private partnership which allows us to operate independent of any outside interests. As a result of this unique culture, Egon Zehnder has the highest professional staff retention rate for a global firm in our profession. We have a blue chip client base across all industries and operate at the Board and senior management level.\nEgon Zehnder, Knowledge Centre India (KCI)\nEstablished in January 2005, KCI in Gurgaon, works in close collaboration with the Global offices of Egon Zehnder. There are 5 teams that make up KCI: Experts, Research Operations, Visual Solutions, Projects\/CV Capture and Global Technology Services.\nRequirements\nPurpose and Scope\nThe Data Operations & Engineering Lead will build our data operations practice to ensure effective data pipeline engineering, deployment, ongoing operations, and continuous improvement. This individual is responsible for the implementation and oversight of all Data Operations Team activities, including facilitating data engineering activities and decisions, monitoring Data Operations Team effectiveness, and aligning enterprise data solutions with data engineering and operations standards. The role will be the key point of contact for all data operations and data engineering solutions and processes and will work as a strategic leader working alongside senior leadership to establish a road map outlining the technical vision for this team and function.\nEssential Job Responsibility\nSystem owner for all data technology platforms such as Data Lake, Data Warehouse, Data Mart, Data Integration tools.\nManage and perform data operations and data engineering requirements including automation and optimization.\nProvide guidance surrounding program development and implementation.\nResponsible for the technical strategy and delivery of all data solutions in addition to providing technical support and administering applications.\nResponsible for the design, development, and deployment of data solutions on cloud platforms\nAssist in the selection of technology vendor including choice of platforms, definition of processes and staff mentorship and growth.\nManage relationships with vendors and other external business partners.\nMust have strong experience managing large budgets and be responsible for all spend associated with those projects.\nIdeal candidate will have a strong background and interest in technology coupled with an understanding of analytics and data modeling.\nThis person can articulate and demonstrate their strategic and critical thinking abilities. Leading by influence and driving results.\nAbility to work in a fast faced environment while managing competing priorities.\nQualification:\nRequired:\nAbility to engage resources outside of direct control to achieve objectives.\nStrong understanding of data technology platforms (Data Lake, Data Warehouse, Data Mart, Data Integration tools)\nExperience with metrics gathering, tracking and reporting to drive operational excellence.\nStrong process viewpoint\nExcellent root cause analysis skills\nKnowledge of data management policies and standards\nAbility to organize working teams and influence others.\nAbility to facilitate discussions to meaningful, agreed upon mutual decisions.\nPreferred\nExperience managing Azure or equivalent Cloud services.\nUnderstanding of information and data architecture\nExperience working with PII, GDPR, and\/or other regulated datasets.\nExperience working for a global company.\nEZIRS Commitment to Diversity and Inclusion\nEgon Zehnder Information Research & Services (EZIRS) aims for a diverse workplace and strive to continuously lead with our firm values. We respect personal values of every individual irrespective of race, national or social origin, gender, religion, political or other opinion, disability, age and sexual orientation as warranted by basic rights enshrined in the UN Declaration of Human Rights. We believe diversity of our firm is central to the success and enables us to deliver better solutions for our clients. We are committed to creating an inclusive environment and supportive work environment, where everyone feels comfortable to be themselves and treated with dignity and respect and there is no unlawful discrimination related to employment, recruitment, training, promotion or remuneration.\nBenefits\n5 Days working\nHybrid Work option\nReward and Recognition\nEmployee friendly policies\nPersonnel development and training\nHealth Benefits, Accident Insurance\nGender Diversity","27":"We partner with the world\u2019s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency.\nHi There, This is Mar\u00eda from CI&T! I am a Talent Attracting Analyst looking for people located in the USA for a Senior Data Ops Engineer Position to work on a project in the Mortgage Industry.\nRequirements for this challenge: - Cloud (Azure, GCP or AWS)- CI\/CD pipelines- Terraform.- Data Bases: SQL, Postgres, Dataproc, Dataplex- Excellent written and verbal English communication skills\nOur benefits: - Premium Healthcare- Meal voucher- Maternity and Paternity leaves.- Mobile services subsidy- Sick pay-Life insurance.-CI&T University-Colombian Holidays-Paid VacationsAnd many others.\n#LI-MJ1#MidSeniorCI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters\u2019 identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow.\nAt CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas.\nWe strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies.","28":"Location: Mumbai,Maharashtra,India\nTitle: Manager \/ Senior Manager\nExperience: 12+ for Manager and 16+ for Sr. Manager (Relevant)\nLocation : Noida \\ Mumbai with ability to work for short-stints at both locations\n Responsibilities :\nA Manager\\Senior Manager will have a coverage of at least 300+\\600+ companies with support from 8-10\\15-20 Research Associates\nCoverage includes maintenance of the data template and coverage of revised models in a time-bound manner to meet internal SLAs\nThe role also involves expansion of coverage in a timely manner based on content available\nThink like a client and use the data as a client would to get to errors that someone working on the Industry\/(s) and associated data processing from models would miss out.\nSuggest logic to identify data error\nTraining team members on the internal tools as well as Industry specific nuances\nContribute in the hiring and development process\nHelp build the knowledge level of the team members, encourage them to read up on the industry and companies in coverage, as well as drive exchange of knowledge and best work practices\n Requirements\nAdvanced Degree and several years of experience across multiple sectors on the BUY \\ SELL side\nThe person will have to be the knowledge bank for companies in a sector or part of a sector with a good understanding of key performance indicators and modeling nuances (to break a model into comparable constituents at a micro level)\nUnderstanding of firm-wide products and inter dependencies between departments in the organization;\nAbility to grasp our internal tools used to capture and QA data with limited manual input (keying in of data)\nStrong communication skills and the ability to successfully represent Visible Alpha at various Industry forums as well as act as a Level 1 support for clients and contributors\nStrong management skills; demonstrated leadership ability.\nTeam player with ability to work with peers\\internal clients across geographies in India and Internationally, has ability to get bottlenecks in the team working cleared by working with members from other departments.\nApply to this job","29":"We partner with the world\u2019s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency.\nHi There, This is Mar\u00eda from CI&T! I am a Talent Attracting Analyst looking for people located in the USA for a Senior Data Ops Engineer Position to work on a project in the Mortgage Industry.\nRequirements for this challenge: - Cloud (Azure, GCP or AWS)- CI\/CD pipelines- Terraform.- Data Bases: SQL, Postgres, Dataproc, Dataplex- Excellent written and verbal English communication skills\nOur benefits: - Health plan and dental plan; - Meal allowances; - Childcare assistance; - Extended parental leave; - Gympass - Annual profit-sharing distribution; - Life insurance; - Partnership with an online mental health platform; - CI&T University; - Discount Club; - Support Program: legal; financial; physiotherapy; psychological guidance; nutritionist and more; - Pregnancy course and responsible parenthood; - Partnership with online course platforms - Platform for language learning;- And many others.\n#LI-MJ1#MidSeniorCI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters\u2019 identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow.\nAt CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas.\nWe strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies.","30":"We partner with the world\u2019s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency.\nWe are looking for engineers who are passionate about data and DevOps eager to tackle big challenges using cloud and modern data processing technologies to be part of our team!\nYour mission: The main focus of this role is to solve non-trivial data engineering problems. This person will mostly work with a mix of structured and unstructured and use cloud and other state-of-the-art techniques and tools to help our customers achieve their business goals.\nWe are looking for someone who has experience with:- Analysing and organising raw data- Intellectual curiosity to find new and unusual ways how to solve data management issues - Defining, building, and delivering high-quality data pipelines - Experience with Cloud as Azure, AWS, or GCP when it comes to infrastructure design and setup- Technical expertise with data models, data mining, and segmentation techniques- Hands-on experience with SQL database design- Analytics services- Familiarity with MSSQL- Ability to write\/maintain custom scripts (powershell \/ bash \/ python)- Experience with DBT is a plus- Advanced oral and written communication skills in English. \nOur benefits:\n- Competitive Salary- Generous paid vacation days- Unlimited sick time- 100% paid health & dental benefits starting day one- Annual profit-sharing distribution- Retirement match- Paid parental leave- Dedicated career advisor- And so much more\u2026\n\n#LI-MR4#Midsenior\nCI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters\u2019 identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow.\nAt CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas.\nWe strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies.","31":"We partner with the world\u2019s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency.\nWe are looking for engineers who are passionate about data and DevOps eager to tackle big challenges using cloud and modern data processing technologies to be part of our team!\nYour mission: The main focus of this role is to solve non-trivial data engineering problems. This person will mostly work with a mix of structured and unstructured and use cloud and other state-of-the-art techniques and tools to help our customers achieve their business goals.\nWe are looking for someone who has experience with:- Analysing and organising raw data- Intellectual curiosity to find new and unusual ways how to solve data management issues - Defining, building, and delivering high-quality data pipelines - Experience with Cloud as Azure, AWS, or GCP when it comes to infrastructure design and setup- Technical expertise with data models, data mining, and segmentation techniques- Hands-on experience with SQL database design- Analytics services- Familiarity with MSSQL- Ability to write\/maintain custom scripts (powershell \/ bash \/ python)- Experience with DBT is a plus- Advanced oral and written communication skills in English. \nOur benefits:\n- Competitive Salary- Generous paid vacation days- Unlimited sick time- 100% paid health & dental benefits starting day one- Annual profit-sharing distribution- Retirement match- Paid parental leave- Dedicated career advisor- And so much more\u2026\n\n#LI-MR4#Midsenior\nCI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters\u2019 identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow.\nAt CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas.\nWe strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies.","32":"Company Description\nPublicis Media harnesses the power of modern media through global agency brands Performics, Spark Foundry, Starcom and Zenith. A key business solution of Publicis Groupe ([Euronext Paris FR0000130577, CAC 40], Publicis Media\u2019s digital-first, data-driven global practices deliver client value and drive growth in a platform-powered world. It is present in more than sixty countries with over 23,000 employees worldwide.\nJob Description\nThis role offers an opportunity to work on Publicis Media\u2019s best-in-class data infrastructure platform where we ingest, process, and enable access to data from major media platforms across categories including search, social, ad serving, and more.  In this role, the Platform Success Lead will coordinate closely with various Publicis agency stakeholders and the Data Infrastructure team to ensure successful delivery of data used to power various agency analytics products and deliverables.  This role will be responsible for coordinating with agency contacts to ensure successful onboarding and enablement of data specific to their media platforms and use cases. Additionally, the role will have responsibility for defining engineering requirements specific to the success of various agency use cases.\nResponsibilities:\nPrepare specs and requirements for data sources and data source features required by agency client teams\nResearch, and where needed, coordinate with vendors to ensure data availability to meet Agency client use cases\nWork closely with Product Manager to help prepare stories for grooming and to help the grooming process with Engineers\nCoordinate with Product Peers, Engineering Team and Scrum Master to ensure delivery of Data Infrastructure features and data sources required to achieve Agency client product vision\nAct as Data Infrastructure Product SME with a focus on the DSP and Social data, data access procedures, and data certification practices.\nCoordinate closely with global contacts and maintain ongoing communications to help ensure success using Data Products\nOwn relationships with Data Source vendors\nQualifications\n5-7 years of related work experience\n5-7 years of digital media experience, particularly experience working in ad tech industry with a data-centric role\nHands-on analytics-based query experience in SQL and ability to articulate technical ETL requirements\nStrong written and verbal communication, including technical writing skills\nUnderstanding of systems engineering concepts\nRequirements gathering, analysis, translation, organization, documentation and communication experience\nPractical experience in scrum-based Agile development methodology\nExperience working with JIRA, Confluence, or equivalent\nB.S. in Engineering, Information Management, or Computer Sciences preferred\nHands-on experience working in Business Intelligence platform, preferably Tableau, is a plus\n Additional Information\nPublicis Media provides benefits and resources designed to support all of our employees. With comprehensive health and dental benefits, 401K match program, generous time off, and flexibility to work remotely we strive to support work life balance. We encourage participation in the over 13 Business Resource Groups, including groups for Women, People of Color, Veterans, LGTBQ community and allies, Parents, and more.\nPlease let your Publicis Recruiter know if there are any particular adjustments we can consider to make the interview more accessible and comfortable.\nAll your information will be kept confidential according to EEO guidelines.\nCompensation Range: $130,000-$204,500 annually. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. For this role, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off.","33":"Why We Work at Dun & BradstreetDun & Bradstreet unlocks the power of data through analytics, creating a better tomorrow. Each day, we are finding new ways to strengthen our award-winning culture and accelerate creativity, innovation and growth. Our 6,000+ global team members are passionate about what we do. We are dedicated to helping clients turn uncertainty into confidence, risk into opportunity and potential into prosperity. Bold and diverse thinkers are always welcome. Come join us!\nAre you passionate and familiar with publicly available data ranging from Business Registration, Bankruptcies, Suits, Liens, Judgements, UCC and\/or Adverse news? If so, we have the position for YOU! Dun & Bradstreet is looking for a Data Operations Analyst II to join our firm and be apart of our Public Intelligence Operations team.\nThis position will be responsible for supporting and owning core data operational functions. Furthermore, this position will be vital in solving key business challenges and may involve working with stakeholders throughout the business, sales\/product, operations, legal, technology and may involve communicating with Sr. Leaders.\nApplicants that have 2-4 years of business experience, are self-starters, and have a knack for initiating and driving change are highly desirable for this role!\nIn addition, the role is expected to become well versed in operational processes that include and not limited to:\nWorking with data source providers; establishing and maintaining a relationship\nWork closely with Business partners and defining\/documenting requirements, making recommendations for improvements, and being a subject matter expert\nReporting weekly on progress of application from an operations point of view, if applicable\nEssential Key Responsibilities\/Job Summary\nEnsuring operational processing runs daily, including working with and knowledge of day-to-day processes with BPO vendor(s)\nWork closely with Business partners and defining\/documenting requirements, making recommendations for improvements\nThought leadership \u2013 owning your functional area and being the subject matter expert\nWorking with data source providers; establishing and maintaining a relationship\nEducation\/Experience and Competencies\nBachelor\u2019s degree (preferable in computer science or a related field)\nStrong communication skills, both written and oral\nAbility to work closely with others to problem solve\nExperience with Data Profiling tools, Data Analysis and Data Specification writing\nModern Data Analytical Skills a plus and including but not limited to: (SQL, Python, Business Intelligence (PowerBI)\nEqual Employment Opportunity (EEO): Dun & Bradstreet is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, age, national origin, citizenship status, disability status, sexual orientation, gender identity or expression, pregnancy, genetic information, protected military and veteran status, ancestry, marital status, medical condition (cancer and genetic characteristics) or any other characteristic protected by law.  View the EEO is the Law poster here and its supplement here. View the pay transparency policy here.\nGlobal Recruitment Privacy Notice","34":"Let\u2019s face it, a company whose mission is human transformation better have some fresh thinking about the employer\/employee relationship.\n\nWe do. We can\u2019t cram it all in here, but you\u2019ll start noticing it from the first interview.\n\nEven our candidate experience is different. And when you get an offer from us (and accept it), you get way more than a paycheck. You get a personal BetterUp Coach, a development plan, a trained and coached manager, the most amazing team you\u2019ve ever met (yes, each with their own personal BetterUp Coach), and most importantly, work that matters.\n\nThis makes for a remarkably focused and fulfilling work experience. Frankly, it\u2019s not for everyone. But for people with fire in their belly, it\u2019s a game-changing, career-defining, soul-lifting move.\n\nJoin us and we promise you the most intense and fulfilling years of your career, doing life-changing work in a fun, inventive, soulful culture.\n\nIf that sounds exciting\u2014and the job description below feels like a fit\u2014we really should start talking. \nWe\u2019re looking for a Senior Data \/ DataOps engineer who cares deeply about their craft, and who wants to use their skills to bring about positive change in the world while working in a high-performing organization. On the Data Operations team, our mission is to architect, build and operate a world class data platform enabling teams to apply analytics and ML for social good.  We are product engineers that strive to enable all BetterUppers to build data driven products that further our mission.\nWe're looking for someone who is comfortable in the rapidly changing nature of a startup environment but also adept at moving relentlessly forward: doing what needs to be done to unblock projects that truly deliver value to our users. At BetterUp we delight in supporting and pushing each other to bring out the best in our colleagues, and would love someone to join the team who shares our passions for empathy, excellence, and continuous improvement. We also deeply understand that a key to peak performance is balance, and our culture is focused on providing the support our people need to be able to bring their whole selves to bear in service of our mission.\nWhat you\u2019ll do:\nData evangelist: Bring, build, and drive data culture and best practices, enabling the product and engineering org to build better, more reliable, and secure data pipeline and data-driven products and powering use cases spanning internal and customer-facing analytics, data science \/ ML needs, and in-app experiences\nDevEx delighter: Use tooling and automation to deliver a developer experience that enables teams to quickly and easily build out data products following mature SDLC principles\nSystem designer: Passion for building systems, platforms, and tools that people use. You\u2019ll use your expertise in the broader data ecosystem and the modern architectures, approaches, and emerging technologies in this space, on top of a strong foundation on the fundamentals of building distributed systems in the cloud.\nAct as an owner: It may start with a proof of concept but it\u2019s not done until it\u2019s in production. Adept at moving projects forward and able to unblock projects regardless of where we are in the development lifecycle.\nDo less, deliver more: Familiar with the terms YAGNI and yak shaving?  Focus your efforts on high-impact initiatives that really move the needle.\nImpress yourself: We hold ourselves to quality above and beyond something that \u201cjust gets it done.\u201d  Each system or line of code is an opportunity to demonstrate craftspersonship.\nCollaborate without ego: Work together with teams to drive cross-team and cross-functional technical roadmaps, and willing to take on roles small or large in order to further the mission at hand.\nIf you have some or all of the following, please apply:\n4+ years of relevant data engineering, data infrastructure, DataOps \/ MLOps, DevOps, SRE, or general systems engineering experience (high growth startup experience is a plus)\nA leader for your teammates and driver of large cross functional projects within your organization\nFamiliarity or expertise using and maintaining modern data platform technologies and services like Kafka, Airflow, Snowflake, Segment, Stitch, Fivetran, dbt, Looker, etc.\nFamiliarity or expertise using and maintaining ML tooling and platforms like AWS Sagemaker, GCP Vertex AI, BentoML, MLFlow, Kubeflow, etc.\nExperience doing infrastructure-as-code using tools like Terraform, Ansible, Chef, etc., and a pathological inclination towards automation and CI\/CD\nFull lifecycle ownership up through production and experience with observability and monitoring tools like DataDog, Honeycomb, Sentry, etc.\nExperience architecting and implementing data governance processes and tooling (such as data catalogs, lineage tools, role-based access control, PII handling)\nStrong coding ability in Python (preferred) or other languages like Java, C#, Golang, etc., and a solid grasp of SQL fundamentals\nBenefits:\nAt BetterUp, we are committed to living out our mission every day and that starts with providing benefits that allow our employees to care for themselves, support their families, and give back to their community. \nAccess to BetterUp coaching; one for you and one for a friend or family member \nA competitive compensation plan with opportunity for advancement\nMedical, dental and vision insurance\nFlexible paid time off\nPer year: \nAll federal\/statutory holidays observed\n4 BetterUp Inner Work days (https:\/\/www.betterup.co\/inner-work)\n5 Volunteer Days to give back\nLearning and Development stipend\nCompany wide Summer & Winter breaks \nYear-round charitable contribution of your choice on behalf of BetterUp\n401(k) self contribution\nWe are dedicated to building diverse teams that fuel an authentic workplace and sense of belonging for each and every employee. We know applying for a job can be intimidating, please don\u2019t hesitate to reach out \u2014 we encourage everyone interested in joining us to apply.\n\nBetterUp Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, disability, genetics, gender, sexual orientation, age, marital status, veteran status. In addition to federal law requirements, BetterUp Inc. complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.\nAt BetterUp, we compensate our employees fairly for their work. Base salary is determined by job-related experience, education\/training, residence location, as well as market indicators. The range below is representative of base salary only and does not include equity, sales bonus plans (when applicable) and benefits. This range may be modified in the future.\nThe base salary range for this role is $136,850 \u2013 $193,000.\nWe value your privacy. Your personal data will be processed in accordance with our Privacy Policy. If you have any questions about the privacy of your personal data or your rights with regards to your personal data, please reach out to support@betterup.co\n#LI-Remote\n ","35":"Why We Work at Dun & BradstreetDun & Bradstreet unlocks the power of data through analytics, creating a better tomorrow. Each day, we are finding new ways to strengthen our award-winning culture and accelerate creativity, innovation and growth. Our 6,000+ global team members are passionate about what we do. We are dedicated to helping clients turn uncertainty into confidence, risk into opportunity and potential into prosperity. Bold and diverse thinkers are always welcome. Come join us!\nAre you passionate and familiar with publicly available data ranging from Business Registration, Bankruptcies, Suits, Liens, Judgements, UCC and\/or Adverse news? If so, we have the position for YOU! Dun & Bradstreet is looking for a Data Operations Analyst II to join our firm and be apart of our Public Intelligence Operations team.\nThis position will be responsible for supporting and owning core data operational functions. Furthermore, this position will be vital in solving key business challenges and may involve working with stakeholders throughout the business, sales\/product, operations, legal, technology and may involve communicating with Sr. Leaders.\nApplicants that have 2-4 years of business experience, are self-starters, and have a knack for initiating and driving change are highly desirable for this role!\nIn addition, the role is expected to become well versed in operational processes that include and not limited to:\nWorking with data source providers; establishing and maintaining a relationship\nWork closely with Business partners and defining\/documenting requirements, making recommendations for improvements, and being a subject matter expert\nReporting weekly on progress of application from an operations point of view, if applicable\nEssential Key Responsibilities\/Job Summary\nEnsuring operational processing runs daily, including working with and knowledge of day-to-day processes with BPO vendor(s)\nWork closely with Business partners and defining\/documenting requirements, making recommendations for improvements\nThought leadership \u2013 owning your functional area and being the subject matter expert\nWorking with data source providers; establishing and maintaining a relationship\nEducation\/Experience and Competencies\nBachelor\u2019s degree (preferable in computer science or a related field)\nStrong communication skills, both written and oral\nAbility to work closely with others to problem solveExperience with Data Profiling tools, Data Analysis and Data Specification writing\nModern Data Analytical Skills a plus and including but not limited to: (SQL, Python, Business Intelligence (PowerBI)\nEqual Employment Opportunity (EEO): Dun & Bradstreet is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, age, national origin, citizenship status, disability status, sexual orientation, gender identity or expression, pregnancy, genetic information, protected military and veteran status, ancestry, marital status, medical condition (cancer and genetic characteristics) or any other characteristic protected by law.  View the EEO is the Law poster here and its supplement here. View the pay transparency policy here.\nGlobal Recruitment Privacy Notice","36":"Who we are \nBitpanda simplifies wealth creation. Founded in 2014 in Vienna, Austria by Eric Demuth, Paul Klanschek and Christian Trummer, Bitpanda exists to help people trust themselves enough to build financial freedom for their future. Our user-friendly, trade-everything platform empowers both first-time investors and seasoned experts to invest in the cryptocurrencies, crypto indices, stocks, precious metals and commodities they want \u2014 all possible with any sized budget, 24\/7. With more than 700 team members and steadily approaching 4 million customers, our company is one of Europe's most successful fintechs.\nHeadquartered in Austria but operating across all of Europe, our products are built by fast-moving, talented, \u201croll-up-your-sleeves-and-make-it-happen\u201d kind of people who represent more than 50 nationalities. If you\u2019re someone who thinks big, moves fast and wants to make an impact right from day one, then get ready to join our industry-changing team. Let\u2019s go!\nYour mission\nAs an AML Operations Specialist at Bitpanda, your mission is to mitigate money laundering and terrorist financing risks and to comply with applicable regulations in the anti-financial crime field. You are well-versed in the principles of the financial crime patterns, also connected to the cryptocurrencies environment, and possess a very strong problem-solving-oriented mindset.\nWhat you\u2019ll do\nPerform day-to-day reviews for Source of Funds (cryptocurrencies and fiat), oversee risk-relevant activities of user accounts, spot possible red flags on user\u2019s accounts and collaborate with other teams \nAnalyse user\u2019s financial data both related to Individual users and Business users, as well as explanations and additional documents that may be requested to assess the origin of the funds used to identify and report potential suspicious activity - including money laundering, terrorist financing, human trafficking, fraud and other possible financial crimes\nConduct investigations over available tools, databases and online search \nDocument  the analysis and investigation findings performed on the users and escalate the high-risk ones to the second line of defence\nProvide insight and recommendations for streamlining and enhancing the various activities related to the Proof of Funds and Transaction Monitoring processes \nWho you are\nAt least 2 years\u2019 of proven success in a similar role, gained in management consulting firms, FinTecs, startups, or VASPs with non-face-to-face customers\nStrong knowledge of the cryptocurrencies field, with proven experience in digital assets compliance \nKnowledge and experience working with at least one investigation software connected to cryptocurrency transactions \nComprehensive understanding of all types of financial crime patterns and of the AML \/ CTF landscape\nProven analytical and problem-solving skills\nWhat\u2019s in it for you\nFlexibility-first approach to work* including:\nUnlimited fully-paid annual leave\nRecharge Breaks \n20 weeks gender-neutral New Parent Leave \nHybrid Working*: \n60 days Work From Anywhere* following the 80\/20 Rule\n\u20ac500 Work from Home budget\nAn attractive individual stock option plan* in a high growth company, and a competitive salary\nExclusive premiums when trading on Bitpanda\nOccasional company-wide and team events \u2014 both in-person and virtually!\nLearning & development opportunities\nTop-notch \u201ctech pack\u201d \u2013 your choice between PC or Mac\nBitpanda merch to keep you swagged out and living the Bitpanda brand\nA global Bitpanda team of fast-moving, talented, \u201croll-up-your-sleeves-and-make-it-happen\u201d kind of people who are united (across cultures and time zones) by our unique way of working\n*These benefits do not apply for our internships and exceptions to our Hybrid Working policy apply to teams with shift schedules or for folks whose roles require them to be in office (think: Workplaces team or IT).\nAnd, above all, the opportunity to learn & grow as part of Bitpanda\u2019s incredible journey towards being Europe\u2019s future #1 investment platform.\nBitpanda is committed to fostering a fair and equal environment based on trust and mutual respect. We believe that a diverse and inclusive workplace is paramount to our success and we are committed to building a team that represents a wide variety of backgrounds, perspectives, and skills.","37":"Mitek (NASDAQ: MITK) is a global leader in digital & biometric identity authentication, fraud prevention, and mobile deposit solutions. Our verified identity platform and advanced image capture solutions are built on the latest advancements in biometric recognition, artificial intelligence, computer vision and machine learning, and trusted by over 7,500 organizations worldwide. We are headquartered in San Diego, California, with operations in the United Kingdom, Spain, France, Mexico, and the Netherlands. Visit us at www.miteksystems.com.\nWe are Virtual 1st! Whether you choose to work remotely from your home office or in-person from one of Mitek\u2019s offices, our practices, processes and tools are designed to enable your success. At Mitek, the Future of Work is about flexibility and preference wherever and whenever we are working.\nWe're looking for a Senior Cloud Engineer to join our global cloud operations team, to help us scale, maintain, and improve our SaaS products.\nYour initial mission will be focused on our internal Machine Learning infrastructure and operations initiative to help our organization streamline its Data and AI lifecycle.\nYou'll work alongside our internal engineering teams to design, architect, and automate cloud-based products, and support internal or customer-facing production infrastructure and systems. You'll develop tools and strategies for deployment,\u202ftesting, monitoring, and automation to support Mitek\u2019s goal to create best-in-class cloud-based products.\nYou should bring experience in infrastructure as code, configuration management, monitoring, metrics,\u202fand tools development for enterprise software, systems, and cloud operations. You should have a solid and successful background in infrastructure architecture and automation in serverless cloud environments.\u202fSome background in software development is a plus.\nYou should have great communication skills, apply skills creatively, have the passion to automate\u202feverything, be customer-oriented, and have a deep sense of ownership. \u202fA proven track record of designing, developing, and maintenance of dependable, mission-critical systems and products is a must.\nWhat will you do?\nContinuously improve the global cloud infrastructure in order to easily deploy, scale, secure, and build fault-tolerant systems.\nBuild and innovate tools and automation to replace manual operational processes, such as configuration and deployment.\nImplementation of system and service telemetry to enable improvements in reliability and availability.\nRespond to production issues, participate in an on-call schedule, and drive production operational\u202fexcellence.\nProvide build and deployment automation support (CI\/CD).\nEnsuring system security through understanding and execution of industry best practices.\nDevelopment of deep insight into application and service performance.\nWork with engineering teams on\u202fproduct\u202fdevelopment and resolution of issues related to application configuration, deployment, and performance.\nDesign automated systems management solutions with self-repair as the goal.\nCreate processes that enhance operational workflow and provide positive customer impact.\nWhat do you need to bring? (to be a good fit)\nBachelor\u2019s degree (or equivalent experience) in computer science or a related field.\nSkills and abilities typically associated with 4 or more years of experience in DevOps and Cloud technologies.\nProficiency in spoken and written English as a primary professional language.\nExperience with Amazon Web Services in a production environment including EC2, VPC, S3, RDS, IAM, ELB, and CloudWatch.\nExperience with Serverless architectures in AWS including Lambdas\/ DynamoDB\/ EventBridge\/ SNS\/ SQS\/Batch.\nExperience using and developing infrastructure as code.\nExpert at Bash and Python.\nExperience with Docker and related tooling and infrastructure at scale.\nExperience in maintaining and managing production environments at scale.\nExperience with operational monitoring tools for dashboarding, alerting, metrics, and logs.\nExperience with software development infrastructure and tools for source control and artifact management.\nWhat do we offer you?\nFlexible hours and the possibility to work fully remote (in Spain) or from our Barcelona office.\nOpportunity to join a successful and growing global Tech company that works with cutting-edge technologies, and be part of a highly qualified international team.\nAn innovative, fast-paced environment with a great culture.\nA diverse, inclusive, Agile-native ecosystem where everybody counts.\nAccess to continuous learning and development opportunities within our company.\nA highly competitive salary plus perks and benefits.\nWe take pride in enabling career growth in an environment of innovation and teamwork.  Our commitment to all Mitekians is to do meaningful work that matters.  Our culture is defined by delivering our best to our customers by providing high value solutions and impactful outcomes, by continuously challenging convention, and by caring for each other through collaboration and celebrating our successes.  We are committed to creating competitive, equitable compensation & benefits programs and career development opportunities.\nWe sincerely appreciate your interest in Mitek. We know your time is valuable and look forward to the potential of speaking with you further!\n#LI-OCL#LI-Remote","38":"Help Us Shape the Future of Healthcare   At League, we\u2019re big on building connections - both through our product and with each other. Our platform is consumer centric, personalized and always on. We\u2019re reimagining the health benefits experience to give people a more consumer-centric way to manage their health: immediate, seamless, and tailored to their unique needs. It\u2019s a front door to healthcare that empowers people to live healthier, happier lives. Every day.\nAs a Manager at League, you are responsible for accomplishing your own projects and goals, while managing a team of Individual Contributors. The Manager of Operations is responsible for the effective and successful management of labor, productivity, quality control, and data safety measures as established and set for by Operations Leadership.\nIn the role of Manager, and under the guidance of the Director of Client Operations, you:\nEffectively manage the day to day activities of yourself and your team to meet defined SLA(s)\nDevelop and implement timelines to manage multiple projects and competing deadlines to achieve organizational goals\nEstablish ongoing process improvement measures to increase efficiency, accuracy and scalability\nEstablish communications processes to ensure the appropriate dissemination of information to direct reports and across department leaders\nDevelop systems to monitor key operational processes to track the effectiveness, quality and cost of operating our business\nPromote a company culture that encourages top performance and high morale\nEmpower the team to improve their overall skills and product knowledge by conducting a bi-weekly 1:1 and a semi annual performance evaluation with each direct report\nRequired:\nAdvanced level understanding of US employee benefits\nExperience with data integration for benefit administration (e.g. HRIS, payroll, insurance carriers)\nExperience with reusable data processing models (e.g., enrollment & eligibility, self billing, payroll, COBRA & ACA integrations)\nPrevious experience working within SaaS \/ insurance \/ insurance administration \/ healthcare \nAbility to pass a background check and drug screen\n USA APPLICANTS ONLY: The US-specific compensation range below for this full-time position is exclusive of  bonus, equity and benefits. This range reflects the minimum and maximum target for base salaries for the position across all US locations. Where in the band you may land is determined by job-related skills\/experience and location. Your recruiter can share more about the specific salary range for your location during the hiring process.Compensation range for USA applicants only$75,086\u2014$112,629 USDAt League, everyone is welcome. We believe individuals should not be disadvantaged because of their background or identity, but instead should be considered based on their strengths and experience. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you are an individual in need of assistance at any time during our recruitment process, please contact us at recruitinginfo@league.com.\n\nOur Application Process:   Applying to a role you love can be exhausting, and understanding the next steps can feel vague and uncertain. You have done the hard part of submitting your application; let's do ours by sharing potential next steps\nYou should receive a confirmation email after submitting your application.\nA recruiter (not a computer) reviews all applications at League.\nIf we see alignment with League's needs, a recruiter will reach out to learn more about your goals. The recruiter will also share the team-specific interview process depending on the roles you are exploring.\nThe final step is an offer, which we hope you will accept!\nPrior to joining us, we conduct reference and background checks. Additional checks could be required for US Candidates, depending on the role you are exploring.\n  Here are some additional resources to learn more about League: Learn more about us in this short video! League, Cleveland Clinic collaborate to make employees healthier across North America League and Loblaw bring next-generation digital health platform to customers League Completes Workday Approved Integration\nRecognize and Avoid Employment scams. Practice safe job searching.\nScammers are getting craftier and leveraging fake job postings to get personal information. Know the warning signs and protect yourself from scammers. Learn more here.   Privacy Policy Review our Privacy Policy for information on how League is protecting personal data.","39":"605 is an independent TV measurement and analytics firm that offers advertising and content measurement, full-funnel attribution, media planning, optimization and analytical solutions. Comprised of engineers, analysts, data scientists, media experts and marketing strategists, 605 forges new paths using groundbreaking innovations that set industry standards for audience targeting and measurement.\nThe 605 Summer 2023 Internship Program is a ten week program, running from June 5th to August 11th. Interns for this program will be based out of our Syosset, NY office and will be expected to be in the office at least 2 days per week.\nWhy should you intern with 605?\nYou will receive valuable experience working with cutting edge technologies\nYou will learn from highly experienced and educated team members\nWe will welcome you with a team lunch, where you will be joined by senior members of management\nYou can expect a top of the line swag bag upon start\nMany of our part-time and full-time employees started as interns\nThis is a paid internship, where you will earn $20\/hr\nThe Quality Assurance Intern provides testing and validation support for 605\u2019s core products and processes. This intern will be responsible for establishing and performing testing procedures to ensure 605 software and data transformation processes are of the highest quality and to ensure end user requirements are met by 605 processes and products based on updates to code, environment and usage. The individual will be responsible for reviewing requirements, and then generating and executing test cases, test plans and test scripts to validate the product or service.\nYou will join a dynamic and fast-paced environment and work with cross-functional teams to deliver products that deliver the company\u2019s vision and strategy.\nEducational Components:\nFirst-hand exposure to workings of TV industry from experienced professionals\nHands-on data analytic experience using tools such as Databricks and Python\nTraining in working with SQL and database best practices\nOpportunity to hone verbal and visual communication skills in a business setting\n\nRequirements\nBachelor\u2019s degree in related field either in progress or completed\nExceptional written and verbal communication.\nProficiency in analytical thinking\nCollaborative team skills.\nIs conscientious about detail, thorough in completing tasks, and intellectually creative in solving technical challenges.\nStrong competence in Microsoft Office tools including Excel, Word and Powerpoint.\nPreferred Skills\nWorking knowledge of SQL, Pyspark and\/or Scala.\nKnowledge of the US television industry.\nKnowledge of the advertising industry.\nProficiency in Quality Assurance tools such as Test Rails or HP ALM\/Quality Center.\nKnowledge and experience in Agile\/SCRUM environments along with associated tools including JIRA and Confluence.","40":"Why We Work at Dun & BradstreetDun & Bradstreet unlocks the power of data through analytics, creating a better tomorrow. Each day, we are finding new ways to strengthen our award-winning culture and accelerate creativity, innovation and growth. Our 6,000+ global team members are passionate about what we do. We are dedicated to helping clients turn uncertainty into confidence, risk into opportunity and potential into prosperity. Bold and diverse thinkers are always welcome. Come join us!\nAbout the roleYou will be part of the team that is responsible for the accuracy and integrity of our UK and Ireland Identity Data.  You will deliver and maintain data engineering solutions that ensure consistent operation of our UK and Ireland Data Management System.  You will develop new innovative processes to manage data quality and streamline existing processes to execute data improvement plans more efficiently and effectively.   You will also be key technical support in conversations with our data partners to help understand their data and ensure we are maximizing value from all our data sources\nKey Responsibilities\nDay-to-day operations of our Data Management System; ensuring process and procedures run as expected and any bugs are fixed in a timely manner with business-critical processes prioritised\nArchitecting solutions; Design, develop and test fit for purpose, resilient, scalable, and future-proof data services.\nRecognise and exploit opportunities to ensure efficient and effective performance of Data processes. Explore new ways of conducting operational processes; developing ways of maximising the update cycle on data; achieving the best cost model whilst maintaining data quality\nWrite ETL scripts and code to make sure ETL processes perform optimally\nDesign, write and iterate code from development to production-ready. Understands security, accessibility, and version control. Can use a range of coding tools and languages.\nPlan, design, manage, execute, and report tests, using appropriate tools and techniques, and works within internal policy and regulations. Ensuring risks associated with deployment are adequately understood and documented\nDesign and maintain appropriate metadata repositories to enable understanding of data assets and full auditability.\nPartnering with cross-functional teams to understand how new sources will contribute towards the ongoing enhancement of data assets to achieve goals for database size, completeness, and other desirable improvements.\nCreation of operational reports to measure usability and performance of data sources\nContribute to the vision and scope for the next generation of our data to drive revenue, performance quality and ensure operational efficiency, including new types of data and emerging capabilities for data collection.\nSupport operational plans that deliver business requirements through leading and coordinating their development, testing, and managing stabilisation activities.\nWhat we're looking for\n3+ years of proven in-depth knowledge and experience of SQL and database querying languages\nKnowledge of other languages, like Python, would be advantageous\nAbility to use PowerBI would be advantageous\nExperience with ETL tools, in particular SSIS (SQL Server Integration Services)\nExperience working with API\u2019s and services\nHas a demonstrable understanding of how to expose data from systems (for example, through APIs), link data from multiple systems using different storage technologies\/access methods and deliver streaming services. Creates repeatable and reusable procedures.\nAbility to correctly execute test scripts under supervision. Understanding the role of testing and how it works.\nAware of the types of problems in databases, data processes, data products and services.\nAbility to run development using Agile and Kanban methodologies\nDynamic and results-driven with the focus on facilitating action and effecting change\nAn innovative and inspirational approach\nSelf-motivation with the desire to learn new techniques \u2013 relentlessly curious\nDemonstrable experience in Database design, modelling and best practice\nAnalytical, process and problem-solving skills in a highly complex environment. A clear thinker who can articulate database issues and solutions and gain support for implementation, whilst remaining focused on what is important. \nAbility to prioritise and multitask with flexible approach to changing deadlines and scope of project\nAbility to work independently\nA great team player\nGlobal Recruitment Privacy Notice","41":"Strength in Trust  \nAt OneTrust, we exist to unlock every company's potential to thrive by doing what's good for people and planet. Using cutting-edge technology and a real-world approach to privacy,\u202fGRC, ethics, and ESG, we\u2019ve created a no-nonsense platform to help supercharge the global push for Trust Intelligence. \nThe Challenge \nThe MLOps Engineer role is critical because it plays a key role in the successful deployment, management, and monitoring of machine learning models in production environments. At onetrust we are building several ML Model and deployment and operation in a secure, efficient, and effective manner, enabling onetrust to derive maximum value from their machine learning investments. \nYour Mission \nDesign the data pipelines and engineering infrastructure to support our clients\u2019 enterprise machine learning systems at scale\nTake offline models data scientists build and turn them into a real machine learning production system\nDevelop and deploy scalable tools and services for our clients to handle machine learning training and inference\nIdentify and evaluate new technologies to improve performance, maintainability, and reliability of our clients\u2019 machine learning systems\nApply software engineering rigor and best practices to machine learning, including CI\/CD, automation, etc.\nSupport model development, with an emphasis on auditability, versioning, and data security\nFacilitate the development and deployment of proof-of-concept machine learning systems\nBuild data systems and pipelines\nAutomate the deployment and scaling of machine learning models in production\nMonitor and maintain the performance and accuracy of machine learning models in production\nImplement continuous integration and delivery pipelines for machine learning models\nCollaborate with data scientists, software engineers, and other stakeholders to ensure the effective deployment and operation of machine learning models\nEnsure the security, privacy, and compliance of machine learning models and related data\nStay up-to-date with the latest technology and industry trends in MLOps\nYou Are:\nBachelor's or Master's degree in Computer Science, Information Technology, or a related field\n5+ years of experience in data engineering or a related field\nStrong analytical skills\nStrong communication and writing skills\nExcellent organizational skills\n3+ Years experience working with Cloud Platforms (i.e. Microsoft Azure, AWS, GCP)\n3+ Years experience on Python, Databricks \/ Hadoop\n3+ years experience in ML OPS\nBenefits\nAs an employee at OneTrust, you will be a part of the OneTeam. That means equity, bonuses, unlimited PTO, and 100% paid medical benefits (and that\u2019s just the beginning!).  \nOur employee rewards philosophy spans mental, physical, and emotional well-being because we want our people to succeed both in and out of the office. Some benefits differ depending on region, but here\u2019s what you can expect from our OneTeam Total Rewards Program: \nCompetitive Compensation: We offer top pay for top talent with competitive total packages including equity for all, performance bonuses, and retirement savings with match. We\u2019re also committed to fair and equitable pay practices. \nWorkstyle Flexibility: At home or in the office, we trust you to get the job done. Our people have the option to work in the office, fully remote, or a hybrid based on their role. Go green with commuter program discounts and in-office perks.  \nCareer Development: You\u2019re not just joining any company; you\u2019re joining the category-defining software platform for trust. You can become an expert and earn industry certifications with training and exams paid for by us and access to our learning & development program and guest speaker series. \nEmployee Recognition: We celebrate our accomplishments the best way we know how \u2013 together. Our people are invited to attend employee appreciation social events (including our awesome annual holiday party), participate in ticket giveaways for local city events based on your home office location, and celebrate one another through our #CheersforPeers channel. \nFocus on Wellbeing: Take the vacation or volunteer - we have unlimited PTO globally. You\u2019ll also have access to ClassPass memberships, generous company holidays and your birthday off, paid sick days, Employee Resource Groups (or, as we call them, Employee Trust Groups), and other ways to get connected or support company diversity, equity, and inclusion goals.  \nHealth Benefits: No package is complete without great health benefits. This role may receive company-paid employee healthcare premiums, parental leave, and access to mental health benefits and employee assistance programs. Specific benefits differ by location, so please check with your recruiter to specify what this role will receive. \nOur Commitment to You\nWhen you join OneTrust you are stepping onto a launching pad \u2014 the countdown has begun. The destination? A career without boundaries working alongside a diverse and inclusive crew who is passionate about doing meaningful work. As a pioneer, your voice and expertise will help chart the direction of an entirely new industry \u2014 Trust. Our commitment to putting people first starts with you. Your growth is part of the mission. Our goal is to give you the power to embark on the next phase of your uniquely, unique career\nOneTrust provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, colour, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by local laws.\n Resources  \nCheck out the following to learn more about OneTrust and its people: \nOneTrust Careers on YouTube\nYour Ultimate Guide to Careers at OneTrust\n@LifeatOneTrust on Instagram","42":"605 is an independent TV measurement and analytics firm that offers advertising and content measurement, full-funnel attribution, media planning, optimization and analytical solutions. Comprised of engineers, analysts, data scientists, media experts and marketing strategists, 605 forges new paths using groundbreaking innovations that set industry standards for audience targeting and measurement.\nThe 605 Summer 2023 Internship Program is a ten week program, running from June 5th to August 11th. Interns for this program will be based out of our Syosset, NY office and will be expected to be in the office at least 2 days per week.\nWhy should you intern with 605?\nYou will receive valuable experience working with cutting edge technologies\nYou will learn from highly experienced and educated team members\nWe will welcome you with a team lunch, where you will be joined by senior members of management\nYou can expect a top of the line swag bag upon start\nMany of our part-time and full-time employees started as interns\nThis is a paid internship, where you will earn $20\/hr\nThe Data Management Intern provides day-to-day operational support for data quality monitoring, and the management of core 605 reference data. This intern will be responsible for maintaining and ensuring the completeness and accuracy of key dictionaries and metadata within 605, including station\/network mappings and data reference tables. This role will be responsible for investigating data associated with Television Network and Station relationships and related information, as assigned by their Manager. This individual will also be responsible for providing operational support which includes (but is not limited to) identifying data issues, tracking issue resolution, daily monitoring and reporting on data quality, and implementing quality assurance best practices across the core 605 metadata and dictionaries.\nYou will join a dynamic and fast-paced environment and work with cross-functional teams to deliver products that deliver the company\u2019s vision and strategy.\nEducational Components:\nFirst-hand exposure to workings of TV industry from experienced professionals.\nHands-on data analytic experience using tools such as Databricks and SQL.\nTraining in working with SQL and database best practices.\nOpportunity to hone verbal and visual communication skills in a business setting.\n\nRequirements\nBachelor\u2019s degree in progress or completed\nExceptional written and verbal communication\nProficiency in analytical thinking\nCollaborative team skills\nIs conscientious about detail, thorough in completing tasks, and intellectually creative in solving technical challenges\nStrong competence in Microsoft Office tools including Excel, Word and PowerPoint\nPreferred Skills\nWorking knowledge of SQL, Data Bricks.\nWorking knowledge of tableau.\nKnowledge of the US television industry\nKnowledge of the advertising industry\nProficiency in Quality Assurance tools such as Test Rails or HP ALM\/Quality Center.\nKnowledge and experience in Agile\/SCRUM environments along with associated tools including JIRA and Confluence.\nAdditional Notes\nThis role will be expected to work 35\u201340 hours per week this summer. Ideal candidates would be able to continue on in a part-time role in the fall","43":"Robotec.ai is a software company that develops high-tech solutions for automated vehicles and robotics. Our multi-disciplinary teams consist of experts in robotics, electrical engineering, software development, machine-learning and human factors.\nWe are currently working on a project aimed at synthetic dataset generation for testing autonomous driving functions. You will use modern simulation tools based on established game engines and cloud services (AWS). You will join our team in setting up MLOps as a part of the CI\/CD pipeline for the autonomous driving stack.\n\nIf you want to learn more about projects you will work on in our company, check out our Case Studies or our projects on GitHub.\nRequirements\nUniversity degree in a related field e.g.: Computer Science, Electrical Engineering, Machine Learning, Computer Vision, Applied Physics or Robotics.\nStrong software engineering skills with Python\nGood understanding of machine learning\nDevOps experience implementing Continuous Integration \/ Continuous Delivery pipelines\nExperience working with MLOps tools (e.g., MLflow, Kubeflow, Amazon SageMaker)\nExperience in using AWS services for machine learning, cloud infrastructure & services, monitoring, logging and alerting tools\nProficiency with Docker,\n\u201cGet things done\u201d attitude\nAbility to learn and upskill rapidly.\nTeam-player mindset and good communication skills\nSelf-motivation and sense of ownership\nGenuine interest with robotics, computer simulation and\/or autonomous vehicles\nFluent English\nAdditional \u2013 nice to have skills:\nExperience in team management \/ tech lead role\nExperience with cloud-native Kubernetes services (e.g., Amazon EKS, GKE, AKS)\nFamiliarity with data related Python libraries and frameworks such as TensorFlow, PyTorch, Numpy, Pandas and Matplotlib\nBenefits\nWhat\u2019s in it for you:\nWork with the latest technologies\nOpportunity to contribute to open source\nOpportunity to assume leadership a role in the future\nCompetitive salary (up to 30 000 z\u0142 on B2B, contract of employment is also possible)\n26 days off on B2B contract\nCosy office space at Hala Koszyki, Warsaw\nPrivate medical care and sports card\nFlexible working hours in hybrid mode\nFriendly and team-oriented culture\nMore benefits coming soon!","44":"Company Description\nDo you want beneficial technologies being shaped by your ideas? Whether in the areas of mobility solutions, consumer goods, industrial technology or energy and building technology - with us, you will have the chance to improve quality of life all across the globe. Welcome to Bosch.\nPosition your career for long term success by joining the world's top admired motor vehicle parts supplier as ranked by Fortune. \nJob Description\nOrganization, analysis, and administration of Automotive Aftermarket Master Data in support of business objectives. \nManage the daily operations and transactions within Bosch AA SAP and affiliated systems. The role requires high levels of data competency, accuracy standards and reporting capacity. Our database harvest tens of thousands of products and its attributes, covering over 10 product lines; requiring a dedicated and organized approach to operate vast amounts of of data points.  \nWork cross functionally with an international team of Product Management, Sourcing, Purchasing, Controlling, Finance, Engineering and Logistics teams.\nMAIN RESPONSIBILITIES\n1) Master Data Management: Ensure continuity, operational excellence and efficient resolution of product data base maintenance requests covering the complete product life cycle. Including the continuous tasks of Part Number set-up, releases, transfer price updates, product blocks among other SAP Material Master operations.  \n2) Master Data Management improvement projects: Identify, organize, start, support or lead initiatives related to Simplification, Automatization, Quality Assurance, Risk Management and Problem Solving. \n3) Drive the usage of dashboards, reports and processes within the organization to improve decision making and efficiency. \n\n\n Qualifications\nBachelor\u2019s Degree required in Marketing, Business, Finance, Engineering, Data Science, Mathematics or similar\nOperational - administrative 2-5 years of relevant experience in automotive, industrial or manufacturing settings\nERP experience: SAP is a must (Material Management preferably)\nAnalytical, accuracy and problem-solving skills within a professional setting\nAbility to plan, organize and execute\nProficient in Microsoft Office suite (advanced Excel) as well as data base collecting, mining, exploration and analysis tools\nEnglish professional proficiency, as direct working environment requires written and spoken communication within an international setting","45":"Labelbox\u2019s mission is to build the best products to align with artificial intelligence. Real breakthroughs in AI are reliant on the quality of the training data. Labelbox's data engine enables organizations to dramatically improve the quality of their training data, which makes their machine learning models more accurate and performant. We are determined to build software that is more open, easier-to-use, and singularly focused on helping our customers get to production AI faster.\nCurrent Labelbox customers are transforming industries within insurance, retail, manufacturing\/robotics, healthcare, and beyond. Our platform is used by Fortune 500 enterprises including Allstate, Black + Decker, Bayer, Warner Brothers and leading AI-focused companies including FLIR Systems and Caption Health. We are backed by leading investors including SoftBank, Andreessen Horowitz, B Capital, Gradient Ventures (Google's AI-focused fund), Databricks Ventures, Snowpoint Ventures and Kleiner Perkins.\nAbout Active LearningIn machine learning, data curation is only part of the battle to create a successful model. Once data is labeled, it is used to train, validate, and test models with the goal of production deployment. Upon validation, an engineer may discover a model may perform well at predicting one particular subset or class of data, but struggle on another. \nThe mission of the Active Learning team is to enable rapid model iteration with tooling and workflows to surface insights into model performance after completing the training process. We seek to give engineers the tools they need to validate models against ground truth data, spot model inaccuracies, identify gaps in cohorts of training data, and initiate workflows to improve that data for future model versions.\nAbout the RoleAs our MLOps engineer, you will be responsible for building our model inference and training infrastructure for both internal and external users. This includes model serving using Tensorflow Serving or TorchServe; performance optimization; monitoring, maintenance, and reporting; integration with labeling and data curation processes; development of generic training and inference services; as well as debugging and troubleshooting.\nAbout You\nStrong software engineering skills. Experience working with distributed systems.\nYou have experience designing microservices and data processing pipelines at scale.\nWorking machine learning knowledge of either LLMs or Video Models.\nAbility to modify and train open source models.\nExperience with optimizing models for production deployments (e.g. architecture modifications, quantization, or fusing layers).\nExperience with distributed training and\/or inference.\nPrevious experience deploying systems for efficient batch or online ETL.\nLabelbox strives to ensure pay parity across the organization and discuss compensation transparently.  The expected annual base salary range for this United States based position is $170,000 - $215,000. This range is not inclusive of any potential equity packages or additional benefits. Exact compensation varies based on a variety of factors, including skills and competencies, experience, and geographical location.\nDo great work. From anywhere.\nWe hire great people regardless of where they live. Work wherever you\u2019d like as reliable internet access is our only requirement. We communicate asynchronously, work autonomously, and take ownership of our work.\n#LI-Remote","46":"REIMAGINE TRUST\nIncode is the leading provider of world-class identity solutions that is reinventing the way humans authenticate and verify their identities online to power a world of digital trust.\nThrough our revolutionary identity solutions, we are unleashing the business potential of universal industries including finance, government, retail, hospitality, gaming and more, by reducing fraud and transforming human interactions with data, products, and services.\nWe\u2019re in the process of rapidly scaling our diverse global team and we\u2019re looking for entrepreneurial individuals and leaders who are curious, driven, and excited by ownership to join a Unicorn-status scale-up!\nThe Opportunity \nAre you a passionate product manager who wants to build digital identity products for millions of end-users?  \nAs a Senior Product Manager at Incode, you will own the business strategy and vision for a multi-functional team to design, develop, test, and deploy new features and products. A successful candidate will have a solid underpinning in product management as well as knowledge of software development, excellent project management skills, great communication skills, and motivation to achieve results in a fast-paced environment. \nResponsibilities\nOwn product vision, strategy, and execution to build the AI & ML platform and tooling from data collection, to labelling, automation and quality assurance to empower our best-in-class AI driven identity verification technologies including ID verification, facial recognition, etc. \nLead the prioritization and development of your product's roadmap to deliver value to our customers and the business. \nDevelop hypothesis, success metrics & KPIs, run experiments, analyze data, and make improvements to machine learning platform, architecture, and data pipelines. \nPartner closely with analytics and engineering teams, and interface with cross functional stakeholders e.g., executives, sales, product, marketing, legal, and customer success teams. \nRegularly meet and work with our B2B customers to gather feedback and refine product strategy. \nDefine best practices to help build a data driven culture across the company.\nRequirements \nBA\/BS in Computer Science, Engineering or a similar discipline from a reputable University. \nMinimum 5 years of experience in product management within the AI\/ML domain; prior experiences in building Machine Learning platform, data labeling tools, etc. are highly preferred. \nMaster\u2019s degree in business, computer science or any related field. \nTrack record of working with AI\/ML\/Data Science and Engineering teams to define, build and maintain highly scalable, mission-critical systems. \nFull stack knowledge of building AI platform, microservice architecture, Cloud (AWS) architecture, ML infrastructure and architecture, risk and fraud modeling and controls. \nHigh-level understanding of machine learning concepts and general practices. \nExperience with rapid experimentation, including definition of hypothesis, success metrics, A\/B Testing and data analysis. \nProficiency in data analysis using SQL, Tableau, Redshift, and Python.\nAbility to work effectively within a team and build positive relationships cross-functionally. \nSelf-driven and highly motivated with a strong attention to accuracy and detail. \nExcellent troubleshooting, analytical and problem-solving abilities with a commitment to finding the root cause of issues. \nGood understanding of AI & ML ecosystem and products in the market.\nStrong written and verbal communication skills to help drive strategy and influence stakeholder teams. \nExperience leading a cross- functional team in an agile environment. \nOpen to learn, develop, change, experiment, and have fun! \n8 Aspects of our Culture:\nValues are what we value\nHigh performance\nFreedom & responsibility\nContext, not control\nHighly aligned, loosely coupled\nContinuous Feedback\nPay Top of Market\nPromotions & Development\nLearn more about Life at Incode!\nBenefits & Perks:\nMeaningful Equity\nFlexible Working Hours & Workplace\nOpen Vacation Policy\nWellness Program\nInternational Travel Opportunities\nAdditional benefit package according to location (401k, medical insurance, etc.)\n    Equal Opportunities:\nIncode is an equal opportunity employer, committed to creating a diverse and inclusive work environment. We take great pride in having an inclusive, diverse, and global team and are always on the lookout for talented, passionate people from all backgrounds and walks of life.\nApplicant Data Privacy:\nWe will only use your personal information in connection with Incode\u2019s application, recruitment, and hiring processes.","47":"At SiteMinder we believe the individual contributions of our employees are what drive our success. That\u2019s why we hire and encourage diverse teams that include and respect a variety of voices, identities, backgrounds, experiences and perspectives. Our diverse and inclusive culture enables our employees to bring their unique selves to work and be proud of doing so. It\u2019s in our differences that we will keep revolutionising the way for our customers. We are better together!\nWhat We Do\u2026\nWe\u2019re people who love technology but know that hoteliers just want things to be simple. So since 2006 we\u2019ve been constantly innovating our world-leading hotel commerce platform to help accommodation owners find and book more guests online - quickly and simply. We\u2019ve helped everyone from boutique hotels to big chains, enabling travellers to book igloos, cabins, castles, holiday parks, campsites, pubs, resorts, Airbnbs, and everything in between. And today, we\u2019re the world\u2019s leading open hotel commerce platform, supporting 34,000 hotels in 150 countries - with over 100 million reservations processed by SiteMinder\u2019s technology every year.\nAbout the (UPDATE JOB TITLE) role...\nUpdate job info here - Normal font size and leave no space at the end.\nWhat you\u2019ll do\u2026\n\nWhat you have\u2026\n\n\nOur Perks & Benefits\u2026\n- Equity packages for you to be a part of the SiteMinder journey - Hybrid working model (in-office & from home) \/ Fully remote- Mental health and well-being initiatives- Generous parental (including secondary) leave policy- Paid birthday, study and volunteering leave every year- Sponsored social clubs, team events, and celebrations- Employee Resource Groups (ERG) to help you connect and get involved - Investment in your personal growth offering training for your advancement\nDoes this job sound like you? If yes, we'd love for you to be part of our team! Please send a copy of your resume and our Talent Acquisition team will be in touch. When you apply, please tell us the pronouns you use and any adjustments you may need during the interview process. We encourage people from underrepresented groups to apply.\n#LI-Remote OR #LI-Hybrid","48":"About Apixa:\nApixa is specialized in solving challenging computer vision problems. We offer services and solutions in various areas of computer vision, including deep learning and artificial intelligence, hyperspectral imaging, pattern recognition, medical imaging, visual inspection, photogrammetry and 3D imaging. Over the years, Apixa has engaged in a multitude of both research oriented projects and industrial automation projects, and amongst its customers there are both renowned international players and high-tech niche players\nWhat will you do?\nYou build data pipelines and ML enablement systems while working with your colleagues to deploy AI systems (internally and in production).\nYou develop dashboards to gauge the performance over time of ML models.\nYou develop CI\/CD pipelines, in close collaboration with Apixa\u2019s engineers.\nCollaborate with internal research, development and QA teams to help ensure end-to-end quality.\nWrite and maintain architectural documentation.\n\nRequirements\nPrevious experience in a DevOps role\nFamilarity with AI and ML, and MLOps methodology\nFamiliarity with Windows and Linux deployment models\nFamiliarity with common CI\/CD tools and toolchains (e.g. Jenkins, Azure pipelines, TeamCity, ... )\nFamilarity with MLOps tools (e.g. MLFlow, Kubeflow,...)\nKnowledge of C++ and Python\nExperience with computer vision AI models is a plus\n\n\n\n\nBenefits\nApart from a competitive salary package, Apixa offers a fun and exciting work environment where you will be part of a team that is at the forefront of computer vision technologies. We also provide extensive training and educational paths so you can continuously grow your knowledge and sharpen your skills. You will be working in a team of collaborative and supportive colleagues in a culture where quality of life is key.\n\nTo find out more about our company culture, our offices, our job openings and the recruitment steps: https:\/\/www.apixa.com\/careers","49":"While candidates in the listed locations are encouraged for this role, we are open to remote candidates in other locations.\nYou will be the Product Manager for the ML Platform on Databricks. Your counterpart engineering and cross-functional teams will build a best-in-class hosted ML Platform that enables customers of all sizes to deliver business impact through training and deploying ML models. This platform empowers any company in the world to harness the same technologies that drive the success of major tech companies heavily investing in their own proprietary ML platforms.\nYou will coordinate all product activities from vision to implementation, including engaging large enterprise customers to understand their needs, developing long-term product strategy, defining product roadmaps, working with engineering to build those products, and coordinating with various internal stakeholders (both pre- and post-launch) to ensure product success.\nThe impact you will have:\nDeveloped a deep understanding of customer needs and use-cases in the Data Science and Machine Learning domain.\nCreated and communicated a competitive analysis of Data Science and ML solutions relevant to our customer's needs.\nDefined the end-to-end user experience for customer success beyond the scope of the ML Platform product and features.\nTook a feature from ideation \/ exploration with customers to full launch and rollout, including marketing plan and field enablement.\nWhat we look for:\n5+ years of Product Management or relevant Engineering Leadership position\nEducational background in computer science or related engineering practice\nExperience working with a Data Science\/ML stack, including Python, Jupyter, Scikit-Learn, TensorFlow\nUnderstanding of Data Platforms, Machine Learning Frameworks, and common ML deployment patterns (e.g. batch scoring, online\/real-time serving)\nStrong track record of delivering products with cross-functional teams common to enterprise software industry (field engineering, sales, marketing, partnerships, etc.)\nAnalytical skills to make data-driven decisions (e.g. analyze product usage)\nExcellent communication skills to clearly and concisely communicate complex topics to diverse stakeholders (engineers, customers, etc.) in written and verbal form\nExperience in working closely with enterprise customers and channel partners in the enterprise software industry\nBenefits\nComprehensive health coverage including medical, dental, and vision\n401(k) Plan\nEquity awards\nFlexible time off\nPaid parental leave\nFamily Planning\nGym reimbursement\nAnnual personal development fund\nWork headphones reimbursement\nEmployee Assistance Program (EAP)\nBusiness travel accident insurance\nCOVID-19 Vaccination Requirement\nAs a federal government contractor, Databricks requires new U.S. employees to be fully vaccinated against COVID-19. Proof of vaccination will be required as a condition of employment. Databricks will make reasonable accommodations based on medical conditions or religious grounds for qualified candidates in accordance with applicable law.\nAbout Databricks\nDatabricks is the lakehouse company. More than 7,000 organizations worldwide \u2014 including Comcast, Cond\u00e9 Nast, H&M and over 50% of the Fortune 500 \u2014 rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark\u2122, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world\u2019s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.\nOur Commitment to Diversity and Inclusion\nAt Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.","50":"About the Company\nClarifai is a leading, full-lifecycle deep learning AI platform for computer vision, natural language processing, and audio recognition. We help organizations transform unstructured images, video, text, and audio data into structured data at a significantly faster and more accurate rate than humans would be able to do on their own. Founded in 2013 by Matt Zeiler, Ph.D. Clarifai has been a market leader in AI since winning the top five places in image classification at the 2013 ImageNet Challenge. Clarifai continues to grow with employees remotely based throughout the United States and in Tallinn, Estonia.\nWe have raised $100M in funding to date, with $60M coming from our most recent Series C, and are backed by industry leaders like Menlo Ventures, Union Square Ventures, Lux Capital, New Enterprise Associates, LDV Capital, Corazon Capital, Google Ventures, NVIDIA, Qualcomm and Osage.\nClarifai is proud to be an equal opportunity workplace dedicated to pursuing, hiring, and retaining a diverse workforce.\nYour Impact\nAs one of Clarifai's ML-OPS Engineers, you will have impact within the developer community, machine learning field, and on Clarifai's business by using state-of-the-art machine learning tools, assisting with our innovation engine, and transferring your deep learning knowledge to others at Clarifai.\nThe Opportunity\nAs a member of our Research Team, you will solve real world problems through a process of prototyping, implementation, measurement, and iteration. You'll research the latest developments in machine learning, understanding what works best for our users. You will develop models, techniques, and tools and integrate new machine learning capabilities into Clarifai's machine learning platform.\nAs an ML-OPS Engineer on our product team, you will research the latest tools and techniques in machine learning and determine their potential use in our platform. You will run experiments to test performance, consider optimizations, and improve the features that we offer. You will work on a team of scientists and engineers, and be responsible for staying up to date with the latest research, testing and experimenting with new ideas and techniques, and building what works best into our products.\nWe are looking for someone motivated to learn and experiment with new ideas, and who is interested in staying up to date with the latest research in machine learning. We are looking for candidates interested in project ownership - you will have the opportunity to determine the best way to figure out a solution to our problems, how to evaluate your solution, and how it could be best used by our team. An ideal candidate will love trying out new ideas and developing the ones that work best into usable software.\nYou will:\nDevelop data processing workflows for optimized ingestion\nDevelop SOTA data augmentation techniques\nDevelop and Improve a robust experiment tracking system \nDesign KF pipelines for computationally intensive operations\nBuild python-utils for internal and external uses\n  Requirements\nFluent with using an NN framework such as TensorFlow, Keras, Caffe, or Torch, and understanding how back-propagation works\nFluent with Python, as well as experience with packages such as NumPy, pandas, scikit-learn, and matplotlib.\nExperience with popular machine learning hubs and frameworks, such as hugging face, OpenMMLab, and detectron2\nPhD\/Masters in Computer Science or related field \nKubernetes at a high level\nFamiliar with ML hardware and related technology\nKnowledge on scaling ML\nGreat to Have\nExperience working in product teams\nExperience with GO programming language\nExperience with TensorRT, Deepstream, TRITON\nProjects in video, speech, or NLP\nPublished Research papers\/patents\nContribution to open-source projects","51":"Company Description\nSyngenta Group is a $28B leading science-based agtech company, operating in more than 100 countries, with more than 50\u2019000 employees. We are proud to stand at the forefront of the tech revolution in agriculture. Using the latest digital innovations, data, and cutting-edge technologies we want to transform the way that crops are managed and enable farmers and agronomists to enhance efficiency and sustainable food production.\nOur business success reflects the quality and skill of our people. We recognize that human diversity is as important to our business as biodiversity. Embracing the unique perspectives and capabilities of our employees helps us continue to catalyze innovation, maximize performance, and create business value. Join us and help shape the future of agriculture.\nJob Description\nMake a difference\nIn this role you will work within a multidisciplinary global team to discover, define, and design experiences that empower farmers to work more effectively and efficiently by utilizing our data-driven solutions.\nThe ideal candidate will work collaboratively with Data Scientists, Data engineers, and Cloud Engineers to deploy and operate ML systems. You will help automate and streamline our ML operations and processes from discovery to deployment. You\u2019ll build and maintain tools for deployment, monitoring, and operations. You will also troubleshoot and resolve issues in development, testing, and production environments\nWe all have a critical role to play and add value. Here is how this role will help:\nBuild out our ML Ops platform in partnership with data scientists, data engineers, and cloud engineers\nOperate and maintain systems supporting the provisioning of new clients, applications, and features.\nSoftware deployment and configuration management in both QA and Production environments.\nCollaborate with Data Scientists and Data Engineers on product teams to containerize and build out deployment pipelines for new capabilities and services\nDesign, build and optimize applications containerization and orchestration with Docker and Kubernetes within a cloud environment\nAutomate applications and infrastructure deployments.\nSupport development, experimentation, verification\/validation and monitoring of AI\/ML models\nProduce build and deployment automation scripts to integrate between services\nBe a subject matter expert and an evangelist on DevOps practices, CI\/CD, Configuration Management and Cloud Computing Assess current level of maturity of the teams you are interacting with and prepare a technology adoption plan.\nContribute to a team culture that values effective collaboration, technical excellence, and innovation\nQualifications\nWe are highly people-focused \u2013 we look for professionals who are engaged, collaborative and excellent in execution. Leaders are expected to communicate effectively, develop teams and lead by example. Our industry and our function are changing rapidly so we are looking for new team members with a strong desire to develop themselves. You will be a great fit if you have:\nMinimum 5 years\u2019 post-academic experience working with cloud-base services and DevOps concepts, tools and practices\nExperience with the cloud computing platforms: AWS, GCP, Azure \nExperience in MLFlow, Kubeflow, Sagemaker, Vertex AI, or equivalent\nExperience with containerization using Docker and Singularity\nKnowledge and experience of machine learning frameworks: Tensorflow, Pytorch, or Keras\nExperience working in cross-functional Agile engineering teams\nProficiency with standard concepts and technologies used in CI\/CD build, deployment pipelines.\nExperience with pipeline automation tools, such as ArgoCD, Tekton, Gitlab CI\/CD, Jenkins\nExperience with scripting and coding using Python, R, Shell\nExperience with logging tools such as Splunk, ElasticSearch, Kibana, Logstash\nExperience with monitoring tools such as Prometheus, Grafana, AlertManager, PagerDuty\nBig data technical stack experience is a plus such as HDFS, Spark, Kafka\nExcellent Written and Verbal Communication Skills\nAbility to collaborate effectively with highly technical resources in a fast-paced environment\nAbility to solve complex challenges\/problems and rapidly deliver innovative solutions\nProficiency with feature stores, Graph databases, SQL, NoSQL, Data Lakes and other data storage technologies \nExperience with data visualization tools\nStrong overall software development approach. You deliver clean, well-tested code.\nAdditional Information\nWhat We Offer:\nFull Benefit Package (Medical, Dental & Vision) that starts the same day you do\n401k plan with company match, Profit Sharing & Retirement Savings Contribution \nPaid Vacation, 9 Paid Holidays, Maternity and Paternity Leave, Education Assistance, Wellness Programs, Corporate Discounts among others\nA culture that promotes work\/life balance, celebrates diversity and offers numerous family-oriented events throughout the year\nSyngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, marital or veteran status, disability, or any other legally protected status.\nFamily and Medical Leave Act (FMLA) \n(http:\/\/www.dol.gov\/whd\/regs\/compliance\/posters\/fmla.htm)\nEqual Employment Opportunity Commission's (EEOC)\n(http:\/\/webapps.dol.gov\/elaws\/firststep\/poster_direct.htm)\nEmployee Polygraph Protection Act (EPPA)\n(http:\/\/www.dol.gov\/whd\/regs\/compliance\/posters\/eppa.htm)\n        #LI-DO1\n ","52":"We believe that we are better together, and at Tripadvisor we welcome you for who you are. Our workplace is for everyone, as is our people powered platform. At Tripadvisor, we want you to bring your unique identities, abilities, and experiences, so we can collectively revolutionize travel and together find the good out there. \nWhat we do in Engineering:\nWe have a fun and friendly environment where the key objective is getting things done. Our engineers are part of the full process from design, to code, to test, to deployment and back again for further iteration. Our team is building the Machine Learning Platform for all data scientists across Tripadvisor. Our mission is to make data scientists more productive and to enable broader and deeper utilization of machine learning techniques to help improving the business performance.\nWe use variety of 3rd party packages, including MLFlow, Seldon for ML model tracking and deployment, Kubernetes for hosting models, Argo and Git for CI\/CD automation, Spark for big data processing. This is a rapidly changing field and we are deeply involved in open source community to help shape the technology evolution and are constantly looking for components to adopt in order to enhance our platform.\nWhat you\u2019ll do:\nCollaborate closely with data science teams to define feature specifications and develop high quality deliverables for our customers.\nProvide technical leadership for the team.\nDrive innovation, generate and promote new ideas, solve complex problems in innovative way\nDevelop across our evolving technology stack - we\u2019re using Python, Spark, Postgres, ArgoCD, Argo Workflow, Seldon, MLFlow and more. We are migrating into AWS cloud and adopting many services that are available in that environment.\nYou will have the opportunity to learn many cutting edge technologies around Machine Learning Platform. You will push the boundaries, to test, develop and implement new ideas, technology and opportunities, and be well rewarded and recognized for doing so.\nTake responsibility for all aspects of software engineering, from design to implementation, QA and maintenance.\nTouch code at every level \u2013 from the UI, backend microservices, database, big data processing, operations, to CD\/CI automation.\nTake ownership for the quality of the code.\nMentor and coach others on the team.\n  What we are looking for?\nComputer Science degree or equivalent experience\n10+ years of experience of commercial software development\nDemonstrated excellence participating on cross functional teams in fast-paced environments, both in terms of technical leadership and hands-on coding.\nExcellent ability to break down complex problems into simple solutions\nWillingness and ability to take on new technologies.\nStrong analytical skills and desire to write clean, correct and efficient code.\nSense of ownership, urgency and pride in your work.\nProven that you are a leader who prioritizes, communicates clearly, and partners effectively with both technical and non-technical employees.\nExcellent command of tools and expertise for troubleshooting production issues.\nExperience with Python, Docker, Kubernetes, Argo, Spark and AWS cloud services a plus.\nExposure to Machine Learning practices a plus.\n  What you\u2019ll get\nHighly competitive salary along with the following:\nAnnual bonus\nStock\nExcellent contributory pension\nFull family private medical cover\nFull dental cover\nAnnual wellbeing allowance (e.g. gym membership)\nPersonal travel reimbursement\nCritical illness plus full life cover\nFantastic career support and progression opportunities.\n*This role gives the flexibility to work from home and\/or the office.\nWe strive to create an accessible and inclusive experience for all candidates. If you need a reasonable accommodation during the application or the recruiting process, please make sure to reach out to your individual recruiter or our team at greenhouse@tripadvisor.com.\n  #LI-AM1","53":"Company Description\nCGG is a global technology and HPC leader that provides data, products, services and solutions in Earth science, data science, sensing and monitoring. Our unique portfolio supports our clients in efficiently and responsibly solving complex digital, energy transition, natural resource, environmental, and infrastructure challenges for a more sustainable future.\nOur Visions \nOur new \u201cIncubator\u201d team is working on the development of new business opportunities for sectors beyond Earth science. It represents an opportunity to make a real change in the company, while having fun in an enjoyable work environment. \nWe want to achieve 3 goals: \nBuild new and sustainable businesses. \nOffer everyone in the company the opportunity to be an innovator. \nChallenge the status quo.\nJob Description\nYou are pursuing the last year of Engineering School or Master 2, with a solid background in computer science and machine learning. You are looking for a six-month internship where you can deeply participate in the development of a MLOps framework.\nYou will build a fundamental tool that will ease the knowledge sharing across several teams within Incubator, helping them build their own production-ready Machine Learning pipeline on day-1. You will also contribute to a business-driven project which helps potential client solve their real-world problems.\nWhat will you learn? \nDuring your internship, you will work within the Incubator team, a new team within CGG. You will work on a fundamental MLOps project which will ease the creation of reproducible, maintainable, and modular ML code from experimentation to production, with straightforward interfaces ensuring that all ML tools work together seamlessly.  \nDuring the internship, you will work on the following aspects: \nDevelopment of mentioned MLOps framework, \nContribute to the research & development of ML algorithms for a business-driven project in Incubator,\nKnowledge sharing within & across teams,\nQualifications\nIn the last year of Engineerin School or Master\u2019s degree in computer science with Development & Machine learning & MLOps skills. \nWhat you will need :\nAbility to write robust & clean code in Python,\nWriting good tests,\nExperience with CI\/CD,\nExperience of development with one machine learning framework, Pytorch or Tensorflow,\nKnowledge of the life cycle of MLOps and understand the importance of building a production-ready pipeline at day-1 of experimentation,\nKnowledge of some opensource MLOps libraries\/framework is a plus (DVC, Kerdo, ZenML, MLFlow\u2026), \nComfortable with spoken\/written English,\nWe are also looking for someone with :\nEnthusiastic attitude towards learning and passion for your subject,\nThe technical agility to adapt your existing knowledge to a new field,\nAbility to effectively communicate technical concepts,\nAdditional Information\nStart date internship : April 2023 for 6 months\nWe see things differently. Diversity fuels our innovation, we value the unique ways in which we differ, and we are committed to equal employment opportunities for all professionals.","54":"We are looking for a Senior Machine Learning Engineer to join our Supply Management and Pricing team.  Partnering with hundreds of boutiques around the world as well as our very own in-house ones presents Farfetch with unique challenges when adjusting prices.  How well is the item performing?  How do different price points affect our margins?  Which markets will the item be selling to?  Pricing is often the most visible aspect of any e-commerce business and getting it right is crucial to our and our partners\u2019 success.\nTHE ROLE\nWorking in a cross-functional team of DS and MLE, you will be tasked with taking models from conceptualization into production.  We do not believe in a strict handoff where the work of a DS ends and that of an MLE begins.  ML is an inherently iterative process that benefits from the continuous close collaboration of the various players on a team.  Decisions you make and the components you build will directly impact your team's ability to deliver a quality product on time. Our MLOps cycle is constantly evolving but is predominantly built on Azure with aspects in GCP.  Both Databricks and K8s are most commonly used for our pipelines, but you are expected and in fact encouraged, to push the boundaries of what is possible. While this role is specific to a team, because of the nature of the work and your experience, you will be expected to interact with the greater DS\/MLE community at Farfetch to make sure ideas are shared and benefit everyone.\nWHAT YOU'LL DO\nRefactoring code to make it ready for production with an emphasis on -Maintainability, Testability, and Performance.\nWriting unit, integration, and data quality tests\nBuilding CI\/CD pipelines for both training and inference with an emphasis on -Automation, Visibility, Reproducibility, and Lineage.\nMonitoring the health of your pipelines- Dashboards, Alerting and CT\nWHO YOU ARE\nAs an experienced Senior Machine Learning Engineer, you will be an integral member of the team.  You will be expected to deliver and maintain production-grade pipelines, have a deep understanding of the domain itself, and be able to communicate clearly with various stakeholders.\nThe ideal candidate must possess the following qualities\nStrong understanding of Python\nExtensive experience writing production-quality code, especially as it pertains to MLPandas, scikit, PyTorch, and various other DS\/ML packages\nExtensive experience with MLOps and CI\/CD tooling\nExperience with Spark, or better yet, Databricks\nExperience with cloud providers such as Azure, GCP, or AWS\nExperience with IaC toolings such as Terraform\nExperience with data and experiment tracking such as DVC and MLFlow is beneficial\nExperience with orchestration\/workflow management such as Airflow","55":"Company Description\nRobert Bosch Engineering and Business Solutions Private Limited is a 100% owned subsidiary of Robert Bosch GmbH,\none of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions.\nWith over 18,000 associates, it\u2019s the largest software development centre of Bosch, outside Germany, indicating that it is the\nTechnology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region.\nJob Description\nAs an MLOps Engineer, you will join the Video Perception team, at the forefront of autonomous vehicle development. Our goal is to sense physical objects in the world using Deep Learning and other cutting-edge technologies\nMust Have requirements (Hands On experience):\nRich hands-on experience in writing object-oriented code using Python\n3+ years of experience in MLOps and Data engineering, including model versioning, model and data lineage, monitoring, model hosting and deployment, scalability, orchestration, continuous training & deployment, and automated pipelines\nUnderstanding of Data Structures, Data Systems and data base management, and software architecture\nExperience in using MLOps frameworks like Kubeflow, MLFlow, Airflow Pipelines for building, deploying, and managing multi-step ML workflows based on Docker containers and Kubernetes\nCloud Exposure: Experience with Azure cloud services, Azure functions, Azure compute environments, etc.\nBuild and optimize MLOps pipeline from data curation to automatic model deployment\nStrong DevOps mentality: Knowledge of making a complicated pipeline simple and easy to maintain, with proven experience of Terraform\/Spark\nImprove system architecture and infrastructure on Cloud for high-performance and scalable platform.\nQualifications\nExposure Needed:\nExposure to deep learning approaches and modeling frameworks (PyTorch, Tensorflow, Keras, etc.)\nWork throughout machine learning products\/services integration pipeline i.e., model inference, service integration, service testing, deployment, and maintenance.\nMinimum Requirements:\nB.Sc. in Computer Science \/ Software Engineering\n3+ years of experience in MLOps and Data engineering,\nAdditional Information\nGood to have:\nExperience with SQL and working with cloud technologies\nExperience with numerical\/ML python libraries (NumPy, Pandas, Pyspark, TensorFlow)\nExperience with CICD pipelines\n ","56":"Data and Machine Learning (ML) are revolutionizing the way of doing business at a global scale. sennder is a European digital freight forwarder with a data-centric problem-solving approach to build the next generation of supply chain and road logistics services. Do you want to help us to shape the future?\nWe are looking for a Senior) Machine Learning Engineer (MLOps) o join our central Machine Learning Engineering team as part of sennder\u2019s Data department. The department\u2019s mission is to \u201cRelentlessly build exceptional value-adding products that inspire data-centricity in everything sennder does\u201d. We\u2019re a large, diverse team of ML\/data engineers, data scientists, analysts and technical product people that are passionate by such mission. We want to attract and train world-class talent to form a incredible group that aim to provide you with the most productive and growth-friendly time of your career.\nAll Data dept. teams are multidisciplinar (e.g.: data engineering, MLOps, Data Science). The teams\u2019 scope ranges from creating a unique technological backbone for our data platform to developing advanced predictive and prescriptive analytical services. Our proprietary data platform enables our operation teams to work in a distributed analytics-as-a-service ecosystem where everyone is empowered to be data driven in every decision they make. Our predictive and prescriptive analytics services bring us an unprecedented competitive advantage in terms of business automation across the industry. The obtained insights are then translated in a better customer experience, enabling a scalability flywheel data and revenues grow exponentially with each\nother. Every day, we acquire 3M+ new real-time data points (augmenting by the day!) about the cross-region road logistics industry in Europe. This data is used to build the future of logistics marketplaces where pricing optimization, load-to-carrier recommendation, load search and network optimization happen in an automated fashion. Can you even imagine where we can go with your help? Let\u2019s #keepOnTrucking... together!\n  YOUR MISSION:\nDesign and maintain scalable ETL data pipelines \nDesign and develop health and performance monitoring tools (MLOps) of data pipelines and the machine learning services in production;\nDesign and improve heterogeneous, asynchronous and high-performance large-data processing pipelines from\/to multiple sources\/destinations;\nOperationalize innovative, data-intensive, end-to-end machine-learning(ML)-based decision engines;\n  YOUR PROFILE:\nYou are someone who\nHas extensive experience with one or more orchestration tools (e.g Airflow, Flyte, Kubeflow)\nHas experience working with MLOps tools like experiment tracking, model registry tools and feature stores (e.g MLFlow, Sagemaker, Azure)\nHas extensive experience with DevOps focused around data intensive applications. You are comfortable with infrastructure-as-code, you have used the likes of Terraform, Kubernetes extensively. \nHas experience building and scaling model serving tools, i.e building APIs with tight SLAs.\nAdheres to best coding practices. You find joy in beautifully written code. \nWorks the best in Agile teams.\nHas experience with a programming language(Python preferred).\n  BONUS:\nExperience in the digital logistics industry.\nExperience in Machine Learning modelling, especially in Pricing, Recommendations.\nMentoring experience.\n  ABOUT sennder:\nsennder is moving trucks with the power of data to unlock endless and sustainable capacity at unparalleled quality. Through our proprietary transportation operating system, built by our in-house tech teams, we not only connect shippers to our fleet of thousands of trucks, but also improve how they move products in sustainable, cost-efficient, and transparent ways - making the logistics industry fit for the future. In a traditional industry, we\u2019re growing and moving fast to digitally automate all road logistics processes. \nWe are building a curious team that is driven by an ambitious desire to solve the toughest logistics puzzles. What others may consider uncertainty, we see as an opportunity to learn and be proactive. We invite you to go on this journey with us and be part of one of Europe\u2019s inspiring growth stories as we fast-forward road logistics into digitalization. \n  Get to know us, our culture, green business, funding history, and more on our blog here.\n  Why Us?\nAt sennder, we want to maximize the individual\u2019s potential for all employees and reinforce an inclusive culture and environment of continuous learning that empowers people to succeed as a team. In addition to humility, we value commitment, team spirit, respect, and kindness to build trusted relationships across teams. Learn more on our career site. \nA fast-growing, start-up-oriented international team of 1000+ people with 65+ nationalities spread across 8 country offices with English as our company language.\nContinuous feedback and bi-annual review process for personal development, professional growth, and career opportunities. We also use \u201cObjectives and Key Results\u201d for company goals.\nA structured promotion process, providing everyone with fair and transparent career growth.\nLearning and development opportunities on the job and through conversations with your manager.\nVarious opportunities to connect with colleagues, formally and informally, digitally or in-person (when allowed), through regular team events, company get-togethers, and partnership events with other companies and local organizers.\nFlex\/hybrid remote working options.\nWhen in office: unlimited snacks, drinks, and fruits.\nAll interviews are currently conducted on a remote basis.\nPlease send your application in English and help us reduce negative unconscious bias by leaving out your picture, age, address, and other unnecessary information in your CV. We only want to know the merits on which you\u2019d be great for this role.\nWe value humility and we're as interested in your character as we are in your talent. Please apply, even if you feel you only meet part of our listed criteria. Diversity drives our innovation and we offer a collaborative, dynamic and international work environment. Just be yourself. We are excited to meet you and for you to join us in shaping the future of the logistics industry in Europe.\nIf you have any questions or problems please reach out to us at ta@sennder.com. We do not accept applications via email.\n#LI-MS1","57":"The AdTech & Data Operations Lead reports to the Head of AdTech & Solutions and is responsible for owning, managing, and maintaining data operations and adtech partner relations for Insider\u2019s Advertising business while partnering with Revenue Operations\u2019 Department Heads, Solutions Engineering, Product & Tech, & Editorial in a multi-faceted capacity.\nResponsibilities:\nPlan, design, and build audience segments in line with IAB standards, 1st Party Readership consumption & behaviors, engagement, intent, contextual, psychographics, demographics, Google\u2019s Topics, FLEDGE, and other future solutions via Insider\u2019s DMP and supplemental tools\nInvestigate, test, and prove the success or failures of alternative identifiers and solutions in the adtech ecosystem with our SSP partners to help address anonymous users\nOwn all ad tech and data provider relationships in conjunction with the Head of AdTech & Solutions\nVetting of net new data providers for data enrichment opportunities, audience profiling, and additional opportunities and solutions\nBuild relationships with key stakeholders across Revenue, Product, Technology, & Editorial teams to improve and automate workflows and processes, including but not limited to: content tagging,\nPartner with Data Products, Data Engineering, Solutions Engineering, & Tech teams on data centralization, data visualization,  data modeling, data manipulation, data visualization, platform integrations, and overall data-based innovation and data innovation projects leveraging cloud provider services (Snowflake, AWS, GCP)\nQualifications:\nUnderstanding how ad operations, programmatic buying, and audience segmentation works in the Buying (Brand\/Advertisers & Agencies) and Selling (Publishers) sectors\nKnowledge of relational databases, data schemas, data joins, data modeling, data science, and data manipulation\nProficient experience working with SQL for data querying, and more\nExperience working with Snowflake, Google Cloud Platform, AWS, or similar data warehouse technologies\nBuilding relationships with internal and external stakeholders, clients, and team members\nAlways curious and willing to learn, try new things, and not be afraid to fail\nPersonable with everybody, even-keeled, and analytical thinker\nSalary & Benefits:\nSalary: $95,000. - $115,000. (dependent on skills, experience, and competencies)\nMedical, health, and vision\nUnlimited PTO, paid holidays, and parental leave\nMatched 401k plan\nAdditional benefits include commuter benefits, phone reimbursement, gym membership discounts, etc.\n Are you passionate about this opportunity, but worried that you don\u2019t have 100% of the experience we\u2019re looking for? We still want to hear from you! Apply online and let us know why you would make a great addition to the Insider community.\nAbout Us: Insider Inc. is the global media company behind Insider and an ever-growing family of brands. Our mission is to inform and inspire the digital generation and become the most influential journalism brand in the world. We reach an audience of more than 375 million users with our stories, which command attention and inspire action.\nOur core value is effectiveness. We make things happen. We listen to each other, learn from each other, and take risks together. We understand that a diverse set of perspectives and an inclusive environment are critical to our success. All of this helps us get better every day. Check out our mission, values, and culture page to learn more.\nInsider Inc supports a distributed workforce that allows for varied work locations. Many roles are eligible for 100% remote or hybrid remote\/office work unless otherwise noted.","58":"Wealthsimple is on a mission to help everyone achieve financial freedom, no matter who they are or how much they have. Using smart technology, Wealthsimple takes financial services that are often confusing, opaque and expensive and makes them simple, transparent, and low-cost.\nOur team is reimagining what it means to manage your money. Smart, high-performing team members will challenge you to learn and grow every day. We value great work and great ideas \u2014 not ego. We're looking for talented people who love a fast-paced environment, and want to ship often and make an impact with groundbreaking ideas. We\u2019re a remote-first team and output is more important than facetime, so where you choose to work is up to you \u2014 as long as you have internet access, you can work from anywhere in Canada. Be a part of our Canadian success story and help shape the financial future of millions \u2014 join us! At Wealthsimple, we are building products for a diverse world and we need a diverse team to do that successfully. We strongly encourage applications from everyone regardless of race, religion, colour, national origin, gender, sexual orientation, age, marital status, or disability status. Wealthsimple provides an accessible candidate experience. If you need any accommodations or adjustments throughout the interview process and beyond, please let us know.\nRead our Culture Manual and learn more about how we work.\nAbout the role\nThe AML Operations team is responsible for the detection, response and elimination of inherent and residual money laundering and terrorist financing risks. As an AML\/CTF subject matter expert, the Senior Analyst will be responsible for managing complex investigations and support the overall development of Wealthsimple\u2019s AML program. This role will require attention to detail, innovative thought, resourcefulness, and the ability to apply a rational, research-oriented approach to the work at hand. \nIn this role, you will:\nReview and adjudicate alerts that are generated using standard policies, procedures and tools, aimed at meeting internal and external AML regulatory requirements. Alerts include, but are not limited to:\na. Name Screening matches against relevant Adverse Media, PEP, Economic Sanctions and Terrorism Listsb. Transaction Monitoringc. Unusual Transaction Reports (UTR) \nDocument and report investigation findings and prepare comprehensive case files with required supporting documentation. \nDraft Suspicious Transaction Reports (STRs) for filing to FINTRAC.\nEngage in critical thinking and leverage data analysis techniques and pattern detection to uncover financial crime.\nManage multiple alerts\/cases at a time and maintain Service Level Agreements within specified timeframes.\nParticipate in bi-weekly calibration sessions with peers and relevant internal staff to shape and enhance the growth of the team and the AML program overall.\nProvide assistance in performing quality assurance reviews of Analyst work product, and deliver neutral, accurate and constructive feedback.\nWork collaboratively with peers and manager to help drive execution, meet quality and production goals and deadlines.\nThe ideal candidate for this role has:\n2+ years of experience in financial technology or technology-driven financial services firm with experience in AML\/CTF programs\nThorough understanding of AML\/CTF risks and regulations\nKnowledge of transaction monitoring and name screening processes\nExperience performing complex AML\/CTF investigations including writing detailed cases, providing recommendations, and filing of regulatory reporting\nHave high level of precision and attention to detail\nInvestigative mentality; identifies gaps and challenges, asks the right questions at the right time, and looks beyond the obvious for solutions\nAbility to do independent research\nResourceful, persistent and able to thrive in fast paced environment\nAbility to take ownership with a proactive, not reactive, approach\nGreat communication skills, both verbally and via written reports\nPassionate about technology, and eager to grow in the AML industry","59":"Company Description\nSyngenta Group is a $28B leading science-based agtech company, operating in more than 100 countries, with more than 50\u2019000 employees. We are proud to stand at the forefront of the tech revolution in agriculture. Using the latest digital innovations, data, and cutting-edge technologies we want to transform the way that crops are managed and enable farmers and agronomists to enhance efficiency and sustainable food production.\nOur business success reflects the quality and skill of our people. We recognize that human diversity is as important to our business as biodiversity. Embracing the unique perspectives and capabilities of our employees helps us continue to catalyze innovation, maximize performance, and create business value. Join us and help shape the future of agriculture.\nJob Description\nMake a difference\nIn this role you will work within a multidisciplinary global team to discover, define, and design experiences that empower farmers to work more effectively and efficiently by utilizing our data-driven solutions.\nThe ideal candidate will work collaboratively with Data Scientists, Data engineers, and Cloud Engineers to deploy and operate ML systems. You will help automate and streamline our ML operations and processes from discovery to deployment. You\u2019ll build and maintain tools for deployment, monitoring, and operations. You will also troubleshoot and resolve issues in development, testing, and production environments\nWe all have a critical role to play and add value. Here is how this role will help:\nBuild out our ML Ops platform in partnership with data scientists, data engineers, and cloud engineers\nOperate and maintain systems supporting the provisioning of new clients, applications, and features.\nSoftware deployment and configuration management in both QA and Production environments.\nCollaborate with Data Scientists and Data Engineers on product teams to containerize and build out deployment pipelines for new capabilities and services\nDesign, build and optimize applications containerization and orchestration with Docker and Kubernetes within a cloud environment\nAutomate applications and infrastructure deployments.\nSupport development, experimentation, verification\/validation and monitoring of AI\/ML models\nProduce build and deployment automation scripts to integrate between services\nBe a subject matter expert and an evangelist on DevOps practices, CI\/CD, Configuration Management and Cloud Computing Assess current level of maturity of the teams you are interacting with and prepare a technology adoption plan.\nContribute to a team culture that values effective collaboration, technical excellence, and innovation\nQualifications\nWe are highly people-focused \u2013 we look for professionals who are engaged, collaborative and excellent in execution. Leaders are expected to communicate effectively, develop teams and lead by example. Our industry and our function are changing rapidly so we are looking for new team members with a strong desire to develop themselves. You will be a great fit if you have:\nMinimum 5 years\u2019 experience working with cloud-base services and DevOps concepts, tools and practices\nExperience with the cloud computing platforms: AWS, GCP, Azure \nExperience in MLFlow, Kubeflow, Sagemaker, Vertex AI, or equivalent\nExperience with containerization using Docker and Singularity\nKnowledge and experience of machine learning frameworks: Tensorflow, Pytorch, or Keras\nExperience working in cross-functional Agile engineering teams\nProficiency with standard concepts and technologies used in CI\/CD build, deployment pipelines.\nExperience with pipeline automation tools, such as ArgoCD, Tekton, Gitlab CI\/CD, Jenkins\nExperience with scripting and coding using Python, R, Shell\nExperience with logging tools such as Splunk, ElasticSearch, Kibana, Logstash\nExperience with monitoring tools such as Prometheus, Grafana, AlertManager, PagerDuty\nBig data technical stack experience is a plus such as HDFS, Spark, Kafka\nExcellent Written and Verbal Communication Skills\nAbility to collaborate effectively with highly technical resources in a fast-paced environment\nAbility to solve complex challenges\/problems and rapidly deliver innovative solutions\nProficiency with feature stores, Graph databases, SQL, NoSQL, Data Lakes and other data storage technologies \nExperience with data visualization tools\nStrong overall software development approach. You deliver clean, well-tested code.\nAdditional Information\nWhat We Offer:\nFull Benefit Package (Medical, Dental & Vision) that starts the same day you do\n401k plan with company match, Profit Sharing & Retirement Savings Contribution \nPaid Vacation, 9 Paid Holidays, Maternity and Paternity Leave, Education Assistance, Wellness Programs, Corporate Discounts among others\nA culture that promotes work\/life balance, celebrates diversity and offers numerous family-oriented events throughout the year\nSyngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, marital or veteran status, disability, or any other legally protected status.\nFamily and Medical Leave Act (FMLA) \n(http:\/\/www.dol.gov\/whd\/regs\/compliance\/posters\/fmla.htm)\nEqual Employment Opportunity Commission's (EEOC)\n(http:\/\/webapps.dol.gov\/elaws\/firststep\/poster_direct.htm)\nEmployee Polygraph Protection Act (EPPA)\n(http:\/\/www.dol.gov\/whd\/regs\/compliance\/posters\/eppa.htm)\n        #LI-DO1\n ","60":"Wealthsimple is on a mission to help everyone achieve financial freedom, no matter who they are or how much they have. Using smart technology, Wealthsimple takes financial services that are often confusing, opaque and expensive and makes them simple, transparent, and low-cost.\nOur team is reimagining what it means to manage your money. Smart, high-performing team members will challenge you to learn and grow every day. We value great work and great ideas \u2014 not ego. We're looking for talented people who love a fast-paced environment, and want to ship often and make an impact with groundbreaking ideas. We\u2019re a remote-first team and output is more important than facetime, so where you choose to work is up to you \u2014 as long as you have internet access, you can work from anywhere in Canada. Be a part of our Canadian success story and help shape the financial future of millions \u2014 join us! At Wealthsimple, we are building products for a diverse world and we need a diverse team to do that successfully. We strongly encourage applications from everyone regardless of race, religion, colour, national origin, gender, sexual orientation, age, marital status, or disability status. Wealthsimple provides an accessible candidate experience. If you need any accommodations or adjustments throughout the interview process and beyond, please let us know.\nRead our Culture Manual and learn more about how we work.\nAbout the role\nThe AML Operations team is responsible for the detection and mitigation of inherent and residual money laundering and terrorism financing risks. As a crypto AML\/CTF subject matter expert, the Senior Analyst will be responsible for managing complex investigations and support the overall development of Wealthsimple\u2019s AML program. This role will require attention to detail, innovative thought, resourcefulness, and the ability to apply a rational, research-oriented approach to the work at hand. \nIn this role, you will:\nReview and adjudicate alerts that are generated using standard policies, procedures and tools, aimed at meeting internal and external AML regulatory requirements. Alerts include, but are not limited to:\na. Crypto Transaction Monitoring alertsb. Fiat Transaction Monitoring alertsc. Name Screening matches against relevant Adverse Media, PEP, Economic Sanctions and Terrorism Listsd. Unusual Transaction Reports (UTR) \nDraft Suspicious Transaction Reports (STRs) and Large Virtual Currency Transaction Reports (LVCTRs) for filing to FINTRAC.\nEngage in critical thinking and leverage data analysis techniques and pattern detection to uncover financial crime.\nManage multiple alerts\/cases at a time and maintain Service Level Agreements within specified timeframes.\nParticipate in bi-weekly calibration sessions with peers and relevant internal staff to shape and enhance the growth of the team and the AML program overall.\nProvide assistance in performing quality assurance reviews of Analyst work, and deliver neutral, accurate and constructive feedback.\nWork collaboratively with peers and managers to help drive execution, meet quality and production goals and deadlines.\nThe ideal candidate for this role has:\n1+ years of AML\/CTF experience with a cryptocurrency exchange. Working experience with blockchain analysis tools (such as Chainalysis) is an asset.   \n2+ years of AML\/CTF experience with a financial institution or financial services company. \nThorough understanding of AML\/CTF risks and regulations, and crypto crime typologies.\nKnowledge of transaction monitoring and name screening processes.\nExperience performing complex AML\/CTF investigations including writing detailed cases, providing recommendations, and filing of regulatory reporting.\nHave a high level of precision and attention to detail.\nInvestigative mentality; identifies gaps and challenges, asks the right questions at the right time, and looks beyond the obvious for solutions.\nAbility to do independent research.\nResourceful, persistent and able to thrive in a fast paced environment.\nAbility to take ownership with a proactive, not reactive, approach.\nGreat communication skills, both verbally and via written reports.\nPassionate about technology, and eager to grow in the crypto and AML industries.","61":"Senior Data Scientist - Computer Vision and MLOps \nEvents in recent years have made us all too familiar with the havoc that natural disasters can wreak, and the increasing frequency and intensity with which they are occurring.  Despite record levels of losses, conventional methods of risk modeling continue to paint at best an incomplete picture of these threats.\nZesty.ai uses novel data gathering and data science methods to produce higher quality information about the risks to property from catastrophes like floods and wildfires.  While AI alone may not be able to thwart these disasters, it can help us become more prepared for them, and ultimately that will lead to better outcomes.\nAs a Senior Data Scientist - Computer Vision and MLOps, you are comfortable and excited to work closely with the Data Science and Machine Learning team to build the best AI tech possible. You will scale the development of top-tier models by using diverse data sources to provide strong insights and maximize the impact of our company efforts. You thrive in a collaborative, creative environment that moves fast and you\u2019re comfortable setting in place structures and processes to help the company scale. \nThe Opportunity:\nWe\u2019re looking for a Senior Data Scientist that would be excited to work on computer vision projects for the first 3 to 6 months in order to get a good sense of our systems and then transition into an MLOPs role (we feel that this would be the best way for you to be familiar with our problem set and systems).\nIn the initial 3 to 6 months, you\u2019ll develop and improve on our computer vision property insights models using the latest techniques in deep learning.\nFollowing the initial rotation with the deep learning team, you\u2019ll transition into an Ops role where you\u2019ll work on improving our tooling, processes and systems to help enable our team to perform at its best.\nTranslate product management, engineering, and business constraints and queries into tractable data science questions.\nWhat You Bring to the Zesty.ai Team:\nExperience working with deep learning \/ neural network models (using PyTorch, TensorFlow, Keras, Caffe) \nExperience working with computer vision and building and testing computer vision systems\nExperience deploying machine learning models in production environments\nBA \/ BS \/ BEng degree in Math, Physics, Computer Science, Engineering, or Economics. MS degree or Ph.D. is certainly a bonus\nStrong organizational and management skills with past experiences implementing best practices and processes\nExperience working with large image datasets (great if you\u2019ve already worked with satellite imagery and related tools OpenCV, Pillow, etc.)\nProficient in SQL, BigQuery\nExperience working with cloud platforms (AWS, Google Cloud, etc) \nKubernetes, docker experience\nMust be legally eligible to work in Canada\nWhy ZestyAI:\nBe part of a well-funded growth-stage start-up\nMarket competitive comp and equity incentives to give you a stake in our future\nComprehensive health care plan \nFlexible Time Off \nAn upbeat and collaborative work culture \nCompany-sponsored outings and offsites\n\nAll of your personal information will be kept confidential according to EEO guidlines.","62":"Company\nPixelogic Media Partners, LLC provides distribution services and technology solutions to the entertainment industry. We help studios, broadcasters and digital retailers localize and distribute their feature and episodic titles to global audiences on-time and with superior quality.\nOur service offerings cover end-to-end workflows including language services such as scripting, subtitling, access services, dubbing, text and metadata localization in over 50 languages. Our technical services master and prepare this content in all distribution products including digital cinema, digital media and physical media (Ultra HD Blu-ray, Blu-ray and DVD).\nTo date, we serviced thousands of titles for iTunes, Google Play, YouTube, Netflix, Amazon, Movies Anywhere and others. We also authored thousands of Ultra HD Blu-ray, Blu-ray and DVD discs. Our research and development team works on cutting-edge technologies such as 4K, high dynamic range (Dolby Vision, HDR10+), artificial intelligence and machine learning, software automation and our proprietary end-to-end operating platform branded as pHelix.\nAbout the role\nTo support our various departments including Digital Cinema, Localization, Digital Mastering etc, we are seeking a Data Specialist who can fulfill the responsibility of handling day-to-day data entering or leaving the facility in the form of physical media or electronic transmission, and ensure that all security protocols are followed when dealing with sensitive material.\nIn addition, the ideal candidate will have a good understanding of the transmission methods and workflows used widely in the media industry. You should have knowledge and experience with various physical media formats including films, drives and tapes. You should be highly motivated, possess a flexible attitude and adapt quickly in a fast pace environment. Be able to work as part of a team that deal with changing priority and workloads.\nSchedule:\nWed - Sun, 9:00 - 17:00\n\nResponsibilities:\nEnsuring incoming, outgoing, and internal physical elements are properly tracked within the facility\nIngest source materials via physical media or electronic transmission\nMake all final internal and external deliveries\nCreate video proxies using source media for different workflows\nConduct initial pre-qualifications check on incoming materials\nFollow internal as well as client specific security protocols\nMust be willing to work weekends, holidays and pass their normal scheduled shift if needed\nOther related tasks as assigned to fulfill responsibilities\nRequirements\nExperience in transmissions related to the media industry and postproduction workflows\nExperience in industry standard delivery and file transfer mechanisms including Aspera P2P, Aspera Faspex & Signiant\nExperience in dealing with different types of physical media formats including drives, tapes, disks as well as managing LTO archive\nExperience in MAC OS, Windows and Linux Understanding of computer networks, including hardware, protocols and firewalls in a production environment a plus\nUnderstanding of media including metadata, formats and codec etc.\nUnderstanding of XML format is a plus\nAbility to prioritize, manage orders and work well close to deadlines whilst producing high quality work\nPassionate about quality, customer experience and customer service excellence\nDetail oriented and strong organizational skills\nExcellent in multi-tasking Excellent communication skills\nAbility to work on own initiative however also be a good team player\nA positive attitude when experiencing obstacles and enthusiastic towards getting work done\nAbility and willingness to learn new methods, procedures, or techniques and take on new tasks\nMinimum one year's experience in a data operations environment is preferred\nBenefits\nPension Scheme\nSupplemental Health Plan\nLife Assurance Plan\nPlus others","63":"Company Description\nAs part of the Wilshire family, you can rest assured that every day you are contributing to an organization that is helping millions of people around the world make better investment decisions for a more secure future. For 50 years, our clients have trusted Wilshire to transform complex theory into practical investment solutions and products.\nFounded in 1972, Wilshire advises on over $1.3 trillion in assets and manages $93 billion in assets. Wilshire underwent a corporate transformation in 2021 and is on an exciting journey to deliver best-in-class Investment Solutions, Indices and Benchmarks and Innovative Analytics to a wide range of investors across the world.\nJob Description\nThe Senior Data Operation Engineer will be responsible for passionately leading the Analytics Data Engineering and Data Operations team in support of our rapidly expanding investment analytics business. This position will guide the team with responsibility to deliver and maintain accurate, complete, and timely data sets. This position reports to the Sr. Vice President, Investment Analytics.\nWhat you\u2019ll do:\nPassionately lead a small team of highly impactful Data Engineering and Data Operation Associates and Analysts\nSupport and ensure seamless data delivery, maintain databases with high attention to detail, and thoughtfully implement operational practices for our investment risk, Quantitative Research, and Analytics platform\nSupport the creative efforts of design, and actively maintain database systems for our investment risk, Quantitative Research, and Analytics platform\nEffectively collaborate with IT and the data management team with respect to our data requirements and system design\nQualifications\n\u00ad\u00ad\u00ad\u00ad\u00adUndergraduate degree (preferably in Computer Science, Computer Engineering or equivalent)\nPostgraduate degree in finance, Financial Engineering or equivalent preferred\n5+ years of experience creatively designing, developing, troubleshooting, and tuning databases\n5+ years of excellent experience with and understanding of programming in SQL\n5+ years of financial service experience preferred\n3+ years of experience leading a team\nExcellent experience with and understanding of C, C#, Java, C++ and Python preferred\nExcellent communication skills\nExcellent ability to work in a highly collaborative atmosphere within the team as well as cross functionally\nExcellent ability to cultivate a communal environment under which your team can thrive\nExcellent problem-solving skills with a high attention to detail\nHighly dependable with an excellent level of professionalism \nAdditional Information\nThis position will work on a hybrid model out of our Santa Monica office\nWe offer a comprehensive benefits package including a collaborative work environment, generous PTO, 401(k) match, affordable & comprehensive medical\/dental\/vision insurance, CFA and other professional membership reimbursement, and more.\nThe salary range for this position is $110,000 - $150,000\/year. However, base pay will be determined on an individualized basis considering various factors, including location, qualifications, skills, and experience. The total compensation package includes eligibility for an annual discretionary bonus and a full range of health and financial benefits, which will be provided in conjunction with an offer of employment.\nVisit www.wilshire.com for additional company information. \nWilshire is an SEC registered investment adviser and required to track certain political contributions under Rule 206(4)-5.  As such, you may be required to disclose your prior political contributions.  \nWe are an equal opportunity employer, which means we afford equal employment opportunity to all individuals regardless of race\/ethnicity, creed, color, religion, sex (including gender and gender identity), national origin, ancestry, age, marital status, veteran status, citizenship status, disability, medical condition (as defined by California Government Code section 12926), or sexual orientation.  Our employees, as well as applicants and others with whom we do business, will not be subjected to sexual, racial, religious, ethnic, or any other form of unlawful harassment.  In addition, Wilshire Associates adheres to the equal employment opportunity requirements of all states and localities in which it does business.  We are completely committed to these principles not only because of the various laws which address these subjects, but because it is the right thing to do for our employees and clients to thrive.\nIf you have a disability, and require reasonable accommodations in the application process, contact Human Resources at ApplicantAccessibility@wilshire.com or 310-584-6011.\n#LI-Hybrid","64":"Veeva is a mission-driven organization that aspires to help our customers in Life Sciences and Regulated industries bring their products to market, faster. We are shaped by our values: Do the Right Thing, Customer Success, Employee Success, and Speed. Our teams develop transformative cloud software, services, consulting, and data to make our customers more efficient and effective in everything they do. Veeva is a work anywhere company. You can work at home, at a customer site, or in an office on any given day. As a Public Benefit Corporation, you will also work for a company focused on making a positive impact on its customers, employees, and communities.\nThe Role\nThe vision of our Link product family is to build connected data applications to improve research and patient outcomes.  As the Lead of Agile Projects, you will lead and develop a remote international team of data curators who collect information that will translate into new product features. You will run multiple projects where you will design and optimize the production processes while following compliance and quality standards. You will constantly improve the quality, efficiency, and performance of the team. To thrive in your role, you are highly motivated to lead and have a \u201ccan-do\u201d attitude. You are results-oriented, analytical, and socially skilled. You communicate effectively with managers, analysts, and web researchers to deliver results with high quality and speed. We care about a great cultural fit. You should enjoy working remotely and at speed in multicultural teams. If you are excited about leadership, operations, and working for a fast-growing tech company, we are the optimal fit.\nWhat You'll Do\nLead a remote team of 30+ data curators\nOwn your team\u2019s KPIs and use them to manage performance\nMonitor and improve the efficiency of the existing processes\nOptimize and design operations processes\nPlan and execute quality control checks \nIdentify and eliminate the root causes of quality issues\nCollaborate with the software engineering team on process automation\nEscalate all risks and incidents with speed and clarity\nDrive an amazing team culture of focus, fun, and constructive feedback\nRequirements\nUniversity bachelor's degree in business, life science, or engineering-related field\nProven knowledge and experience in business process design and improvements\nExperience in leading cross-team projects with multiple stakeholders\nFluent English\nProficiency in Microsoft Excel and Google Sheets\nNice to Have\nMaster\u2019s degree, MBA, or PhD\nIndustry or academic experience in life sciences\nAt least one year of working experience in leading a team\nRemote team management experience \nLean Six Sigma certification\nSQL skills\nPerks & Benefits\nOpportunity to work in a diverse and international workspace (Office space in Frankfurt am Main)\nPersonal development budget\nVeeva giving budget\nA significant contribution to a pension fund\nLife insurance\nFitness reimbursement\n#RemoteHungary\nVeeva\u2019s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.\nVeeva is committed to fostering a culture of inclusion and growing a diverse workforce. Diversity makes us stronger. It comes in many forms. Gender, race, ethnicity, religion, politics, sexual orientation, age, disability and life experience shape us all into unique individuals. We value people for the individuals they are and the contributions they can bring to our teams.","65":"As an Anti-Spam Adaptive Data Specialist, you will be responsible for helping to keep Discord free of spam. The highly analytical and strategic position will be responsible for user questions and reports regarding spam, as well as influencing scaled approaches to uprooting new spam vectors before they impact users and for managing quality assurance of existing anti-spam measures.  Successful candidates will be highly collaborative and versatile in their approaches, be comfortable rolling up their sleeves to uncover abuse vectors as they take shape, and be able to communicate technical complexity and policy considerations with a range of technical and non-technical stakeholders.\nWhat you'll be doing\nOwn documentation and quality assurance of Discord\u2019s scaled anti-spam efforts, and flag potential deviations to relevant stakeholders\nThink both quantitatively and qualitatively to create reports and suggestions that improve, optimize, and innovate our scaled anti-spam methods\nAnalyze new and potential product features and propose plans to help reduce or remove spammy behavior before it happens\nManage incoming streams of spam reports and spam-related appeals from users and communities to identify developing patterns of abuse\nWork cross-collaboratively with other teams, including Product, Safety Engineering, ML, CX in responding to complex and time-sensitive issues\nWhat you should have\n1-3+ years experience using data analysis and\/or ad-hoc scripting to solve complex problems.\nStrong problem-solving, troubleshooting, and investigative skills: we believe in getting to the root of the matter instead of just addressing symptoms\nA strong interest in online harm mitigation--you\u2019ve seen how seemingly safe features are abused by bad actors, and understand tradeoffs and risk that come with online interactions\nPrevious experience with data analysis and\/or scaled quality assurance\nStrong stakeholder management skills\u2013\u2013you\u2019re adept at improving processes and know how to leverage the skills of multiple disparate teams\nAbility to work in a fast-paced environment and make important decisions under pressure\nExcellent communication skills\u2013\u2013you can efficiently and eloquently present ideas, updates and results to key stakeholders at various levels\nBonus Points\nBackground in data and\/or user-facing support roles, such as Trust & Safety or CX.\nHigh-level understanding of statistics concepts (e.g., hypothesis testing, probability distributions, relationship between variables)\nDemonstrated interest in anti-spam and\/or responsible innovation initiatives\nProficiency in various data analysis and scripting languages such as:\nSQL\nPython\nGit\nFamiliarity with ticketing systems. (Ex. Zendesk)\nNew York City residents only: Minimum salary of $117,000\/year + equity and benefits\n*Note: Disclosure as required by NYC Pay Transparency Law.\n\nColorado residents only: Minimum salary of $93,600\/year + equity and benefits\n*Note: Disclosure as required by sb19-085(8-5-20).\nBenefits and Perks\nComprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures)\nMental health resources and quarterly wellness stipends\n16+ paid holidays, 4 weeks of PTO + use-what-you-need sick days \nPaid parental leave (plus fertility, adoption and other family planning benefits)\nFlexible long-term work options (remote and hybrid)\nVolunteer time off\nA diverse slate of Employee Resource Groups \nPlus commuter contributions and other perks for office-based employees\nAbout Us\nDiscord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests \u2014 from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations.\nWe\u2019re working toward an inclusive world where no one feels like an outsider, where genuine human connection is a click, text chat, or voice call away. A place where everyone can find belonging. Challenging? Heck yes. Rewarding? Double heck yes. It\u2019s a mission that gives us the chance to positively impact millions of people all over the world. So if this strikes a chord with you, come build belonging with us!","66":"The Content and Media team is part of Gracenote, a Nielsen company. It provides entertainment metadata, content IDs and related offerings to the world\u2019s leading creators, distributors and platforms. Gracenote technology enables advanced content navigation and discovery capabilities so consumers can easily connect to the TV shows, movies, music and sports they love while delivering powerful content analytics making complex business decisions simpler.\n Position: Part Time Soccer Live Data Operator Shift: Evenings & Full Weekends.  Wage: $15.50 per hour\nGracenote - Oldsmar, FL\nCalling all soccer fans!  If you have a passion for soccer, enjoy working with data, and want to get paid for watching what you love, this is the position for you!  Nielsen is expanding our team and looking for part-time Soccer Live Data Operators. We are searching for a highly motivated and knowledgeable sports gurus, specializing in American soccer.\nAbout this Job:  As a Soccer Live Data Operator, you are required to capture and register data during live professional soccer matches following well-defined standards and procedures. You will capture several live match events and use Gracenote\u2019s Sports-based tooling in the process. You will work as quickly as possible watching, analyzing, and entering data to deliver the required deep sports data to our (media) customers within seconds\nAbout You: \u2022 You are a huge Soccer fanatic and follow several different leagues and teams!\u2022 You are willing to learn and have a positive attitude \u2022 Have basic computer skills including working with Google Chrome and good internet searching skills.\u2022 We are monitoring several major North and South American leagues and if you are able to understand Spanish or Portuguese, that is a major plus.\nQualifications: \u2022 You have a passion for soccer!\u2022 You have an eye for detail and are able to quickly detect what\u2019s happening on the pitch without a commentator narrating the plays.\u2022 You are able to commit to either a Saturday or Sunday every week at Gracenote Sports to work during live sports events, which happen during evening and weekend hours.\u2022 You are able to work quickly with computers, be focused, and keep a cool head when tempers flare on the pitch.\u2022 You possess excellent communication skills - collecting sports information is teamwork. You need to be able to communicate clearly, accurately and promptly with your supervisors and colleagues, and have a positive attitude even during the most hectic situations of a match.\u2022 Being able to travel to the Gracenote Oldsmar office during the evenings and weekends is a plus but we are willing to support remote workers.\u2022 You are 18 years or older. \u2022 No professional experience needed. \nWhat Nielsen can offer you:\u2022 A competitive hourly rate of $15,50 \u2022 An opportunity to play an important role in a global operation that delivers live soccer data all around the world.\u2022 A challenging, dynamic, and international work environment. \u2022 An atmosphere of openness, mutual respect, teamwork, and fun.\u2022 An opportunity to be around others who share the same interest and love for Soccer. \n\nSchedule Requirements: \u2022 Weekend availability is a MUST\u2022 Weekday evening availability is a plus \u2022 Hours will fluctuate during the year due to league schedules.\u2022 Punctuality and reliability are essential due to the live nature of the work.\u2022 You should know that shift availability is dependent on several international soccer leagues, this means that your schedule will be impacted when the leagues go on break. ABOUT NIELSENAs the arbiter of truth, Nielsen Global Media fuels the media industry with unbiased, reliable data about what people watch and listen to. To discover what\u2019s true, we measure across all channels and platforms\u2060\u2014from podcasts to streaming TV to social media. And when companies and advertisers are armed with the truth, they have a deeper understanding of their audiences and can accelerate growth. Do you want to move the industry forward with Nielsen? Our people are the driving force. Your thoughts, ideas and expertise can propel us forward. Whether you have fresh thinking around maximizing a new technology or you see a gap in the market, we are here to listen and take action. Our team is made strong by a diversity of thoughts, experiences, skills, and backgrounds. You\u2019ll enjoy working with smart, fun, curious colleagues, who are passionate about their work. Come be part of a team that motivates you to do your best work!  #LI-JR1Nielsen: Enabling your best to power a better media future. Our comprehensive benefits package (including health & wellness plans, 401(k) retirement coupled with a Nielsen match, a generous paid time off policy, and if eligible, a discretionary incentive\/bonus) is designed to be inclusive for all employees and families, and we take pride in ensuring that employees are rewarded holistically for the role they are doing and their performance.\nThe hourly rate for a new employee to be offered this role would be $15.50, which would be adjusted based on each employee's geographic location.  The position of each employee within a compensation range at Nielsen is dependent on several individual circumstances, such as experience, training, certifications and other business requirements\/needs.  Nielsen is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity\/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class.","67":"As the Manager of Adaptive Data, you will manage and lead a team responsible for keeping Discord safe. You will work hand-in-hand with leaders across the Safety org, from Tech to Operations, to transform how we detect, respond to incidents, communicate to users, and measure impact. You will lead and invigorate a high-performing team that is skilled at uprooting new threat vectors before they impact users. \nWe are looking for a leader that has done this before: you are comfortable rolling up your sleeves to uncover abuse vectors as they take shape AND you excel at building the necessary operational rigor to drive overall accountability for your team.  \nWhat you'll be doing\nLead and manage a team of high performers, ensuring that individual and org level goals are met\nCoach and mentor team members to help them grow and develop professionally\nStay up-to-date on industry trends for problem spaces, and combine information to make fast, high quality decisions with less than complete data\nPartner closely with Safety leadership, product, engineering and ops teams to in responding to complex and time-sensitive issues\n  You'll thrive in this role if\n7+ years of experience, including minimum 2 years of experience managing high performing ICs\nA strong interest in online harm detection and mitigation--you\u2019ve seen how seemingly safe features are abused by bad actors, and understand tradeoffs and risk that come with online interactions\nAffinity for a fast paced work environment, detecting and crafting solutions to high intensity problems with strong attention to detail and a high bar for quality\nDemonstrated ability to lead, influence other leaders and deliver complex projects involving multiple stakeholders\nStrong analytical skills, and the ability to use data to drive business decisions\n  Bonus Points\nBackground in data and\/or user-facing support roles, such as Trust & Safety or CX.\nHigh-level understanding of statistics concepts (e.g., hypothesis testing, probability distributions, relationship between variables)\nProficiency in various data analysis and scripting languages such as:\nSQL\nPython\nGit\nFamiliarity with ticketing systems. (Ex. Zendesk)\nNew York City residents only: Minimum salary of $168,000\/year + equity and benefits\n*Note: Disclosure as required by NYC Pay Transparency Law.\n\nColorado residents only: Minimum salary of $134,400\/year + equity and benefits\n*Note: Disclosure as required by sb19-085(8-5-20).\n#LI-Hybrid\nBenefits and Perks\nComprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures)\nMental health resources and quarterly wellness stipends\n16+ paid holidays, 4 weeks of PTO + use-what-you-need sick days \nPaid parental leave (plus fertility, adoption and other family planning benefits)\nFlexible long-term work options (remote and hybrid)\nVolunteer time off\nA diverse slate of Employee Resource Groups \nPlus commuter contributions and other perks for office-based employees\nAbout Us\nDiscord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests \u2014 from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations.\nWe\u2019re working toward an inclusive world where no one feels like an outsider, where genuine human connection is a click, text chat, or voice call away. A place where everyone can find belonging. Challenging? Heck yes. Rewarding? Double heck yes. It\u2019s a mission that gives us the chance to positively impact millions of people all over the world. So if this strikes a chord with you, come build belonging with us!","68":"\u00bfTe apasiona desarrollar y trabajar con las tecnolog\u00edas m\u00e1s trending en el mundo? Si es as\u00ed, \u00a1te queremos conocer!\nSomos una compa\u00f1\u00eda que ofrece soluciones de consultor\u00eda y desarrollo de software end to end 100% remota y digital de crecimiento exponencial\ud83d\udcc8.\nInt\u00e9grate a nuestro equipo y convi\u00e9rtete en el nuevo Divelever \ud83d\ude0e \ud83d\udca5 \ud83d\udcbb \"MLOps Engineer\" en Divelement.\n\u2705Te damos un peque\u00f1o recorrido por Divelement:\n\ud83c\udf10Nuestra p\u00e1gina web www.divelement.io\n\ud83c\udf10LinkedIn Divelement Web Services\nRequirements\nM\u00e1s de 4 a\u00f1os de experiencia en dise\u00f1o y desarrollo de sistemas escalables utilizados para ejecutar cargas de trabajo de Machine Learning, entrenamiento de modelos distribuidos, ajuste de hiperpar\u00e1metros e inferencia en tiempo real\nM\u00e1s de 3 a\u00f1os de experiencia en la nube, preferiblemente en el ecosistema de AWS (Sagemaker)\nCompetencia en el dise\u00f1o e implementaci\u00f3n de flujos de trabajo de ML de producci\u00f3n escalables en la nube (Automatizaci\u00f3n de Docker images, deploy de modelos de ML, monitoreo de los modelos)\nExperiencia con al menos un marco de aprendizaje autom\u00e1tico como Pytorch, TensorFlow o Scikit-learn (Deseable)\nExcelentes habilidades de comunicaci\u00f3n en ingl\u00e9s (C1) INDISPENSABLE\nBenefits\n\ud83d\ude80Sueldo altamente competitivo en la industria\n\ud83d\ude80Seguro de gastos m\u00e9dicos mayores\n\ud83d\ude80Apoyo de internet\n\ud83d\ude80Bono por reconocimiento de apoyo\n\ud83d\ude80Bono por referidos\n\ud83d\ude80Vacaciones superiores a la ley desde los primeros 3 meses\n\ud83d\ude801 mes de Aguinaldo\n\ud83d\ude80Medio d\u00eda libre en tu cumplea\u00f1os\n\ud83d\ude80Herramientas de trabajo para que te desarrolles con \u00e9xito\n\ud83d\ude80Maestro de ingl\u00e9s particular desde la comodidad de tu hogar\n\ud83d\ude80Horario flexible de trabajo\n\ud83d\ude80Cultura de trabajo din\u00e1mica y colaborativa\n\ud83d\ude80Incre\u00edble esquema de PTO \/ Permisos\n\ud83d\ude80Desarrollo constante (Certificaciones y cursos)\n\ud83d\ude80Cultura remota permanente","69":"Are you looking for a hybrid or remote work opportunity? Are you interested in a workplace that allows for flexibility in your day? Are you ready for a workplace that provides benefits that suit your needs?\nAs the Machine Learning Operations intern you will join our Research team and collaborate cross-functionally to help build a research infrastructure for the AI Researchers.\nAs the MLOps Intern you will:\nWork with AI Researchers to build a research infrastructure to facilitate experimentation process.\nImplement various AI research tools, role-based access controls mechanism and secure data access mechanisms.\nBe involved in environmental security hardening.\nIdentify, document, automate, and engineer processes for repeated tasks.\nRun machine learning tests and experiments.\nCollaborate with cross-functional teams\nQualifications\nCompletion of 3 years of undergraduate studies in Computer Science or equivalent related fields.\nDemonstrated industry experience in internships and\/or research projects\nStrong computer science fundamentals in algorithms, data structures and complexity analysis.\nStrong analytical and problem-solving skills\nProficiency in at least one modern programming language like Python\nProficiency in working with Linux based systems.\nAbility to consistently deliver elegant, modular and scalable solutions in a timely manner \nBonus Qualifications\nExperience in cloud platforms like Azure, GCP, AWS, etc.\nExperience with machine learning platforms like Databricks, MLFlow, etc.\nRelativity is a diverse workplace with different skills and life experiences\u2014and we love and celebrate those differences. We believe that employees are happiest when they're empowered to be their full, authentic selves, regardless how you identify.\nBenefit Highlights:Comprehensive health, dental, and vision plans Parental leave for primary and secondary caregivers Flexible work arrangements Two, week-long company breaks per yearUnlimited time off Long-term incentive program Training investment program\nTransparency in Coverage InformationThe Transparency in Coverage Final Rule requires disclosure of the negotiated rates with in-network providers and the historic allowed amounts paid to out-of-network providers, for all health plans available to employers. Files containing this information for the plans covered are published on this page.Link: https:\/\/www.bcbsil.com\/asomrf?EIN=123456789\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law.","70":"We are looking for a Data Operation Specialist with legal expertise to join our fast-growing team; to help us promote our data-for-justice revolution. We developed a platform that uses AI and Machine Learning to discover harmful legal violations, securing compensation for millions of victims.\nWho Are You?You are a highly motivated, organized, and process-oriented person, ready to put your skills to work. You are a team player, open-minded, and collaborative. You have an entrepreneurial spirit and can make things happen in a fast-paced startup environment.\nNot Your Typical Legal\/Data RoleOur mission is about justice at scale, and we provide our team members with the resources they need to get the job done. Imagine walking into work every day knowing that you\u2019re not only advancing your career but making a positive impact on the world. At Darrow, we have created an open, action-based culture unlike any other. Join us and play an integral role in our mission of shaping a better future as part of our dynamic and impactful research team. \nWhat Will You Be Doing? As a legal professional with a passion for data and machine learning, you will take the lead on our data labeling and annotation efforts and drive data quality improvement processes. With your expertise, you will provide legal guidance to our Data Science team, and together partner to shape the future of the justice system through innovative AI. \nResponsibilities:\n Label and annotate legal data for data science and machine learning projects\nAssist with the development of machine learning algorithms by giving legal advice and context to our data scientist.\nWrite annotation and labeling guidelines for external labels.\nAnalyze and monitor data and provide insights on data-driven decisions.\nLead data quality processes such as data analysis, profiling, monitoring, and cleansing to drive data quality improvements.\nRequirements:\nLL.B degree\nKnowledge of best practices in data analysis and familiarity with statistical methods\nExperience with SQL and Python\nAdvanced problem-solving skills\nProject management skills\nExcellent interpersonal and communication skills\nExperience as a data analyst\/data quality analyst  -  an advantage","71":"We are a leading digital identity company that believes in a future where customers can perform any transaction without friction. We enable banks, fintech, retailers, marketplaces, healthcare systems, government agencies, and many others to provide more secure and delightful experiences to their customers.\nThrough our flagship suite, Incode Omni, we offer an end-to-end omnichannel identity platform that helps businesses address all of their identity needs, from digital onboarding and know-your-customer (KYC) to omnichannel authentication and more.\nWe\u2019re in the process of rapidly scaling our global but close-knit team and we\u2019re looking for leaders who are curious, driven and excited by ownership!\nThe Opportunity\nIncode is seeking ML Support\/ML Ops Team Lead  to join our Machine Learning team.\nWe are building world-class solutions for facial biometrics, document analysis, and risk assessment.\nYou will be working in an experienced, hard-working, and open-minded team of great engineers.\nWe are looking for curious, driven, and hard-working candidates who want to be part of a culture of innovation and creativity that will revolutionize biometrics.\nResponsibilities:\nLead a team that builds and maintains the ML infrastructure and works on the deployment process of the ML components.\nCollaborate with data science and engineering teams to integrate and validate computer vision solutions end-to-end.\nDeliver enduring value in terms of software and modeling artifacts.\nRequirements:\n5+ years of experience in ML\/MLOps. Worked on several comprehensive industry-level projects (it should not be a part of your academic program).\n1+ years of team-leading experience.\nExperience with Cloud (AWS) and on-premise (bare metal) administration.\nFluency in Python. Ability to write clear and maintainable code compliant with PEP 8.\nComprehensive knowledge of C\/C++.\nCreativity and curiosity for solving highly complex problems \nFluent in English \nOther skills:\nExperience in applying machine learning & computer vision to resource-constrained devices (such as mobile phones).\nExperience in one of the following fields: face recognition and anti-spoofing, document processing and validation, OCR\nBenefits & Perks\nMeaningful equity\nCompetitive salary\nTravel \u2013 yearly sprints\nBenefit allowance for health insurance, life insurance or pension contribution\nOpen vacation policy\nFlexible working hours\nWorking as part of a global business with a diverse team\nOpportunity to grow from the ground up with a well funded early-stage start-up \nWorking closely with passionate and supportive team members\n  Our Culture Values matter! We share a set of core values and want to hear from you if you believe in:\nCustomer centric and impactful products\nWorking as part of a bright, passionate, and diverse team\nSimplicity\nQuality\nBias for action\nIntegrity\nEmpathy\nCourage\n  Please note - our commitment to keeping our workforce safe and healthy is of utmost importance. We are working remotely for the time being and have switched to an entirely virtual recruitment process. All of our new recruits will be onboarded safely and are provided with all the tools to work effectively from home!   Incode are an equal opportunity employer, committed to creating a diverse and inclusive work environment. We take great pride in having an inclusive, diverse and global team and are always on the lookout for talented, passionate people from all backgrounds and walks of life.","72":"Successful applicants for this position must be fully vaccinated against COVID-19 as a condition of employment. Vaccine verification will be required.\n  POSITION SUMMARY:\nClinical Data Operator accessions patient samples according to standard operating procedures (SOP) with high efficiency and accuracy. Shift is: Tuesday - Saturday,  Swing Shift 530pm-2am.  Hourly pay $20.70, with a Saturday shift differential.       Natera requires successful applicants for this position must be fully vaccinated against COVID-19 as a condition of employment. Vaccine verification will be required.    PRIMARY RESPONSIBILITIES:\nCreate new orders on Laboratory Inventory Management System (LIMS) and perform necessary checks to ensure proper accessioning.\nAccession samples with high accuracy and efficiency.\nAccurately enter patient data into the Laboratory Inventory Management System (LIMS).\nEnsure that the information in LIMS is up-to-date.\nScan test requisition forms and attached paperwork.  Ensure that all paperwork belong to patient and upload to case.\nProtect patient health information (PHI) at all times to ensure compliance with HIPAA and privacy policies.\nPerform safe and proper handling of samples (blood, buccal, and tissue).\nMaintain tidiness of workstations and lab.\nMaintain familiarity with standard operating procedures (SOP) and quality standards determined by the clinical laboratory.\nPerform safe and proper handling of tools provided to open packages and kit boxes.\nSort packages at the dock upon arrival of packages and bring packages up to the lab.\nThis role works with PHI on a regular basis both in paper and electronic form and have an access to various technologies to access PHI (paper and electronic) in order to perform the job.\nEmployee must complete training relating to HIPAA\/PHI privacy, General Policies and Procedure Compliance training and security training as soon as possible but not later than the first 30 days of hire.\nMust maintain a current status on Natera training requirements.\nPerforms other duties as assigned.\nQUALIFICATIONS:\nHigh School Diploma (or equivalent) required.\n0 - 1 year of industry related experience.\nPrevious computer experience is required.\nPrevious data entry experience is preferred\nKNOWLEDGE, SKILLS, AND ABILITIES:\nTrained on all product types and able to accession with accuracy and efficiency.\nTyping speed of at least 45wpm with high accuracy.\nGood oral and written communication skills.\nEffective critical thinking skills and the ability to use good judgment.\nAbility to perform required duties with a high degree of accuracy and attention to detail.\nPositive attitude and ability to work well with others.\n  #LI-LS1\nOUR OPPORTUNITY\nNatera\u2122 is a global leader in cell-free DNA (cfDNA) testing, dedicated to oncology, women\u2019s health, and organ health. Our aim is to make personalized genetic testing and diagnostics part of the standard of care to protect health and enable earlier and more targeted interventions that lead to longer, healthier lives.\nThe Natera team consists of highly dedicated statisticians, geneticists, doctors, laboratory scientists, business professionals, software engineers and many other professionals from world-class institutions, who care deeply for our work and each other. When you join Natera, you\u2019ll work hard and grow quickly. Working alongside the elite of the industry, you\u2019ll be stretched and challenged, and take pride in being part of a company that is changing the landscape of genetic disease management.\nWHAT WE OFFER\nCompetitive Benefits - Employee benefits include comprehensive medical, dental, vision, life and disability plans for eligible employees and their dependents. Additionally, Natera employees and their immediate families receive free testing in addition to fertility care benefits. Other benefits include pregnancy and baby bonding leave, 401k benefits, commuter benefits and much more. We also offer a generous employee referral program!\nFor more information, visit www.natera.com.\nNatera is proud to be an Equal Opportunity Employer. We are committed to ensuring a diverse and inclusive workplace environment, and welcome people of different backgrounds, experiences, abilities and perspectives. Inclusive collaboration benefits our employees, our community and our patients, and is critical to our mission of changing the management of disease worldwide.\nAll qualified applicants are encouraged to apply, and will be considered without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, disability or any other legally protected status. We also consider qualified applicants regardless of criminal histories, consistent with applicable laws.\nIf you are based in California, we encourage you to read this important information for California residents. \nLink: https:\/\/www.natera.com\/notice-of-data-collection-california-residents\/\nPlease be advised that Natera will reach out to candidates with a @natera.com email domain ONLY. Email communications from all other domain names are not from Natera or its employees and are fraudulent. Natera does not request interviews via text messages and does not ask for personal information until a candidate has engaged with the company and has spoken to a recruiter and the hiring team. Natera takes cyber crimes seriously, and will collaborate with law enforcement authorities to prosecute any related cyber crimes.\nFor more information:\n- BBB announcement on job scams \n- FBI Cyber Crime resource page ","73":"Company Description\nThe largest ICT employer in Hungary, Deutsche Telekom IT Solutions (formerly IT-Services Hungary, ITSH) is a subsidiary of the Deutsche Telekom Group. Established in 2006, the company provides a wide portfolio of IT and telecommunications services with more than 5000 employees. ITSH was awarded with the Best in Educational Cooperation prize by HIPA in 2019, acknowledged as one of the most attractive workplaces by PwC Hungary\u2019s independent survey in 2021 and rewarded with the title of the Most Ethical Multinational Company in 2019. The company continuously develops its four sites in Budapest, Debrecen, P\u00e9cs and Szeged and is looking for skilled IT professionals to join its team.\nJob Description\nWe are searching for a Senior Software Engineer to join our highly skilled team in the area of AI and ML with the respective skill set in the area of CI\/CD and Kubernetes on automated infrastructures (e.g. AWS). The candidate will have the chance to grow into emerging technologies of AI as well.\nYour tasks will be:\n- Ensure that scalable IT infrastructures are created in the cloud.\n- Build robust data pipelines using data from our customers.\n- You will integrate ML models into ML infrastructure and ensure that they function correctly.\n- Implementation of AI and ML automation\n- You are responsible for different CI\/CD pipelines -  private and public cloud providers (e.g. AWS)\n- Continuous Deployment (automation, and SW quality aspects)\n- Gitlab Pipelines\nQualifications\n- Container architectures (K8S Docker)\n- Ingress Control\n- Templating of k8s manifests\n- Experience in programming (ideally Python)\n- Exposure to public cloud providers (ideally AWS) \n- Experience in logging and monitoring (ELK)\n- Experience in developing\/consuming RESTful API\n- Docker Security\n- Linux experience \nAdditional Information\nOptional skills which can provide a +:\n- Apache\/Cloudera\n- Basic Frontend experience in order to adapt config interfaces\n- Kubeflow\n* Please be informed that our remote working possibility is only available within Hungary due to European taxation regulation.","74":"About TruEra\nTruera provides the first AI Quality platform, to help enterprises analyze machine learning, improve model quality and build trust. Powered by enterprise-class Artificial Intelligence (AI) Explainability technology based on six years of research at Carnegie Mellon University, Truera\u2019s platform helps eliminate the black box surrounding widely used AI and ML technologies. This visibility leads to higher quality, explainable models that achieve measurable business results, address unfair bias, and ensure governance and compliance.\nWe are excited about the amazing team we\u2019re building at Truera. One of the core cultural principles at Truera is: \u201cCreate what\u2019s not there.\u201d We\u2019re building a team of creator-builders who are excited about our mission and keen to build large-scale systems and drive cutting-edge research in support of it.\nWe are a rapidly growing Series B company funded by Greylock, Wing, and Menlo Ventures, and working with both Fortune 100 customers and startups throughout the world!\nAbout the job\nAs a Machine Learning Engineer on the TruEra ML team, you will be designing, building, and managing scalable and highly available Data platforms, AI\/ML infrastructure ecosystems. We're developing the platform for both public and private cloud environments with the container as first-class citizens. Infrastructure is at the core of our platform, and we're constantly innovating to make our systems more performant, timely, cost-effective, and capable while maintaining high reliability. You'll be architecting our core data and ML infrastructure and pipelines.\nAnnual Base Salary Range: $180,000 - $230,000 USD\nWhat You Will be Doing:\nBuild high-quality and scalable systems for deploying AI models\nDesign, develop, and lead platform features \nCollaborate with ML Engineers, Backend Engineers, and Products Managers to deliver new Platform capabilities\nParticipate in early customer engagements and PoCs, and use that context to drive new product features\nReview design and code, and make sure what we ship is awesome\n\u201cCreate what\u2019s not there\u201d\nPrior Experience:\nBachelor's degree in computer science or equivalent \n5+ years experience in Software Engineering, preferably in data Infrastructure, machine learning, and\/or cloud ecosystems\nExperience building data systems or machine learning ecosystems \nExperience with Machine learning frameworks including sklearn, PyTorch, TensorFlow\nStrong mathematical skills and data manipulation using tools like numpy, pandas, PyTorch, TensorFlow\nExperience in the ML development cycle such as training, testing, monitoring, and\/or deployment\nSolid background in the fundamentals of computer science and distributed systems\nAbility to build systems that balance scalability, availability, and latency\nAdvocate for the continuous deployment and automation tools, monitoring, and self-healing systems\nGreat communication skills and a team player\nNice to haves:\nExperience in one or more data stores including Postgres, Redshift, Hadoop, Cassandra, BigQuery, etc.\nExperience in containerized deployment or Kubernetes\nExposure to ML pipeline Kubeflow, mlflow, etc. \nHaving been a part of an engineering team at an early-stage startup\nFamiliarity with open-source data & machine learning landscape","75":"Job Overview\nAs a Machine Learning Operations (MLOps) Engineer, you will be responsible for enabling model deployment automation to production systems to increase the number and quality of users as the G123 platform grows its portfolio of games and expands globally. Main tasks include:\n\nBuild and turn offline model data into a real machine learning production system\nApply software engineering rigor and best practices to machine learning (i.e. CI\/CD, automation etc.)\nRequirements\nProven proficiency in Python\nExpertise in AWS and its services such as SageMaker, EC2, ECS etc\nExperience using DAGs to define data pipelines with airflow\nMaster SQL and manipulating database systems (TiDB, etc)\nKnowledgeable in ML libraries (e.g. TensorFlow & PyTorch)\nKnowledgeable in CI\/CD & Devops principles\nProficient in Software Engineering fundamentals\n\nLanguage Requirements\nCan work in Chinese OR Japanese OR English\nCan read and understand technical documents in English\nBenefits\nVisa support\nFree lunch catering (*after 3 months employment) and early-bird breakfast\nFree in-office Starbucks, coffee, tea, beverages, snacks, sweets, & vitamins\/supplements\nModern office space in the heart of Tokyo, with views of Tokyo Tower and Mount Fuji\nIndustry-leading work-life harmony: overtime is rare and discouraged\nCommute expenses covered\n30,000 yen rent support if you live 2 stops from Roppongi 1-chome or Kamiyacho stations\nBonus for continuous employment (50,000 yen\/month added to base salary after 5 years of continued employment)\nHealth insurance\nDiverse & international environment\nWorking hours: 10:00 \u2013 19:00, Monday to Friday (in-office)\nAbout CTW.inc\nFounded in 2013, CTW is Japan\u2019s No.1 browser game company. Our primary service is the G123 IP game platform \u2014 which publishes video games based on famous Japanese IP.\nWe\u2019ve been experiencing steady growth in revenue in the past few years as our player base has exploded to over 50 million users worldwide.\nWe must grow quickly to keep up with market demand.\nOur CEO founded and named this company with the aspiration to \"Change the World.\" As a fast-growing startup, we hope our team will drive themselves to try new things and accelerate their careers to match the rapid expansion of the company.\n\nOur core values are\n- ambition\n- drive\n- simplicity\n\nWith global hits like Vivid Army, Queen's Blade, and many more, we\u2019re looking to go from a market leader in Japan to an industry leader globally!","76":"WHAT YOU\u2019LL DO\nThe Data Operations Specialist will work closely with our Data Partners and our internal data-oriented teams to ensure products and services related to 3rd party data are accurate and working properly.   They play an essential role in maintaining relationships with our data partners and providing them support.  This position is ultimately responsible for ensuring that data is onboarded\/updated accurately and consistently for use by all our advertising partners.\nTHE DAY-TO-DAY\nLiaise with sales, product, solutions, business development, technical production and product marketing on new partner integrations\nDevelop expert knowledge on both Viant\u2019s and 3rd party data partners systems to recommend, research, and build audience segments\nBecome an expert of Viant\u2019s 3rd party data partners to provide strategic feedback and to develop optimal workflows and prcoesses.\nWork closely with external data partners, product, engineering, internal support teams and ultimately onboarding, analyzing and executing the data for use\nGREAT TO HAVE\nStrong collaboration and communication skills with a diplomatic approach across inter-departments and external partners\nHighly organized and capable of developing efficient work processes\nStrong analytical skills with ability to identify trends and draw conclusions based on data\nExperience with Google Big Query and SQL a plus\nWHO WE ARE\nViant\u00ae (NASDAQ: DSP) is a leading advertising software company that enables marketers to plan, execute and measure omnichannel ad campaigns through a cloud-based platform. Viant\u2019s self-service Demand Side Platform, Adelphic\u00ae, powers programmatic advertising across Connected TV, Linear TV, mobile, desktop, audio, gaming and digital out-of-home channels. In 2022, Viant was recognized as a Leader in the DSP category, earned Great Place to Work\u00ae certification and Co-Founders Tim and Chris Vanderhook were named EY Entrepreneurs of the Year. To learn more, please visit viantinc.com.\nLIFE AT VIANT\nInvesting in our employee\u2019s professional growth is important to us, but so is investing in their well-being. That\u2019s why Viant was voted one of the best places to work and some of our favorite employee benefits include fully paid health insurance, paid parental leave and unlimited PTO and more. \nNot the right position for you? Check out our other opportunities!  Viant Careers\n#LI-MK1 #LI-Hybrid\n\n\nAbout Viant\nViant\u00ae (NASDAQ: DSP) is a leading advertising software company that enables marketers to plan, execute and measure omnichannel ad campaigns through a cloud-based platform. Viant\u2019s self-service Demand Side Platform, Adelphic\u00ae, powers programmatic advertising across Connected TV, Linear TV, mobile, desktop, audio, gaming and digital out-of-home channels. As an organization committed to sustainability, Viant\u2019s Adricity\u00ae carbon reduction program helps clients achieve their sustainability goals. In 2022, Viant was recognized as a Leader in the DSP category, earned Great Place to Work\u00ae certification, became founding a member of Ad Net Zero, and Co-Founders Tim and Chris Vanderhook were named EY Entrepreneurs of the Year. To learn more, please visit viantinc.com.\nViant is proud to be an equal opportunity employer. To provide equal employment and advancement opportunities to all individuals, employment decisions at Viant are based on merit, qualifications, and abilities. We do not discriminate in employment opportunities or practices on the basis of race; color; religion (includes religious beliefs, observance or practice, religious dress or grooming practices); creed; sex; sexual orientation; gender; gender identity or expression; transgender status; pregnancy, childbirth or related condition (including breastfeeding); marital status; national origin; citizenship; military status, veteran status; ancestry, age; physical or mental disability; medical condition (includes cancer or a record or history of cancer), genetic characteristics; or any other characteristic protected by applicable federal, state, or local laws, and Viant prohibits harassment based on any such protected basis or characteristics.\nBy clicking \u201cApply for this Job\u201d and providing any information, I accept the Viant California Personnel Privacy Notice.","77":"Hey you! \ud83d\udc4b  Want to work for one of the fastest growing SaaS companies in the world? \ud83d\udcc8We\u2019re building the next generation of learning software that companies like AWS, Netflix, Opentable and L\u2019Oreal rely on to deliver training \ud83d\udcbb We believe learning is for everyone, and that we all have something we can learn from each other. We rely on one another to continuously innovate our products and processes to create an exceptional experience for our employees, customers and partners.\nStill not sure? We are a culture where values are at the center of everything we do. We also embody what we call the Docebo Heart. We trust our teammates, assume the best of one another, and also hold space for all the differences that make us better. \ud83d\udc99\nSo what are you waiting for? Apply today! Join 800+ global Docebians and change the way people learn. \nAre you ready to be a part of the learning revolution? \ud83d\ude80\nAbout This Opportunity:\n\nAs Machine Learning Operations Engineer you will work in a multi-functional team focusing on the development, delivery, and continuous improvement of ML models that are an integral part of Docebo products. You will lead the advancement of its current MLOps framework, based upon Kubeflow and KServe, and will advise the team manager on upcoming technologies and innovation opportunities that may enhance the capabilities and productivity of the team.\nReports to: Machine Learning ManagerLocation: Biassono (Hybrid)\n\nResponsibilities:\nOutlook and scouting on the frontier of the technologies for the delivery of Machine Learning functionality and services in the Cloud Evolution of the Kubeflow-based tools\nPractices and ML model development environments that support the whole model development\nevaluation and testing lifecycle, boost Data Scientists\u2019 productivity, and reduce time to market for ML solutions\nMaintenance and improvement of the Cloud infrastructure underlying those environments, in collaboration with Cloud Engineers\nMake training and inference infrastructure decisions in collaboration with Data Scientists on developed ML models, and orient the engineering and production teams regarding the best way to seamlessly deploy and serve those models and ensure efficient inference in production\nCoordinate between the AI teams the connections and pipelines for production\nSupport to Data Engineers in the technology choices and the design of data pipelines that are used to produce data sets for ML model development\nDesign and implementation of workflows for the continuous monitoring, re-training and improvement of delivered ML models, in collaboration with Data Engineers and Data Scientists Decision-making\nIn collaboration with engineering and production teams - on how to operationalize developed ML models and integrating them with Docebo products, to ensure their seamless deployment and delivery, and efficient inference in production\nRequirements:\nExtensive experience with Cloud infrastructure and DevOps practices, preferentially on AWS\nExperience working with the Python ecosystem and major ML and Deep Learning libraries and frameworks\nExtensive hands-on knowledge of the Kubernetes ecosystem that supports the development and delivery of ML models including: Kubernetes core (Deployment stack, networking, etc.) Knative Kubeflow\nDeep understanding of the lifecycle of ML models, from experimentation, to evaluation, inference, monitoring and evolution, and how to support each of those phases with suitable Cloud technologies\nExperience with Continuous Integration and Delivery and with CI\/CD\/CT pipeline technologies (e.g. GitLab pipelines, Kubeflow Pipelines)\nExperience with repositories and versioning of ML models, data and experiments (e.g DVC)\nPreferred Requirements:\nExperience with infrastructure-as-Code (IaC) and Terraform in particular\nProficiency in designing and building A\/B testing experiments in production conditions for model comparison and competition\nHands-on experience with Spark Experience with cloud-based managed frameworks for integrated model development, delivery and monitoring, in particular the AWS SageMaker ecosystem\n#LI-Hybrid\nBenefits & Perks \ud83d\ude0d-Inclusive and flexible work environment-Generous Vacation Policy, plus 2 extra floating holidays to use for religious or cultural events that matter to you-Employee Share Purchase Plan-Career progression\/internal mobility opportunities-Four employee resource groups to get involved with (the Docebo Women's Alliance, PRIDE, BIDOC, and Green Ambassadors)\n\nAbout Docebo \ud83d\udc99Here at Docebo, we power learning experiences for over 3000 customers around the world with our easy-to-use, AI-powered Suite designed to close the enterprise learning loop. We have successfully achieved 2 IPOs (TSX: DCBO & NASDAQ: DCBO), been recognized as a Top SaaS e-learning Solution, and are growing exponentially in the process.Docebo is a global company with offices in North America, EMEA, APAC and more. Our people believe in six core values, simply defined and manifested in everything we do - Innovation, Simplicity, Accountability, Togetherness, Curiosity, and Impact. If this sounds like you, now is your time to join one of the fastest-growing learning technology companies on the market. Apply today!\nDocebo is an Equal Employment Opportunity employer. We are committed to diversity and inclusion in our workforce. All qualified applicants and employees will receive consideration for employment regardless of their race, color, religion, sex (including pregnancy, gender identity, and sexual orientation), national origin, citizenship status, age, disability, genetic information, or any other category protected under applicable law.\nAny individuals requiring a reasonable accommodation to assist with their job search or application for employment should send an e-mail to recruiting_accommodations (at) docebo.com. The e-mail should include a description of the requested accommodation and the position you\u2019re applying for or interested in.","78":"Senior Data Scientist - Computer Vision and MLOps \nEvents in recent years have made us all too familiar with the havoc that natural disasters can wreak, and the increasing frequency and intensity with which they are occurring.  Despite record levels of losses, conventional methods of risk modeling continue to paint at best an incomplete picture of these threats.\nZesty.ai uses novel data gathering and data science methods to produce higher quality information about the risks to property from catastrophes like floods and wildfires.  While AI alone may not be able to thwart these disasters, it can help us become more prepared for them, and ultimately that will lead to better outcomes.\nAs a Senior Data Scientist - Computer Vision and MLOps, you are comfortable and excited to work closely with the Data Science and Machine Learning team to build the best AI tech possible. You will scale the development of top-tier models by using diverse data sources to provide strong insights and maximize the impact of our company efforts. You thrive in a collaborative, creative environment that moves fast and you\u2019re comfortable setting in place structures and processes to help the company scale. \nThe Opportunity:\nWe\u2019re looking for a Senior Data Scientist that would be excited to work on computer vision projects for the first 3 to 6 months in order to get a good sense of our systems and then transition into an MLOPs role (we feel that this would be the best way for you to be familiar with our problem set and systems).\nIn the initial 3 to 6 months, you\u2019ll develop and improve on our computer vision property insights models using the latest techniques in deep learning.\nFollowing the initial rotation with the deep learning team, you\u2019ll transition into an Ops role where you\u2019ll work on improving our tooling, processes and systems to help enable our team to perform at its best.\nTranslate product management, engineering, and business constraints and queries into tractable data science questions.\nWhat You Bring to the Zesty.ai Team:\nExperience working with deep learning \/ neural network models (using PyTorch, TensorFlow, Keras, Caffe) \nExperience working with computer vision and building and testing computer vision systems\nExperience deploying machine learning models in production environments\nBA \/ BS \/ BEng degree in Math, Physics, Computer Science, Engineering, or Economics. MS degree or Ph.D. is certainly a bonus\nStrong organizational and management skills with past experiences implementing best practices and processes\nExperience working with large image datasets (great if you\u2019ve already worked with satellite imagery and related tools OpenCV, Pillow, etc.)\nProficient in SQL, BigQuery\nExperience working with cloud platforms (AWS, Google Cloud, etc) \nKubernetes, docker experience\nMust be legally eligible to work in Canada\nWhy Zesty.ai:\nBe part of a well-funded growth-stage start-up\nMarket competitive comp and equity incentives to give you a stake in our future\nComprehensive health care plan \nFlexible Time Off \nAn upbeat and collaborative work culture \nCompany-sponsored outings and offsites\nAll of your personal information will be kept confidential according to EEO guidelines.","79":"Location: Hyderabad,Telangana,India\nQuantium\nFounded in 2002, Quantium combines the best of human and artificial intelligence to power possibilities for individuals, organisations and society. Our solutions make sense of what has happened and what will, could or should be done to re-shape industries and societies around the needs of the people they serve.\nAs one of the world\u2019s fully diversified data science and AI leaders we operate across every sector of the economy and we\u2019re growing fast - with growth comes opportunity! We\u2019re passionate about building out our team of smart, fun, diverse and motivated people.\nWe combine a team of experts that spans data scientists, actuaries, statisticians, business analysts, strategy consultants, engineers, technologists, programmers, product developers, and futurists \u2013 all dedicated to harnessing the power of data to drive transformational outcomes for our clients.\nWe actively foster a culture where our people can stretch themselves to reach their full potential.\nWe also know that work has to work for you, and modern life is fast-paced and balance can be tricky. You want to work where you are respected and valued as an individual, not a number. Quantium embraces a flexible and supportive environment dedicated to powering possibilities for our team members, clients and partners.\nMLOps Resposibilities\nDesign the data pipelines and engineering infrastructure to support our clients\u2019 enterprise machine learning systems at scale\nTake models data scientists build and turn them into a real machine learning production system\nDevelop and deploy scalable tools and services for our clients to handle machine learning training and inference\nIdentify and evaluate new technologies to improve performance, maintainability, and reliability of machine learning solutions\nApply software engineering rigor and best practices to machine learning pipelines, including CI\/CD, automation, etc.\nSupport models with an emphasis on auditability, versioning, and data security\nFacilitate the development and deployment of proof-of-concept machine learning systems \nSkills Required\nAbility to build MLOps pipelines\nAbility to design and implement solutions in GCP\nExperience in Kubeflow Pipelines platform for building and deploying portable, scalable machine learning (ML) workflows\nExperience in Vertex AI services for building, deploying, and managing machine learning models in the cloud\nExperience with containerization and Kubernetes\nGood understanding of Linux for managing servers\nAutomation for deploying machine learning solutions using Python\/Bash\/Go\/Ruby scripting etc.\nExposure to machine learning models built using scikit frameworks in Python\nExposure to machine learning frameworks such as Keras or PyTorch or Tensorflow\nHands-on experience managing or provisioning GPU\/CPU clusters, or other large-scale cloud or Linux\/Unix systems.\nExperience embedding monitoring solutions in ML applications\nHands on experience developing and training AI\/ML models.\nProven experience implementing CI\/CD on large-scale operational AI pipelines\nApply to this job","80":"Location: Hyderabad,Telangana,India\nQuantium\nFounded in 2002, Quantium combines the best of human and artificial intelligence to power possibilities for individuals, organisations and society. Our solutions make sense of what has happened and what will, could or should be done to re-shape industries and societies around the needs of the people they serve.\nAs one of the world\u2019s fully diversified data science and AI leaders we operate across every sector of the economy and we\u2019re growing fast - with growth comes opportunity! We\u2019re passionate about building out our team of smart, fun, diverse and motivated people.\nWe combine a team of experts that spans data scientists, actuaries, statisticians, business analysts, strategy consultants, engineers, technologists, programmers, product developers, and futurists \u2013 all dedicated to harnessing the power of data to drive transformational outcomes for our clients.\nWe actively foster a culture where our people can stretch themselves to reach their full potential.\nWe also know that work has to work for you, and modern life is fast-paced and balance can be tricky. You want to work where you are respected and valued as an individual, not a number. Quantium embraces a flexible and supportive environment dedicated to powering possibilities for our team members, clients and partners.\nLead ML Ops Engineer\nMLOps Resposibilities\nDesign the data pipelines and engineering infrastructure to support our clients\u2019 enterprise machine learning systems at scale\nTake models data scientists build and turn them into a real machine learning production system\nDevelop and deploy scalable tools and services for our clients to handle machine learning training and inference\nIdentify and evaluate new technologies to improve performance, maintainability, and reliability of machine learning solutions\nApply software engineering rigor and best practices to machine learning pipelines, including CI\/CD, automation, etc.\nSupport models with an emphasis on auditability, versioning, and data security\nFacilitate the development and deployment of proof-of-concept machine learning systems \nSkills Required\nAbility to build MLOps pipelines\nAbility to design and implement solutions in GCP\nExperience in Kubeflow Pipelines platform for building and deploying portable, scalable machine learning (ML) workflows\nExperience in Vertex AI services for building, deploying, and managing machine learning models in the cloud\nExperience with containerization and Kubernetes\nGood understanding of Linux for managing servers\nAutomation for deploying machine learning solutions using Python\/Bash\/Go\/Ruby scripting etc.\nExposure to machine learning models built using scikit frameworks in Python\nExposure to machine learning frameworks such as Keras or PyTorch or Tensorflow\nHands-on experience managing or provisioning GPU\/CPU clusters, or other large-scale cloud or Linux\/Unix systems.\nExperience embedding monitoring solutions in ML applications\nHands on experience developing and training AI\/ML models.\nProven experience implementing CI\/CD on large-scale operational AI pipelines\nApply to this job"}}