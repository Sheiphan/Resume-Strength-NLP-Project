Our Mission To restore cell health and resilience through cellular rejuvenation programming to reverse disease, injury, and the disabilities that can occur throughout life. For more information, see our website at altoslabs.com. Diversity at Altos We believe that diverse perspectives are foundational to scientific innovation and inquiry.  We are building a company where exceptional scientists and industry leaders from around the world work side by side to advance a shared mission.  Our intentional focus is on Belonging, so that all employees know that they are valued for their unique perspectives.  At Altos, we are all accountable for sustaining a diverse and inclusive environment. Responsibilities Develop new statistical and machine learning-based methods for querying biological data to produce insights about cell health and rejuvenation. Train and optimize machine learning models on large, complex datasets. Partner with experimental biologists across Altos to help design experiments and interpret their results. Bring computational thinking to bear on Altos’ mission and challenges, ranging from modeling biological phenomena to supporting the research process and culture at Altos through computation and AI. Excitement about the Altos mission of investigating cellular rejuvenation programming to restore cell health and resilience. Qualifications PhD in Computational Biology or related fields. Experience with machine learning and deep learning models applied to biological data. Strong understanding of machine learning concepts, including model training, generalization and optimization. Strong programming skills in R and Python. Experience with deep learning libraries such as TensorFlow or PyTorch. Working knowledge of cellular and molecular biology. Track record of analysis of -omics data (RNA expression, chromatin accessibility, DNA methylation, etc.). Bonus: Experience in cell health and rejuvenation related research area. Bonus: Proven track record in open-source software development, e.g., demonstrated by high-impact github repository. Bonus: Proven track record of high-caliber scientific work, e.g., demonstrated through publications in peer-reviewed scientific journals. The job ranges for this position are: Scientist I £51,850 to £70,150; Scientist II £61,000 to £91,800; Senior Scientist £68,000 to £130,980   #LI-LY1  What We Want You To Know We are a culture of collaboration and scientific freedom, and we believe in the values of diversity, inclusion and belonging to inspire innovation. Altos Labs provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.  This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.  Altos currently requires all employees to be fully vaccinated against COVID-19, subject to legally required exemptions (e.g., due to a medical condition or sincerely-held religious belief). Thank you for your interest in Altos Labs where we strive for a culture of scientific freedom, learning, and belonging. Note: Altos Labs will not ask you to download a messaging app for an interview or outlay your own money to get started as an employee. If this sounds like your interaction with people claiming to be with Altos, it is not legitimate and has nothing to do with Altos. Learn more about a common job scam at https://www.linkedin.com/pulse/how-spot-avoid-online-job-scams-biron-clark/ Company Description REFID276761 At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking for a Senior Big Data Software Engineer to join our ciValue Technology team in Israel. The ciValue division of NIQ is a leading provider of AI-powered customer analytics, personalization, and brand collaboration platform. Serving dozens of retailers and brands across the world using cutting-edge big-data, real-time analytics, and data-science automation. Our solution is disrupting existing data & media monetization model by enabling retailers to remain in control of their revenue. Job Description We believe that building a great product and teams starts with amazing, diverse-minded, and bright people who make an impact, generate creative & innovative ideas, and take on new perspectives.   The Big Data Software Engineer is responsible for building new data solutions for our rapidly expanding customer base and working with the top data ingestion technologies in an open, collaborative, and innovative environment.  Responsibilities Be responsible for Data flow stages from definition to architecture, including Data acquisition, Data set acceptance criteria and Data Science integration.  Architecture designing and customizing technological solutions for large-scale data processing.  Develop and deploy real-time and batch data processing infrastructures and pipelines.  Take responsibility to explore technologies to scale up the Data ecosystem to handle rapid Big Data growth.  Work closely with the Data Science team to embed ML / AI algorithms into the product. Work with cloud, DevOps, application, and client teams to make sure your solution is solving significant business problems in a robust, scalable manner.  Use cutting-edge technologies: Python, Airflow, Java, Kubernetes, Spark, Scala, and Kafka. Qualifications 4+ years of backend engineering work experience in production environments (Data environments, Big Data processing, Database techniques).  Experience in Big Data – Spark / Kafka / Flink.  Proven experience with Python and Java/Scala. Experience in the design and development of scalable Big Data solutions. Experience working with SQL & NO-SQL Databases – PostgreSQL, DataLake, Columnar DB. Experience in Kubernetes, containers & Helm is a plus. Ability to learn new technologies and work in a dynamic fast-paced environment. Result-driven, pragmatic, and innovative.  Experience with Cloud technology is an advantage. Excellent English communication skills spoken and written.  Bachelor's or Master’s degree in Computer Science, Computer Engineering, or a related field. Additional Information #LI-SG About NIQ NIQ, the world’s leading consumer intelligence company, reveals new pathways to growth for retailers and consumer goods manufacturers. With operations in more than 100 countries, NIQ delivers the most complete and clear understanding of consumer buying behavior through an advanced business intelligence platform with integrated predictive analytics. NIQ delivers the Full View.  NIQ was founded in 1923 and is an Advent International portfolio company. For more information, visit NIQ.com  Want to keep up with the latest updates on our business and #LifeAtNIQ? Follow us on: LinkedIn | Instagram | Twitter | Facebook Our commitment to Diversity, Equity, and Inclusion NIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion/ NIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process. At Definitive Healthcare, our passion is to transform data, analytics and expertise into healthcare commercial intelligence. We help clients uncover the right markets, opportunities and people, so they can shape tomorrow’s healthcare industry. Our SaaS platform creates new paths to commercial success in the healthcare market, so companies can identify where to go next.   Our employees are kind, collaborative, energetic, approachable and driven. On top of that, we value the unique perspectives, backgrounds and voices of our employees. Why? Because their diverse experiences drive new ideas and help us build a better community.  For over 10 years, we’ve built a collaborative culture driven by employees who share a passion for improving the healthcare ecosystem, enjoy giving back to the local community and value diversity and inclusion.   One of the hallmarks of our culture is our commitment to community service. Through the DefinitiveCares program, employees can work with their choice of more than 40 charitable organizations, supporting causes from hunger and homelessness to healthcare, LGBTQ+ issues, racial justice, women’s initiatives and more. 2021 marked the sixth year that we had 100% employee participation in DefinitiveCares.  We also provide a range of opportunities for employees to connect with each other. Employees can join any of our employee run affinity groups supporting causes such as women’s empowerment, LGBTQ+, Black, indigenous and people of color (BIPOC), disabilities and working parents and potential for many more. Affinity groups often enable greater education companywide through training, events and speaker series.  We’re also a great place to work. For five years in a row, we’ve been recognized by the Boston Business Journal and the Boston Globe as a best place to work in Massachusetts. In 2022, Energage recognized us for Culture Excellence in Compensation & Benefits, Innovation, Great Leadership, Purpose & Value and Work-Life Flexibility!  Think you’d be a good addition to our team? Explore our available positions here. We’d love the chance to get to know you.   Your challenge:  As a Senior Big Data Engineer, you will join our growing Engineering team. You will work with teams of big data and software engineers to build data solution utilizing big data technologies such as Databricks, Snowflake, etc., Leveraging scala or python you will develop data pipelines to transform/wrangle/integrate the data into different data zones. You will enhance your skillset by learning from your seniors and share your knowledge to build sustainable solution. You will hold accountability for technical decisions. The Senior Big Data Engineer at Definitive Healthcare: Ensures solutions are built using databricks, snowflake according to business and technical specifications. Deploy and support highly optimized solutions with a focus on automation. Support an error-free, predictable, high-performing platform in AWS Actively Contributes to architectural discussions around our data. Performs code reviews Is always thinking of better ways to do something Isn’t afraid to fail. Provide leadership to the ongoing maturity of the development process, coach/mentor the development team on best practices and methodologies for enhanced solution development. Cares deeply about quality Stay up to date on the relevant technologies, plug into user groups, understand trends and opportunities. Skills we’re looking for: Must be results driven, customer focused, technologically savvy, and skilled at working in an agile development environment. Deep expertise in working with data (Structured, Unstructured etc.,) Strong Experience with at-least one scripting language i.e., Python, Scala, Java, C++ etc., Deep Understanding of distributed computing principles Data modeling and processing fundamentals with large-scale (> 50B rows) data Experience with Apache Spark using Scala and Spark SQL (Batch, streaming) Demonstrated ability to create normalized and star-schema database designs using database modeling techniques. Superior understanding of normalization and denormalization. Expert Knowledge of Big Data PaaS components in the cloud, such as Databricks, Snowflake Working knowledge of RDBMS, NoSQL and Graph databases Knowledge of Hadoop, Spark, and HDFS Experience with containerization  Experience with automation technologies such as Argo, Oozie, Airflow Knowledge of Linux/Unix  Why we love Definitive, and why you will too! Industry leading products Work hard, and have fun doing it Incredibly fast growth means limitless opportunity Flexible and dynamic culture Work alongside some of the most talented and dedicated teammates Definitive Cares, our community service group, gives all of us a chance to give back Competitive benefits package including great healthcare benefits and a 401(k) match What our Employees are saying about us on Glassdoor:   “Great Work atmosphere, great work life balance, excellent company to work for, amazing top notch product, incredible customer service, lots of tools to help you succeed.” -Business Development Manager “Great team. Amazing growth. Employees are treated very well.” -Research Analyst “I have waited 36 years to work at a dream job for a dream company and I am so happy to have finally got there.” -Profile Analyst   If you don’t fit all of these qualifications, but believe you’re still a great fit, feel free to apply and tell us why in your cover letter.   If you are a California, Colorado, New York City or Washington resident and this role is a remote role, you can receive additional information about the compensation and benefits for this role, which we will provide upon request.   Definitive Hiring Philosophy Definitive Healthcare is an equal opportunity employer that celebrates diversity and is committed to creating an inclusive workplace with equal opportunity for all applicants and teammates. Our goal is to recruit the most talented people from a diverse candidate pool regardless of race, color, religion, age, gender, gender identity, sexual orientation or any other status. If you’re interested in working in a fast growing, exciting working environment – we encourage you to apply!   Privacy  Your privacy is important to us. Please review our Candidate Privacy Notice which tells you how we use and process your personal information   Please note: All communications regarding the hiring process at Definitive Healthcare will come directly from one of our corporate recruiters or coordinators with an @definitivehc.com email address. We will never request any money transfer or purchase of equipment with a promise of reimbursement. If you receive any suspicious communications, please reach out to careers@deinfitivehc.com to confirm your status in the application process.  We partner with the world’s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency. Hi There, This is Miguel from CI&T! I am a Talent Attracting Analyst looking for people located in Colombia for a Mid-Level Data/ETL Engineer Position to work on a project in the Mortgage industry (USA). Requirements for this challenge: - High value on GCP experience (dataproc, dataplex), familiarity with SQL and ETL concepts. - Postgres/Snowflake experience (nice to have).- Excellent written and verbal English communication skills. Our benefits: - Premium Healthcare- Meal voucher- Maternity and Paternity leaves.- Mobile services subsidy - Sick pay -Life insurance. -CI&T University - Colombian Holidays -Paid Vacations - And many others. #LI-MP1#MidseniorCI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters’ identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow. At CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas. We strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies. Description de l'entreprise Business & Decision est un groupe international des services du numérique, spécialisé, depuis sa création, dans l’exploitation et l’analyse de données. Business & Decision conseille et déploie les solutions et les services les plus innovants pour accompagner les directions métier à relever les défis majeurs de création de valeur de leurs organisations. Data Intelligence, Big Data, Data Gouvernance, véritables socles de l’intelligence artificielle et de l’expérience digitale, sont les domaines d’expertise et de spécialisation du groupe. Business & Decision, filiale d’Orange Business Services, emploie 2 500 talents dans 10 pays dans le monde et dans 14 villes en France. Description du poste Rattaché à un Manager Opérationnel, vous intégrez des équipes de projet et pouvez participer à toutes les phases de mise en œuvre de projets Big Data. Vos missions : Recueil des besoins à travers des spécifications ou des user stories Développement à travers des frameworks de calcul distribué (Spark, Flink, Beam, …) Mise en place ou exploitation de chaînes CI/CD Réalisation des documentations Industrialisation ou aide à l’industrialisation (Ansible, Terraform) Qualifications De formation informatique Bac+5, vous justifiez d’au minimum 3 ans d’expérience, , dans la mise en œuvre de projets Big Data et vous maîtrisez le développement sur des systèmes de calcul distribué (python, scala ou java à travers des frameworks Spark, Beam, …) La maîtrise de l’anglais est souhaitée pour intervenir auprès de nos clients internationaux. Votre curiosité, votre autonomie et esprit d’initiative sont des atouts pour développer vos compétences et contribuer à votre évolution. Votre esprit d’équipe favorisera votre intégration au sein de l’agence. Informations supplémentaires Ce que nous vous proposons : Une carrière dans un environnement multiculturel, dynamique et formateur, Une réelle possibilité de télétravail, Un appui et un suivi régulier d’un manager sénior dans le métier, Des formations et les certifications associées au parcours de carrière choisi (en environnement Microsoft mais aussi sur d’autres offres Data), Des possibilités d’activités complémentaires (avant-vente, formation, conseil, expertise, montage d’offre, POC..), Des événements festifs, Une intégration au sein d’une communautés d’experts passionnés Pour aller plus loin : https://fr.blog.businessdecision.com/ Vous êtes partant pour vivre l’aventure ? Postulez dès maintenant en nous envoyant votre CV. Tous nos postes sont accessibles, à compétences égales, aux travailleurs en situation de handicap. We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas or take over sponsorship at this time. About the role: In this role, you will design, develop, implement and maintain reporting functionality and analytic applications across multiple business units including Finance, Marketing, Operations and more. You will interface with Business Owners, leveraging our data infrastructure and Enterprise BI tools to facilitate faster decision-making, standardize key customer, loan, and business metrics, and support the company’s strategic initiatives. You will also capture and translate requirements through a variety of techniques to create coherent report design documents leading to successful solutions. We are looking for creative problem solvers who enjoy collaborating with others to build new data warehouses, data mart and business intelligence solutions, while supporting our existing applications. You will operate as an owner by completing the full life cycle of a project from understanding the business process and requirements through implementation and ongoing support. Requirements: 6+ years of related experience building data warehouses and reporting 6+ years of experience in the design and implementation of ETL/ELT frameworks for complex data mart projects 5+ years of experience in MicroStrategy and/or Tableau or a comparable BI tool 3+ years of experience in Python or other programming Strong knowledge of databases like PostgreSQL, Snowflake, etc. and data analysis skills  Strong knowledge of dimensional modeling and Data Warehousing would be an advantage Good communication and interpersonal skills Highly motivated Team player A Bachelor’s or Master’s degree in Engineering, Computer Science, IT or related study Benefits & Perks: Flexible work schedule (In-office T/W/Th and remote M/F for hybrid-eligible roles) Health, dental, and vision insurance including mental health benefits 401(k) matching plus a ROTH option PTO & paid holidays off Sabbatical program Summer hours Paid parental leave Pet insurance DEI groups (B.L.A.C.K. @ Enova, HOLA @ Enova, Women @ Enova, Pride @ Enova, South Asians @ Enova, APEX @ Enova, and Parents @ Enova) Employee recognition and rewards program Charitable matching and a paid volunteer day…Plus so much more! About Enova Enova International is a leading financial technology company that provides online financial services through our AI and machine learning-powered Colossus™platform. We serve non-prime consumers and businesses alike, while offering world-class technology and services to traditional banks—in order to create accessible credit for millions.  Being a values-driven organization is at the core of Enova’s success. We live our values by listening to our customers, challenging assumptions, thinking big, setting high expectations, and hiring and developing the best. Through our values and our commitment to making Enova an awesome place to work, we maintain an environment of inclusion and culture where our employees can thrive. You can learn more about Enova’s values and culture here.  It is our policy to provide equal employment opportunity for all persons and not discriminate in employment decisions by placing the most qualified person in each job, without regard to any other classification protected by federal, state, or local law. California Applicants: Click here to review our California Privacy Policy for Job Applicants. What if… you could join an organization that creates, resources, and builds life sciences companies that invent breakthrough technologies to transform human health and sustainability? Company Summary: FL86, Inc. is a privately held, early-stage company developing a novel genomics platform and therapeutics for diseases with a large unmet need. FL86 was founded by Flagship Pioneering, an innovative enterprise that conceives, creates, resources, and grows first-in-category life sciences companies. Flagship Pioneering has created over 100 groundbreaking companies over the past twenty years, all of which are pioneering novel and proprietary biological, industrial, and engineering approaches to solve major needs in human health and sustainability. These companies include Moderna (MRNA) Generate Biomedicines, Sana Biotechnology (SANA), Tessera Therapeutics, Evelo Biosciences (EVLO), Indigo Agriculture, Seres Therapeutics (MCRB), Syros Pharmaceuticals (SYRS), and Rubius Therapeutics (RUBY). To date, Flagship has deployed over $2.5 billion in capital toward the founding and growth of its pioneering companies alongside more than $19 billion of follow-on investments from other institutions. In 2021, Flagship Pioneering was ranked 12th globally on Fortune’s “Change the World” list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies. Position Summary: We are seeking a computational scientist (leveling flexible based on experience) who wants to leverage genomics data to identify new ways to treat human diseases. The candidate brings enthusiasm, intellectual curiosity, scientific rigor, and a deep-rooted desire to innovate in genomics. This role is based in the vicinity of Cambridge UK and hybrid work arrangements will be considered, but all applicants will require permission to work in UK.  Key Responsibilities: Be an active member of a scientific team focused on the design and deployment of bioinformatics, with the end goal of developing new therapeutics for diseases with large unmet needs Work on collaborative project teams to design experiments and analyze results to address underlying genomics questions Identify and integrate relevant structured and unstructured functional and genomics datasets into FL86’s database Develop and deploy statistical models to assess database for novel discoveries Participate in ongoing work on method development and analysis Communicate key findings to stakeholders across the company, in written and presentation formats Collaborate closely with other members across the organization Requirements: PhD, or equivalent work-experience, in cancer genetics, human genetics, statistical genetics, computational biology, bioinformatics, genomics or similar discipline is required 0-5+ years of industry/post-doc experience working with genomics data, with ability to process, analyze, and interpret genetic datasets Can write and interpret data analysis code Candidates with experience in (a) Target Discovery, (b) Writing and operating data pipelines, or (c) Human or Cancer Genomics analysis will be preferred Strong leadership, management, and collaboration skills Excellent verbal and written communication. Ability to work successfully in a matrix environment, prioritize and manage multiple tasks simultaneously, integrate cross-functional issues and balance competing priorities effectively. A high degree of energy, accuracy and attention to detail, and a passion for creating transformative medicines for patients with serious diseases Location: Cambridge, England   Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.   Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto. Power BI Developer Reporting to: Data & Reporting Manager Location: Scale Space Building, 58 Wood Lane, London W12 7RZ.   We’ve been pioneering embedded finance since 2007 and over the years, we’ve worked in partnership with banks, SaaS providers, payment processors, checkout providers, and even the UK government – providing all they need to offer easy and frictionless revenue-based finance solutions to their SME customers through our API-powered funding platform. We are in a very exciting period of growth, both within the UK and internationally, with teams based in London, Nottingham, USA and Scandinavia. As we continue to grow we are looking for talented and ambitious individuals to join us to reshape business finance. We are proud to have been included in The Sunday Times Hiscox Tech Track 100 as one of the 100 fastest growing FinTechs in the UK for two years running.   Who are you?    The ideal candidate will have solid practical experience as a Power BI developer. Knowledge & experience of Power Apps and Power Automate is desirable but not essential. The candidate should feel comfortable across the whole data lifecycle – specifically with competent SQL skills.   The ability to confidently communicate up and down the stakeholder ladder is essential, as is the ability to advise, train and support our user base. A keen eye for detail is critical.   While technical skills are a necessary requirement, the key to success in this role is the ability to be able to understand and interpret user requirements across the business, often by challenging the status quo of methods and processes.     Responsibilities   Work collaboratively across all business functions to deliver Reporting. Identify key improvements and requirements in reporting and processes. Translate those business requirements into robust, scalable technical solutions Create and test the quality and accuracy of reporting outputs before they are released. Work closely with the data engineers, analysts, and other core stakeholders to develop a data strategy across the business to leverage the data assets we have     We think you'll need   Significant experience with Power BI is a must. Experience with advanced Power BI functionality including Power Apps is very valuable but not a must-have Experience of managing and delivering reporting projects. Understanding of data modelling, with competent SQL skills. Strong data analysis, interpretation, and visualisation skills. Knowledge & experience of Power Apps and Power Automate is desirable but not essential. An inquisitive mindset, proactive approach to problem solving and the ability to work both autonomously and collaboratively.     What happens next?   A lot of businesses talk about the importance of diversity and inclusion, at Liberis we want to make sure that we’re genuinely fostering a highly inclusive culture that not only welcomes diversity, but celebrates it. Our commitment is not just surface level. We’re on a mission to create a safe space where everyone and anyone, regardless of their background, can thrive.    It’s not just the right thing to do. We also recognise that diverse teams perform better because we have so much to learn from one another. We think that’s pretty cool, and if you do to then you’re in the right place.     We have a hive of activity happening around the business to make sure we’re always pushing for more. Everyone is encouraged to get involved to help us to continue to build an excellent culture at Liberis.     Think this sounds like the right next move for you? If you’re not completely confident that you fit our exact criteria, get in touch! Humility is a wonderful thing and we are interested in hearing about what you can add to Liberis. You can reach us at talent@liberis.co.uk - we look forward to chatting with you!    #LI-CG1 Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description This position is ideal for an engineer who is passionate about solving challenging business problems. You will be an integral part of the Payment Products Development team focusing on test automation. The candidate will be extensively involved in hands-on activities including POCs, design, documentation, and testing of new and existing functionality. Candidate must be flexible and willing to switch tasks based on team's needs. Develop systems and processes to refine efficiency of automated testing solutions Design and execute tests for applications and services Develop and maintain tools for automation tracking and reporting Review product requirements and specifications and recommend improvements to ensure product testability Recommend areas of applications and services where automation would be beneficial Present technical solutions, capabilities, considerations, and features in business terms Effectively communicate status, issues, and risks in a precise and timely manner Perform other tasks on data governance, system infrastructure, and other cross team functions on an as-needed basis This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs. Qualifications We are seeking team members that are passionate, visionary and insatiably inquisitive. Successful candidates frequently have a mix of the following qualifications:  • Bachelor’s Degree or an Advanced Degree (e.g. Masters) in Computer Science/ Engineering, Information Science or a related discipline • Minimum of 3 years of quality assurance experience (with a concentration in data centric initiatives), with demonstrated expertise in leveraging standard testing best practice methodologies • Professional experience delivering test automation at the unit, business logic, and integration level testing • Experience building and writing code with unit level tests for REST APIs, and web applications • Experience writing code in Core Java and SQL • Working knowledge of Unix/Linux • Experience using frameworks and tools like Junit, Selenium / WebDriver will be a plus point • Knowledge of Automated Test-Driven Development or Test-Driven Development (TDD) • Experience with one or more of the following database technologies: MySQL, Redis • Experience with data visualization and business intelligence tools like Tableau, or other programs highly desired • Experience working in an Agile environment • Knowledge of open-source Big Data eco-system is highly desirable • Demonstrated intellectual and analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style • Previous exposure to financial services is a plus, but not required Additional Information Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. We partner with the world’s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency. Hi There, This is María from CI&T! I am a Talent Attracting Analyst looking for people located in the USA for a Senior Data Ops Engineer Position to work on a project in the Mortgage Industry. Requirements for this challenge: - Cloud (Azure, GCP or AWS)- CI/CD pipelines- Terraform.- Data Bases: SQL, Postgres, Dataproc, Dataplex- Excellent written and verbal English communication skills Our benefits: - Premium Healthcare- Meal voucher- Maternity and Paternity leaves.- Mobile services subsidy- Sick pay-Life insurance.-CI&T University-Colombian Holidays-Paid VacationsAnd many others. #LI-MJ1#MidSeniorCI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters’ identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow. At CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas. We strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies. Who We Are 23andMe, the leading consumer genetics and research company, has accumulated a wealth of genotypic and phenotypic information from participants committed to improving human health through advances in genomics. Our Therapeutics team in South San Francisco leverages this data to discover and develop new treatments that can offer significant benefits for patients with serious, unmet medical needs. This dedicated research and drug development group identifies novel targets using 23andMe's genetic database and performs preclinical research to advance programs towards clinical development. We currently have programs across several therapeutic areas, including but not limited to oncology, respiratory, and cardiovascular diseases. More information about our Therapeutics team is available at https://therapeutics.23andme.com/. We are looking for an exceptional Computational Biologist to join our collaborative, cross-functional research team focused on discovery of novel therapeutic targets and interpretation of association signals from the world’s largest database of genotypes and phenotypes. Successful candidates will have demonstrated experience analyzing large genetic, gene expression and functional genomics datasets using the best practices in statistics or machine learning. They will use rigorous quantitative reasoning, creativity, and understanding of molecular biology to develop computational tools to analyze high-throughput functional data and integrate it with human genetics to identify promising drug targets. Our team is very collaborative, and the ability to communicate ideas and results with other scientists is key.   What You'll Do Build tools and develop computational methods to provide biological interpretation of genetic signals identified in the 23andMe database Extend existing target discovery efforts to incorporate additional data types and novel analysis methods Work collaboratively with members of Computational Biology, Statistical Genetics and Discovery Biology teams on integrative analysis of public and in-house generated gene expression and functional genomics data with the goals of elucidating disease biology Provide scientific expertise and leadership and drive complex projects forward Mentor and manage PhD-level scientists    What You’ll Bring Ph.D. in Computational Biology, Bioinformatics, Biomedical Informatics, Biostatistics, Genetics, Computer Science, Statistics or a similar quantitative field Experience in interpretation and fine mapping of genetic association signals Hands-on experience working with large scale *omics datasets Experience developing robust data analysis software in R and/or Python 5+ years of post-Ph.D. research work experience in an academic or for-profit setting Demonstrated success in leading complex projects with multiple contributors and/or stakeholders Experience managing one or more Ph.D. level scientists Demonstrated ability to effectively work as part of interdisciplinary teams Exceptional communication skills, with an ability to convey complex computational results to colleagues from a wide range of life sciences backgrounds Ability to work from 23andMe's office in South San Francisco a minimum of 2 days per week   Strongly Preferred Industry experience in pharmaceutical or biotechnology research   About Us 23andMe, headquartered in Sunnyvale, CA, is a leading consumer genetics and research company. Founded in 2006, the company’s mission is to help people access, understand, and benefit from the human genome. 23andMe has pioneered direct access to genetic information as the only company with multiple FDA authorizations for genetic health risk reports. The company has created the world’s largest crowdsourced platform for genetic research, with 80 percent of its customers electing to participate. The platform also powers the 23andMe Therapeutics group, currently pursuing drug discovery programs rooted in human genetics across a spectrum of disease areas, including oncology, respiratory, and cardiovascular diseases, in addition to other therapeutic areas. More information is available at www.23andMe.com. At 23andMe, we value a diverse, inclusive workforce and we provide equal employment opportunity for all applicants and employees. All qualified applicants for employment will be considered without regard to an individual’s race, color, sex, gender identity, gender expression, religion, age, national origin or ancestry, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, genetic information, military or veteran status, or any other basis protected by federal, state or local laws.  If you are unable to submit your application because of incompatible assistive technology or a disability, please contact us at accommodations-ext@23andme.com. 23andMe will reasonably accommodate qualified individuals with disabilities to the extent required by applicable law. Please note: 23andMe does not accept agency resumes and we are not responsible for any fees related to unsolicited resumes. Thank you.   Pay Transparency 23andMe takes a market-based approach to pay, and amounts will vary depending on your geographic location. The salary range reflected here is for a candidate based in the San Francisco Bay Area.  The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.San Francisco Bay Area Base Pay Range$168,000—$252,000 USD The InMobi Story  We like big challenges. Building a new company in 2007 was no ordinary task. As the recession hit, the iPhone was born and launched a revolution. Mobile advertising wasn’t yet a thing, other than SMS, and venture capital funding was hard to come by for four guys in India.     Yet with passion, foresight, and conviction – InMobi charted its own course, helping to transform the way consumers engage with their phones and create today's booming app economy wherein consumers now spend 4.2 hours per day.    After fourteen years of innovation, our end-to-end advertising software platform, connected content and commerce experiences have formed a powerful engine for growth that activates audiences, drives real connections, and diversifies revenue for companies around the world.   Our global organization of InMobians are excited to continue discovering and developing impactful technologies that will continue to transform people, businesses, and society.    Title: Head of Data Science, InMobi Ads Platform Location: San Mateo Position Summary: Reporting to the Chief Technology Officer, this person will be driving the overall vision and strategy for data science with the InMobi Ads Platform group and will play a foundational role in setting up the DS unit, in terms of hiring and driving the larger AI-first aspirations of the company. If you are looking for a technology company where you can drive business outcomes in an ambitious, high-growth environment, then this is the place for you!  The Head of Data Science will design and launch innovative and complex analytic models, utilizing a blend of contemporary and traditional data mining techniques, and when applied to both structured and unstructured data sets, will drive insights and benefits not otherwise apparent. You should have business domain expertise to translate goals into data-based deliverables, using quantitative analysis, statistical modeling, predictive and prescriptive analytics, optimization and attribution algorithms, pattern detection analysis, etc.   You will have knowledge of current AI and machine learning capabilities and advances in the field. And you should also be interested in the academics of data science, but more focused on practical application. You will be able to clearly articulate the purpose of data science solutions to key stakeholders and customers, and then translate those into action for the business. The solutions you and your teams provide will encompass such things as product innovations, create efficiencies and automation across the business, improve data architecture and system architecture, mitigate business risks, and create process improvements.  We are searching for an executive who thrives on describing a vision and inspiring a team to achieve it. We need a leader who will remove obstacles, break barriers, empower, communicate, and engage. Someone who truly harnesses advanced analytic data modeling systems to drive positive outcomes for our customers. From the defining of a strategy to the execution of it, you will also develop, collect, and report the objective metrics required to assure it. You will own driving employee engagement and increasing productivity across Data Science and into Engineering.  This is a senior level role in which you will work directly with the CTO and the founders and lead all the efforts across data science for the InMobi Ads Platform business.    The impact you’ll make: Define the overall vision for our data science applications, focused on up-leveling internal use of machine learning Provide technical leadership of overall architecture, ML approaches, performance monitoring, continuing improvement, and production deployments Manage, develop, coach, and mentor a team of Data Scientists, machine learning engineers and big data specialists Partner with our business and product teams to help predict system behavior, establish metrics, identify bugs, and improve debugging skills Ensure data quality and integrity within our products as well as our teams Test performance of data-driven products Partner with our client-facing teams and customers to enhance products and develop client solutions applying critical thinking skills to remove extraneous inputs Conceive, plan, and prioritize data projects Lead data mining and collection procedures, especially focused on unstructured and siloed data sets Build analytic systems and predictive models Visualize data and create reports Experiment with new models and techniques Drive the implementation of models into Production through various Engineering teams Create a positive culture to maximize productivity and minimize attrition   The experience you'll need: Master’s or PhD in Statistics, Machine Learning, Mathematics, Computer Science, Economics, or any other related quantitative field. Equivalent work experience is also acceptable for the position. At least 7 years of working experience in a data science position, preferably working as a Senior Data Scientist that progressed into a leadership position. A proven and successful track record of leading high-performing data analyst and data science teams leading through the successful performance of advanced quantitative analyses and statistical modeling that positively impact business performance. Knowledge of data management and visualization techniques Excellent understanding and knowledge of statistical analysis and predictive modeling Practical knowledge and solid understanding of machine learning tools and techniques. (e.g.  Python, Deep Learning Architectures, TensorFlow, PyTorch, Spark, Scala) Able to work with diverse teams (product, engineering, analytics, sales, services) and at various levels within the organization Strong interpersonal skills, demonstrating an ability to collaborate with and influence teams & key stakeholders Strong executive leadership presence and business mindset   About Us  InMobi is the leading provider of content, monetization, and marketing technologies that fuel growth for industries around the world. Our end-to-end advertising software platform, connected content and commerce experiences activate audiences, drive real connections, and diversify revenue for businesses everywhere. With deep expertise and unique reach in mobile, InMobi is a trusted and transparent technology partner for marketers, content creators and businesses of all kinds.   Incorporated in Singapore, InMobi maintains a large presence in San Francisco and Bangalore and has operations in New York, Chicago, Kansas City, Los Angeles, Delhi, Mumbai, Beijing, Shanghai, Jakarta, Manila, Kuala Lumpur, Sydney, Melbourne, Seoul, Tokyo, London and Dubai. To learn more, visit inmobi.com.       Our Purpose   InMobi creates transformative mobile experiences and software platforms to positively impact people, businesses, and societies around the world.    We believe that our innovations at the intersection of artificial intelligence, commerce, and the creator economy will revolutionize the way consumers use their mobile devices. Our mission is to power our customers’ growth with innovative content and commerce experiences that help them activate their audiences and drive real connections. How do we do it?   An End-to-End Content, Monetization, & Marketing Platform the fuels industry growth   AI-Powered Audience Activation for the open content, media and marketing ecosystem   New Content and Commerce experiences for a world of connected devices    Award-winning culture, best-in-class benefits:      Competitive salary, bonus, and stocks      Quality medical, vision, dental      401(k) match      Flexible working hours     Parent friendly health benefits and work environment Wellness stipend     Healthy time off through a combination of PTO, sick days, and company-wide holidays     $400 to set up your own home office to thrive in a post COVID world Post-covid hybrid work model for employees close to our offices in New York, San Francisco, Irvine, and Kansas City    InMobi is an equal opportunity employer      InMobi is a place where everyone can grow. However you identify, and whatever background you bring with you, we invite you to apply if this sounds like a role that would make you excited to work.  InMobi provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type.  All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.  InMobi has implemented a mandatory COVID vaccination policy for all employees in the U.S. Employees who are unable to be vaccinated may request an exemption under certain circumstances.    #LI-BM1 About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to Know our Team:  The Supply Analytics team is a team of creative entrepreneurs that develop solutions for Agoda’s non-accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek.  Utilizing our strong brand and resources, we build new channels to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.  The Opportunity:   The role sits within the Supply Analytics team under Central Supply Team, where new business ideas, and partnership types are incubated and scaled. We are looking for a Senior BI Analyst whose main focus areas are providing visibility and insights for people-related issues through Business Intelligence tools like Tableau and SQL, managing data warehouses, building ETL processes, and helping build other tools to optimize the business. This role will be involved in strategic projects and work closely with commercial owners and business stakeholders, using data to identify and translate business needs and opportunities into actionable initiatives. In this Role, you’ll get to: Translate internal briefs into analytical projects (to include refining the initial brief and asking the ‘right questions’, working through potential hypotheses and storyboarding the output) Use and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders. Proactively identify opportunities for growth within supply and the wider business. Drive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply. Identify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence. Automate manual operational processes and present back on time savings gained through modernization of business operations What you’ll Need to Succeed: 4+ years of experience in analytics/data science/insights/strategy. Bachelor’s degree ideally in a business or quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance). 3+ years of experience with BI & analytics tools (SQL, Tableau, Metabase, Data Studio, or similar technologies) 2+ years of solid project management Good stakeholder management experience. Comfortable presenting to senior leadership and C-suite. Strong experience in finding data insights and provide business recommendation to the business A hacker’s mindset – the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping. Excellent communicator with superior written, verbal, presentation and interpersonal communication skills. Data driven in both decision making and performance measurement. Extreme comfort in ambiguous, fast-paced environment. Ability to multi-task, prioritize and coordinate resources. It’s Great if you Have:   Travel industry / e-commerce / tech / consulting experience. Experience in conducting A/B testing experimentation (a plus) A good understanding of statistical modelling knowledge or any machine learning technique knowledge is a plus (regression, logistic regression, random forest, etc.)   #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Responsibilities Design and further development of our existing and future dashboards and reporting based on Power BI, Azure DataBase and Azure DataFactory Analysis, conception, design and implementation of new requirements from the business departments on the basis of Power BI, Azure DataBase and Azure DataFactory Collaboration with business departments in process analysis, conception and design of solutions as well as their documentation Setting up ETL flows respectively connecting new systems to Azure DataBase / Azure DataFactory Application administration (monitoring, user and authorisation management) Key-User support Requirements 3-5 years of experience in a similar data-related role, using Microsoft technologies Completed technical education in Informatics (e.g. higher technical school or university) or equivalent qualification within business field Deep knowledge with Power BI, Azure DataBase and Azure DataFactory Good knowledge of ETL (Extract, Transform, Load) Knowledge of relational databases and data modelling Knowledge of SAP-BW is an advantage Very good English language skills Benefits A competitive package, depending on level of experience. You can work remote (hybrid) and you will also be provided with private insurance and extra benefits. You will have the opportunity to work in a motivating and multicultural environment as well as on global scale projects. You will have the opportunity to build a long-run career in a well-established multinational company. Description de l'entreprise Rejoindre LINCOLN, c’est rejoindre un cabinet de conseil reconnu pour son expertise data depuis plus de 30 ans, en proposant des prestations d’expertise, de conseil et d’accompagnement en Modern BI, Big Data et Science de la donnée.  Vous progresserez au sein d’une équipe de 380 experts de l’ingénierie  Vous évoluerez ainsi dans un environnement technique stimulant et en constante évolution : architectures distribuées ; sécurisation, configuration et optimisation de plateformes ; gouvernance QoD ; industrialisation de projets data science… Enfin, vous perfectionnerez vos compétences grâce à notre Lincoln Academy, véritable institut de formation interne et data-docké. Description du poste En intégrant nos équipes de consultants, vous participez à la mise en œuvre des solutions Big Data adaptées aux enjeux de nos clients. Nous recherchons pour l’un de nos clients Grands Comptes deux data engineer Big Data : En tant que de Data Engineer Big Data, vous aurez pour mission : Monter en compétences sur l’TL BigL, développé en interne en Shell Bash sur une base GCP Développer des cas d’usage : architecture des traitements TL, modélisation Datawarehouse en CICD Participer aux évolutions, à la documentation du Framework et à la gestion des livrables (Git) Vous travaillez dans un contexte Agile et sur un environnement Unix / Linux Qualifications Des fondamentaux théoriques acquis en cursus école d’ingénieurs informatique ou universitaire avec une spécialisation IT, avec une expérience d’au minimum 3 ans Une maîtrise de SQL, noSQL Expérience requise sur Scala ou Java Maîtrise sur l’écosystème Big Data : Hadoop, Spark, Kafka,… Une connaissance de Google Cloud Platform est un vrai plus CI/CD : Git / Jenkins / Nexus Outils de déploiement : Kubernetes, Docker, Ansible,… La cerise sur le gâteau: Dôté(e) d’un bon relationnel, vous aimez travailler en équipe Summary: As a Senior or Lead Big Data DevOps Engineer, you will be working with a team responsible for setting up, scaling, and maintaining Big Data infrastructure and tools in private and public cloud environments.   Main Responsibilities: Driving improvement of the efficiency of Big Data infrastructure. Coordinating cross-team infrastructure and Big Data initiatives. Leading Big Data – related architecture and design efforts. Ensuring availability, efficiency, and reliability of the Big Data infrastructure. Building and supporting tools for operational tasks. Evaluating, designing, deploying monitoring tools Design and implementation of DR/BC practices and procedures. On-call support of production systems. Requirements: 7+ years of experience working with Hadoop, preferably Open Source 3+ years of leading Big Data, DevOps, SRE, DBA, or development team. Experience setting up and running Hadoop clusters of 1000+ nodes. Solid knowledge of NoSQL databases, preferably Cassandra or ScyllaDB. Experience running and troubleshooting Kafka. Working knowledge of at least one of: Terraform, Ansible, SaltStack, Puppet. Proficiency in shell scripting. Nice to have: Experience with Prometheus. Experience managing Showflake. Solid knowledge of Graphite and Grafana. Python or Perl scripting skills. Experience with installing and managing Aerospike. DBA experience with one of: PostgreSQL, MySQL, MariaDB.   Diversity, Equity and Inclusion at Zeta  We are committed to building diverse teams with different identities, backgrounds and perspectives.  We believe in providing a forum to connect at Zeta, to learn and celebrate differences. Our mission is to ensure we have an environment that enables a deep level of trust and belonging, so everyone feels invited to bring their whole selves to work, and to increase both diversity at Zeta as well as in the technology industry.  Zeta considers applicants for employment without regard to, and does not discriminate on the basis of an individual’s sex, race, color, religion, age, disability, status as a veteran, or national or ethnic origin; nor does Zeta discriminate on the basis of sexual orientation or gender identity or expression.   About Zeta Global  Zeta Global is a data-powered marketing technology company with a heritage of innovation and industry leadership. Founded in 2007 by entrepreneur David A. Steinberg and John Sculley, former CEO of Apple Inc and Pepsi-Cola, the Company combines the industry’s 3rd largest proprietary data set (2.4B+ identities) with Artificial Intelligence to unlock consumer intent, personalize experiences and help our clients drive business growth.  Our technology runs on the Zeta Marketing Platform, which powers ‘end to end’ marketing programs for some of the world’s leading brands. With expertise encompassing all digital marketing channels – Email, Display, Social, Search and Mobile – Zeta orchestrates acquisition and engagement programs that deliver results that are scalable, repeatable and sustainable.  Zeta Global Recognized in Enterprise Marketing Software and Cross-Channel Campaign Management Reports by Independent Research Firm https://www.prnewswire.com/news-releases/zeta-global-opens-ai--data-labs-in-san-francisco-and-nyc-300945353.html  https://www.prnewswire.com/news-releases/zeta-global-recognized-in-enterprise-marketing-software-and-cross-channel-campaign-management-reports-by-independent-research-firm-300938241.html   #LI-PM1 #LI-Remote Primary Location Salary Range: $100,000.00 - $200,000.00 We are Kaizen Gaming Kaizen Gaming is the leading GameTech company in Greece and one of the fastest-growing in Europe, with the Stoiximan brand in Greece and Cyprus and Betano in Germany, Romania, Bulgaria, Czech Republic, Portugal, Brazil, Chile, Peru, Ecuador and Canada. Our aim is to leverage cutting-edge Technology in order to provide the optimum experience to those who trust us for their entertainment. The Role We’re looking for a Reporting Engineer Team Lead to join our Big Data reporting team, who will lead the delivery of our reporting ecosystem. As a Reporting Engineer Team Lead (Big Data), you’ll design, develop and maintain our data flows/modeling to meet business analysis and reporting needs. Equally important, you will lead the reporting engineers by developing their skills and fostering a culture of open communication and support. Together with the Principal Engineer your goal will be to improve the team’s performance, technical expertise and delivery velocity.   The Team Our Big Data reporting team(s) consists of twelve members with diverse backgrounds and expertise in several fields including, but not limited to, Databricks/ Delta lake/ SQL Server/ Azure Data Warehouse/ SSRS/ SSIS.   Responsibilities Lead the reporting engineers to adopt best practices in data system creation, data integrity, test design, analysis, validation, and documentation; Translate business and functional requirements into robust, scalable, operable solutions; Implement and operate large-scale, high-volume, high-performance data structures for analytics and data science; Implement data transformation pipelines, using ETL/ELT processes; Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service modeling and production support for customers.   Requirements Must have: 6 years of hands-on experience in writing complex, highly optimized T-SQL code for data manipulation and reporting; 4+ years of experience in ETL/ELT, Data Modeling, Data Warehouse Architecture and Reporting tools; 2+ years of experience in leading teams Experience in the Microsoft BI stack (SQL Server, SSRS, SSAS); Analytical abilities & problem-solving skills; Ability to meet deadlines with high attention to detail and quality. Nice to have: A bachelor's degree in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering) or equivalent industry experience; Experience with Azure Data platforms such as Synapse Analytics, Data Lake, Databricks;  Experience in programming languages preferable in Python or Scala; Exposure to CI/CD; Exposure to an Agile team-working environment.   Kaizen Gaming Perks 🕑 Work from home & remote working options. 🏃 A buddy will support you with your onboarding. 💸Competitive salary package and bonus scheme. 👩‍⚕️ Health and life insurance for you and your family. 💰 Monthly allowance for lunch & commuting expenses. 💻Nice rigs - 2.5K monitor, latest i7, tons of RAM, fast SSD. 📚 Pluralsight, unlimited access to Udemy & continuous training for all your learning and development needs. ⭐Clear career paths & a developmental 360° feedback framework. ✈️ Relocation package and "Brain Gain" relocation bonus for Greek expats. Recruitment Privacy Notice Regarding the data you share with us, you may find and read our recruitment privacy notice here. Description de l'entreprise Business & Decision est un groupe international des services du numérique, spécialisé, depuis sa création, dans l’exploitation et l’analyse de données. Business & Decision conseille et déploie les solutions et les services les plus innovants pour accompagner les directions métier à relever les défis majeurs de création de valeur de leurs organisations. Data Intelligence, Big Data, Data Gouvernance, véritables socles de l’intelligence artificielle et de l’expérience digitale, sont les domaines d’expertise et de spécialisation du groupe. Business & Decision, filiale d’Orange Business Services, emploie 2 500 talents dans 10 pays dans le monde et dans 14 villes en France. Description du poste Au sein de notre agence Rennaise, vous intégrez une équipe projet et contribuez à toutes les phases de mise en œuvre d’une application décisionnelle. Vos principales missions : Animer des études de cadrage. Auditer des architectures DATA existantes Déployer des infrastructures DATA cloud ou on-premise Transmettre ses compétences à des profils ayant une trajectoire d’expertise Rester informer, se former et former sur les nouvelles solutions DATA Domaine de compétences techniques :  Maîtrise des technologies du Big Data (Hadoop, Spark, Kafka, Nifi, ELK…)  Maitrise des outils de déploiement automatisé et DEVOPS (ANSIBLE, JENKINS, DOCKER, KUBERNETES…) Connaissance au moins d'une architecture Cloud (AWS, AZURE, GCP…) Connaissances d'au moins un langage de programmation objets ou/et de langage scripts (Java, Javascript, Scala, Python…) Connaissances en solutions de bases de données (SQL, NoSQL…) Quelques exemples de missions actuelles : Revue d’une architecture hybride Cloudera/Azure pour un client souhaitant évoluer vers l’industrie 4.0 Mise en place d’une plateforme data sous Kubernetes à base de composants open source pour bénéficier des avantages du cloud sur un environnement sécurisé souverain Industrialisation d’outils de monitoring Kafka sous Ansible pour un client dans le secteur du transport Qualifications Profil de formation bac+5, vous justifiez d'au moins 3 ans expériences significatives en qualité d'Ingénieur DATA et BIG DATA.  Informations supplémentaires Ce que nous vous proposons : Une carrière dans un environnement multiculturel, dynamique et formateur, Du temps dédié à des chantiers innovants permettant de tester de nouvelles technologies Une réelle possibilité de télétravail, Un appui et un suivi régulier d’un manager sénior dans le métier, Des formations et les certifications associées au parcours de carrière choisi. Des possibilités d’activités complémentaires (avant-vente, formation, conseil, expertise, montage d’offre, POC..), Des événements festifs, Une intégration au sein d’une communautés d’experts passionnés Pour aller plus loin : https://fr.blog.businessdecision.com/ Vous êtes partant pour vivre l’aventure ? Postulez dès maintenant en nous envoyant votre CV. Tous nos postes sont accessibles, à compétences égales, aux travailleurs en situation de handicap. Company Description At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.  With more than 7,400+ customers, we serve approximately 80% of the Fortune 500, and we're proud to be one of FORTUNE's 100 Best Companies to Work For® and World's Most Admired Companies® 2022. Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow. Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates. Job Description Company Description At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.  With more than 7,400+ customers, we serve approximately 80% of the Fortune 500, and we're on the 2021 list of FORTUNE World's Most Admired Companies®.  Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow. Job Description You will be part of the ServiceNow Cloud Services Big Data Team.  The Big Data team is building the next-generation platform that collects, stores and provides real-time access to large amounts of data. What you get to do in this role:     Build the next-generation libraries, APIs and data pipelines Create tools, libraries, and frameworks for can be reused for multiple applications Apply new technology and innovation to improve platform functionality  Qualifications To be successful in this role you have: Excellent Java programming skills with 4+ years experience using Java Proficiency on scripting with shell and python Good understanding of Object-Oriented methodologies, design patterns and data Structures Strong skills working with SQL queries, including performance tuning, utilizing indexes/partitions, and materialized views to improve query performance. Working knowledge of hadoop components such as spark streaming, hdfs, hbase, yarn, hive and impala, kafka Exceptional debugging, testing, and problem solving skills Good understanding of streaming technologies and real time analytics Ability to learn quickly in a fast-paced, dynamic team environment Self-motivated and willing to expand skillset proactively Self-disciplined, organized, strive for clean and maintainable code Highly effective communication and collaboration skill 5 years of overall experience with at least 1 in big data/analytics related positions. BS or MS Degree in Computer Science or equivalent experience. Additional Information ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law. At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office. If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance. For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government. Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.   From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license. Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow. Business Intelligence Developer Reporting to: Data & Reporting Manager Location: Scale Space Building, 58 Wood Lane, London W12 7RZ.   We’ve been pioneering embedded finance since 2007 and over the years, we’ve worked in partnership with banks, SaaS providers, payment processors, checkout providers, and even the UK government – providing all they need to offer easy and frictionless revenue-based finance solutions to their SME customers through our API-powered funding platform. We are in a very exciting period of growth, both within the UK and internationally, with teams based in London, Nottingham, USA and Scandinavia. As we continue to grow we are looking for talented and ambitious individuals to join us to reshape business finance. We are proud to have been included in The Sunday Times Hiscox Tech Track 100 as one of the 100 fastest growing FinTechs in the UK for two years running.   Who are you?    The ideal candidate will have solid practical experience as a Business Intelligence Developer. Knowledge & experience of Power Apps and Power Automate is desirable but not essential. The candidate should feel comfortable across the whole data lifecycle – specifically with competent SQL skills.   The ability to confidently communicate up and down the stakeholder ladder is essential, as is the ability to advise, train and support our user base. A keen eye for detail is critical.   While technical skills are a necessary requirement, the key to success in this role is the ability to be able to understand and interpret user requirements across the business, often by challenging the status quo of methods and processes.     Responsibilities   Work collaboratively across all business functions to deliver Reporting. Identify key improvements and requirements in reporting and processes. Translate those business requirements into robust, scalable technical solutions Create and test the quality and accuracy of reporting outputs before they are released. Work closely with the data engineers, analysts, and other core stakeholders to develop a data strategy across the business to leverage the data assets we have     We think you'll need   Significant experience with Power BI is a must. Experience with advanced Power BI functionality including Power Apps is very valuable but not a must-have Experience of managing and delivering reporting projects. Understanding of data modelling, with competent SQL skills. Strong data analysis, interpretation, and visualisation skills. Knowledge & experience of Power Apps and Power Automate is desirable but not essential. An inquisitive mindset, proactive approach to problem solving and the ability to work both autonomously and collaboratively.     What happens next?   A lot of businesses talk about the importance of diversity and inclusion, at Liberis we want to make sure that we’re genuinely fostering a highly inclusive culture that not only welcomes diversity, but celebrates it. Our commitment is not just surface level. We’re on a mission to create a safe space where everyone and anyone, regardless of their background, can thrive.    It’s not just the right thing to do. We also recognise that diverse teams perform better because we have so much to learn from one another. We think that’s pretty cool, and if you do to then you’re in the right place.     We have a hive of activity happening around the business to make sure we’re always pushing for more. Everyone is encouraged to get involved to help us to continue to build an excellent culture at Liberis.     Think this sounds like the right next move for you? If you’re not completely confident that you fit our exact criteria, get in touch! Humility is a wonderful thing and we are interested in hearing about what you can add to Liberis. You can reach us at talent@liberis.co.uk - we look forward to chatting with you!    #LI-CG1 About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to know our team: Partner Development is a team of creative entrepreneurs that develop solutions for Agoda’s accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. In this role you'll get to This role is designed to mainly growth opportunity identification among mid to long tail hotels, experiment execution and data tracking within Partner Development team for the global teams. You will get to work directly with the regional team to design and put in place global experimentation and initiatives to drive tangible impact in each market. Key activities involved include but not limit to: Apply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations Own end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development Build dashboards, identify new and track key metrics to closely monitor team’s performance and identify quick and long term opportunities for improvements Work closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified Support global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization What you'll need to succeed  Bachelor’s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline 4-8 years experience working in a business analysis, data analysis, reporting or business strategy role Excellent problem-solving skills including the ability to analyze and resolve complex problems using data Team player with strong interpersonal, relationship-building, and stakeholder management skills Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala) Data visualization tool experience such as with Tableau or your weapon of choice. Ability to work under pressure in a fast-paced and rapidly changing environment Excellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         We partner with the world’s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency. Hi there, this is Salwa from CI&T! I am a Talent Attracting Analyst looking for people located in the USA for a Mid-Level Data/ETL Engineer Position to work on a project in the mortgage industry. Requirements for this challenge: - High value on GCP experience (dataproc, dataplex), familiarity with SQL and ETL concepts. - Postgres/Snowflake experience (nice to have).- Excellent written and verbal English communication skills. Our benefits: - Premium Healthcare- Meal voucher- Maternity and Paternity leaves.- Mobile services subsidy- Sick pay-Life insurance.-CI&T University-Colombian Holidays-Paid VacationsAnd many others. #LI-SC1#MidseniorCI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters’ identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow. At CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas. We strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies. Binance is the global blockchain company behind the world’s largest digital asset exchange by trading volume and users, serving a greater mission to accelerate cryptocurrency adoption and increase the freedom of money. Are you looking to be a part of the most influential company in the blockchain industry and contribute to the crypto-currency revolution that is changing the world? Responsibilities Work across all aspects of data from engineering to building sophisticated visualizations, machine learning models and experiments Analyze and interpret large (PB-scale) volumes of transactional, operational and customer data using proprietary and open source data tools, platforms and analytical tool kits Translate complex findings into simple visualizations and recommendations for execution by operational teams and executives Processing confidential data and information according to guidelines Managing and designing the reporting environment, including data sources, security, and metadata Troubleshooting the reporting database environment and reports Requirements Bachelor’s degree from an accredited university or college in Computer Science or Math or Statistics Proficient in data engineering, modeling and ETL - preferred experience with data sourcing and working with APIs Experience with data querying using languages such as SQL, GraphQL, Python  Able to commit minimum 3 days per week for at least 6 months Understands project tokenomics and has good knowledge of the DeFi and Web 3.0 infrastructure landscape Experience in using tools such as Dune analytics, Nansen etc Understanding of addressing and metadata standards High-level written and verbal communication skills INTRACOM TELECOM is a global telecommunication systems and solutions vendor operating for over 40 years in the market. The company innovates in the wireless access and transmission field, offers a competitive telco software solutions portfolio and combines its offerings with a complete range of professional services. Our mission is to shape the future through technology and we recognize that human capital is the key factor to achieve this in today's business environment. Our company's highly specialized and experienced personnel are pivotal to achieving demanding objectives and advancing the capabilities of the company to better serve its customers. Within this framework, we are looking for an experienced Big Data Solution Architect to join our Data Analytics team. As a Big Data Solution Architect, you will be responsible for designing and implementing large-scale, high-performance data solutions that meet the needs of our clients. Responsibilities: Work with clients in multiple industries including Telco, Finance, Utilities and Retail to understand their business requirements and design solutions that meet their needs Design large-scale, high-performance data solutions using Big Data technologies such as Hadoop, Spark, Hive, MinIO, Trino and Kafka Design data integration, storage, and retrieval solutions that meet performance and scalability requirements and coordinate development with teams of Data Engineers. Work with data scientists and analysts to build data pipelines and models for analysis and reporting Collaborate with infrastructure and DevOps teams to ensure data solutions are deployed and managed in a scalable and reliable manner Stay up-to-date with the latest Big Data technologies and trends and recommend new solutions and approaches to clients Requirements Bachelor's or Master's degree in Computer Science or a related field At least 5 years of experience as a Big Data Solution Architect Strong experience with Big Data technologies such as Hadoop, Spark, Hive, and Kafka Experience designing and implementing large-scale data solutions Experience with data integration, storage, and retrieval solutions Experience with data modeling, data warehousing, and data visualization Strong understanding of cloud-based infrastructure and deployment models Strong communication skills and the ability to work effectively with clients and cross-functional teams  If you have a passion for solving complex data problems and enjoy working in a fast-paced, dynamic environment, we encourage you to apply for this exciting opportunity. Benefits INTRACOM TELECOM provides an excellent working environment which encourages team spirit, cooperation and continuous learning, in which the career prospects depend on each employee’s performance. Remuneration is competitive and aligned with the company’s credo “our competitive advantage is our human capital”. Further, the facility of a company bus is convenient for every employee. Education and continuous personal improvement constitute major priorities for the company to keep abreast with the technology evolution and maintain the high growth rate and its strategic position. Our company applies policies for equal opportunities irrespective of caste, national origin, religion, disability, gender, sexual orientation, union membership, political affiliation or age. Unternehmensbeschreibung Bei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch. Die Robert Bosch GmbH freut sich auf Deine Bewerbung! Stellenbeschreibung Im Geschäftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen – von hocheffizienten Antrieben über das erste serienreife ABS fürs Pedelec bis hin zu smarten Connectivity-Lösungen. Für eine nachhaltige Mobilität, die Spaß macht. Du bist Expert:in für den Bereich Data Engineering bei Bosch eBike Systems und stellst die relevanten Daten den Nutzern unserer Cloud-basierten Datenplattform zur Verfügung. Du programmierst gerne und beherrschst Python und SQL. Zu Deinem Repertoire zählen außerdem ausgeprägte Kenntnisse über die performante Verarbeitung und Speicherung großer Datenmengen sowohl in Data Lakes als auch in Data Warehouse Systemen. Im Rahmen Deiner Tätigkeit führst Du Code-Reviews durch und definierst Best Practices und Leitplanken für die Entwicklung von Data Pipelines.  Wir unterstützen Dich, damit Du Deine Kreativität in dem Bereich entfalten kannst und bieten Design Reviews mit anderen erfahrenen Kolleg:innen und Interessengruppen an. Du baust Deine Data Pipelines robust und mit einem hohen Fokus auf Observability, um eine einfache Fehleranalyse zu ermöglichen. Zudem übernimmst Du Verantwortung für deine entwickelten Daten Pipelines auch während des Betriebs und entwickelst diese kontinuierlich weiter, um eine optimale Qualität und Zuverlässigkeit sicherzustellen. Du hast Spaß daran, dein Wissen weiterzugeben und agierst als Mentor:in für Junior Kolleg:innen im Team. Es macht Dir Spaß mit dem Daten-Team, den Fachbereichen, der IT und den Kolleg:innen im fachlichen Diskurs die beste Lösung zu identifizieren. Qualifikationen Ausbildung: abgeschlossenes Hochschulstudium (Master/Diplom/Promotion) der Wirtschaftsinformatik oder eines vergleichbaren Studienganges Persönlichkeit und Arbeitsweise: kommunikativ, selbstreflektiert, getting-things-done-Mindset, stetig lernbereit, Interesse für Innovationen im Arbeitsgebiet, eigenverantwortlich, lösungs- und kundenorientiert, pragmatisch und problembewusst Erfahrungen und Know-how: 5 Jahre Berufserfahrung als Data Engineer sowie Erfahrung im Aufbau von zuverlässigen Data Pipelines; Erfahrung in der agilen Softwareentwicklung (SCRUM, Kanban) und Erfahrung in der Datenmodellierung sowie in unterschiedlichen Ansätzen für Daten Architekturen; Erfahrung im Arbeiten in multinationalen Teams Know-How: Breites Wissen über unterschiedliche Technologien im Bereich Big Data Engineering (z.B. Databricks /Spark, Snowflake, Apache Airflow, dbt, Kafka) sowie fundierte Kenntnisse in relevanten Programmiersprachen (Python, SQL, Scala) und CI/CD (Gitlab CI/CD, Jenkins); Außerdem Kenntnisse der Daten-Analyse, des Daten-Managements und der Softwareentwicklung Begeisterung: Spaß daran, Wissen an andere zu vermitteln Sprachen: sehr gute Deutsch- und Englischkenntnisse in Wort und Schrift Zusätzliche Informationen In diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente.  Bewirb Dich jetzt in nur 3 Minuten! Du möchtest Remote oder in Teilzeit tätig sein - wir bieten tolle Möglichkeiten des mobilen Arbeitens sowie unterschiedliche Teilzeitmodelle. Sprich uns gerne dazu an. Du hast Fragen zum Bewerbungsprozess? Nelly Ehrmann (Personalabteilung) +49 711 811 27525 Du hast fachliche Fragen zum Job? Daniel Grimm (Fachabteilung) +49 7121 35 18668 Interessierst Du Dich für diese oder weitere Stellen? Dann bewerbe Dich auf die Virtual JobFair@BOSCH und verschaffe Dir einen Überblick über die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de/events/                                         Descripción de la empresa ¿Apasionad@ de lo digital, los datos, el IoT o la IA y con ganas de ayudar a un equipo dinámico y ambicioso a escala humana?   Llevamos más de 15 años asesorando a empresas y administraciones y acompañándolas en la puesta en marcha de sus proyectos de transformación en Francia y en el extranjero.     Para ello, nos apoyamos tanto en el apalancamiento tecnológico como en la fuerza de nuestro ADN basado en la inteligencia colectiva, la agilidad y el espíritu emprendedor.     Presentes en los cinco continentes y con más de 5.000 empleados, nuestro objetivo es superar los 1.000 millones de euros de ingresos en 2024. La innovación está en el centro de nuestro desarrollo y participamos en áreas vinculadas a los cambios tecnológicos de los grandes grupos, como Big Data, IoT, Blockchain e Inteligencia Artificial.    Nuestros valores: Inteligencia colectiva   Agilidad   Emprendimiento / Intrapreneurship   Promoción de la diversidad Compromiso (empleados, socios, escuelas, asociaciones...)    Respeto del ser humano y calidad de vida en el trabajo    Apertura de espíritu e inclusión Descripción del empleo Como Junior Big Data Developer, tu misión será contribuir a la transformación y evolución continua de plataformas Necesitamos a alguien como tú para ayudarnos en diferentes frentes: Trabajar activamente en la optimización del software y la eficiencia de los procesos. Trabajar en el diseño técnico para que las soluciones puedan cumplir con la arquitectura de referencia Proponer diseños de software para aplicaciones o componentes aplicando estándares, patrones y herramientas acordadas. Contribuye a los requisitos técnicos de todos los productos/funciones. Requisitos Java / Javascript Conocimientos en distintas bases de datos (Oracle, postgre..) Github Jenkins Drools Kafka Microservicios (Spring Boot) – Openshift Metodología agile y herramientas: Jira, Confluence,… Actitud de ideas estratégicas y de innovación para afrontar todo tiempo de situaciones Deseable: S3 , Elastic ,Angular y Flink Español e inglés fluídos Información adicional Si has leído hasta aquí y tienes ganas de sumarte a este reto, no dudes en aplicar... estaremos encantados de conocerte!!! Unternehmensbeschreibung Bei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch. Die Robert Bosch GmbH freut sich auf Deine Bewerbung! Stellenbeschreibung Im Geschäftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen – von hocheffizienten Antrieben über das erste serienreife ABS fürs Pedelec bis hin zu smarten Connectivity-Lösungen. Für eine nachhaltige Mobilität, die Spaß macht. Du bist Expert:in für den Bereich Data Engineering bei Bosch eBike Systems und stellst die relevanten Daten den Nutzern unserer Cloud-basierten Datenplattform zur Verfügung. Du programmierst gerne und beherrschst Python und SQL. Zu Deinem Repertoire zählen außerdem ausgeprägte Kenntnisse über die performante Verarbeitung und Speicherung großer Datenmengen sowohl in Data Lakes als auch in Data Warehouse Systemen. Im Rahmen Deiner Tätigkeit führst Du Code-Reviews durch und definierst Best Practices und Leitplanken für die Entwicklung von Data Pipelines.  Wir unterstützen Dich, damit Du Deine Kreativität in dem Bereich entfalten kannst und bieten Design Reviews mit anderen erfahrenen Kolleg:innen und Interessengruppen an. Du baust Deine Data Pipelines robust und mit einem hohen Fokus auf Observability, um eine einfache Fehleranalyse zu ermöglichen. Zudem übernimmst Du Verantwortung für deine entwickelten Daten Pipelines auch während des Betriebs und entwickelst diese kontinuierlich weiter, um eine optimale Qualität und Zuverlässigkeit sicherzustellen. Du hast Spaß daran, dein Wissen weiterzugeben und agierst als Mentor:in für Junior Kolleg:innen im Team. Es macht Dir Spaß mit dem Daten-Team, den Fachbereichen, der IT und den Kolleg:innen im fachlichen Diskurs die beste Lösung zu identifizieren. Qualifikationen Ausbildung: abgeschlossenes Hochschulstudium (Master/Diplom/Promotion) der Wirtschaftsinformatik oder eines vergleichbaren Studienganges Persönlichkeit und Arbeitsweise: kommunikativ, selbstreflektiert, getting-things-done-Mindset, stetig lernbereit, Interesse für Innovationen im Arbeitsgebiet, eigenverantwortlich, lösungs- und kundenorientiert, pragmatisch und problembewusst Erfahrungen und Know-how: 5 Jahre Berufserfahrung als Data Engineer sowie Erfahrung im Aufbau von zuverlässigen Data Pipelines; Erfahrung in der agilen Softwareentwicklung (SCRUM, Kanban) und Erfahrung in der Datenmodellierung sowie in unterschiedlichen Ansätzen für Daten Architekturen; Erfahrung im Arbeiten in multinationalen Teams Know-How: Breites Wissen über unterschiedliche Technologien im Bereich Big Data Engineering (z.B. Databricks /Spark, Snowflake, Apache Airflow, dbt, Kafka) sowie fundierte Kenntnisse in relevanten Programmiersprachen (Python, SQL, Scala) und CI/CD (Gitlab CI/CD, Jenkins); Außerdem Kenntnisse der Daten-Analyse, des Daten-Managements und der Softwareentwicklung Begeisterung: Spaß daran, Wissen an andere zu vermitteln Sprachen: sehr gute Deutsch- und Englischkenntnisse in Wort und Schrift Zusätzliche Informationen In diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente.  Bewirb Dich jetzt in nur 3 Minuten! Du möchtest Remote oder in Teilzeit tätig sein - wir bieten tolle Möglichkeiten des mobilen Arbeitens sowie unterschiedliche Teilzeitmodelle. Sprich uns gerne dazu an. Du hast Fragen zum Bewerbungsprozess? Nelly Ehrmann (Personalabteilung) +49 711 811 27525 Du hast fachliche Fragen zum Job? Daniel Grimm (Fachabteilung) +49 7121 35 18668 Interessierst Du Dich für diese oder weitere Stellen? Dann bewerbe Dich auf die Virtual JobFair@BOSCH und verschaffe Dir einen Überblick über die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de/events/                                         Company Description We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable. Job Description Customer Experience  - Visualization Analyst (Power BI) Responsible for working with our business partners to create Power BI dashboards which help drive business decisions. Model the data by writing SQL queries/Python codes to support dashboard requirements. Help the team in enhancing existing dashboards. Working with business partners to increase dashboards usage. Gathers and analyzes data and develops architectural requirements at project level. Researches and evaluates emerging visualization technology, industry and market trends to create a long term roadmap for dashboards. Coaches and mentors team members. Long term development and Technical expertise in DW/BI Practice, communicate well with all stakeholders, optimize objectives, leverage state of the art tools and best practices, integrate into corporate systems and deliver on time. Should have independently worked on designing and launching dashboards. Qualifications Skills Required A minimum of 2-4 years of experience in data architecture and Modeling A Minimum of 2 years of experience on Power BI tool. Deep understanding in Dimensional Modelling, Data Analysis, Data Conversion/Transformation and Database Design etc. Knowledge of SQL language is mandatory (python will be preferred). Additional Information At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.    Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.   But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.   It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.    At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.  At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We have received the Great Place to Work® Certification for the fifth consecutive year. We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.  Verisk’s Statement on Racial Equity and Diversity supports our commitment to these values and affecting positive and lasting change in the communities where we live and work.   Verisk Analytics is an equal opportunity employer. All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability. http://www.verisk.com/careers.html Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.  Consumer Privacy Notice At Verisk, the health and safety of our people is our number one priority.  Effective November 15, 2021, and subject to applicable law, all prospective hires for office based roles or roles that support any of our businesses’ government contracts will be required to demonstrate that they are fully vaccinated against COVID-19 by their start date, or qualify for a legally-required medical or religious accommodation to this vaccination requirement, as a condition of employment. Hired candidates who do not demonstrate that they are fully vaccinated against COVID-19 by their start date, and who have not been approved for a legally-required medical or religious accommodation will no longer meet the requirements for employment and their offers of employment will be immediately rescinded, in accordance with applicable law. We partner with the world’s most valuable brands to build digital solutions that transform businesses. As a digital native, we bring a 27-year track record of accelerating business impact through complete and scalable digital solutions. With a global presence of 7,000+ professionals in strategy, research, data science, design and engineering, we unlock top-line growth, improve customer experience, and drive operational efficiency. We are looking for engineers who are passionate about data and DevOps eager to tackle big challenges using cloud and modern data processing technologies to be part of our team! Your mission: The main focus of this role is to solve non-trivial data engineering problems. This person will mostly work with a mix of structured and unstructured and use cloud and other state-of-the-art techniques and tools to help our customers achieve their business goals. We are looking for someone who has experience with:- Analysing and organising raw data- Intellectual curiosity to find new and unusual ways how to solve data management issues - Defining, building, and delivering high-quality data pipelines - Experience with Cloud as Azure, AWS, or GCP when it comes to infrastructure design and setup- Technical expertise with data models, data mining, and segmentation techniques- Hands-on experience with SQL database design- Analytics services- Familiarity with MSSQL- Ability to write/maintain custom scripts (powershell / bash / python)- Experience with DBT is a plus- Advanced oral and written communication skills in English.  Our benefits: - Competitive Salary- Generous paid vacation days- Unlimited sick time- 100% paid health & dental benefits starting day one- Annual profit-sharing distribution- Retirement match- Paid parental leave- Dedicated career advisor- And so much more…  #LI-MR4#Midsenior CI&T is an equal-opportunity employer. We celebrate and appreciate the diversity of our CI&Ters’ identities and lived experiences. We are committed to building, promoting, and retaining a diverse, inclusive, and equitable company and culture focused on creating a better tomorrow. At CI&T, we recognize that innovation and transformation only happen in diverse, inclusive, and safe work environments. Our teams are most impactful when people from all backgrounds and experiences collaborate to share, create, and hear ideas. We strongly encourage candidates from diverse and underrepresented communities to apply for our vacancies. Are you inspired by invention? Is problem solving through teamwork in your DNA? Do you like the idea of seeing how your work impacts the bigger picture? Answer yes to any of these and you’ll fit right in here at Amazon Robotics. We are a smart team of doers who work passionately to apply cutting edge advances in robotics and software to solve real-world challenges that will transform our customers’ experiences. We invent new improvements every day. We are Amazon Robotics and we will give you the tools and support you need to invent with us in ways that are rewarding, fulfilling, and fun.  Amazon Robotics empowers a smarter, faster, more consistent customer experience through automation. Amazon Robotics automates fulfillment center operations using various methods of robotic technology including autonomous mobile robots, sophisticated control software, language perception, power management, computer vision, depth sensing, machine learning, object recognition, and semantic understanding of commands. Amazon Robotics has a dedicated focus on research and development to continuously explore new opportunities to extend its product lines into new areas.  Amazon Robotics co-op opportunities will be based out of the Greater Boston Area in our two state-of-the-art facilities in Westborough, MA and North Reading, MA. Both campuses provide a unique opportunity to have direct access to robotics testing labs and manufacturing facilities.  Amazon Robotics (AR) is looking for a motivated Business Intelligence Engineer Co-op to analyze data sets, build dashboards, and deliver business reports focused on AR network performance. A successful intern candidate will be able to identify the right datasets for the problem statement and develop data visualizations in Tableau. They will incorporate data management fundamentals, and statistical analyses, and provide insights from the performance data of AR’s robotics solutions across the Amazon network. While we don't assume mastery in all areas, successful team members have the willingness to learn new skills and the ability to effectively communicate with and influence decision-makers at all levels. Candidates should have experience in business analytics, data science, data visualization, and/or data engineering. Amazon Robotics’ culture encourages innovation and expects co-ops to take a high level of ownership in solving complex problems.  Key job responsibilities The BIE Co-op will be responsible for: Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to support analytical and business needs Write queries to pull data needed with standard query syntax; periodically identify more advanced methods of query optimization. Convert data to make it analysis-ready Design, implement, and support platforms that provide business teams ad-hoc access to large datasets (e.g. data visualization tools for non-tech business users) Recognize and adopt best practices in reporting and analysis: data integrity, design, analysis, validation, and documentation     About the team The Performance and Insights Team at Amazon Robotics (AR) is responsible to monitor and examine the network performance of all AR products, across all customers and businesses. The Product Analysts, BIEs, and Date Engineers on our team work collaboratively leveraging their deep product experience and operational knowledge to generate insights on the health, status, and adoption of AR products and systems in field. As the new products mature into the General Availability phase, our Performance team will assume the responsibility for network level systems performance monitoring, reporting, and generating insights for AR and customer leadership. Basic Qualifications  Basic Qualifications for the BIE Co-op role: Currently enrolled in a Master’s in an analytically rigorous field (Data Science, Statistics, Computer Science, Industrial Engineering, Econometrics) or other equivalent discipline Must graduate after May 2024/June 2024 Must be eligible and available for a full-time (40h / week) 6-month internship/co-op Experience building dashboards in Tableau or other relevant data visualization tool (Looker, PowerBI, Grafana, etc.) Write high-quality SQL queries to retrieve and analyze complex datasets Basic understanding of Python, R or other relevant scripting language Experience using quantitative methods to evaluate product/system/service performance Demonstrated ability to communicate effectively across stakeholder groups   Preferred Qualifications Understanding of ETL processes Previous experience or interest in business intelligence, data engineering, system engineering or operations engineering Knowledge of AWS (e.g Datalake, Athena, Sagemaker, S3, EC2, RDS) Quantitative and qualitative data analysis experience with demonstrated impact to a project or business use case, a track record of creative problem solving, and the desire to create and build new processes   Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. We’re on the lookout for the curious, those who think big and want to define the world of tomorrow. At Amazon, you will grow into the high impact, visionary person you know you’re ready to be. Every day will be filled with exciting new challenges, developing new skills, and achieving personal growth.  How often can you say that your work changes the world? At Amazon, you’ll say it often. Join us and define tomorrow  Do you enjoy solving complex problems and troubleshooting products? Are you passionate about developing test strategies, finding, and tracking bugs to resolution, and innovating on behalf of customers? Do you want to be a part of a fast-paced, ambiguous environment and contribute to one of the most visited sites on the Internet?  At Amazon, we hire the best minds in technology to innovate on behalf of our customers. The intense focus we have on our customers is why we are one of the world’s most beloved brands – customer obsession is part of our company DNA. Business intelligence engineers use cutting-edge technology to solve complex problems and get to see the impact of their work first-hand.  The challenges business intelligence engineers solve for at Amazon are big and affect millions of customers, sellers, and products around the world. Our path is not always simple, so we are selective about who joins us on this journey. There is a certain kind of person who takes on this role at Amazon – someone who is excited by the idea of creating new products, features, and services from scratch while managing ambiguity and the pace of a company whose ship cycles are measured in weeks, not years. The Amazon EU Student Programs Team are looking for ambitious students to join us as interns at the heart of our core consumer business! Internships are flexible in length to fit in with your university’s placement scheme.   Key job responsibilities Develop analytical solutions to business problems that utilize the highest standards of analytical rigor and data integrity Recognize and adopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation Write high quality code to retrieve and analyze data Analyze and solve business problems at their root, stepping back to understand the broader context Design pragmatic analyses and automated metrics that add value to your business area Understand data resources and how, when, and what to use (and what not to use). Develop analyses (whether fully formed or exploratory) for the business’ sake, not for analyses’ sake Seek to understand the business objectives relevant to your area, and align your work to those objectives and seek to deliver business value Proactively and continually, improve your level of knowledge about Amazon’s business and relevant data resources   A day in the life Our Business Intelligence Engineer builds data pipelines, reports, dashboards, and analyses to deliver metrics and insights to the business. Our Business Intelligence Engineers tackle some of the most complex challenges in large scale computing, work in small teams across the company to contribute to the e-commerce platform that's used by millions of people all over the world. With that in mind, we require applicants to demonstrate their technical skills in a number of areas.   About the team If you’re insatiably curious and always want to learn more, then you’ve come to the right place. Depending on your location, country, job status and other requirements, some or all of the following benefits may be available to you as an intern. Competitive pay Impactful project and internship/role deliverables Hybrid working (team dependent) Networking opportunities with fellow interns Internships events such as speaker series, intern panels, Leadership Principles sessions, Amazon writing skills sessions. Mentorship and career development  If you’re successful during your internship, you could be considered for a graduate role after finishing your university studies.  Internship start dates vary throughout the year. Internship length is ideally 6 months.  We are committed to diversity, equity, and inclusion, and leveraging our unique perspectives to scale our impact and grow. Amazon has 13 affinity groups (https://www.aboutamazon.com/affinity-groups), sometimes known as employee resource groups, which bring employees together across businesses and locations around the world. With executive and company sponsorship, these groups play an important role in building internal networks for creating a community, advising Amazon business units, leading in service projects, and reaching out to communities where Amazonians live and work. Want to know more about our opportunities? Visit our EMEA Student Programs Team Events page to register for one of our upcoming events: https://amazonstudentevents.splashthat.com/careers Basic Qualifications  Currently enrolled in a Bachelor’s or Master’s degree program in computer engineering, computer science, or a similar technical field Availability to complete ideally a 6 months + internship working full time week Advanced knowledge and/or experience using SQL Experience with data querying or modelling with SQL, Excel Experience with scripting language (e.g., Python, Java, or R) Knowledge of BI analytics/reporting/visualization tools (e.g., Tableau, AWS QuickSight, COGNOS, or other third-party tools)   Preferred Qualifications Master’s or advanced technical degree Experience with BI analytics/ reporting/visualization tools (e.g., Tableau, AWS QuickSight, COGNOS, or other third-party tools) Experience in data mining, data warehouse solutions, and ETL, and using databases in a business environment with large-scale, complex datasets Knowledge of algorithm design and complexity analysis Ability to deal with ambiguity in a fast-paced environment Excellent verbal/written communication skills and data presentation skills      Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates. Company Description ¿Apasionad@ de lo digital, los datos, el IoT o la IA y con ganas de ayudar a un equipo dinámico y ambicioso a escala humana?   Llevamos más de 15 años asesorando a empresas y administraciones y acompañándolas en la puesta en marcha de sus proyectos de transformación en Francia y en el extranjero.     Para ello, nos apoyamos tanto en el apalancamiento tecnológico como en la fuerza de nuestro ADN basado en la inteligencia colectiva, la agilidad y el espíritu emprendedor.     Presentes en los cinco continentes y con más de 5.000 empleados, nuestro objetivo es superar los 1.000 millones de euros de ingresos en 2024. La innovación está en el centro de nuestro desarrollo y participamos en áreas vinculadas a los cambios tecnológicos de los grandes grupos, como Big Data, IoT, Blockchain e Inteligencia Artificial.    Nuestros valores: Inteligencia colectiva   Agilidad   Emprendimiento / Intrapreneurship   Promoción de la diversidad Compromiso (empleados, socios, escuelas, asociaciones...)    Respeto del ser humano y calidad de vida en el trabajo    Apertura de espíritu e inclusión Job Description Como Junior Big Data Developer, tu misión será contribuir a la transformación y evolución continua de plataformas Necesitamos a alguien como tú para ayudarnos en diferentes frentes: Trabajar activamente en la optimización del software y la eficiencia de los procesos. Trabajar en el diseño técnico para que las soluciones puedan cumplir con la arquitectura de referencia Proponer diseños de software para aplicaciones o componentes aplicando estándares, patrones y herramientas acordadas. Contribuye a los requisitos técnicos de todos los productos/funciones. Qualifications 2 años de experiencia en el Desarrollo de Software Sólida experiencia en el desarrollo de tecnologías Big Data, especialmente Spark y Scala. Conocimientos en entornos Cloud Computing.  Conocimientos tecnológicos a tener en cuenta: Python, API JSON, RDBMS (postgresql, MySQL o MairaDB), Docker, Kafka, Jenkins, ElasticSearch. Garantizar la calidad del software: integración continua y automatización de pruebas.  Metodologías y herramientas ágiles: Jira, Confluence, GIT Additional Information Si has leído hasta aquí y tienes ganas de sumarte a este reto, no dudes en aplicar... estaremos encantados de conocerte!!! Company Description Publicis Media harnesses the power of modern media through global agency brands Performics, Spark Foundry, Starcom and Zenith. A key business solution of Publicis Groupe ([Euronext Paris FR0000130577, CAC 40], Publicis Media’s digital-first, data-driven global practices deliver client value and drive growth in a platform-powered world. It is present in more than sixty countries with over 23,000 employees worldwide. Job Description We are seeking a driven individual with a proven track record of scalable and innovative business intelligence solutions. He/she shines when serving as a consultant to the business and is genuinely interested in understanding the objectives of complex and evolving projects. In this role, you will champion and advocate the use of Alteryx and Tableau to create an environment of self-service analytics. The candidate must be a self-starter with a sense of urgency and a commitment to quality and professionalism.  Responsibilities: Analyze business needs and partner with stakeholders to provide a strategic solution Work independently on end to end solutions, from data analysis to ETL design and development through to the final visual dashboard Collaborate across the organization to build solutions that achieve business objectives Guide stakeholders with operational decisions that impact data structures and connectivity Bring best practices in data architecture and data visualization to the table Build tools in a generic fashion for reuse across other solutions Develop technical documentation for each solution Manage projects in an agile environment Qualifications Minimum Bachelor’s Degree in Computer Sciences, Information Technology, or its equivalent 3+ years’ experience with Tableau 1+ years’ experience with AWS core+ services (EC2, S3, Lambda, Redshift, Glue) 1+ years’ experience with Python 3+ years’ experience with data visualization Comfortable with data warehousing concepts, preparing data, and configuring automated workflows Excellent communication and presentation skills as well as an analytical mindset Experience with complex logic Strong data analysis skills Experience connecting and merging disparate datasets Strong organizational skills & attention to detail Possess a desire to work for a fast-paced, results-based company Experience managing multiple projects simultaneously  Desired Skills/Experience: Experience with media and ad tech platforms (Ad Servers, Media Planning and Buying systems, DSP’s, Programmatic, etc) SQL Adobe Site Catalyst Google Analytics Basic knowledge of ETL, data modeling, data warehouse, extracting and manipulating large record of data  Additional Information All your information will be kept confidential according to EEO guidelines.   Company Description Our culture is defined by our values and our deep commitment to help our clients succeed. We are a division of the 38th largest company in the world and bring to bear the strength of a very large network of interconnected Hitachi companies. At the same time we remain absolutely committed to the nimble agility that helped us grow Hitachi Solutions from three founding partners to nearly 2,000 consultants, developers and support personnel all around the globe. Hitachi Solutions is a leader in providing industry solutions based on Microsoft Dynamics AX and Microsoft Dynamics CRM. Hitachi Solutions provides its customers with industry focus, software industry domain expertise, and proven tier-1 people. Hitachi Solutions works with its customers to understand their unique formula for success and develops solutions that improve their business and attain measurable results.2011, 2009, 2006 & 2005 Microsoft Dynamics Partner of the Year (Finalist 2008, 2007). Microsoft Global Dynamics Award (Global Dynamics Partner of the year) 2014.  Hitachi Solutions is a core IT company of the Hitachi Group, which employs some 400,000 people worldwide. Through systems integration, we provide ideal solutions and products for customers. Headquartered in Tokyo, Japan, Hitachi Solutions' reach extends to group companies in Japan and abroad, working with a worldwide network of alliance partners. We bring solutions and products to diverse countries and regions including Asia, the United States and Europe. The flagship company in the Hitachi Group's information and communication system solutions business, Hitachi Solutions also offers solutions for social innovation such as smart cities.   For more information on Hitachi Solutions, please visit: https://web.hitachi-solutions.com Job Description Requirements: A minimum of 5+ years full-time experience using VertiPaq Able to quickly provide both M and DAX solutions Hands-on experience working in Business Intelligence, Data Engineering or Data Science Unwavering ability to quickly propose solutions by recalling the latest best practices learned from MVP & Product Team articles, MSFT documentation, whitepapers, and community publications A passion for understanding and integrating business semantics into technology solutions Excellent communication, presentation, influencing, and reasoning skills Ability to lead projects Familiarity with the Azure data platform, e.g., ADLS, SQL Server, ADF, Databricks etc.  We would like to see a blend of the following technical skills: Information Design DAX, M, PowerShell, and T-SQL VertiPaq and MashUp engine knowledge Power BI Desktop, Power BI Dataflows, Tabular Editor, DAX Studio, and VertiPaq Analyzer Power BI Service architecture design and administration Data modelling using the Kimball methodology Description de l'entreprise Dans un monde où savoir se transformer est la clé du succès, Wavestone s’est donné pour mission d’éclairer et guider les grandes organisations dans leurs transformations les plus critiques. Des transformations qui visent à répondre aux grands enjeux stratégiques auxquels elles vont faire face dans les années à venir : l’accélération de la révolution numérique, l’intensification de la concurrence, ou encore la prise en considération de l’urgence climatique.  Le cabinet possède des compétences sectorielles centrées sur le cœur de métier de ses clients, des compétences technologiques parmi les plus pointues tant sur le digital, les systèmes d’information qu’en matière de cybersécurité, et des compétences en développement durable. Wavestone se distingue dans sa capacité à conjuguer étroitement toutes ces compétences, sans couture, au sein d’équipes pluridisciplinaires afin d’apporter une réponse à 360°, en phase avec les grands enjeux auxquels sont confrontés ses clients.  Le cabinet réalise un chiffre d’affaires de l’ordre de 470 M€ et rassemble près de 4 000 collaborateurs en Europe – où il figure parmi les leaders indépendants du conseil – aux Etats-Unis et en Asie.  Wavestone est coté sur Euronext à Paris et labellisé Great Place To Work. Pour plus d'informations, consulter www.wavestone.com Description du poste Contexte  Forte de plus de 400 consultants, la Practice Digital Customer a pour vocation d’accompagner nos clients à basculer dans le digital en designant et développant de nouvelles offres (produits, services...) afin de créer l’expérience du consommateur digital de demain. DC combine une profonde connaissance de l’industrialisation des produits digitaux avec une grande expertise sur la chaîne de valeur de bout en bout. Nous embarquons les parties prenantes clé autour de grands programmes de transformation, afin de créer l’organisation agile de demain et d’encourager l’émergence de nouvelles offres.   Objectif du stage  Dans le cadre de votre stage, vous serez intégré.e activement à la communauté « Data, Analytics & IA » de la practice Digital Customer afin de participer à la formalisation de ses convictions, étoffer sa force de veille technologique, dynamiser son activité commerciale auprès des clients du cabinet, et d’aboutir à la production de supports commerciaux ou de livrables de missions.  Au sein de cette communauté, notre équipe BI & Dataviz regroupe les savoir-faire clés permettant d’accompagner les entreprises à valoriser leurs données : stratégie de valorisation de la donnée, réalisation de rapports et tableaux de bord BI, transformation des usages data des collaborateurs (acculturation à la donnée, formation...).   Travaux à réaliser  Les thématiques abordées lors du sujet de stage sont les suivantes :   Création de rapports d’analyse de données : cadrage et réalisation de rapports et tableaux de bord, définition des bonnes pratiques de data storytelling, définition de bonnes pratiques UX et/ou techniques pour utiliser les outils phares du marché...   Formation & knowledge management : réalisation et dispensation de formations liées à la DataViz, benchmark des bonnes pratiques associées aux principaux outils du marché, réalisation de webinars...  Stratégie BI : définition des bonnes pratiques pour tirer profit de la BI, benchmark des solutions phares du marché...  Vous aurez également l’opportunité de développer votre expertise en suivant des formations, dispensées par nos consultants ou des partenaires, mais aussi en auto-formation via l'accès à de nombreuses plateformes de e-learning & Moocs.  Nous vous donnons la possibilité de participer activement à la vie interne du cabinet à travers :  Des contributions au sein du cercle d'expertise BI&Dataviz  La publication d'articles sur nos blogs et réseaux sociaux  L'appuis à la capitalisation des savoirs  La veille sur les sujets BI&dataviz  La rédaction de convictions et la création d'accélérateurs missions  La participation commerciale à la réponse aux appels d'offre  L'animation du réseau Wavestone international BI&Dataviz  Mais aussi des contributions plus large à envergure practice ou Cabinet :  Le développement de nos Assets : Shake 'up, CréaDesk, Machine Learning & Data Lab, Research & Knowledge Center  La contribution au recrutement, relations écoles, formations internes, événements internes  La participation à la stratégie RSE de Wavestone  En parallèle, vous participerez à une ou plusieurs missions de conseil auprès de nos clients, en étant intégré dans une équipe de consultants placée sous la responsabilité d’un directeur de mission.  Informations supplémentaires Wavestone est un employeur inclusif qui s'engage pour l'égalité des chances. Dans le cadre de cette politique de diversité et inclusion, Wavestone accompagne les personnes en situation de handicap et/ou nécessitant un aménagement durant leur process de recrutement et tout au long de leur prise de poste. Company Profile With studios around the world, Keywords Studios is a leading technical services provider for global video games and beyond. With locations in Asia, the Americas and Europe, Keywords Studios has a breadth and depth in multiple industry-leading service lines including Art, Engineering, Audio, Functionality QA, Localization, Localization QA and Player Support. Working across all major platforms, in over 50 different languages, Keywords Studios delivers support for its clients across the globe. Role Overview The Business Intelligence Data Analyst will become a subject matter expert for BI (data & analytics) on all intelligence-related tasks. The Analyst will work independently and in a team environment performing requirements gathering, data analysis, process mapping, test case definition, development, and collaboration across multiple business units and projects. Requirements Located in Romania, no sponsorship required Excellent written and oral communication skills. Excellent time management and organizational skills. Detail oriented but able to understand the big picture. Ability to analyze and document complex business processes. Experience communicating with business users. 3+ years’ experience with Power BI Proficiency with DAX and M languages Proficiency with Python 2-3 years’ experience with Spark/Databricks. Strong SQL Server SQL skills and experience tuning queries, Working knowledge of data warehouse. Additional Preferred Qualifications Statistical computing experience Exposure to the Azure Data Platform (Data Factory, etc.) Exposure with DevOps implementation practices Scrum methodology delivery experience Duties and Responsibilities Develop and implement interactive analytic reports and dashboards. Translate business requirements into ETL and report specifications. Develop and implement ETL processes, reports and queries in support of business analytics. Perform data analysis to troubleshoot data issues with the BI solutions and data integration processes Ensure compliance with security policies and practices in accordance with internal and external audit governing bodies. Support data governance processes. Provide technical and business knowledge support to the team. Support data governance processes. Benefits Our employees are our most valuable resource; therefore we provide them with a competitive compensation package commensurate with skills and experience, excellent benefits, high level of job satisfaction and a casual and fun work environment.  Extensive Medical insurance provided by Medicover and their partner network in Romania. Days off for special personal events, according to the Internal Regulations, e.g. marriage, childbirth, compassionate leave and exams days off for obtaining professionally relevant certifications. A monthly allowance of 650RON which you will be able to use for a wide range of benefits, that are relevant to you: medical/dental services for you and/or your family members, access to sports clubs, meal tickets, private pension, personal development courses (e.g. IT, accounting, finance, HR, foreign languages, driving courses), tourism in Romania, public transportation subscription, gifts, utility or phone/Internet bills, access to cultural events, etc. Learning & Development to help you reach your true maximum potential by providing access to training and digital resources relevant for your area of expertise. About Us Riskified empowers merchants and shoppers to realize the full potential of eCommerce by making it safe, accessible, and frictionless. Our global team helps the world’s most-innovative eCommerce merchants eliminate risk and uncertainty from their business. Merchants integrate Riskified’s machine learning platform to create trusted customer relationships, driving higher sales while reducing costs. Riskified has reviewed hundreds of millions of transactions and approved billions of dollars of revenue for global brands and fast-growing businesses across industries, including Wayfair, Wish, Peloton, Gucci, and many more. As of July 29th, 2021, Riskified has begun trading on NYSE under the ticker RSKD. About the Role As a BI Developer, you will be responsible for providing analytical support across the organization to enable data-driven decision making and promote strategic planning. You will also deliver an improved understanding of the company’s various metrics to allow for better short and long term forecasting and planning. You will develop close working relationships with various teams including Analytics & Research, Finance, Sales, Marketing, and more. What You'll Be Doing Work with various teams to define key metrics (KPIs) and provide the methodologies to accurately measure Riskified’s performance Create new ETL processes and optimize existing ones Create smart, innovative and effective visualization methods, and promote engagement and implementation of them Be the main point of contact for technical support related to BI activity for various teams within Riskified Qualifications Minimum 2 years experience in a BI position - must  Knowledge in DWH design - must Experience in developing ETL processes - must Experience with BI tools such as Tableau, Looker or similar - must Experience with databases - must Experience with scripting languages - an advantage Experience with BI system analysis - an advantage Bachelor’s Degree in Science/Data Systems Management/Industrial Engineering and Management Good comprehension of data, and how to tell the story behind it Life at Riskified We are a fast-growing and dynamic tech company with 750+ team members globally. We value collaboration and innovative thinking. We’re looking for bright, driven, and passionate people to grow with us. COVID-19 Update:  Our Tel-Aviv team is currently working in a hybrid of remote and in-office work for all our team members. We have recently moved to our new space in Tel Aviv - check it out here!  Some of our Tel Aviv Benefits & Perks: Equity for all employees, Keren Hishtalmut, pension Private medical insurance, extra time off for parents and caregivers Commuter and parking benefits Team events, fully-stocked kitchen,lunch stipend, happy hours, yoga, pilates, functional training, basketball, soccer Wide-ranging opportunities to volunteer and make an impact Commitment to your professional development with global onboarding, skills-based courses, full access to Udemy, lunch & learns Awesome Riskified gifts and swag!  In the News Geektime: Riskified Goes Public Walla!: Happy Hour at the Riskified Offices Geektime Insider: A look at Riskified Tel Aviv Globes: Riskified to contribute the highest amount up to date to Tmura Globes: Riskified is among Israel’s fastest growing companies  TechCrunch: Riskified Prevents Fraud on Your Favorite E-commerce Site Riskified is deeply committed to the principle of equal opportunity for all individuals. We do not discriminate based on race, color, religion, sex, sexual orientation, national origin, age, disability, veteran status, or any other status protected by law. Opis oferty pracy Widełki wynagrodzenia przewidziane przy tym stanowisku na umowie o pracę to: 16 100 - 23 200 PLN brutto. Model pracy hybrydowej według ustaleń lidera i zespołu. W ramach obszaru Data & AI realizujemy projekty oparte o praktyczną aplikację "data science" i "artificial intelligence" o niespotykanej w Polsce skali. Data & AI to grupa ponad 100 doświadczonych inżynierów BigData zorganizowanych w kilkanaście zespołów o różnych specjalizacjach. Część z nich buduje dedykowane narzędzia do tworzenia i uruchamiania przetwarzań BigData czy wdrażania modeli ML dla całej organizacji. Inni pracują bliżej klienta i odpowiadają za realizację silnika wyszukiwarki, tworzenie rekomendacji, budowania profilu kupujących czy rozwój platformy eksperymentacyjnej. W obszarze są też zespoły badawcze, których celem jest szukanie rozwiązań dla nietrywialnych problemów wymagających stosowania uczenia maszynowego. Dołącz do nas! Szukamy programistek i programistów Scala i Python, interesujących się systemami rozproszonymi i przetwarzaniem danych, które/którzy chcą poszerzać swoje kompetencje w tym obszarze.  Zupełnie się nie przejmuj, jeżeli nie masz doświadczenia w technologiach Big Data. Gwarantujemy Ci, że szybko się ich nauczysz od najlepszych inżynierów w Polsce pracując m.in. nad: Systemem zapewniającym możliwość materializacji eventów (krążących pomiędzy mikroserwisami) do postaci umożliwiającej budowanie analiz za pomocą narzędzi Big Data. Nasze codzienne wyzwania to skala ruchu, strukturyzacja informacji oraz streamowa synchronizacja zbiorów pomiędzy rozwiązaniami lokalnymi oraz środowiskiem public cloud Rozproszonym systemem do zbierania informacji i analizy zachowań klientów Allegro. Przetwarzania batch: Spark + Airflow + BigQuery. Procesami agregacji metadanych, zintegrowanymi z platformą danych Allegro, które mają wspierać narzędzia oraz procesy z zakresu: Data Quality, Data Lineage oraz Data Governance Szukamy osób, które: Potrafią i lubią programować w językach: Scala i Python Mają doświadczenie w ekosystemie Big Data (Hadoop, Spark, Kafka, Airflow, Druid, Terraform) Dodatkowym atutem będzie znajomość GCP (Dataproc, Dataflow, BigQuery, Pubsub) Stosują dobre praktyki (clean code, code review, TDD, CI/CD) Sprawnie poruszają się w systemach z rodziny Unix/Linux Interesują się zastosowaniem ML/AI Chcą się rozwijać i aktualizować swoją wiedzę Znają język angielski na poziomie min. B2 Ze swojej strony oferujemy: Model pracy hybrydowej, który ustalisz z liderem i zespołem. Mamy świetnie zlokalizowane biura ( z w pełni wyposażonymi kuchniami i parkingami dla rowerów) i znakomite narzędzia pracy (podnoszone biurka, interaktywne sale konferencyjne) Bonus roczny do 10% wynagrodzenia rocznego (zależny od Twojej oceny roczny oraz wyników firmy) Bogaty pakiet świadczeń pozapłacowych w systemie kafeteryjnym – Ty decydujesz z czego korzystasz (do wyboru mamy m.in. pakiety medyczne, sportowe, lunchowe, ubezpieczenia, bony na zakupy) Zajęcia angielskiego opłacane przez nas i skoncentrowane na specyfice Twojej pracy Laptop z m1, 32GB RAM, SSD - MacBook Pro 16’’ lub 14’’ albo analogiczny Dell z Windows (jeśli nie lubisz Maców), do tego dwa zewnętrzne monitory i wszystkie gadżety, których potrzebujesz Pracę w zespole, na którego wsparcie zawsze możesz liczyć -  na pokładzie mamy najlepszych specjalistów i ekspertów w swojej dziedzinie Dużą autonomię w organizacji pracy zespołu, zachęcamy do ciągłego rozwoju i próbowania nowych rzeczy Hackathony, turystykę zespołową, budżet szkoleniowy oraz wewnętrzna platforma MindUp (m.in. szkolenia z zakresu organizacji pracy, sposobu komunikacji, motywacji do pracy oraz różnych technologii i zagadnień merytorycznych) Jeśli chcesz wiedzieć więcej - sprawdź sam/a. Dlaczego miał(a)byś z nami pracować?  W Allegro zajmiesz się przetwarzaniem petabajtów danych i miliardów zdarzeń dziennie  Staniesz się uczestnikiem jednego z największych projektów budowania platformy danych w GCP Twój rozwój będzie podążał za najnowszymi trendami technologicznymi opartymi o open source  Poza tym, zespół IT liczy ponad 1700+ osób, które dzielą się wiedzą na wielu konferencjach, takich jak Big Data Technology Warsaw Summit, Warszawskie Dni Informatyki, Agile By Example, DevOps Days, Code Europe oraz współtworzą bloga allegro.tech Stosujemy Code Review, Continuous Integration, Scrum/Kanban, Domain Driven Design, Test Driven Development, Pair Programming w zależności od zespołu Autonomia technologiczna - wybierasz technologię, która pasuje do problemu (nie trzeba zgody wszystkich świętych). Ty za nią potem odpowiadasz Ponad 100 autorskich projektów open source, kilka tysięcy gwiazdek na github Organizujemy Allegro Tech Live, w 100% zdalną odsłonę naszych stacjonarnych meetupów Allegro Tech Talks i występujemy gościnnie na zaproszenie takich społeczności jak Warsaw AI, JUG (Poznań, Łódź, Lublin, Wrocław), WG .Net, Dare IT, Women in Tech Summit Sami również stawiamy na rozwój. Organizujemy hackathony i wewnętrzne konferencje (np. coroczny Allegro Tech Meeting), regularnie wyjeżdżamy na wydarzenia w Polsce i za granicą (Europa i USA), a każdy zespół ma budżet na szkolenia i książki. Jeśli chcesz się rozwijać lub dzielić swoją wiedzą z innymi, to zawsze Ci pomożemy. To też może Cię zainteresować:   Allegro Tech Podcast → https://podcast.allegro.tech/ Booklet → https://allegro.tech/booklet.pdf Wyślij nam swoje CV i sprawdź dlaczego #dobrzetubyć Big Data Graduate Program 2022 Founded in 2016 with only a handful of individuals, Quantexa was built with a purpose that through a greater understanding of context, better decisions can be made. 7 years, 12 locations and 600+ employees later we still believe that today. We connect the dots within our Customers data using dynamic entity resolution and advanced network analytics to create context, empowering businesses to see the bigger picture and drive real value from their data. Due to the continuous success and high demand from our Customers, we are looking for Graduates to kick start their career by joining our Quantexa family. 🚀 What does the Graduate Program at Quantexa look like? Our Big Data Graduate Program is designed for you to develop your technical skill set, think creatively and be a real problem solver of major issues our clients are facing today. If you are someone who likes to think outside the box, holds a real passion for data and is open to new ideas, you’ll find a Qmmunity that recognizes your needs to be a creative innovator and embrace it. You will work on big data projects where you will have exposure to data science, data engineering and DevOps methods, whilst learning to engage with both internal and external stakeholders. In a typical Quantexa project, you’ll work with high volume data, helping our top clients solve business problems in financial crime, fraud and money laundering along with playing a huge part in helping our others solve complex terrorism cases, human trafficking, and even modern-day slavery. You’ll be working closely with Data Scientists, Data Engineers, Business Analysts, Technical Leads, Project Managers and Solutions Architects, using entity resolution to generate networks and apply a scoring framework to identify risks. At Quantexa everyone is following the same goal of meeting our client’s expectations and delivering a first-class service. What training is provided, and technology will you use? We want our graduates to learn the latest Big Data technologies and being the huge fans of functional programming that we are, your first 3 months will consist of going through our dedicated training academy. You’ll have exposure to learning Scala, which is our primary language here at Quantexa, so you are confident and comfortable using our platform. Part of this exciting journey will also have you exposed to other tools such as Spark, Hadoop, Hive, Kubernetes, with our platform being hosted on Google cloud (GCP). You will learn how to create entities and networks and loading data using Elasticsearch in the Quantexa interface. You’ll be required to generate a solution using our explorer in a world leading big data tool set. This training is heavily self-paced learning giving you the flexibility to add to the task and complete with set timings. Following completion of the academy you will be working on multiple projects. You can expect to work with different lead experts who share their love of big data to deliver the best for our clients. Check out our graduate brochure here to find out more and here from current graduates 🙌 Requirements What do I need to have? We are looking for enthusiastic individuals who share a love of ‘big data’ and have a numerate degree ie. Mathematics, Physics, Computer Science, IT/Technology. 👩‍💻 Must be a graduate already or expecting to graduate in a STEM subject. A passion and the desire to learn and code in Scala using multiple big data tool sets. Hold problem solving skills and enthusiasm to pick up a broad set of tasks. Client facing and Consulting skills such as communication, adaptability, critical thinking etc. Experience in Python, Java, Scala, R or similar technologies is desirable. Passion and drive to grow within one of the UK’s fastest scale ups. Benefits Why join Quantexa? We know that just having an excellent glass door rating isn’t enough, so we’ve put together a competitive package as a way of saying thank you for all your hard work and dedication. We offer: Competitive salary Company bonus Competitive holiday allowance + public holidays + birthday off! Access to our unlimited technical library Private Healthcare RRSP Plan with Q match up to 5% Short term & long-term disability Life Insurance & Accidental health Ongoing personal development Great WeWork Office Space & Company wide socials Company Description Natixis in Portugal is fully integrated in the global organization of Natixis, a French multinational financial services firm specialized in Asset & Wealth Management, Corporate & Investment Banking, Insurance and Payments. A subsidiary of Groupe BPCE, Natixis counts nearly 16.000 employees across 38 countries. Based in Porto, Natixis Centre of Expertise mission is to transform traditional banking by developing innovative solutions for the bank’s business, operations and work culture worldwide, as a key driver of the company’s culture of agility and innovation. Teams of IT and Banking Support Activities work in an integrated, inclusive and transversal way, supporting all the business lines and country platforms. Natixis in Portugal is the best combination of a “start-up mindset” with a large, solid structure. Its unique culture gives true meaning to a “beyond banking” personality: to be a real entrepreneur, self-challenging, ever striving to excel and go that extra mile. Job Description We are looking for a Data Analyst with a background in Business Intelligence to work in Regulatory reporting across the globe. This position will be integrated in the IT Financing department within the CIB business unit. The candidate will be working with REGBOX, an Oracle datawarehouse built to centralize all the data (Accounting, Inventory, Repository, Risk, etc.) necessary for the regulatory reporting for Natixis branches in APAC and EMEA. REGBOX stores and processes the data in accordance with the requirements of the different downstream tools (from external providers), responsible of the regulatory reporting submission to each Central Bank. Cognos tool is also plugged to Regbox and used to build directly some regulatory reports or for internal reporting. In this role, the DA will have to respond to the data requirements submitted by the regulators and the providers, working in close communication with business users, local vendors in each country, other REGBOX DA and IT developers.  Roles and responsibilities: Discuss requirements with business users and local vendors in each country; Specify and lead the implementation of changes in the REGBOX data model in order to meet regulatory needs; Investigate data issues and lead the steps towards their resolution; Create or modify SQL extractions; Create or modify Cognos reports (only for one location, so it is a small component of the role) Qualifications Previous experience as IT Data Analyst or Business Analyst, Product Owner or similar role; Knowledge of business intelligence methodologies, in particular data modeling (mandatory); Experience with report building; Experience in SQL; Very good communication (written and oral) and interpersonal skills; Good level of English (at least B2) ;  Previous experience in Banking IT, Accounting and Regulatory topics would also be a plus.  Additional Information Early morning. Campo 24 de Agosto. In 4 minutes, you are clocking in at the office. After grabbing a cup of coffee and fresh fruit, pick up your laptop and choose your spot for the day. It's going to be a busy one: French class before lunch and, just after, quick medical appointment at Natixis doctor's office.   Lunch break. Outside in the big terrace (look at your crops at the Urban Garden; ready to harvest!) or, if you feel like stretching your legs, walk downtown to grab lunch.   Back inside. Quick sprint review (working together anywhere means virtual happy birthday to that colleague in Paris that just turned 35). The afternoon went flying (tasks, reports, calls, some jokes with your teammates). End it on a high note: just one PlayStation game or the final match for that ping-pong tournament.   Tomorrow, you complete that certified technical training and the day after, you will work from home, taking advantage to finally do that online course on Udemy. Once you are done with your tasks for the day, you can visit the office for a board games session or show up at the rehearsal of one of Natixis bands. If that is too steady for you, meet your colleagues to surf some waves or join them in a football match. Company Description Hitachi Solutions is a global Microsoft solutions integrator passionate about developing and delivering industry-focused solutions that support our clients to deliver on their business transformation goals. Our industry focus, expertise, and intellectual property is what truly sets us apart. We have earned, and continue to maintain, a strategic relationship with Microsoft. Recognized for our achievements - teaming with our clients to deliver innovative digital solutions and services - is how we have achieved year after year recognition. As their trusted advisor, we support our clients to deliver on their strategic business initiatives as they unify, automate, and modernize their data and operations to increase efficiency, reduce costs, and enhance their customer’s experience. Our over 3,000 team members across 14 countries, and our 18 years of 100% focus on Microsoft technologies and business applications, is how we deliver excellence through expert services and industry-focused cloud solutions.  A part of Hitachi, Ltd., our company has a long and rich history of innovation, financial strength, and international presence of one of the world’s largest companies. Since 1910, Hitachi, Ltd. has been a leader in manufacturing innovative products and solutions that support industry and social infrastructure around the globe supported by 303,000 employees in over 100 countries and across 864 companies. Job Description This is a full-time position for a consulting role to be a member of our customer-facing project delivery teams for POC’s, Technical Assessments, and Production Project Delivery.  Qualifications Bachelor’s Degree   7+ years relevant experience in consulting on large scale Data Warehouse/Big Data projects in team environments.   Experience with Power BI, (Power Query, PerformancePoint, PowerView a plus), Power Platform, Analytics (Synapse, backend data modeling in support of Analytics), SSRS, SSAS, Excel Services  Knowledge of Agile processes (Scrum preferred)   Experience with Power BI Dashboard/Report, Data Warehouse, Data Modeling and Data Integration   Proficiency in extracting and manipulating large data sets with SQL in MS SQL.    Some experience (not all mandatory) using mapping Software and Programming Languages: SQL, R, DAX, Microsoft Power BI, SSRS, Excel, and Tableau  Experience designing and building large-scale, distributed systems   Able to work with the customer’s stakeholders to understand business and technical requirements.  Experience with complex data modeling   Able to identify and communicate issues/risks applying technical and root cause analysis skills   Strong decision making, problem solving, and analytical skills   Excellent communication, presentation, influencing, and reasoning skills (there will be client and pre-sales exposure)  Creativity and ability to think outside-the-box while defining sound and practical solutions   Experience with the following Technologies/Methodologies is a plus:   Azure and/or AWS  Tableau  SQL Server 2014/2016   Oracle, DB2, NoSQL  C#/.NET  Azure Data Services/Azure SQL Data Warehouse (PLUS)  Additional Information We are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. All your information will be kept confidential according to EEO guidelines.  #LI-CC1 Veeva [NYSE: VEEV] is the leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, our customers range from the world’s largest pharmaceutical companies to emerging biotechs. Veeva’s software helps our customers bring medicines and therapies to patients faster. We are the first public company to become a Public Benefit Corporation. As a PBC, we are committed to making the industries we serve more productive, and we are committed to creating high-quality employment opportunities. Veeva is a Work Anywhere company which means that you can choose to work in the environment that works best for you - on any given day. Whether you choose to work remotely from home or work in an office - it’s up to you. The Role Veeva is looking for a Sales BI Analyst with analytics experience in support of our Global Sales and Operations teams. If you are a “Data Person,” who knows Tableau, loves to get hands-on, enjoys data modeling, and is good at bringing data to life, we’d love to talk with you. What You'll Do Serve as the business expert in support of our Global Sales and Sales Operations Team regarding sales analytics and data visualization Participates in planning processes including technical design, development, testing, and delivery of solutions Analyzes business and functional requirements and translates these requirements into robust, scalable, operable solutions Serve as the point person for all things Tableau for Sales/Operations Implements data structures using best practices in data modeling, processes, and technologies Performs data conversions, imports, and exports of data within and between internal and external software systems Assists in vendor evaluations Assist with the upkeep of our data warehouse and semantic layers Requirements Bachelor's degree in Computer Science, Information Systems, Business Management, Mathematics, or specialized training/certification 1+ years of professional experience in business intelligence and/or analytics Strong visualization skills with Tableau Proven ability to model data efficiently to support data requirements Ability to work with large data sets, obtain information, identify trends, and solve complex problems Strong verbal, written & presentation skills with the ability to effectively communicate complex technical information to personnel at all levels of the organization Nice to Have SQL experience for building complex joins and analytical queries Data Warehouse experience best practices (Databricks (preferred), Snowflake, etc.) Understanding of data governance best practices and implementation Software industry and/or Life Sciences experience is a plus Perks & Benefits Flexible PTO Allocations for continuous learning & development Health & wellness programs #LI-RemoteUS#BI-Remote Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world. Veeva is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristics protected by local laws, regulations, or ordinances. If you need assistance or accommodation due to a disability or special need when applying for a role or in our recruitment process, please contact us at talent_accommodations@veeva.com. Position may not be eligible for remote work in Colorado. Geomagical Labs is a 3D research & development lab, fusing 3D computer vision, deep neural networks, graphics, and computational photography into magical experiences for hundreds of millions of users, in partnership with IKEA. Our best-in-industry applications allow customers to scan photorealistic models of their indoor spaces, then reimagine them with new furniture in life-like 3D, from anywhere --- changing home commerce along the way. We are looking for a computer vision technologist, with hands-on experience implementing computer vision algorithms on modern smartphones, to push the state of the art in mobile phone scene capture technologies. This could be a dream job for highly-motivated technologists and applied researchers, with strong 3D vision foundations and entrepreneurial drive. Requirements Ph.D. or Master's degree focused on computer vision preferred. Highly productive and ambitious software engineer with a track record of success. Broad theoretical & practical foundations in 3D computer vision. Hands-on experience developing 2D & 3D vision algorithms on mobile devices. Hands-on expertise deploying and using neural networks on mobile phones for live processing of photographic imagery. Hands-on experience developing cool AR apps. Strong applied math skills in optimization, linear algebra, 3D perspective geometry. Excellent written & verbal communication skills. Appreciation for visual aesthetics and customer success. Must be adventurous, ambitious and excited about R&D innovation. Benefits Join a mission-driven R&D lab, strategically backed by an influential global brand. Work in a dynamic team of computer vision, AI, computational photography, AR, graphics, and design professionals, and successful serial entrepreneurs. Opportunity to publish novel and relevant research. Excellent health & retirement benefits. Fully remote work available to people living in the USA or Canada. Headquartered in Mountain View, California, in the heart of the Castro Street downtown --- an easy walk from restaurants, coffee shops, the Stevens Creek Trail, and Caltrain commuter rail. The USA base salary for this full-time position ranges from $150,000 to $340,000 determined by location, role, skill, and experience level. Geomagical Labs offers a comprehensive set of benefits, and for qualifying roles, substantial incentive grants, vesting annually. Unternehmensbeschreibung Wir bei rheindata beraten unsere Kunden in den Bereichen Big Data, Business Intelligence und Data Science. Wir sind ein buntes Team aus den unterschiedlichsten Fachbereichen wie z.B. Mathematik, VWL, Informatik oder Physik. Uns ist wichtig, dass wir uns weiterbilden können und offen sind, unser Wissen zu teilen. Bei uns gibt es wenig Bürokratie, stattdessen kurze und flache Entscheidungswege und großes Mitspracherecht. Wenn du also Lust hast, uns kennenzulernen… los geht´s! Stellenbeschreibung Als BI Berater ETL/ELT (m/w/d) arbeitest du in unterschiedlichen BI Projekten bei unseren Kunden und entwickelst kreative und innovative BI Lösungen, entwickelst du ETL/ELT Strecken und zudem orchestrierst und parallelisierst du Ladestrecken, erstellst du SQL-basierte Datenbank-Abfragen, arbeitest du mit strukturierten und unstrukturierten Daten und bist du offen für neue Technologien und gibst dein Wissen auch gerne weiter. Qualifikationen Das bringst du mit: Einige Jahre praktische Erfahrung im BI Bereich, ein abgeschlossenes Studium in einem MINT (Mathematik, Informatik, Wirtschaftsinformatik, -mathematik, Physik o.ä.)- oder wirtschaftswissenschaftlichen (BWL, VWL, o.ä.) Fach, Kommunikationsstärke, Deutschkenntnisse auf muttersprachlichem Niveau (C2), Englisch fließend in Wort und Schrift. Zudem verfügst du über Kenntnisse z.B. in: SSIS, Talend oder Informatica SQL Erfahrung in Cloud-Plattformen wie Azure, AWS oder GCP Zusätzliche Informationen Das bieten wir dir: 6 Wochen Urlaub im Jahr und in jedem fünften Jahr sogar 10 Wochen eine deinen Bedürfnissen entsprechende Einarbeitungsphase mit Begleitung deines Mentors, die Möglichkeit zu individuell gestaltbaren Sabbaticals, die Teilnahme an unserem Mitarbeiter-Beteiligungsprogramm, eine kostenlose M-Mitgliedschaft bei Urban Sports Club und vergünstigte Konditionen bei L- und XL-Tarifen neben einem attraktiven Vergütungspaket erhältst du natürlich ein Notebook und ein Smartphone sowie weitere Zusatzleistungen wie z.B. Jobticket, JobRad oder betriebliche Altersvorsorge je nach Projektgegebenheiten, die Möglichkeit im Homeoffice zu arbeiten – wobei du in unserem Büro im belgischen Viertel natürlich auch immer willkommen bist. About At-Bay The Data & Research department oversees all of  At-Bay’s data-related requirements. Our ultimate goal is to enable and increase the use of data in the company through creative approaches and the implementation of powerful resources such as analytical databases, advanced data pipelines, BI tools, and data science technology. We hire the brightest minds to take on this challenge and equip them with the knowledge and tools that contribute to their personal growth and success while supporting our company’s culture of diversity and experimentation. The role the Data team plays at At-Bay is critical as business users, product managers, engineers, and many others rely on us to empower their decision-making. This is what drives up the challenge as part of the Data department, but also the reward. At-Bay is seeking an experienced and data-driven BI Engineer to join our BI team. Our BI team is a core business & data-oriented team that leads BI solutions to various products and departments around the organization. As a BI engineer, you will work directly with cross-functional teams, internal and external customers to understand the business needs, you will provide reliable and creative BI solutions for complex data challenges and take part in POCs and migrations of new technologies. If you are sharp with technical skills & analytical thinking, passionate about data, and want to be a focal point of analytical & technical aspects of our team activity, come and help us turn our growing amount of events into critical information, business insights that will help to make impactful decisions on our business.   Responsibilities: End to end modeling the core Data warehouse of the company, providing BI Infrastructure to the Product, Cyber , RnD, Sales, Finance, Claims teams. Gather requirements and business needs from internal and external customers and turn them into technical specifications. Work closely with BI engineers, analysts, RnD, product, data teams to improve our data flow & internal processes. Create new ETL processes and optimize existing ones (DBT, Airflow, Python).   Qualifications: 2+ years experience working as a Data/BI Backend engineer (DWH, ETL) - Must. Experience with dimensional data modeling & schema design in DWH - Must. Advanced knowledge in SQL - Must.  Experience working with ETL tools (dbt, Informatica, SSIS) - Must. Experience with Snowflake - Advantage. Experience with workflow managers such as Airflow/Luigi - Advantage. Experience with source control systems (Github) – advantage Programming skills (Python or other) - Advantage. BA/B.Sc. in a technical discipline such as Industrial and Management Engineer/ Information Systems Engineer – Advantage.   Location: Tel Aviv, Israel   What you'll get A competitive salary, and equity in a super fast-growing company, taking over commercial insurance. A strong emphasis on work-life balance. Beautiful offices in the heart of Tel Aviv, near the train station and main bus stops. Passionate, smart, and fun people to work with. You will never lack a challenge, we are a unique blend of a fast-growing tech startup, an international firm, and an insurance company. Learn more at at-bay.com Schrödinger is seeking a Computational Biology Intern to work on new and exciting drug discovery and development programs. Our company aims to revolutionize drug design through the use of breakthrough computational methods. Our powerful platform is transforming the discovery of novel therapeutics, and we’re developing a strong preclinical pipeline and portfolio in multiple therapeutic areas, including oncology, immunology and neurology. Who will love this job: A capable collaborator and scientist who’s eager to learn and adopt novel methodologies to answer biological questions, while applying their experience with large data consortia and genomic data  A proficient R and/or Python programmer who’s familiar with machine learning and AI methodology applied to biological data An excellent verbal and written communicator What you’ll do: Work on programs in early drug discovery and translational research with a group of energetic scientists and developers Apply modern machine learning, deep learning and AI methods to novel biological discovery and biomarker development Interpret and visualize analysis results in a way that facilitates biological or disease discovery  Facilitate translational biology research by finding and applying new genomic data sources What you should have: A graduate major in computational biology, bioinformatics, statistics, computer science or a related field Broad background in computational biology and exposure to machine learning Experience analyzing genomics and multi-omics data, especially with large public data sets Experience with cell line drug sensitivity and CRISPR screen data is a plus  Experience with drug combination modeling and prediction is a plus   Pay and perks: Schrödinger understands it’s people that make a company great. Because of this, we’re prepared to offer a competitive salary, stock options, and a wide range of benefits that include healthcare (with dental and vision), a 401k, pre-tax commuter benefits, a flexible work schedule, and a parental leave program. We have catered meals in the office every day, a company culture that is relaxed but engaged, and over a month of paid vacation time.  Our Administrative and Human Resources departments also plan a myriad of fun company-wide events. New York is home to our largest office, but we have teams all over the world. Schrödinger is honored to have been selected as one of Crain's New York Best Places to Work for the past three years running. Estimated base salary (NYC only): $7,500/mo. Actual compensation package is dependent on a number of factors, including, for example, experience, education, degrees held, market data, and business needs. If you have any questions regarding the compensation for this role, do not hesitate to reach out to a member of our Strategic Growth team.  Sound exciting? Apply today and join us! As an equal opportunity employer, Schrödinger hires outstanding individuals into every position in the company. People who work with us have a high degree of engagement, a commitment to working effectively in teams, and a passion for the company's mission. We place the highest value on creating a safe environment where our employees can grow and contribute, and refuse to discriminate on the basis of race, color, religious belief, sex, age, disability, national origin, alienage or citizenship status, marital status, partnership status, caregiver status, sexual and reproductive health decisions, gender identity or expression, sexual orientation, or any other protected characteristic. To us, "diversity" isn't just a buzzword, but an important element of our core principles and key business practices. We believe that diverse companies innovate better and think more creatively than homogenous ones because they take into account a wide range of viewpoints. For us, greater diversity doesn't mean better headlines or public images - it means increased adaptability and profitability. Our mission is to make biology easier to engineer. Ginkgo is constructing, editing, and redesigning the living world in order to answer the globe’s growing challenges in health, energy, food, materials, and more. Our bioengineers make use of an in-house automated foundry for designing and building new organisms. Today, our foundry is actively developing multiple organisms to make different products across multiple industries. As a Computational Biologist working on the Design Team, you’ll support Ginkgo's RNA cell engineering programs by designing and analyzing high-throughput experiments using a variety of synthetic biology and genomic approaches. You’ll develop novel computational tools that expand Ginkgo's mammalian cell engineering toolbox. As part of the Design Team, you will partner with an interdisciplinary team of bench scientists, computational biologists, data scientists, and software engineers, to develop world-changing tools to engineer biology.  The successful candidate will bring their deep knowledge of mammalian gene regulation,  transcription and RNA biology to design, support, and analyze synthetic biology projects within the foundry. The candidate will bring knowledge and experience in modern molecular biology techniques applied to higher eukaryotes. To be successful in this role, you will think big and execute systematically. You will draw on your fluency in gene therapy, mammalian cell engineering and NGS to design, analyze and interpret large scale screens. You will put your organizational and communication muscles to work every day as you work closely with teams across Ginkgo. Please note: we recognize that not all candidates may meet the entire list of Desired Experience and Capabilities. We’re eager to train the right candidates for this role, and encourage those who meet at least two-thirds of the criteria to apply. #LI-DW1 Responsibilities Support Ginkgo’s mammalian cell engineering teams with your expertise in mammalian biology, providing the knowledge needed to design, screen and test novel cell lines, vectors and molecules designing megabases of DNA for each project. Analyze integrated internal and external data to advance mammalian cell engineering programs focused on RNA therapeutic tool development. Help maintain computational biology software owned by the Design Team. Troubleshoot moderate- to high-complexity technical problems, proposing biological design solutions in the dry lab, and maintaining familiarity with protocols (e.g. cell culture, diagnostic/QC, assay design, and execution) in the wet lab. Collaborate with stakeholders across Ginkgo to create the next generation of synthetic biology tools (e.g. algorithms, data structures, predictive models, software pipelines, and/or experimental approaches) that yield step changes in our ability to engineer mammalian cell lines. Maintain high-quality documentation of your work and discoveries, creating written reports, technical presentations for internal or external audiences, electronic lab notebooks, internal database records, code comments, and software documentation. Desired Experience and Capabilities PhD (or equivalent experience) in computational biology, genomics, RNA biology, mRNA therapeutics, quantitative biology, or other relevant field. Interdisciplinary work is strongly preferred. Subject matter expertise in RNA molecular biology, mRNA expression systems or mRNA therapeutics development as evidenced by publication in journals or patents. 2+ years of professional experience (grad school counts) working with mammalian genome engineering tools, such as CRISPR/Cas systems, recombinases, and viral vectors.  Proficiency with at least one software programming language (Python preferred). Knowledge of best practices for collaborative software development (version control systems, test-driven development, and good documentation habits). Familiarity with cloud services (e.g. AWS) is preferred. First-hand technical experience in at least two of the following areas: synthetic biology, bioinformatics, RNA biology, structural RNA biology,  transcriptomics, translatomics, gene regulation, post transcriptional regulation, sequence analysis, genomics, NGS analysis, machine learning, and quantitative modeling of biological systems. Demonstrated ability to meet the demands of multiple concurrent projects. Strong curiosity about (and comfort working in) areas of biology previously unknown to you and, at times, your peers. We look forward to hearing from you. Please send us the following: A résumé or curriculum vitae A sample of your code. A GitHub profile, if you have one, is preferred. Otherwise, attached files are ok. We also feel it’s important to point out the obvious here – there’s a serious lack of diversity in our industry and it needs to change. Our goal is to help drive that change. Ginkgo is deeply committed to diversity, equality, and inclusion in all of its practices, especially when it comes to growing our team. We hope to continue to build a company whose culture promotes inclusion and embraces how rewarding it is to work with engineers from all walks of life. Making biology easier to engineer is a tough nut to crack – we can’t afford to leave any talent untapped. It is the policy of Ginkgo Bioworks to provide equal employment opportunities to all employees and employment applicants. To learn more about Ginkgo, visit www.ginkgobioworks.com/press/ or check out some curated press below:What is it really like to take your company public via a SPAC? One Boston biotech shares its journey (Fortune)Ginkgo Bioworks resizes the definition of going big in biotech, raising $2.5B in a record SPAC deal that weighs in with a whopping $15B-plus valuation (Endpoints News)Ginkgo Bioworks CEO on scaling up Covid-19 testing: ‘If we try, we can win’ (CNBC)Ginkgo raises $70 million to ramp up COVID-19 testing for employers, universities (Boston Globe)Ginkgo Bioworks Redirects Its Biotech Platform to Coronavirus (Wall Street Journal)Ginkgo Bioworks Provides Support on Process Optimization to Moderna for COVID-19 Response (PRNewswire)The Life Factory: Synthetic Organisms From This $1.4 Billion Startup Will Revolutionize Manufacturing (Forbes)Synthetic Bio Pioneer Ginkgo Raises $290 Million in New Funding (Bloomberg)Ginkgo Bioworks raises $350 million fund for biotech spinouts (Reuters)Can This Company Convince You to Love GMOs? (The Atlantic) We also feel that it’s important to point out the obvious here – there’s a serious lack of diversity in our industry, and that needs to change. Our goal is to help drive that change. Ginkgo is deeply committed to diversity, equity, and inclusion in all of its practices, especially when it comes to growing our team. Our culture promotes inclusion and embraces how rewarding it is to work with people from all walks of life.   We’re developing a powerful biological engineering platform, so we must remain mindful of the many ways our technology can – and will – impact people around the world. We care about how our platform is used, and having a diverse team to build it gives us the best chance that it’s something we’ll be proud of as it continues to grow. Therefore, it’s critical that we incorporate the diverse voices and visions of all those who play a role in the future of biology. It is the policy of Ginkgo Bioworks to provide equal employment opportunities to all employees and employment applicants. Do you want the opportunity to leverage your skills to make a direct impact on the world’s leading life sciences, consumer products, and retail companies? Join Clarkston Consulting as a Power BI Developer to help deliver creative business solutions to our market-leading clients as a part of our team of experienced professionals. We are looking for motivated, self-driven leaders who are energized by team results and interested in joining a firm that values its culture and people as its biggest strengths. Together, we can help find the answers to our clients most challenging business problems. What You’ll Do Clarkston gives you the opportunity to deliver great solutions, become recognized as an industry expert, and help build a great practice. As a Power BI Developer at Clarkston, you will: Turn data into stories by visualizing complex data in an intuitive and user-friendly way Gather requirements, prototype design, iterate based on client feedback, and develop final visual solutions How You’ll Grow At Clarkston, we feel that we provide the greatest value to our clients through a combination of our industry expertise, business process knowledge, and consulting excellence. Beyond your day-to-day responsibilities, throughout your career at Clarkston you will: Have the support and mentorship of your Clarkston colleagues and leaders Own your career – you'll be able to take charge of your career journey with diverse opportunities to lead and expand your skillset both at the client site and within the firm Have the opportunity to make a real and positive impact not only the clients you work with, but on the firm as well  Travel Requirement Travel is an integral part of this role and is estimated to average 20-30%. This may vary based upon client and project needs. While travel is a requirement of the role, due to COVID-19 restrictions, all non-essential travel has been limited and any on-site requests are subject to review. When not traveling, consultants work from their home office. Relocation is not required. Requirements What We’re Looking For: An ideal candidate as a Power BI Developer would have the following qualifications and experience: Ability to use complex expressions to calculate, group, filter, and format custom dashboards/reports Knowledge of best practices for visual flow, interactivity, and drilldown between graphics Background in design principles for UI Experience utilizing visualization tools like Power BI and Tableau Understand the various audiences for consuming the visualizations and tailor design and UI approach to those groups (executive, analyst, information consumer) Understanding of steps to productionizing a solution, including testing, administration, and security Solid understanding of the underlying data models driving visualization, including relational databases and joins Minimum degree required: bachelor's degree from an accredited college or university Benefits Our benefits include: Comprehensive Health and Wellness Benefits (Medical, Dental, Vision, and more) 401k with company contributions Paid vacation, personal days, holidays, and sick leave Paid Parental Leave and Family Building Benefits (Adoption, Surrogacy, and Infertility Support) Life and Disability Insurance Training and Professional Development investments, Tuition Assistance, and more Visit Careers at Clarkston to learn more about our culture, benefits, and opportunities. We hope you’ll join us! COVID-19 Vaccination Statement While Clarkston Consulting has not mandated vaccination at this time, COVID-19 vaccinations are required in order to access Clarkston Consulting facilities and those of many of our clients. With this in mind, all prospective hires will be required to provide their vaccination status. Company Description At Experian Health, our employees have the opportunity to shape more than products – they shape the future of U.S. healthcare. Experian Health is a pioneer for innovations leading the way in revenue cycle management, identity management, patient engagement, and care management for hospitals, physician groups, labs, pharmacies and other risk-bearing entities. Our success relies on people who are given the freedom to imagine new frontiers in the rapidly changing healthcare space and push the boundaries of innovation. Help us realize our vision of applying data for good and changing the healthcare landscape for the better – for all of us. Our mission is to use data driven insights to simplify healthcare for all. Simply put, we want to make the healthcare system work better for us as consumers and for those who work in healthcare. Our ONE Experian Health culture is the centerpiece of making this happen. Our aspiration is to bring people together who are driven by purpose and want to make a difference.  We strive to have a diverse group of people and minds who are: OPEN: Have a growth mindset and collaborate often with others to make things happen NIMBLE:  Always embracing change and pushing the envelope on innovative ways to solve problems EFFECTIVE:  Accountable to themselves and to others Job Description 100% REMOTE (NOT HYBRID) - WORK ANYWHERE IN THE US The primary responsibility of the Data Analyst will be to support application development leveraging strong SQL skills, knowledge of relational databases, and the skills to ensure custom coordination of benefit software, containing over 400 million rows of data, only allows accurate data to be loaded, and data integrity is maintained after bug fixes and enhancements.  This position will ensure this software is thoroughly tested from all angles focusing primarily on the backend by developing custom test plans and executing them using SQL, analyzing production data, and writing custom reports.  Job duties: Fully understand custom built Healthcare Medical Eligibility/Coordination of Benefits software solution. Understand the technical design and be able to traverse through and fully test the system using custom developed test plans using SQL Work collaboratively at ground level with senior level development staff to fully understand product requirements. Be willing to ask questions, push back as necessary, and ultimately ensure the new code meets stringent customer expectations Identify software defects, conduct research, develop plan for resolution, and engage appropriate internal resources as necessary Perform data analysis as needed on production data (400+ million rows of data) Collaborate with team members on, and provide peer review of, test plans, test cases, test data, and automation/tool enhancements. Work collaboratively with development team to make technical judgments based upon understanding of the business process and customer/user needs whereby a design change or modification should (or needs to be) changed. Support inquiries from client, operations, and customer support on content related questions and monitor areas for improvement. Design and document test cases to ensure optimal system performance with new code releases Utilize QA best practices Tests will be executed at the database level, using SQL Build automated tests using tools such as Selenium Operate load testing on Web Based Portal Run smoke tests and regression tests Prepare appropriate test data Communicate and document testing results in appropriate tool Maintain defect reporting and tracking Maintain current test plans, test cases, test scripts, and test data. Availability for planned after hours deployments and unplanned issue resolution Planned deployments typically occur once a month on Thursday nights Qualifications Bachelor’s degree in Information Systems, Computer Science, or other related field OR equivalent experience required At least 3 years combined prior business analyst, SQL programming, software QA, SQL data analysis Minimum 3 years of SQL usage in a professional setting Experience working as an analyst with large datasets (1+ million records) highly desired Experience with SDLC and iterative development processes, specifically Agile work processes highly desired Experience in working in a highly competitive team environment Strong SQL skills required (Data Analyst SQL skill set, not necessarily SQL programming) Focus on relational databases Business analyst knowledge is highly preferred QA knowledge is preferred. Willingness to be trained on QA fundamentals is required Coordination of Benefits, and/or Healthcare Revenue Cycle knowledge a plus Effective communication and relationship building skills Self-motivated, team player, but who can work independently Ability to adapt to an Agile/Scrum environment Strong written and verbal communication skills Problem-solving as part of a distributed team Time management and organizational skills Knowledge of the HIPAA transaction sets and requirements is desirable Become an expert on highly complex custom software - willingness to self-study and learn through trial and error required.   Additional Information Experian is an Equal Opportunity Employer. Anyone needing accommodation to complete the interview process should notify the talent acquisition partner. The word "Experian" is a registered trademark in the EU and other countries and is owned by Experian Ltd. and/or its associated companies. EOE including Disability/Veterans. Experian is proud to be an Equal Opportunity and Affirmative Action employer. Our goal is to create a thriving, inclusive and diverse team where people love their work and love working together. We believe that diversity, equity and inclusion is essential to our purpose of creating a better tomorrow. We value the uniqueness of every individual and want you to bring your whole, authentic self to work. For us, this is The Power of YOU and and it reflects what we believe.  See our DEI work in action! Please contact us at JobPostingInquiry@experian.com to request the salary range of this position (please include the exact Job Title as it reads above in your email). In addition to a competitive base salary and variable pay opportunity, Experian offers a comprehensive benefits package including health, life and disability insurance, generous paid time off including 12 company paid holidays and parental and family care leave, an employee stock purchase plan and a 401(k) plan with a company match. Experian Careers - Creating a better tomorrow together Find out what its like to work for Experian by clicking here Company Description At Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people’s lives. Our promise to our associates is rock-solid: we grow together, we enjoy our work, and we inspire each other. Join in and feel the difference! Job Description Tasks: As Operations Specialist you will handle day-to-day operations of our Big Data Cloud Platform Services and ensure stability, security, and scalability. You drive industrialization of different manufacturing and logistic cloud based platforms through further automation of deployment, configuration, upgrade and maintenance processes.  Part of your work also entails developing new platform features supporting  (cost) monitoring, logging and alerting as well as the implementation of new operations related processes.    In your responsibility lies the development of scripts for automation (deployment, configuration) and monitoring, as well as providing expert product support to Bosch business units (e.g. root-cause analysis of non-standard issues). Your tasks also include testing and evaluating new product features in close alignment with project stakeholders, internal customers, and vendors. Furthermore, you consult internal customers on technical level regarding tool selection, code quality, connectivity topics and workload performance. Qualifications Profile: Experience with the Microsoft Azure ecosystem (e.g. Azure Services, Azure CLI, Azure DevOps). Experience in working on larger projects, including multiple customers and international teams. Hands-on experience with Cloud or infrastructure operation. Knowledge of version control tools (e.g. GIT, Bitbucket) and CI/CD pipeline tools (e.g. Azure DevOps). Knowledge of IT monitoring and logging techniques and relevant technology stack (e.g. Grafana). Ideally knowledge of one scripting language (e.g. Bash or Python). Nice to have: knowledge of Cloud Security. University degree in Computer Science, Information Technology, Engineering or related fields. Proficiency in English both written and spoken. Additional Information Benefits: We would like to offer you number of amenities for you and your loved ones. Work #LikeABosch: Contract of employment  and a competitive salary (together with annual bonus) Flexible working hours with home office after the pandemic as well Referral Bonus Program Copyright costs for IT employees Canteen in the office with co-financed lunches Grow #LikeABosch: Complex environment of working, professional support and possibility to share knowledge and best practices On-going development opportunities in a multinational environment Broad access to professional trainings, conferences and webinars Language courses Live #LikeABosch: Private medical care and life insurance Multisport card and sports teams Number of benefits for families (for instance summer camps for kids) Non working days on the 24th and 31st of December Discounts for Bosch products For more than 20 years, PointClickCare has been the backbone of senior care. We’ve amassed the richest senior care dataset making our market density untouchable and our connections to the healthcare ecosystem exponentially more powerful than those of any other platform.  With Collective Medical & Audacious Inquiry, we’ve become the most expansive, full-continuum care collaboration network, offering care teams immediate, point-of-care access to deep, real-time insights at every stage of a patient’s journey. For more information on PointClickCare, please connect with us on Glassdoor and LinkedIn. Position Type: You must be in a co-op program to be considered. 8 month term from May 8 - December 22, 2023 Reporting to the Director of Business Intelligence, the Business Intelligence Developer I plays an important role as a supporting member of the Business Intelligence department and the broader employee base of PointClickCare.  Customer service and a positive, supportive, personality are essential to the success of this role. This role will provide you the opportunity to gain exposure to some of the core systems and tools that help run our business. You will learn various data transformation and analytical tools such as MS SSIS, MS SSMS, SQL Server, Power BI. Key Responsibilities: Engage technology and business leaders to leverage business tools to solve real world business challenges Supporting the existing Business Intelligence environment through job trouble shooting Documenting existing Business Intelligence configurations Designs, prototypes, codes and tests new or enhanced SQL queries Performs customer support processes and activities for the implementation of new or existing applications Monitors the efficiency and effectiveness of application operations and troubleshoots problems, as necessary Learn and be involved in different phases of project plan (Business Requirements to Solution Delivery) Evaluating new products and services to judge their suitability for use Preliminary research and investigation of software and evaluating new products and services to judge their suitability for use Desired Skills & Experience: Enrolled in a Business, Computers, Engineering, or IT related co-op program Motivated learner with the eagerness to work with data Exposure in ETL and Data Integration, Data Profiling, Data Modeling Knowledge of SQL Experience with SQL Server, SSIS, SSMS, Visual Studio or ETL tools MS Office Applications (Excel), Strong Excel experience (macros) Workflow design and implementation Scripting experience Demonstrating strong written and verbal communication Critical thinker, problem solver, with the ability to pursue help when required Experience composing project documentation (e.g., high level use cases, detailed business specifications) It is the policy of PointClickCare to ensure equal employment opportunity without discrimination or harassment on the basis of race, religion, national origin, status, age, sex, sexual orientation, gender identity or expression, marital or domestic/civil partnership status, disability, veteran status, genetic information, or any other basis protected by law. PointClickCare welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process. Please contact recruitment@pointclickcare.com should you require any accommodations. When you apply for a position, your information is processed and stored with Lever, in accordance with Lever’s Privacy Policy. We use this information to evaluate your candidacy for the posted position. We also store this information, and may use it in relation to future positions to which you apply, or which we believe may be relevant to you given your background. When we have no ongoing legitimate business need to process your information, we will either delete or anonymize it.  If you have any questions about how PointClickCare uses or processes your information, or if you would like to ask to access, correct, or delete your information, please contact PointClickCare’s human resources team: recruitment@pointclickcare.com  PointClickCare is committed to Information Security. By applying to this position, if hired, you commit to following our information security policies and procedures and making every effort to secure confidential and/or sensitive information. Company Description Natixis in Portugal is fully integrated in the global organization of Natixis, a French multinational financial services firm specialized in Asset & Wealth Management, Corporate & Investment Banking, Insurance and Payments. A subsidiary of Groupe BPCE, Natixis counts nearly 16.000 employees across 38 countries. Based in Porto, Natixis Centre of Expertise mission is to transform traditional banking by developing innovative solutions for the bank’s business, operations and work culture worldwide, as a key driver of the company’s culture of agility and innovation. Teams of IT and Banking Support Activities work in an integrated, inclusive and transversal way, supporting all the business lines and country platforms. Natixis in Portugal is the best combination of a “start-up mindset” with a large, solid structure. Its unique culture gives true meaning to a “beyond banking” personality: to be a real entrepreneur, self-challenging, ever striving to excel and go that extra mile. Job Description We are looking for a Data Analyst with a background in Business Intelligence to work in Regulatory reporting across the globe. This position will be integrated in the IT Financing department within the CIB business unit.  In this role, the DA will have to respond to the data requirements submitted by the regulators and the providers, working in close communication with business users, local vendors in each country. Roles and responsibilities: Discuss requirements with business users and local vendors in each country; Specify and lead the implementation of changes in the data model in order to meet regulatory needs; Investigate data issues and lead the steps towards their resolution; Create or modify SQL extractions; Create or modify Cognos reports (only for one location, so it is a small component of the role) Qualifications Previous experience as IT Data Analyst or Business Intelligence Analyst, Product Owner or similar role; Knowledge of business intelligence methodologies, in particular data modeling (mandatory); Experience with report building; Knowledge on data modeling for Data Warehouses (data modeling on big data context is a plus) Experience with Power BI (tableau is a plus) Knowledge and experience with SQL/HiveQL Experience with big data environment - Hive (experience with Indexima is a plus) Good communication with business users to collect business requirements Very good communication (written and oral) and interpersonal skills; Good level of English (at least B2) ; Additional Information Early morning. Campo 24 de Agosto. In 4 minutes, you are clocking in at the office. After grabbing a cup of coffee and fresh fruit, pick up your laptop and choose your spot for the day. It's going to be a busy one: French class before lunch and, just after, quick medical appointment at Natixis doctor's office.   Lunch break. Outside in the big terrace (look at your crops at the Urban Garden; ready to harvest!) or, if you feel like stretching your legs, walk downtown to grab lunch.   Back inside. Quick sprint review (working together anywhere means virtual happy birthday to that colleague in Paris that just turned 35). The afternoon went flying (tasks, reports, calls, some jokes with your teammates). End it on a high note: just one PlayStation game or the final match for that ping-pong tournament.   Tomorrow, you complete that certified technical training and the day after, you will work from home, taking advantage to finally do that online course on Udemy. Once you are done with your tasks for the day, you can visit the office for a board games session or show up at the rehearsal of one of Natixis bands. If that is too steady for you, meet your colleagues to surf some waves or join them in a football match. Company Description Guardant Health is a leading precision oncology company focused on helping conquer cancer globally through use of its proprietary tests, vast data sets and advanced analytics. The Guardant Health oncology platform leverages capabilities to drive commercial adoption, improve patient clinical outcomes and lower healthcare costs across all stages of the cancer care continuum. Guardant Health has commercially launched Guardant360®, Guardant360 CDx, Guardant360 TissueNext™, Guardant360 Response™, and GuardantOMNI® tests for advanced stage cancer patients, and Guardant Reveal™ for early-stage cancer patients. The Guardant Health screening portfolio, including the Shield™ test, aims to address the needs of individuals eligible for cancer screening. Job Description Department Summary – This department works towards (NGS) Assay Workflow Software, Data Infrastructure, Data Research and Systems Integration. About the Role: This position is part of the Systems Integration team for an early-stage cancer screening NGS Assay and associated automation and bioinformatics software components. We are looking for a motivated scientist/engineer who is interested in crossing the bridge from academia to industry, in the near future and has either completed a grad program or is currently enrolled. This individual will get the opportunity to work at the forefront of scientific and technological innovation within an interdisciplinary Screening Systems Integration team and will make core contribution to evolving cancer screening products designed to have clinical impact on patients. Come join us!  Essential Duties and Responsibilities: Analyze large amounts of data on NGS assay performance and generate visualizations for storytelling, monitoring and tracking  Assess various fundamental calculations in assay and associated software implementation  Generate test methods for assessing assay and software calculations in Python  Generate data visualization to assess the performance of the assay and various assay Quality Controls (in Python).  Generate reports integrated in python notebooks, that include data visualization and Quality Control calculations.  Once the project is completed, provide written documentation and requirements related to Assay, Software and Automation.  Present findings and results to cross functional highly technical audience in Bioinformatics, Software, Automation and Assay functions.   Contribute to a highly collaborative work environment among cross functional teams.   Qualifications Completed or currently enrolled in a MS or PhD program in Biomedical Sciences, Engineering, Software or Bioinformatics.  Significant research experience in these areas.   Proficiency in Python, including visualization packages such as Matplotlib and Plotly  Ability to work with large amounts of structured or semi-structured data.   Ability to build reproducible and well-written Python code for data analytics  Ability to communicate highly technical findings to a diverse audience, within NGS assays development teams.   Preferred Qualifications:  Experience with analysis of NGS assay data. Additional Information Hybrid Work Model: At Guardant Health, we have defined days for in-person/onsite collaboration and work-from-home days for individual-focused time. All U.S. employees who live within 50 miles of a Guardant facility will be required to be onsite on Mondays, Tuesdays, and Thursdays. We have found aligning our scheduled in-office days allows our teams to do the best work and creates the focused thinking time our innovative work requires. At Guardant, our work model has created flexibility for better work-life balance while keeping teams connected to advance our science for our patients. Covid Vaccination Policy:  Guardant Health requires all employees to be fully vaccinated. We follow the CDC guidelines for the definition of “fully vaccinated”, meaning an employee is consider fully vaccinated against COVID-19 after receiving the second dose of a two-dose vaccine or one dose of a single-dose vaccination, and necessary booster vaccines. In addition, fully vaccinated employees will be required to maintain their fully vaccinated status under this policy by obtaining, if applicable, any FDA-approved boosters. Candidates may request and obtain an approved exemption from Guardant’s COVID-19 U.S. Vaccination Policy as a reasonable accommodation, as consistent with applicable laws.  Candidates will not be able to start their employment with Guardant until they show proof of vaccination or have an approved exemption. For positions based in Palo Alto, CA or Redwood City, CA, the hourly range for this full-time position is Undergraduate $27/hr., Graduate $32/hr., and Doctorate $40/hr. The range does not include benefits and, if applicable, overtime, bonus, commission, or equity. Within the range, individual pay is determined by work location and additional factors, including, but not limited to, job-related skills, experience, and relevant education or training. If you are selected to move forward, the recruiting team will provide details specific to the factors above. Employee may be required to lift routine office supplies and use office equipment. Majority of the work is performed in a desk/office environment; however, there may be exposure to high noise levels, fumes, and biohazard material in the laboratory environment. Ability to sit for extended periods of time. Guardant Health is committed to providing reasonable accommodations in our hiring processes for candidates with disabilities, long-term conditions, mental health conditions, or sincerely held religious beliefs. If you need support, please reach out to Peopleteam@guardanthealth.com Guardant Health is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. All your information will be kept confidential according to EEO guidelines.  To learn more about the information collected when you apply for a position at Guardant Health, Inc. and how it is used, please review our Privacy Notice for Job Applicants. Please visit our career page at: http://www.guardanthealth.com/jobs/ #LI-CS4 At Beyond Finance, we’ve made it our mission to help everyday Americans escape the endless cycle of crippling debt and step into a brighter financial future. Through compassionate, individualized care, supportive user-centric technology, and customized financial solutions, we’ve helped over 200,000 clients on their path to a debt-free life. While we’re proud of what we’ve already accomplished (over $1 billion in resolved debt), we're searching for new collaborators to help us get to the next level! If you’re looking to join a forward-thinking, rapidly growing organization with helping people as its number one goal, we want to hear from you. Job Title: Senior Business Intelligence Engineer Location: 333 W Wacker Drive, Suite 1800, Chicago, IL 60606 Job Description Design strategies for enterprise databases, data warehouse systems, and multidimensional networks for a financial services company. Model, design, and construct large relational databases or data warehouses. Create and optimize data models for warehouse infrastructure and workflow. Document and map existing data structures from the operational system to the new curated data structures and author ETL scripts. Work with various internal business groups to understand their short and long-term business needs and create a plan to deliver the data using the existing system or new data. Use multidimensional modeling techniques to develop models to help internal business users understand data. Perform dimensional modeling, relational databases, tables, columns, and data types. Supervise others and participate in building the BI layer, ensuring integration of BI access in data and reporting. Supervise team members and participate in building BI reports. Train team members to build BI reports. Supervise others and participate in using advanced SQL and LookML techniques to transform excel-based reports into executive summary Looker dashboards with key performance metrics. Supervise others and participate in using SQL and Snowflake data warehousing concepts to build new data repositories by authoring complex ETL logic and evolve current data structures to render them reporting ready. Refine and curate Salesforce data using dimensional modeling techniques to enable operational statistics measurement and agent compliance tracking. Coach / mentor junior members on the team. Telecommuting / remote work permitted. Education Requirement: Master’s degree in Computer Science, Management Information Systems, or related. Experience Requirement: 1 year of experience as BI Engineer, Data Engineer, Data Architect, or related. Alternate Requirements: In lieu of a master's degree plus one year of experience, will accept a bachelor's degree plus five years of experience in the same fields. Special Skills: Must have work experience with each of the following: (1) Use advanced SQL and LookML techniques to transform excel-based reports into executive summary Looker dashboards with key performance metrics for the financial services industry; (2) Use SQL and Snowflake data warehousing concepts to build new data repositories by authoring complex ETL logic and evolve current data structures to render them reporting-ready; and (3) Refine and curate Salesforce data using dimensional modeling techniques to enable operational statistics measurement and agent compliance tracking. The base salary range represents the anticipated salary range for this position. The actual base salary offered within the range will depend on numerous factors including the individual’s skills, experience, performance, and the location where work is performed. In addition to base salary, this position qualifies for an annual bonus subject to the terms outlined in the company's bonus plan. Full-time employees hired into this position are eligible for health care benefits shown here. Base Salary Range$141,000—$150,000 USD Why Join Us? While you make a difference for others, we’ll work to make a difference for you, providing an uplifting, collaborative work environment and benefits that reflect your value to us. For eligible full-time employees, we offer: Considerable employer contributions for health, dental, and vision programs Optional remote and hybrid work models Generous PTO, paid holidays, and paid parental leave 401(k) matching program Merit advancement opportunities Career development & training And finally, our team spirit and culture! Even as we’ve shifted to a remote-first model, we continue to cultivate an environment of community, connection, and belonging across our entire organization. Location: Gurgaon, Noida, Hyderabad, Chennai, Bangalore, Pune, Kolkata, Indore, Jaipur, Ahmedabad,None,None About Material Material is a global strategy, insights, design, and technology partner to companies striving for true customer centricity and ongoing relevance in a digital first, customer-led world. By leveraging proprietary, science-based tools that enable human understanding, we inform and create customer-centric business models and experiences + deploy measurement systems – to build transformational relationships between businesses and the people they serve. About Srijan Srijan is a global engineering firm that builds transformative digital paths to better futures for Fortune 500 enterprises to nonprofits all over the world. Srijan brings advanced engineering capabilities and agile practices to some of the biggest names across FMCG, Aviation, Telecom, Technology, and others. We help businesses embrace the digital future with cloud, data, API and platform centric technologies and adapt to changing business models and market demands. Srijan leads in Drupal with 350+ Drupal engineers, 80+ Acquia certifications. Srijan is also a Drupal Enterprise Partner & Diamond Certified Skillls and Requrement : Experience: 5+ years’ professional experience developing reports using enterprise reporting tools Minimum 4 years’ experience designing and developing dashboards using Tableau Desktop for various organizational metrics and indicators using best practices and industry standards 4 + years of experience with Data Visualization tools such as Power BI & Tableau required; Well organized, with attention to detail and a strong focus on accuracy; Has the ability to work effectively in a fast-paced environment, juggling multiple priorities; You possess demonstrated analytical and critical thinking skills; Data artisan – can tell a story with the data in a dashboard. Highly Experience with Tableau Server and Tableau Desktop across various versions of Tableau 9.x/10.x- Good in BI and data warehousing concepts Experience with BI applications comprised of multiple / inconsistent data sources Understanding of ETL process- good database knowledge and experience, should be able to write complex SQL queries against RDBMS (such as Oracle, MySQL etc.) and NoSQL databases (such as MongoDB, Couchbase etc.) Particularly good understanding of SDLC and Agile processes. Experience in data modelling, data loading, data migration, data analysis (must), along with semantic (business rules) layer implementation Understanding of the Data warehouse life cycle right from data source to ETL to transformations to multidimensional models like data marts, star schema and Reporting Experience with Cloud native BI/ Analytics implementation and service integration Preferred experience with Tableau / Looker / Power-BI / Alteryx Excellent communication and inter-personal skills, accustomed to work in a team environment with tight schedules and capable of working efficiently under pressure Ability to interact with stakeholders throughout the organization Solid understanding of data and database technologies (data analysis, data prep, ETL, ELT, etc.) required;  Responsibilities: Requirement Gathering & Analysis: Responsible for participating in business requirements gathering exercise and translating business requirements into functional and technical specifications. Participate and provide inputs during requirements feasibility analysis and provide alternate solutions based on application architecture. Responsible for functional requirements interpretation and guiding the team on design and development process. Technology Review: Responsible for end-to-end analysis of the application portfolio and provide inputs for transformation opportunities for a given line of business. Testing: Responsible for creating the test plan and associated functional test cases. Perform functional testing as required for a given release. Project Support: Guide the delivery team during impact analysis of incidents by providing inputs on upstream and downstream dependencies. Provide inputs for prioritizing incidents and problems. Participate and provide inputs during change impact analysis and prioritization process. Assist the delivery team in complying with regulatory and compliance requirements. Participate in release acceptance exercise and provide inputs for business signoff. People Management: Drive the SME development program to assess and develop domain experts. Create a career road map for Application SME to become domain experts and track the progress periodically. Business Development: Work with pre-sales and practice on business development and existing growth opportunities in terms of discovery, solution options, evaluation, estimation, training and creation of collaterals Customer Relationship Management: Contribute to continuous service improvement plans (CSI). Knowledge Management: Contribute and participate proactively in knowledge sharing sessions. Audits Participate in security and compliance audits.  What you will get: Competitive Salaries with flexi benefits  Group Mediclaim Insurance and Personal Accidental Policy 30+ Paid Leaves in a year  Learning and Development of quarterly budgets for certification    Apply to this job Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value Job Description As Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions. You will independently drive design discussions to ensure the necessary health of the overall solution. The role requires a hands-on technologist who has strong programming background like Java / Scala / Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.  Role & Responsibilities: Your role is focused on the Design, Development and delivery of solutions involving: Data Integration, Processing & Governance Data Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations Infrastructure & Cloud Computing Data Management Platforms Implement scalable architectural models for data processing and storage Build functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode Build functionality for data analytics, search and aggregation #LI-REMOTE  Qualifications Overall 5+ years of IT experience with 3+ years in Data related technologies Minimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS / Azure / GCP) Hands-on experience with the Hadoop stack – HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline. Strong experience in at least of the programming language Java, Scala, Python. Java preferable Hands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc  Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security   Competency 1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience 2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc 3. Knowledge on distributed messaging frameworks like ActiveMQ / RabbiMQ / Solace, search & indexing and Micro services architectures 4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 – Data Engineering 5. CI/CD – Infra provisioning on cloud, auto build & deployment pipelines, code quality 6. Cloud data specialty and other related Big data technology certifications Personal Attributes: Strong written and verbal communication skills Articulaion skills Good team player Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Process orientation and the ability to define and set up processe Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements Employee Assistance Programs to help you in wellness and well being Join the fast growing Global Ads Partner Development team as the Senior Business Intelligence Engineer. In this role you will work with a team of Business Intelligence Engineers aimed at providing data driven business insights to inform our partner development strategy. You will drive impact by helping your team to focus on the right priorities, building mechanisms and dashboards to make data accessible to internal teams, and leading the development of strategic initiatives including marketing attribution models and impact measurement.  You will be part of the Ads Partner Development and Marketing org and will work closely with stakeholders including marketing, product, finance, and partner development teams.  This highly visible and strategic role will require you to use SQL, ETL, data warehouse concepts, data modeling, business analysis, reporting, scripting, descriptive & inferential statistics to create business insights. You will need to be savvy about leveraging large data sets, defining BI requirements, and building scalable and automated dashboards to provide self-service BI capability to your stakeholders.   Key job responsibilities Design, build, and maintain automated reporting, dashboards, and ongoing analysis to enable data driven decisions across our team and with partner teams. Identify, develop, manage, and execute queries across multiple data sets to uncover areas of opportunity and present written business recommendations. Lead Agile Sprints and task prioritization to drive impact Lead infrastructure creation for partner advertiser datasets which will include setting up new redshift cluster, creating new data pipelines and building schema for partner tables Strong proficiency at querying and architecting relational databases - e.g. ETL, Data Warehouse, Redshift Develop attribution analysis to measure the impact of marketing activities and engagement with partners Develop a framework to understand the impact that partners drive on our business globally Communicate with internal teams to showcase results and identify best practices  #adptjobs #sspajobs  About the team This role is within Partner Analytics team within the Global Advertising Partner Development organization. We help advertisers and developers to scale their use of Amazon Advertising and grow their business via software tools and marketing/engagement programs that enable developers (internal and external) and partners (agencies and tool providers) to better serve advertiser needs. Basic Qualifications  6+ years of professional or military experience 5+ years of SQL experience Experience programming to extract, transform and clean large (multi-TB) data sets Experience with theory and practice of design of experiments and statistical analysis of results Experience with AWS technologies Experience in scripting for automation (e.g. Python) and advanced SQL skills. Experience with theory and practice of information retrieval, data science, machine learning and data mining  Preferred Qualifications Master’s degree in BI, Finance, Engineering, Statistics, Computer Science, Mathematics, Finance or related field required. Experience in designing and delivering cross functional custom reporting solutions. Experience with Massively Parallel Processing (MPP) databases - Redshift (preferred), Teradata. Experience with R, Python or other statistical/machine learning software. Experience with Tableau. Advanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as required, both verbally and written. Be self-driven, and show ability to deliver on ambiguous projects.   Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.   Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $104,300/year in our lowest geographic market up to $202,800/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site. Company Description We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable. Job Description This Research Engineer is responsible for developing and supporting the engineering components of Verisk’s wind vulnerability models that cover multiple regions and perils, including perils such as straight-line wind, tornadic wind, hail, snow, and freezing temperatures.  General responsibilities include identifying the impact that these perils can have on the built environment, including physical damage which can result in monetary loss to buildings/infrastructure, contents, and loss of use (downtime).  In this role, you will work closely with a team of structural engineers and atmospheric scientists to perform probabilistic risk assessments for the built environment, and present and explain results to internal stakeholders and external clients.  The evolving nature of research work at Verisk creates unique and challenging problems that spark innovation and growth and creates opportunities for its employees. A successful candidate should have a desire to use problem-solving skills in applying sound engineering principles to solve unique and challenging problems in the fields of civil/structural engineering and risk assessment.  It is expected that candidates will be highly motivated, detail-oriented, well-organized, able to perform high-quality self-directed research, have outstanding written and verbal communication skills, and be team-oriented. About the Day to Day Responsibilities of the Role As a member of our Atmospheric Perils Vulnerability Team, your day-to-day responsibilities will include the following: Data acquisition and analysis for the purpose of understanding building inventory and its vulnerability subjected to atmospheric-based hazards in multiple regions worldwide Analytical analyses and research aimed towards the development of vulnerability functions and monetary loss curves for structural and non-structural building and infrastructure components subjected to hazards such as wind, tornadoes, hail, and snow for several regions of interest worldwide Implementation of research into AIR’s portfolio risk analysis models, including programming loss simulation codes and analysis tools, and probabilistic assessment validation Use of GIS tools for data visualization and analysis Real-time and virtual building damage assessments due to natural catastrophes during and after significant events Preparation and presentation of work at staff internal and client external meetings as well as technical writing for internal and external publications and client-facing documentation #LI-SM1 Qualifications About You and How You Can Excel in This Role Ph.D. in Wind Engineering, Structural Engineering, Civil Engineering, and/or other relevant fields Experience in performance-based design, probabilistic and stochastic risk assessment and modeling, and reliability theory with applications to the field of structural engineering Proficient in C/C++, MATLAB, R, and/or FORTRAN Demonstrated data mining skills (SQL and/or statistical analysis) Excellent written and verbal communication skills Strong organizational and excellent documentation skills Knowledge of GIS applications (e.g. ArcView) and SQL server is a plus Additional Information At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.    Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.   But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.   It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.    At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.  At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We have received the Great Place to Work® Certification for the 7th consecutive year. We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.  Verisk’s Statement on Racial Equity and Diversity supports our commitment to these values and affecting positive and lasting change in the communities where we live and work.   Verisk Analytics is an equal opportunity employer. All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability. http://www.verisk.com/careers.html Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.  Consumer Privacy Notice Descripción de la empresa Con casi 10K empleados en todo el mundo, apoyamos a las empresas en su transformación digital. Imaginamos y hacemos realidad sus ambiciones gracias a las infinitas posibilidades de las plataformas digitales, para cambiar su cultura y su forma de trabajar, y crear valor en sus organizaciones. Presentes en 18 países de Europa y Oriente Medio y con 25 años de experiencia, ponemos la "Tecnología al servicio del Hombre" para construir un mundo más humano y sostenible. #CreativeTechForBetterChange  https://www.youtube.com/watch?v=ir-IZHrTS0c Trabajar en Devoteam significa: Trabajar junto a partners como Google, Microsoft, AWS o Salesforce cuyas soluciones implementamos para nuestros clientes; evolucionar en un grupo internacional que te apoya en el desarrollo de tu carrera con cursos de formación y certificación adaptados. unirse a un equipo especializado, acompañado por un responsable local que podrá guiarle en sus elecciones y promover los intercambios con sus compañeros, ya sea durante eventos técnicos o de convivencia. crecer en una empresa que desafía a sus equipos siendo ágil y ambiciosa, adaptándose para permitir el éxito individual y colectivo. Descripción del empleo BIG DATA ENGINEER (AWS) Buscamos un/a Big Data Engineer para que se incorpore a nuestro equipo de Data. Formarás parte del equipo que configura la estrategia, la arquitectura y la infraestructura de datos de importante empresa del sector retail ubicada en Barcelona.  ¿CÓMO ES NUESTRO EQUIPO? Inspiramos y unimos mediante nuestra pasión por el estilo y la cultura. Estamos en 118 países y nuestra presencia online se extiende a más de 80 países. Nuestro equipo está formado por personas de 112 nacionalidades y en un 80% por mujeres. Somos un equipo muy dinámico, motivado por las nuevas tecnologías, con pasión por lo que hacemos y abiertos a afrontar grandes retos que nos permitan seguir creciendo y aportando valor a través de los datos. ¿QUÉ HACE UN/A BIG DATA EGINEER EN UNA EMPRESA RETAIL? Tu objetivo será desarrollar soluciones de procesamiento de datos de última generación para permitir casos de uso que sean muy innovadores en el sector retail, como geo-analítica, robotización, personalización omnicanal, la tienda online, experiencia del consumidor 360º y decisiones en tiempo real. En tu día a día… •            Desarrollarás pipelines en batch y tiempo real con Spark, dbt, Spark Structured Streaming y Kafka. •            Desarrollarás y gestionarás el Data Lake, el procesamiento de datos y las plataformas de datos end to end: 1.           Diseñarás y gestionarás soluciones de arquitectura cloud. Desarrollarás integraciones de datos escalables y confiables para alimentar los modelos de Data Science. 2.           Administrarás y orquestarás mecanismos adecuados de monitorización. 3.           Diseñarás pipelines CI / CD. Participarás en la automatización de tests, calidad del código y despliegue automático de nuestras aplicaciones. 4.           Estarás conectado con los últimos avances en Big Data y colaborarás en el I+D que aportarán nuevos casos de uso y mejoras. ¿QUÉ ESPERAMOS DE TI? •       Que aportes al menos 3 años de experiencia desarrollando en Python, Scala, o cualquier otro lenguaje orientado a objetos. •       Que aportes experiencia en el desarrollo de ELT escalable, procesos de integración de datos con Spark, Spark Structured Streaming o cualquier otra tecnología de procesamiento de datos. •       Que estés interesado/a y apliques buenas prácticas: tests, automatizaciones, construyas pipelines en CI, etc. •       Que tengas experiencia en la construcción y el mantenimiento de cargas de datos de alto volumen complejas y orquestando dependencias (por ejemplo, Airflow). •       Que hayas trabajado con servicios de AWS (por ejemplo, S3, Lambda, DynamoDB, API Gateway, Glue, Athena, ECR/ECS), y Databricks es muy deseable. •       Que seas una persona comprometida, proactiva, que se preocupe por la calidad de sus entregables, y una mentalidad hands-on. ¿QUÉ NOS HACE ESPECIALES? •       Incorporación inmediata con contrato indefinido •       Ofrecemos horario flexible (puedes entrar de 8 a 9.30 y salir de 17 a 18.30) con jornada intensiva todos los viernes (puedes entrar de 8 a 9 y salir de 14 a 15) y la mayoría de las vigilias de festivos •       Posibilidad de teletrabajo del 50%  en nuestra sede central en Palau-Solità i Plegamans •       25% de descuento en todas nuestras líneas •       Te podrás formar a nivel técnico en plataformas como O'Reilly, Udemy, Codely, entre otras, así como en idiomas, y en habilidades para tu desarrollo personal. Te acompañamos para que sigas creciendo a nivel profesional y personal! •       Política de referrals, podrás participar en la incorporación de talento a nuestros equipos, ¡y te recompensaremos por ello! •       Transporte gratuito de empresa desde Barcelona y el Vallès para llegar a nuestras oficinas centrales •       Servicio de fisioterapia en las oficinas centrales, así como sala de fitness y vestuarios por si te gusta hacer deporte en tu tiempo libre •       Workshops, meetups, comunidades de prácticas, team buildings y company meetings •       Paquete de retribución flexible con ventajas fiscales: seguro médico, formación, descuento comedor, guarderías etc •       Servicio de comedor y cocina en las instalaciones de la central. La empresa subvenciona parte del menú diario así como los artículos de cafetería. •       Servicio médico propio en las instalaciones de la central. •       Formarás parte de una empresa líder en el sector de la moda, dinámica, en plena innovación, con gran concienciación y realizando acciones hacia la sostenibilidad •       Ambiente de trabajo cercano, inspirador y ambicioso , trabajarás con un gran equipo que va en la misma dirección para conseguir los mejores resultados •       Oportunidades constantes de desarrollo con retos muy variados que generan aprendizaje en el puesto de trabajo Información adicional    Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description Visa Consulting and Analytics (VCA), the consulting arm of Visa, is a global team of industry experts in strategy, marketing, operations, risk and economics consulting, with decades of experience in the payments industry. Our VCA teams offers: Consulting services customized to the needs of Visa client's business objectives and strategy Business and economic insights and perspectives that impact business and investment decisions Self-service digital solutions Visa clients can leverage to improve performance in product, marketing and operations Proven data-driven marketing strategies to increase clients' ROI VCA team is looking for a passionate individual to join our consulting practice and play a role in the data engineering team. The ideal candidate is adept at using big data sets to understand our client's challenges and deploy targeted solutions to drive meaningful benefits, leveraging our world-class payment knowledge, in combination with our diverse service offerings to address key strategic needs for Visa's clients including issuers, acquirers and merchants. He/She must have experience using a variety of data mining/data analysis methods, using a variety of distributed data platforms, and leveraging the latest open-source technologies. He/She must have a proven ability to drive business results with their data-based insights. Adept at creative and critical thinking, be able to deconstruct problems and transform insights into large scale, state-of-the-art solutions. Responsibilities Automate and standardize data processes developed by team members. Leverage DevOps to create end-to-end streamline CI/CD data and ML pipelines. Review and manage data pipelines, branching, and deployment process. Work with partners on requirements and implementation designs of data solutions. Implement data quality framework at scale using open-source technologies. Create data monitoring dashboards with real-time notifications. Understand VisaNet data and platform ecosystem to deploy fully automatic data applications for internal and external clients. Unify data engineering and machine learning engineering pipelines. Apply spark optimization techniques to production jobs to accelerate data prep. Document process, designs, test results, and analysis. Ability to articulate complex architectures to non-technical audiences, management, and leadership. Continuously research industry best practices and technologies. Evangelize end to end automation and standardization across the organization. Partner with functional areas, and regional and global teams to leverage the breadth and depth of Visa’s resources. This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs. Qualifications Basic Qualifications  • BA/BS required, MBA or other relevant Master’s degree preferred (e.g. engineering, computer science, computer engineering, applied mathematics, or other related fields)  Preferred Qualifications  • At least 5 years of experience as data engineer or data scientist with open-source tools. • Experience in retail banking, payments, financial services, and/or technology industries is a plus. Strong interest in the future of payments is a must. • Strong technical competency and experience with shell-scripting and Linux systems. • Experience with CI/CD pipeline using Azure DevOps, GitHub actions, Jenkins, or Airflow. • Strong coding skills in Spark, Python and SQL to manipulate big data in distributed platforms. • Good to have experience in navigating in Linux/Unix/Container based apps such as Docker, Kubernetes, or Microservices environments. • Knowledge in how to leverage AI assistance tools like chatGPT for creating and debugging code. • Ability to interact with big data clusters using Jupiter Notebooks, terminal, or GUI. • Demonstrate experience leveraging open-source tools, libraries, and platforms. • Experience with data visualization and business intelligence tools like Tableau, PowerBI, Microstrategy, or Excel. • Problem solving ability and process creator with strategic focus on replicability, scalability, innovation, and governance. • Proficient with git for version control and code collaboration using branches and pull requests. • Must be passionate about automation and data and able to deliver high quality work. • Experience developing as part of Agile/Scrum team. • Fluency in English (spoken/written). Portuguese or Spanish is a plus. • Experience in developing integrated cloud applications with services like AWS, Azure Cloud, and GCP is a plus. Additional Information Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. Company Description Ocorian is a global leader in corporate and fiduciary services, fund administration and capital markets. Wherever our clients hold financial interests, or however they are structured, we provide compliant, tailored solutions that are individual to their needs. We manage over 17,000 structures for 8000+ clients with a global footprint operating from 18 locations. Our scale offers all our people great opportunities to develop their knowledge and skills and to progress their careers. Job Description Purpose of the job To assist in the development of business intelligence and management information solutions for Ocorian taking information from the financial, HR, corporate administration systems, and Cloud-based solutions to create a reporting base for the business, the single source of truth Delivery of key dashboards and reporting requirements from the BI/MI solutions with appropriate robust security models Assist with data cleansing and data loading exercises, which may extend to jurisdictional and regulatory filing requirements Documentation of solutions, handover to BAU Teams, and supporting solutions Prior experience of creating/supporting ETL, data warehouses and Tabular data models. Ocorian utilises Microsoft SQL Server technologies, including SSIS, SSAS, SSRS and Power BI and the successful candidate should have delivered projects using aspects of this technology stack in recent times The individual will be expected to work across all levels of the Business to liaise with key stakeholders to ensure the design, development and documentation meets the requirements of the Business. The role will work extensively with IT functions and the role may be matrix-managed when required with tasks assigned by the BAU BI Team Main Rresponsibilities Design and implement data warehouse solutions and Tabular data models Develop dashboards and reporting to meet business reporting needs Deliver approved projects within timeframe Provide regular updates to management Make recommendations for potential improvement or changes Promote the use of core systems for data capture aligned to standards and initiatives Qualifications Technical Skills SQL Server 2016 onwards SQL Server BI stack – SSAS / SSIS / SSRS Microsoft Power BI Experience of data cleansing tools and methodologies Businesss Skills Demonstrated ability to apply IT in solving business problems Good written, oral, and interpersonal communication skills Ability to present ideas in business-friendly and user-friendly language Highly self-motivated, proactive and attentive to detail Ability to effectively prioritise and execute tasks in a high-pressure environment Extensive experience working in a team-oriented, collaborative multi-jurisdictional environment Experience of working in project teams with mixed skillsets and levels of technical knowledge Energy and enthusiasm to support the future growth and success of the business Additional Information All staff are expected to embody our core values that underpin everything that we do and that reflect the skills and behaviours we all need to be successful.  These are: We are AMBITIOUS - We think and act globally, seizing every opportunity to support our clients and staff - wherever in the world they may be. We are AGILE - Our independence from any financial institution gives us the flexibility and freedom to keep things simple, efficient and effective. We are COLLABORATIVE - We take the time to understand our clients' needs so that we can deliver personalised solutions every time. Company Description Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and our environment safer, healthier and more sustainable. From the food you eat, to the water you drink, to the medicines you rely on, Eurofins laboratories work with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic, and labelling is accurate. The Eurofins network of companies is the global leader in food, environment, pharmaceutical and cosmetic product testing and in agro-science Contract Research Organization services. It is one of the market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, advanced material sciences and in the support of clinical studies, as well as having an emerging global presence in Contract Development and Manufacturing Organizations. It also has a rapidly developing presence in highly specialized and molecular clinical diagnostic testing and in-vitro diagnostic products. In over 30 years, Eurofins has grown from one laboratory in Nantes, France to 58,000 staff across a decentralized and entrepreneurial network of 900 laboratories in over 54 countries. Eurofins companies offer a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products. In 2021, Eurofins generated total revenues of EUR 6.72 billion, and has been among the best performing stocks in Europe over the past 20 years. Job Description Job Summary:  Eurofins is looking for a PowerBI Developer to be take responsibility for developing and maintaining meaningful monthly, quarterly and annual reporting metrics for an Americas IT Infrastructure Support Team. This involves aggregating data from multiple sources, including but not limited to ServiceNow, MS Endpoint Configuration Manager, and Security/Vulnerability databases, and translating that data it into reports and visuals to drive key operational decisions.  Roles & Responsibilities:  Understand business requirements and translate them into a Power BI context  Create dashboards and interactive visual reports using Power BI  Identify, prepare, monitor and analyze KPI’s used to aid business decision-making  In lieu of automated PowerBI reporting being available, build reports and KPI’s manually using Excel or other available tools  Design, develop, test, and deploy Power BI scripts and perform detailed analytics  Perform DAX (data analysis expressions) queries and functions in Power BI  Analyze current ETL (extract and transform load) process, define and design new systems  Influence technical/strategic changes to enhance existing Business Intelligence systems    Qualifications Technical Requirements: 3+ years of work experience in: PowerBI development in an IT Service setting  Microsoft SQL queries, database management, modeling, warehousing and business intelligence. Aggregating and correlating large datasets into actionable reporting Advanced English level Desired: SSRS, SSIS knowledge. ITSM/PM experience  Soft skills:  Flexible Self-motivated Proactive Company Description At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.  With more than 7,400+ customers, we serve approximately 80% of the Fortune 500, and we're proud to be one of FORTUNE's 100 Best Companies to Work For® and World's Most Admired Companies® 2022. Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow. Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates. Job Description You will be part of the ServiceNow Cloud Services Big Data Team.  The Big Data team is building the next-generation platform that collects, stores and provides real-time access to large amounts of data. You will be driving the design and implementation of ServiceNow in-house real-time data visualization and analytics platform to support the growth of ServiceNow. What you get to do in this role: Bring your innovation and experience in designing and developing the next generation data analytics platform using cutting-edge technologies.  Lead a global engineering team to drive end to end product design and implementation.  Standardize processes for complete development cycle including design, implementation, unit testing, code review, testing automation etc.  Research and adopt the right technologies to improve the scalability and productivity of the engineering group.  Work closely with key stakeholders and product owners to drive technical design for requirements of various use cases.  Coordinate with cross-function teams (DevOps, network, QA, etc.) to ensure a smooth cycle from development to deployment. Qualifications To be successful in this role you have: Hands-on experience architecting enterprise data analytics products with high scalability and performance. 6+ years of software development experience along with strong troubleshooting and debugging skills. Expert level skills with JavaScript, NodeJS, Webpack, ReactJS or other modern UI frameworks, Java and REST API developments. Background with data analytics, data visualization, BI tools and Hadoop ecosystem. Ability to produce high-quality software that is unit tested, code reviewed, and checked in regularly for continuous integration. Solid background in complicated SQL & data analytics. Zeal for learning and adopting new ideas and patterns. Strong Computer Science fundamentals,  data structures, algorithms, and software design. For positions in California (outside of the Bay Area), we offer a base pay of $136,800 - 239,400, plus equity (when applicable), variable/incentive compensation and benefits. Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. Please note that the base pay shown is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location. We also offer health plans, including flexible spending accounts, a 401(k) Plan with company match, ESPP, matching donations, a flexible time away plan and family leave programs.  Compensation is based on the geographic location in which the role is located, and is subject to change based on work location. For individuals who will be working in the Bay Area, there is a pay enhancement for positions located in that geographical area; please contact your recruiter for additional information. Additional Information ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law. At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office. If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance. For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government. Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.   From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license. Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow. GumGum is a contextual-first, global digital advertising platform that uses advanced AI  technology to serve captivating creative ads that drive consumer attention, without the use of personal data. At GumGum, we don’t need to know who you are to deliver relevant and engaging ads that align with your active frame of mind. We believe that a digital advertising industry based on context rather than personal data builds a more equitable and less invasive future for the internet and is better for consumers, publishers and advertisers alike. Our blueprint for the future, The Mindset Matrix™, combines the power of context and creative in digital advertising to deliver superior attention and drive consumer action without sacrificing personal data.  To be a part of this next phase of digital advertising that prioritizes data privacy, please visit www.gumgum.com/careers The BI Developer is responsible for working on our Looker BI platform to drive near real-time data analytics solutions which then supports our internal stakeholders. This role has a core focus on identifying essential reports in Looker for the advertising business.  Reporting to our Data Engineering Manager, the BI Developer will work as part of a team of engineers in the technology division of our advertising business. Note: GumGum currently operates in a ‘work from home’ virtual environment with sporadic opportunities for in-person business and morale events (health guidelines permitting). There will not be any requirement to go into the office on a daily basis moving forward.  What You'll Achieve Build and maintain our big data BI platform with Snowflake and Looker Develop data products that offer new and emerging business insights Contribute to our self-serve data products that serve hundreds of global users Work with stakeholders in various departments to fully understand the business requirements and translate them into database query models and data analytics. Create and manage BI Access controls for users with row level, column level and report level security Perform data analysis, discovery, profiling and work with the Data Engineering team to identify and resolve data related issues. Establish governance processes around metadata to ensure data integration, accuracy, validity, and reusability. Skills You'll Bring Minimum Bachelor's degree in Computer Science, Engineering, or a related technical field 1+ year experience building and managing complex BI platforms 1+ year experience with data modeling 1+ year experience in data analytics and reporting 1+ year experience working with product squads Very strong with SQL  Deep technical understanding of at least one BI platform tool (Looker, PowerBI, or Tableau) Strong communications skills and a "customer service attitude" Very strong problem solving skills - they should strive to find the root of the problem rather than designing band-aids Enthusiasm for exploring new technologies Someone who enjoys working remotely as part of a geographically dispersed team Cool, calm and collected attitude Benefits & Perks Medical, Dental and Vision Coverage including 100% premium coverage for employee + spouse/family  Life Insurance, AD&D and TPD Retirement contributions Short-Term Disability and Short-Term Sickness Work From Home and Wellness Stipend Initial 12 Days PTO of vacation with 1 additional day per year up to a cap of 15 days + 5 sick day Employee Assistance Program  GumGum Gives Back volunteering/social impact opportunities Virtual and in-person company events/celebrations Anniversary recognition and awards Modern Family Support and Resources Awards BuiltIn #37 Best Places to Work 2023 across the United States BuiltinLA #7 Best Places to Work 2022 BuiltinLA Best Places to Work 2021 Ad Exchanger Programmatic Power Player 2022 and 2021 Digiday Media Awards Europe finalist 2022 and 2021 GumGum is proud to be an equal opportunity employer. At GumGum, we believe in cultivating an environment where our team members can bring their authentic, whole selves to work. Encouraging identity and belonging is one of the many aspects of our culture that makes us stronger as an organization and drives innovation. We are committed to building and delivering a diverse, inclusive, and equitable workforce that is representative of the world around us, where all individuals are treated with respect and dignity - and to act swiftly if this value is ever threatened. We are constantly striving to be better, and we continue to take strategic steps to advance representation. - Phil Schraeder, CEO Learn more about our DEIB programming at gumgum.com/deib Follow us on our socials... Instagram: @gumgum & @dogsofgumgum LinkedIn: GumGum Tweet us: @gumgum Facebook: GumGum Company Description At Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people’s lives. Our promise to our associates is rock-solid: We grow together, we enjoy our work, and we inspire each other. Welcome to Bosch. The Bosch Power Tools GmbH  is looking forward to your application! Job Description The team market & competitive intelligence owns the global responsibility for the contents and processes of the business development pillars market, competition & trends Your task mainly evolves around business intelligence in the fields of market & competition, for which you are in close interaction with global internal & external stakeholders Your biggest topics within the area of business intelligence: You actively drive our team target to develop our contents and data to intelligence Responsibility for all data science & intelligence projects evolving around market & competition Development and implementationg of AI & machine-based forecasting models (in close collaboration with your teammates The second pillar of your responsibilities lies within market intelligence: Responsibility for certain sub-markets for an even better understanding of the contents behind the data science projects Coordination of sub-market estimates in close collaboration with the business units, country responsibilities & further internal stakeholders Qualifications Education: Master degree in the field of business informatics or similar Personality: Analytical, structured & independent way of working. Team spirit & strong communication skills Working Practice: Relevant experience in data science, business intelligence and data visualization. Ideally: experience in market intelligence & knowledge about the relevant competitive landscape Experience and Knowledge: Profound knowledge in business intelligence & data science/visualization/modeling. Experienced in handling data analytics tools (i.e. Power BI) Languages: Business fluent in German & English Additional Information You want to work remotely or part-time - we offer great opportunities for mobile working as well as different part-time models or job-sharing. Feel free to contact us. Diversity and inclusion are not just trends for us but are firmly anchored in our corporate culture. Therefore, we welcome all applications, regardless of gender, age, disability, religion, ethnic origin or sexual identity. Need support during your application? Julia Schöffler (Human Resources) +49 711 758 4261 Need further information about the job? Andreas Leinfelder (Functional Department)   Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value. Job Description As Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects: Data Ingestion, Transformation & Consumption, Data Storage and Computation Frameworks, Performance Optimizations, Infrastructure, Automation & Cloud Computing, Data Governance & Security The role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java / Scala / Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. Role & Responsibilities: 1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation. 2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality 3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality 4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies 5. Participate in workshops with clients and align client stakeholders to optimal solutions. 6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc. 7. People management, contributing to hiring and capability building #LI-REMOTE  Qualifications Overall 8+ years of IT experience with 3+ years in Data related technologies  3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS / Azure / GCP) and delivered at least 1 project as an architect. Mandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud.  Expert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions Expert in programming languages like Java/ Scala and good to have Python Expert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc. Expert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc. Should have worked on MPP style query engines like Impala , Presto, Athena, etc Should have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc. Should have a good understanding of how to set up Big data cluster security – Authorization/ Authentication, Security for data at rest, and data in Transit. Should have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager – Data Engineering Should have worked on any of Orchestration tools – Oozie, Airflow, Ctr-M, or similar. Worked on Performance Tuning, Optimization, and Data security   Competency 1. Excellent understanding of data technologies landscape/ecosystem. 2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases 3. Good Exposure in development with CI / CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage. 4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models 5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage. 6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions 7. Thought Leadership – blogs, keynote sessions, POV/POC, hackathon 8. Certification in either one of the cloud platforms or big data technologies Personal Attributes: Strong analytical and problem-solving skills Strong communication skills in verbal, written and visual presentations Strong coordination and negotiation skills Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Multi geo experience and distributed delivery experience in large programs Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements  Employee Assistance Programs to help you in wellness and well being As a BI Engineer at Lalamove, you will be part of the growing BI & Analytics Team, which supports different functional departments in the functional office, as well as our operation offices across the globe. You will be writing and maintaining our data pipelines, reporting scripts and queries. You will be designing and creating visualisations, reports, metrics dashboards and data sources to empower different teams so that they can make informed decisions with the support of analytics. What we seek: Quick learner: you enjoy working with data and you have the ability to learn new technology and frameworks quickly Problem solver: you have strong critical thinking skills, willing to find creative solutions to difficult problems and work smart before hard High autonomy: self-organized, initiator, passionate with a can-do attitude and own end-to-end projects Team player: you go the extra mile to ensure success and alignment of all parties involved Communicative: you have the ability to elaborate complex technical concepts and collaborate effectively with fellow teammates and stakeholders What you'll need: At least 3 years of work experience in a business intelligence or data analysis role Experience working with complex datasets and ability to write efficient SQL queries against Hive and MySQL is a MUST Knowledge of data pipeline, ETL/ELT, workflow management and data warehousing Experience using business intelligence platforms for data visualisation, creating and automating dashboards, reports and data sources. Tableau is preferable Experience scripting Python for data manipulation, analysis and automation Good command of English for communicating technical ideas both orally and in writing   To all candidates- Lalamove respects your privacy and is committed to protecting your personal data.This Notice will inform you how we will use your personal data, explain your privacy rights and the protection you have by the law when you apply to join us. Please take time to read and understand this Notice. Candidate Privacy Notice: https://www.lalamove.com/en-hk/candidate-privacy-notice Company Description Vuori is re-defining what athletic apparel looks like: built to move and sweat in but designed with a casual aesthetic to transition into everyday life. We draw inspiration from an active coastal California lifestyle; an integration of fitness, creative expression and life. Our high energy fast paced office environment is reflected in the clothes we make. We aim to inspire others to take on all aspects of their lives with clarity, enthusiasm and purpose…while having a lot of fun along the way. We are proud to be an outlet for opportunity and for personal growth and success. Job Description The Senior BI Analyst will provide timely and professional onsite and remote support to Vuori Staff and partners in both a growing office and retail brick ‘n’ mortar Omni-Channel eco-system. Primary duties include working with key department stakeholders on validating source and end point data views, defining report/analytics requirements and specifications, teaming up with the tech Product Managers and business users, building workflow and data profiling exercises to ensure full transparency of data integrity, definitions, cadence, and exceptions. This position will be the hub for analytic/reports requirements as well as backend data requirements/needs. They are responsible for answering queries and addressing data and analytic/reports issues in a timely and professional manner. Responsibilities include, but are not limited to: Working alongside the Product Manager, develop report specific details and specifications from high level scope at the reporting level, adjusting course as necessary and communicating changes to requisite audiences. Build reports in PowerBI, DOMO(visualization tool) and other analyst/reporting tools, using the requirements and specifications derived from the requirements gathering exercises. With a high level of communicative expertise, represent and translate the “story of the numbers” via visualizations, graphs, dashboards, commentary, etc., appropriate to the audience and nature of the request. Working with systems and data engineers, source existing data to develop reports, or, in the event of nonexistent data, identify root source systems in which necessary data resides. Work with Data Governance manager to maintain knowledge base/foundation of KPI/Metric/Report definitions, intentions, and access. Manage relationships and time between projects and product owners while effectively communicating progress, obstacles, change of course, etc., as dictated by reporting dependencies and needs of business. Oversee and administer BI & Analytics tool/platform capabilities. Make technological adjustments to BI & Analytics tool/platforms to improve their performance. Develop algorithms and models to mine large data sets. Use statistical analysis to identify patterns, correlations, and actionable results. Qualifications A four-year technical degree or equivalent work experience is preferred. 7 or more years building and maintaining dashboards, analyses, reports, etc. High degree of proficiency with Power BI, including administration. Background with other BI tools and systems such as DOMO, Tableau, and Looker. Fundamental understanding of systems and data architecture. Strong SQL programming skills, including the use of SQL analytic functions and stored procedure development and maintenance. Strong excel experience (sumif, offset, vlookup, pivot tables). Exposure to analytics tools (Alteryx, SAS, etc.). Love for data and data storytelling. Proficient and knowledgeable on the systems and processes required to achieve consistently high customer satisfaction. Comfortable working in a matrixed organization involving cross-functional projects; strong communication and collaboration skills. Excellent organizational skills to manage priorities. Well organized, adaptable, and a clear thinker. Additional Information Pay Range: From $135,000 - $160,000 annually Benefits: Health Insurance Paid Time Off Employee Discount 401(k) All your information will be kept confidential according to EEO guidelines. Company Description TeamViewer is a leading global technology company that provides a cutting-edge platform to remotely access, control and support devices of any kind. Our software solutions empower our users and customers to bridge distances and digitalize their processes through seamless connectivity. Our team is committed to quality and passionately leading the way in the fields of Augmented Reality, Internet of Things and Artificial Intelligence. With over 1.400 employees from more than 80 nationalities in 20+ locations worldwide, we are one global family. We believe that bringing together people from different backgrounds and experiences leads to better, more innovative solutions. One of the keys to our success is our culture, which enables employees to learn, grow, and contribute in meaningful ways. Are you courageous and want to make an impact? Then join our winning team and help us create a world that works better. Job Description Join our Reporting and Analytics team and help us create transparency and actionable insights in a global innovative environment where more than 600,000 customers use products with more than 2.5 billion installations  Build analyses and insightful reports on financial, sales, marketing, product and operational topics Work closely with our Data Engineers in defining data models and enriching existing data Proactively support internal stakeholders on utilizing our data and defining meaningful KPIs Maintain and improve our existing reporting portfolio Optimize flows and processes in the Data Warehouse to work with large amounts of data of a product which has millions of users all over the world Manage our internal backlog and actively prioritize based on business impact Qualifications University or college degree in Computer Science, Mathematics, Statistics, Information Systems or any other related subject At least 3 years of relevant professional experience in the field of Business Intelligence and Analytics Advanced knowledge of SQL and BI tools (e.g. Tableau, Power BI or QlikView) Apache-Airflow, DBT and Docker expertise are beneficial Background in working with AWS or Google cloud solutions is an advantage Excellent grasp of business contexts / processes and a basic understanding of agile development methods Analytical skills, and the ability to work both independently and as part of a team Fluency in English is mandatory, further languages such as German are a plus Additional Information Onsite Onboarding in our HQ office for an optimal start Great compensation and benefits packages including company achievement bonus and stock-based options, regular salary reviews Access to Corporate Benefits platform with many discounts Regular Team events and company-wide celebrations Open door policy, no dress code rules, frequent all Hands and Leadership Lunches Work From Abroad Program allowing up to 40 days of work outside your contracting country We celebrate diversity as one of core values, join and drive one of the c-a-r-e initiatives together with us! TeamViewer is an equal opportunities employer and is committed to building an inclusive culture where everyone feels welcome and supported. We C-A-R-E and understand that our diverse, values-driven culture makes us stronger. As we continue to grow as a company, we also focus on enabling our employees to grow both personally and professionally. We are proud to have an open and embracing workplace environment that will empower you to be your best no matter your gender, civil or family status, sexual orientation, religion, age, disability, education level, or race. About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Overview: The Agoda Content department is currently looking for a curious and questioning self-starter and proactive analyst, who will help drive decision making with insights from content, marketing and partner performance data. You will get the opportunity to own analytical projects to direct our department’s focus, and prioritize our actions. By joining Agoda, you will become part of a truly international team, with leading experts of different backgrounds coming from 50+ countries around the world. This is a genuine opportunity to gain valuable experience in a challenging and cutting-edge tech environment. The ideal candidate would have a passion for high-converting content, great user-experience, data and analysis tools and methods. This position reports to the Associate Director of Content Operations, in Bangkok, Thailand.   Main responsibilities: Understand Content goals and KPIs and be able to align reports and insights based on them. Identify and investigate trends, anomalies and opportunities to improve Agoda’s Content strategy. Identify content opportunities that drive customer value, bookings and conversion Help build business cases around the opportunity and get buy-in from stakeholders Ensure appropriate data/tools/dashboards to measure execution and enable deeper analysis Track execution and report up in regular updates Work with product, data/BI team and IT to create data resources and build appropriate reporting Work with Content team leads to understand their business needs and identify opportunities in terms of team actions prioritization and focus. Use multiple data sources to report Content projects insights and impact; support Content tests and experiments. Encourage and train the Content team in best practice use of Agoda data, analysis techniques and interpretation. Coordinate with other Cross Functional departments like Analytics, Partner Services, and Product Owners Use Web-Analytics for Research and Analysis Requirements: Bachelor degree or higher 2+ years of relevant experience Experience / knowledge in statistics, SQL, Python/R, Tableau and advanced Excel – required Ability to demonstrate data manipulation using data warehouse and create meaningful insight and visualization Experience / knowledge in Vertica and / or Impala – advantage Experience in generating data and / or preparing experiments for product development – advantage Professional characteristics: Attentive to detail and committed to data integrity Keen and curious nature; able and willing to share your opinion Organized; able to manage multiple, competing priorities and deliver results under tight deadlines Able to communicate effectively; fluent in English – both spoken and written #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to Know our Team:  Partner Development is a team of creative entrepreneurs that develop solutions for Agoda’s accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. In this role you'll get to As a Data Analyst in the PD Analytics team, you will be using data and modeling techniques to identify opportunities and build models and tools to improve efficiency and effectiveness for Agoda's supply team.  Key activities involved include but not limit to: Apply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations Own end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development Build dashboards, identify new and track key metrics to closely monitor team’s performance and identify quick and long term opportunities for improvements Work closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified Support global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization What you'll need to succeed  Bachelor’s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline 3-6 years experience working in a business analysis, data analysis, reporting or business strategy role Excellent problem-solving skills including the ability to analyze and resolve complex problems using data Team player with strong interpersonal, relationship-building, and stakeholder management skills Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala) Data visualization tool experience such as with Tableau or your weapon of choice. Ability to work under pressure in a fast-paced and rapidly changing environment Excellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value. Job Description As Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects: Data Ingestion, Transformation & Consumption, Data Storage and Computation Frameworks, Performance Optimizations, Infrastructure, Automation & Cloud Computing, Data Governance & Security The role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java / Scala / Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. Role & Responsibilities: 1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation. 2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality 3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality 4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies 5. Participate in workshops with clients and align client stakeholders to optimal solutions. 6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc. 7. People management, contributing to hiring and capability building #LI-REMOTE  Qualifications Overall 8+ years of IT experience with 3+ years in Data related technologies  3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS / Azure / GCP) and delivered at least 1 project as an architect. Mandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud.  Expert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions Expert in programming languages like Java/ Scala and good to have Python Expert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc. Expert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc. Should have worked on MPP style query engines like Impala , Presto, Athena, etc Should have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc. Should have a good understanding of how to set up Big data cluster security – Authorization/ Authentication, Security for data at rest, and data in Transit. Should have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager – Data Engineering Should have worked on any of Orchestration tools – Oozie, Airflow, Ctr-M, or similar. Worked on Performance Tuning, Optimization, and Data security   Competency 1. Excellent understanding of data technologies landscape/ecosystem. 2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases 3. Good Exposure in development with CI / CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage. 4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models 5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage. 6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions 7. Thought Leadership – blogs, keynote sessions, POV/POC, hackathon 8. Certification in either one of the cloud platforms or big data technologies Personal Attributes: Strong analytical and problem-solving skills Strong communication skills in verbal, written and visual presentations Strong coordination and negotiation skills Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Multi geo experience and distributed delivery experience in large programs Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements  Employee Assistance Programs to help you in wellness and well being Company Description Experian is the world’s leading global information services company. During life’s big moments — from buying a home or a car to sending a child to college to growing a business by connecting with new customers — we empower consumers and our clients to manage their data with confidence. We help individuals to take financial control and access financial services, businesses to make smarter decisions and thrive, lenders to lend more responsibly, and organizations to prevent identity fraud and crime. We have 17,800 people operating across 44 countries, and every day we’re investing in new technologies, talented people and innovation to help all our clients maximize every opportunity. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index. Learn more at www.experianplc.com or visit our global content hub at our global news blog for the latest news and insights from the Group Experian is the world’s leading global information services company. During life’s big moments — from buying a home or a car to sending a child to college to growing a business by connecting with new customers — we empower consumers and our clients to manage their data with confidence. We help individuals to take financial control and access financial services, businesses to make smarter decisions and thrive, lenders to lend more responsibly, and organizations to prevent identity fraud and crime. We have 17,800 people operating across 44 countries, and every day we’re investing in new technologies, talented people and innovation to help all our clients maximize every opportunity. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index. Learn more at www.experianplc.com or visit our global content hub at our global news blog for the latest news and insights from the Group Job Description  As a key aide to both the IT Infrastructure and Development teams, you will help support existing systems 24x7 and responsible for administering current Big Data environments.  The candidate will be responsible for managing BigData Cluster environments and will work with teammates to maintain, optimize, develop, and integrate working solutions for our big data tech stack. To support the product development process in line with the product roadmap for product maintenance and enhancement such that the quality of software deliverables maintains excellent customer relationships and increases the customer base.    If you have the skills and “can do” attitude, we would love to talk to you!   What you’ll be doing   Responsible for implementation and ongoing administration of Hadoop infrastructure  Aligning with the systems engineering team to propose and deploy new hardware and software environments required for Hadoop and to expand existing environments  Expert knowledge with delivering Big Data Cloudera Solutions in the cloud with AWS.  Deliver innovative CI/CD solutions using the most cutting-edge technology stack.  Automating infrastructure and Big Data technologies deployment, build and configuration using DevOps tools.  Hands-on day-to-day expert experience in administering a Cloudera cluster with Cloudera Manager, Cloudera Director, Cloudera Navigator  Working with data delivery teams to setup new Hadoop users. This job includes setting up Linux users, setting up Kerberos principals and testing HDFS, Hive, HBase and Yarn access for the new users  Cluster maintenance as well as creation and removal of nodes using tools like Cloudera Manager Enterprise, etc.  Performance tuning of Hadoop clusters and Hadoop MapReduce routines  Screen Hadoop cluster job performances and capacity planning  Monitor Hadoop cluster connectivity and security  Manage and review Hadoop log files, File system management and monitoring  HDFS support and maintenance  Diligently teaming with the infrastructure, network, database, application and business intelligence teams to guarantee high data quality and availability  Collaborating with application teams to perform Hadoop updates, patches, version upgrades when required  General operational expertise such as good troubleshooting skills, understanding of system’s capacity, bottlenecks, basics of memory, CPU, OS, storage, and networks  The most essential requirements are: They should be able to deploy Hadoop cluster, add and remove nodes, keep track of jobs, monitor critical parts of the cluster, configure name-node high availability, schedule and configure it and take backups  Solid Understanding on premise and Cloud network architectures  Additional Hadoop skills like Sentry, Spark, Kafka, Oozie, etc  Advanced experience with AD/LDAP security integration with Cloudera, including Sentry and ACL configurations  Ability to configure and support API and OpenSource integrations  Experience working with DevOps environment, developing solutions utilizing Ansible, etc.  Will collaborate and communication with all levels of technical and senior business management  Will require on-call 24X7 support of production systems on a rotation basis with other team members  Pro-actively evaluate evolving technologies and recommend solutions to business problems.   Qualifications Typically requires a bachelor's degree (in Computer Science or related field) or equivalent.  3+ years of Linux (Redhat) system administration  3+ years of Hadoop infrastructure administration  Cloud Platforms IaaS/PaaS – Cloud solutions: AWS, Azure, VMWare  Kerberos administration skills  Experience with Cloudera distribution  Good have knowledge on open-source configuration management and deployment tools such as Puppet or Chef and Shell scripting  Must have knowledge on DevOps tools like Ansible and HAProxy. Automating deployments and monitoring/alerting tasks using Ansible.  Advantage if working knowledge on terraform  Working Knowledge of YARN, HBase, Hive, Spark, Flume, Kafka etc.  Strong Problem Solving and creative thinking skills  Effective oral and written communications  Experience working with geographically distributed teams  Bachelors or master’s degree in Computer Science or equivalent experience  Knowledge and understanding of the business strategy and use of back-office applications.  Ability to adapt to multi-lingual and multicultural environment, additional language skills are a bonus.  Ability to handle conflicting priorities.  Ability to learn.  Adaptability.  Receptive to change.  Ability to communicate with business users at all levels  Analytical skills  Self-motivated and pro  Additional Information Experian Careers - Creating a better tomorrow together Find out what its like to work for Experian by clicking here As a Solutions Architect (Analytics, AI, Big Data, Public Cloud), you will guide the technical evaluation phase in a hands-on environment throughout the sales process. You will be a technical advisor internally to the sales team, and work with the product team as an advocate of your customers in the field. You will help our customers to achieve tangible data-driven outcomes through the use of our Databricks Lakehouse Platform, helping data teams complete projects and integrate our platform into their enterprise Ecosystem. You'll grow as a leader in your field, while finding solutions to our customers' biggest challenges in big data, analytics, data engineering and data science problems. You will report to the Solutions Architect Manager. The impact you will have: You will be a Big Data Analytics expert on aspects of architecture and design Lead your clients through evaluating and adopting Databricks including hands-on Spark programming and integration with the wider cloud ecosystem Support your customers by authoring reference architectures, how-tos, and demo applications Engage with the technical community by leading workshops, seminars and meet-ups Together with your Account Executive, you will form successful relationships with clients throughout your assigned territory to provide technical and business value What we look for: Consulting, Pre-sales or post-sales experience working with external clients across a variety of industry markets Understanding of customer-facing pre-sales or consulting role with a core strength in either data engineering or data science advantageous 5+ years of experience demonstrating technical concepts, including demos, presenting and white-boarding 5+ years of experience designing architectures within a public cloud (AWS, Azure or GCP) 5+ years of experience with Big Data technologies, including Spark, AI, Data Science, Data Engineering, Hadoop, Cassandra, and others Coding experience in Python, R, Java, Spark or Scala Benefits : Private medical insurance Accident coverage Employee's Provident Fund Equity awards Paid parental leave Gym reimbursement Annual personal development fund Work headphones reimbursement Business travel insurance Mental wellness resources About Databricks Databricks is the lakehouse company. More than 7,000 organizations worldwide — including Comcast, Condé Nast, H&M and over 50% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook. Our Commitment to Diversity and Inclusion At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics. About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to Know our Team:  The Supply Analytics team is a team of creative entrepreneurs that develop solutions for Agoda’s non-accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek.  Utilizing our strong brand and resources, we build new channels to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.  The Opportunity:   The role sits within the Supply Analytics team under Central Supply Team, where new business ideas, and partnership types are incubated and scaled. We are looking for a Senior BI Analyst whose main focus areas are providing visibility and insights for people-related issues through Business Intelligence tools like Tableau and SQL, managing data warehouses, building ETL processes, and helping build other tools to optimize the business. This role will be involved in strategic projects and work closely with commercial owners and business stakeholders, using data to identify and translate business needs and opportunities into actionable initiatives. In this Role, you’ll get to: Translate internal briefs into analytical projects (to include refining the initial brief and asking the ‘right questions’, working through potential hypotheses and storyboarding the output) Use and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders. Proactively identify opportunities for growth within supply and the wider business. Drive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply. Identify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence. Automate manual operational processes and present back on time savings gained through modernization of business operations What you’ll Need to Succeed: 4+ years of experience in analytics/data science/insights/strategy. Bachelor’s degree ideally in a business or quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance). 3+ years of experience with BI & analytics tools (SQL, Tableau, Metabase, Data Studio, or similar technologies) 2+ years of solid project management Good stakeholder management experience. Comfortable presenting to senior leadership and C-suite. Strong experience in finding data insights and provide business recommendation to the business A hacker’s mindset – the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping. Excellent communicator with superior written, verbal, presentation and interpersonal communication skills. Data driven in both decision making and performance measurement. Extreme comfort in ambiguous, fast-paced environment. Ability to multi-task, prioritize and coordinate resources. It’s Great if you Have:   Travel industry / e-commerce / tech / consulting experience. Experience in conducting A/B testing experimentation (a plus) A good understanding of statistical modelling knowledge or any machine learning technique knowledge is a plus (regression, logistic regression, random forest, etc.)   #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Company Description At Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people’s lives. Our promise to our associates is rock-solid: we grow together, we enjoy our work, and we inspire each other. Join in and feel the difference.  The Robert Bosch GmbH is looking forward to your application! Job Description During your assignment, you will make Big Data analysis to support fleet validation for Fuel Cell and Vehicles using Azure Databricks as well as Hadoop/PySpark. You will visualize the results with Tableau and work with Version Control. You always keep an eye on the documentation / knowledge management with Docupedia. Take an active role and work in an agile team with international colleagues. Qualifications Education: studies in the field of Engineering Experience and Knowledge: experience in programming (e.g.Python or MATLAB) and data wrangling with PySpark Personality and Working Practice: goal-oriented, reliable personality who can solve tasks independently and enjoys collaborating with different departments at multiple locations Languages: very good in English, German is a plus Additional Information Start: according to prior agreement Duration: 6 months We offer you 35 hours/week with flextime a permanent contact person who will accompany you during your internship a modern working environment, as well as mobile working by arrangement the opportunity to become part of our student network students@bosch Stuttgart discounts in our company restaurants Requirement for this internship is the enrollment at university. Please attach a motivation letter, your CV, transcript of records, enrollment certificate, examination regulations and if indicated a valid work and residence permit. Diversity and inclusion are not just trends for us but are firmly anchored in our corporate culture. Therefore, we welcome all applications, regardless of gender, age, disability, religion, ethnic origin or sexual identity. Need further information about the job? Philipp Reiner (Business Department) +49 711 811 23926 About Rezo TherapeuticsRezo is a different kind of biopharma company.  Our mission is to dramatically increase the success rate of drug development by building a disease-agnostic, fully-integrated, network biology platform that will redefine our understanding of human disease and ability to treat it.   Our Founders and members of the Board are a group of esteemed, world-class scientists from the University of California, San Francisco: Nevan Krogan, Kevan Shokat, Sourav Bandyopadhyay, Natalia Jura, as well as renowned biotech executives George Scangos and Norbert Bischofberger. These leaders bring with them a strong track record of amazing discoveries and scientific breakthroughs, leading to very successful companies and many FDA approved drugs.  Capitalizing on our Series A of $78M from top-tier investors, we are leveraging a unique integrated approach, combining capabilities in genetics, proteomics, structural biology and AI to generate deep biological insights and novel therapeutic approaches. A list of seminal studies leading to our company's formation, published in the journal Science, can be found here. Located in San Francisco’s vibrant Mission Bay neighborhood, Rezo is in close proximity to UCSF, numerous urban amenities, and outdoor recreational opportunities.  We recognize that realizing our mission depends as much on our people as it does on our science and are building a workplace that fosters collaboration, respect, and diversity where contributing to your team’s success is valued as highly as individual achievements.   If you’re passionate about team science and breaking down barriers to progress in drug development, please consider joining us!  The Opportunity We are seeking a highly enthusiastic and motivated Staff Machine Learning Engineer to join the Rezo Computational Biology and AI team.  Becoming a member of this team is an excellent opportunity to join Rezo at an early stage and help build the Computational Biology and AI function and the company from the ground up. What You'll Do: Advise on AI strategy and serve as technical lead for ML-based approaches to integrate large-scale gene and protein interaction datasets to power Rezo’s Sequence to Systems to Drugs (SSD) platform and other core company initiatives (e.g. computational chemistry and protein structure prediction) Operate as an individual contributor initially while building a team of ML and software engineers Design, develop, test, deploy, maintain, and enhance large-scale software solutions Adopt and develop data engineering methodologies including feature identification and integration, data pipelining, feature engineering, data munging, and analysis using methods that can translate from research to production Collaborate across biology and computational biology to develop strategy for platform buildout, systematic platform-driven data generation, data management and mining, and buildout of interfaces and tools Manage and analyze experimental data, interpret results, and prepare necessary materials for internal and external meetings, regulatory filings, and publications Contribute to and balance multiple projects/studies in parallel in a fast-paced environment About You: Ph.D. in computer science or a related technical field plus 4+ years work experience OR B.S in computer science or a related technical field plus 8+ years work experience Demonstrated industry expertise in implementing deep learning algorithms and using deep learning frameworks (e.g. TensorFlow, PyTorch, JAX) Proven track record of scientific excellence as evidenced by a strong publication and/or patent record in the ML field (e.g. NeurIPS, ICML, ICLR, and/or top journals in the sciences) Demonstrated expertise in data analysis including proficiency in programming languages, software best practices, and data structures/algorithms Hands-on experience working on computational biology, systems biology, drug discovery, or computational chemistry datasets, highly desirable Previous experience in graph neural networks, a plus Excellent communication, organizational, and interpersonal skills Strong mentoring skills required, prior management experience is a plus Demonstrated ability helping set scientific direction and priorities for projects Able to own and solve a problem, even if it’s ambiguous Able to partner with peers in different functions and contribute to cross-functional projects with a collaborative attitude Able to work with minimal direction Benefits at RezoMedical (HMO or PPO), dental, and vision insuranceDiscretionary time off policyCompany holidays (including summer and winter shutdown)401(k) retirement savings programCommuter / Mass Transit Benefit ProgramHealthcare Flexible Spending Account (FSA)Dependent care Flexible Spending Account (FSA)Parental leaveCompetitive compensationFlexible work schedule EEOCAt Rezo we value a diverse, equitable, inclusive workplace and provide equal employment opportunity to all persons without regard to race, color, sex, gender identity, gender expression, religion, age, national origin, ancestry, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, genetic information, military or veteran status, or any other basis protected by federal, state or local laws.  This statement covers all facets of employment and is especially important when it comes to growing our team.   If you are wondering if you’ll belong at Rezo, or are worried that you don’t meet 100% of the qualifications for this role, take a chance on us and yourself — please apply! SF Fair Chance OrdinancePursuant to the San Francisco Fair Chance Ordinance, Rezo considers qualified applicants with arrest and conviction records for employment. COVID-19All Rezo employees are required to be fully vaccinated against COVID-19 and to provide proof of vaccination prior to their first day, with limited exceptions.  This policy is grounded in scientific and clinical evidence and has been established with the health and safety of our workplace and community in mind. As a Solutions Architect (Analytics, AI, Big Data, Public Cloud), you will guide the technical evaluation phase in a hands-on environment throughout the sales process. You will be a technical advisor internally to the sales team, and work with the product team as an advocate of your customers in the field. You will help our customers to achieve tangible data-driven outcomes through the use of our Databricks Lakehouse Platform, helping data teams complete projects and integrate our platform into their enterprise Ecosystem. You'll grow as a leader in your field, while finding solutions to our customers' biggest challenges in big data, analytics, data engineering and data science problems. The impact you will have: You will be a Big Data Analytics expert on aspects of architecture and design Lead your clients through evaluating and adopting Databricks including hands-on Spark programming and integration with the wider cloud ecosystem Support your customers by authoring reference architectures, how-tos, and demo applications Engage with the technical community by leading workshops, seminars and meet-ups Together with your Account Executive, you will form successful relationships with clients throughout your assigned territory to provide technical and business value What we look for: Consulting, Pre-sales or post-sales experience working with external clients across a variety of industry markets Understanding of customer-facing pre-sales or consulting role with a core strength in either data engineering or data science advantageous 5+ years of experience demonstrating technical concepts, including demos, presenting and white-boarding 5+ years of experience designing architectures within a public cloud (AWS, Azure or GCP) 5+ years of experience with Big Data technologies, including Spark, AI, Data Science, Data Engineering, Hadoop, Cassandra, and others Hands-on experience in Python, R, Java, Spark or Scala Benefits : Private medical insurance Accident coverage Employee's Provident Fund Equity awards Paid parental leave Gym reimbursement Annual personal development fund Work headphones reimbursement Business travel insurance Mental wellness resources About Databricks Databricks is the lakehouse company. More than 7,000 organizations worldwide — including Comcast, Condé Nast, H&M and over 50% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook. Our Commitment to Diversity and Inclusion At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics. About Us Joining Capco means joining an organisation that is committed to an inclusive working environment where you’re encouraged to #BeYourselfAtWork. We celebrate individuality and recognise that diversity and inclusion, in all forms, is critical to success. It’s important to us that we recruit and develop as diverse a range of talent as we can. We believe that everyone brings something different to the table – so we’d love to know what makes you different.  We are/have: Experts in banking and payments, capital markets and wealth and asset management Deep knowledge in financial services offering, including e.g. Finance, Risk and Compliance, Financial Crime, Core Banking etc. Committed to growing our business and hiring the best talent to help us get there Focused on maintaining our nimble, agile and entrepreneurial culture Capco is looking for hardworking, innovative and creative people to join our Data Analyst Team. We are looking for Data Analyst  to work on all aspects of project delivery engaging a complex stakeholder groups across multiple global regions / product lines to execute global change programs in the Investment Banking domain. This includes business analysis, requirements gathering and documentation, driving technical design and specifications in partnership with IT, functional test strategizing and execution, and user acceptance testing coordination. Must possess strong relationship management skills and be able to manage requirements and testing across Ops and IT teams both cross-division and globally. Role is focused on projects to support the development of regulatory/industry driven changes. Role Description This role provides regulatory data analytics using data from different geography. The primary responsibilities would be: Lead a highly skilled, multi-disciplinary team of consisting of data, analytics, technology and delivery professionals to deliver advanced data and analytics solutions Act as Scrum Master to servant-lead teams to deliver business use cases on a global scale and deploying locally Working closely with data, analytics and technology teams across the business, shape solution designs which meets business needs as well as aligning to the broader strategic Data & Analytics objectives Work directly with various stakeholders across multiple geographies; such as technical discipline leads, data scientists, data engineers and data analysts to produce accurate delivery estimates and manage the transition from analysis to successful delivery Define Agile project working approach and enforce all team members to follow the same methodology Ensure awareness, involvement and support from key stakeholders by building strong pod teams and maintaining robust communications on the project status throughout its lifecycle Ensure risks and issues are identified, managed closely and remove project blockers from the team Make key decisions to ensure the successful implementation of all initiatives Support the delivery production line such as definition, implementation and testing and ensuring deliverables meet business requirements and are fit for purpose Drive all stakeholders to deliver on time and to the required quality standards Ensure cross-team delivery plans exist which represent an achievable commitment based on the capacity of available resource and consideration of internal and external dependencies Lead and work closely with all teams (including virtual teams based in non-UK locations), creating a strong culture of transparency and collaboration Demonstrate a continual desire to implement “strategic” or “optimal” solutions and where possible, avoid workarounds or short term tactical solutions Working with stakeholders to ensure that negative customer and business impacts are avoided Understand all changes in the wider context of the business lines/ areas we support and the programme has an impact, including Regulatory and Global Standards projects Manage stakeholder expectations and ensure that robust communication and escalation mechanisms are in place across the project portfolio Strong self-starter with strong change delivery skills who enjoys the challenge of delivering change within tight deadlines "Knowledge of one or more of the following domains (including market data vendors): o Party/Client o Trade o Settlements o Payments o Instrument and pricing o Market and/or Credit Risk" • Structured and organised leader with strong project management, data and business analysis skills • Ability to manage multiple priorities • Good understanding of the control requirement surrounding data handling will be advantageous in this role • Assess the operational risks as part of the analysis and implementation planning and execution in conjunction with business heads • Experience leading multi-disciplined teams of data, analytics, technology and delivery resources to deliver data and analytics solutions • Experience in agile project methodologies and tools such as JIRA and Confluence • Ability to articulate or translate complex information through clear and meaningful written and spoken communication in a structured way • Ability to develop working relationships with a wide variety of stakeholders, from C-suite to technical resources, balancing competing priorities • Proven skills to lead teams and motivate others to achieve objectives • Preferable knowledge and experience in Data Quality & Governance • Ability to communicate effectively in a multi-programme environment across a range of stakeholders • Relevant Agile Certifications such as Certified Scrum Master, SAFe, LeSS, DAD • Understanding of different analyses options and development of implementable solutions • Highly adaptable and ability to approach things differently in order to achieve goals • Experience of big data and/or cloud programmes preferable WHY JOIN CAPCO? You will work on engaging projects with some of the largest banks in the world, on projects that will transform the financial services industry. We offer: A work culture focused on innovation and creating lasting value for our clients and employees Ongoing learning opportunities to help you acquire new skills or deepen existing expertise A flat, non-hierarchical structure that will enable you to work with senior partners and directly with clients A diverse, inclusive, meritocratic culture   At Beyond Finance, we’ve made it our mission to help everyday Americans escape the endless cycle of crippling debt and step into a brighter financial future. Through compassionate, individualized care, supportive user-centric technology, and customized financial solutions, we’ve helped over 200,000 clients on their path to a debt-free life. While we’re proud of what we’ve already accomplished (over $1 billion in resolved debt), we're searching for new collaborators to help us get to the next level! If you’re looking to join a forward-thinking, rapidly growing organization with helping people as its number one goal, we want to hear from you. About the Role As a Sr. Business Intelligence Engineer  your primary day-to-day tasks will include working with stakeholders and using Looker and Snowflake. You will use this tech stack to deliver business value in the form of: Developing business modeling layer in Looker Looker dashboards Automated data extracts ETL (refining & curating data) The ideal candidate would : Have 2+ years of experience with modern day visualization tools like Tableau, Looker, Qlik Expertise in SQL (3-5 years exp) Excellent communication skills Ability to translate business requirements into technical specifications Ability to simplify complex technical jargon into easy to understand business language Knowledge of data warehousing and modeling concepts Familiar with Github or similar tool for code management Self starter, quick learner, able to juggle multiple priorities and work in a fast paced environment Why Join Us? While you make a difference for others, we’ll work to make a difference for you, providing an uplifting, collaborative work environment and benefits that reflect your value to us. For eligible full-time employees, we offer: Considerable employer contributions for health, dental, and vision programs Hybrid work models Generous PTO, paid holidays, and paid parental leave 401(k) matching program Merit advancement opportunities Career development & training And finally, our team spirit and culture! We cultivate an environment of community, connection, and belonging across our entire organization. Beyond Finance does not accept unsolicited resumes from individual recruiters or third-party recruiting agencies in response to job positions.  No fee will be paid to their parties who submit unsolicited candidates directly to Beyond Finance employees or the Beyond Finance HR team.  No placement fee will be paid to any third party unless such a request has been made by the Beyond HR team. Description de l'entreprise Vous êtes passionné par le digital, la data, l’ioT ou l’IA et souhaitez rejoindre une équipe dynamique et ambitieuse à taille humaine ?   N’attendez plus et rejoignez Talan ! Depuis plus de 15 ans, nous conseillons les entreprises et les administrations et les accompagnons dans la mise en œuvre leurs projets de transformation en Suisse et à l'international.   Pour ce faire, nous nous appuyons à la fois sur le levier technologique et sur la force de notre ADN basé sur l’intelligence collective, l'agilité et le goût d’entreprendre.   Présent sur cinq continents, avec plus de 3 500 collaborateurs notre objectif est de dépasser la barre du milliard d’€ de CA à horizon 2024. L'innovation est au cœur de notre développement et nous intervenons dans les domaines liés aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle. Nos valeurs & terrains de jeu : Intelligence collective Agilité Entreprenariat /Intrapreneuriat Promouvoir la diversité/mixité (Soutient à la Fondation femmes@Numerique...) Engagement (employé, partenaires, écoles, associations...) Respect de l’humain et qualité de vie au travail Ouverture d’esprit et inclusivité    Ensemble, construisons le futur de Talan ! Description du poste Le service DAM (Data Management) du département informatique de notre client recherche un consultant avec le profil d’Architecte Big Data pour nous assister sur divers projets dans l’écosystème Hadoop. Le consultant intégrera l’équipe DAM Modelisation et Administration (DADM) qui a comme rôles entre autres : La gestion des bases de données (DB2, MSSQL, Oracle). La gestion des données dans l’écosystèmes Hadoop. Optimisation des performances. Protection de la donnée Missions : Assistance dans la migration de HDP (HortonWorks data platform) vers CDP et sécurisation de l’accès aux données. Recueil des besoins fonctionnels auprès de diverses équipes. Inventorier la donnée brute (source DB2 Z/os) Modélisation des données à ingérer dans hadoop. Design de la solution et des composants nécessaires. Mise en place de la procédure d’alimentation hadoop avec récupération historique. Support des équipes qui vont consommer la donnée. Sous la responsabilité d'un chef de projet interne Qualifications Expérience d’au moins 5 ans dans un poste d’Architecte Big Data Une connaissance dans le domaine DB2 for Z/os est un avantage Maîtrise des technologies liées au Big Data comme Hadoop & Spark idéalement dans l’écosystème CDP (cloudera data platform) Facilité d’intégration dans une équipe de DBA & Data Scientist Aisance de communication Autonomie dans la réalisation des travaux demandés Langues : français, anglais. Le luxembourgeois est considéré comme un avantage. As an Analyst for Professional Service Operations, you will be focused on providing data analytics on the full operations and P&L support to our global Services team throughout Databricks Services (Professional Services (PS) and Education) business. The focus will be on revenue-driving and forecasting activities across billable projects which includes closing monthly and quarterly accounting, establishing revenue rules, accurate forecasting and reporting, resource assignments, and revenue recognition. You will develop/deploy scalable processes and system logic in collaboration with our Services, Operations, and Finance to support the business. As the connective tissue across the Customer Success organization, you will surface important insights to enhance the customer journey and customer experience. You will report to the Global Operations Manager, Professional Services. With a specific focus on technology, data, and reporting, you will work closely with the PS Operations team and the larger business to aggregate data and facilitate reporting that will drive business decisions and predictability. You will enable the business partners to use and understand reports and data sets, and will have a forward looking approach to support growth of the business and deliver at scale. The impact you will have: You will own all aspects of data and reporting for PS Operations You will drive recurring P&L activities to ensure forecasted vs actual metrics are in line You will develop understanding of the metrics that inform Customer Success and manage the business intelligence layer with the goal of driving insights to actions You will ensure data quality across multiple systems of record and flag areas of continuous improvement You will address questions by the Professional Services leadership team with follow up insights and recommended actions You will prioritize and manage high impact projects across Professional Services What we look for: 3+ year's experience with P&L activities, strong data analytics mindset, using analytical frameworks, data, and tools to help structure team thinking, facilitate understanding across multiple senior partners, and reach applicable answers to challenging and ambiguous problems Salesforce and FinancialForce (Salesforce PSA) experience, specifically in creating reports and report types Strong knowledge in Microsoft Excel or Google Sheets (pivot tables, v-lookup, etc.) Knowledge in SQL and experience in Tableau Salesforce administrator certified is a plus Comfort diving into large, complex datasets with little or no documentation Experience using business systems such as CRM, billing and revenue systems, PS Automation, Order Management and Accounting. Hands-on experience coordinating projects and working with leaders across the business to identify areas of improvements, propose and implement solutions Experience communicating with senior leadership to guide understanding across team members from divergent functions Create and automate operational dashboards to monitor changes in our performance Knowledge of SOX Compliance is a plus Please note: This role involves working in 4 p.m.-1 a.m. IST shift. About Databricks Databricks is the lakehouse company. More than 7,000 organizations worldwide — including Comcast, Condé Nast, H&M and over 50% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook. Our Commitment to Diversity and Inclusion At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics. Mission: At Databricks we are on a mission to empower our customers to solve the world's toughest data problems by utilising the Lakehouse platform. As a Delivery Solutions Architect (DSA), you will play a critical role during this journey. You will collaborate with our sales and field engineering teams to accelerate the adoption and growth of the Databricks platform in your accounts. As a DSA, you will help ensure customer success by driving focus and technical accountability to our most complex customers who need guidance to accelerate consumption on Databricks workloads that they have already selected. This is a hybrid technical and commercial role. It is commercial in the sense that you will be required to own and drive growth in your assigned customers and use cases through leading your customers’ stakeholders, owning executive relationships and creating and driving plans and strategies for Databricks colleagues to execute upon. This is in parallel to being technical, with expectations being that you become at least Level 200 across all Databricks products/workloads and that you become the Use Case-specific technical lead post-Technical Win. This requires you to utilize relationship management skills and technical credibility to effectively engage and communicate at all levels with an organisation. You will report directly into a DSA manager as part of your Business Unit’s Technical GM organisation.  Your day-to-day responsibilities: Engage with the Solutions Architect to understand the full Use Case Demand Plan for prioritised customers. Own the Post-Technical Win technical account strategy and investment plan for the majority of Databricks Use CTAMases within our most strategic accounts. Be the accountable technical leader assigned to specific Use Cases and customer(s) across multiple selling teams and internal stakeholders, creating certainty from uncertainty/ambiguity and driving onboarding, enablement, success, go-live and healthy consumption of the workloads where the customer has made the decision to consume Databricks.  Be the first point of contact for any technical issues or questions related to production/go live status of agreed upon Use Cases within an account, oftentimes services multiple use cases within the largest and most complex organisations.  Leverage both Shared Services of User Education, Onboarding/Technical Services and Support resources, along with escalating to Level 400/500 technical experts (Specialist Solution Architects and Product Specialists) to execute on the right tasks that are beyond your scope of activities or expertise.  Create, own and execute a PoV as to how key use cases can be accelerated into production, bringing EM/PM in to prepare Professional Services proposals. Navigate Databricks Product and Engineering teams for New Product Innovations, Private Previews and Upgrade needs (DBR, E2 and Unity Catalog).  Build and maintain mutual success plan that covers all activities of Customer, PS, Partner, SSA, Product Specialist, SA to cover the below workstreams: Key use cases moving from ‘win’ to production Enablement / user growth plan Product adoption (strategy and activities to increase adoption of LH vision) Organic needs for current investment Eg. Cloud Cost control, Tuning & Optimisation Executive and operational governance Proactively provide internal and external updates - KPI reporting on the status of consumption and customer health, covering investment status, key risks, product adoption and use case progression - to your Technical GM.   What we look for (Competencies): 5+ years in a customer-facing pre-sales, technical architecture, customer success, or consulting role Experience understanding architecture-related distributed data systems, specifically within one of the following: Data Engineering technologies (e.g. Spark, Hadoop, Kafka) Data Warehousing (e.g. SQL, OLTP/OLAP/DSS) Data Science and Machine Learning technologies (e.g. pandas, scikit-learn, HPO) Comfortable managing multiple projects at once, and engaging a virtual team of subject matter experts to address any onboarding or technical challenges outside of your remit or bandwidth. Influencing and leading teams - especially without having direct reporting line responsibility for individuals within account and leadership teams, both internally and externally Stakeholder management - experience in effectively engaging and influencing a variety of audiences (technical, non technical) at all levels of an organization (CxO to developer) Executive escalation management - experience in resolving complex and critical escalation with senior customer and Databricks executives Strategic Management Consulting - experience of conducting open-ended discovery workshops,  creating strategic roadmaps, conducting business analysis and managing delivery of complex programmes/projects Building and steering to a value case - business value consulting and realisation Quota ownership, achievement and track record of great performance against objective target About Databricks Databricks is the lakehouse company. More than 7,000 organizations worldwide — including Comcast, Condé Nast, H&M and over 50% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook. Our Commitment to Diversity and Inclusion At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics. Company Description SSENSE (pronounced [es-uhns]) is a global technology platform operating at the intersection of culture, community, and commerce. Headquartered in Montreal, it features a mix of established and emerging luxury brands across womenswear, menswear, kidswear, and Everything Else. SSENSE has garnered critical acclaim as both an e-commerce engine and a producer of cultural content, generating an average of 100 million monthly page views. Approximately 80% of its audience is between the ages of 18 to 40. It is privately held and has achieved high double digit annual growth and profitability since its inception. Job Description Reporting to the Senior Director of Global Operational Excellence & Continuous Improvement, the Manager of Data Visibility, Governance, and Product is responsible for leading the design, development, and successful implementation of current and future data visualisation, reporting standards, and workflow data products for Operations. They will oversee a team of analysts that translate business requirements into technical reporting requirements across all end-to-end processes, define the metrics, and then build the data products and corresponding dashboards that will be a cornerstone of all Operational roles and training programs at SSENSE. The incumbent will ensure data visualisation, metric, and KPI standards are clearly defined ahead of our global network expansion plans over the coming 1-3 years. RESPONSIBILITIES Data visibility, governance, and product design (75%) Develop and lead the Operations Visualization & Data Governance transformation plan that will standardise and operationalize all data points related to physical and systemic movement of products within the SSENSE Network, spanning operational process paths to C-suite executive-level reporting Translate and develop standard metrics for reporting, and collaborate with the Product and Engineering, and Data Platform team to determine the right mechanism for delivering the reports and insights to maximize how they are used and actioned by Operational teams Develop, and implement reporting solutions with AWS tools like Athena, Tableau, and operational reporting capabilities available through operational systems Work closely with all Operational teams and executive leadership to ensure clear and consistent metric definitions, comprehensive capture and up-to-date documentation of operational reporting and analytical reporting requirements  Oversee all data, metric, and dashboard development by the direct team; define the internal development process and stakeholder engagement model, establishing quality measures for product delivery; achieve and maintain best-in-class benchmarks for adoption rates Develop prioritised roadmap for scaling visibility, maturity, automation, and real-time capability for all operational process paths in tandem with process maturity assessment; design agile approach for near-term output and ongoing, ad hoc request management Implement design principles and templates for data visualisation and governance across Operations that guides all dashboard development in current and future state Collaborate with the Product and Data Platform teams to define and demarcate data accessibility and tools for analysis vs. standardised user interface for operational process and reporting Partner with Business Process Owners and Operations leadership to implement standard metrics based on industry best practices to integrate with company-wide metric reporting  Implement continuous improvement processes for refining / streamlining data or visualisation standards, as well as change management practices for deployment; inclusive of scalable approach to deprecating and removing legacy reports and dashboards Pilot workflow tools that support predictive analytics and algorithmic recommendations Oversee successful migration of reporting, visualisation, and workflow tools with existing system or product changes (e.g., WMS); partner with Product teams to define requirements of new systems or product implementation (e.g., YMS, LMS); ensuring successful integration with data governance and reporting standards Partner directly with the Data Platform team and the Product and Engineering teams to develop a design of the future for these collaterals and corresponding data architecture People leadership and development (25%) Work with Senior Leadership to gauge and monitor team engagement and implement solutions to create a transparent, collaborative and productive work environment  Collaborate with Senior Leadership to establish the department short term objectives for the department and ensure the team's are engaged towards achieving them  Hold weekly one-on-ones, conduct performance reviews, analyze individual KPIs and assess promotion readiness to help each contributor evolve in their roles Provide mentorship and development opportunities to team members, catalyzing growth through coaching and team building Qualifications REQUIREMENTS Bachelors Degree in Computer Science, Information Systems, Mathematics, Statistics, Data Science, Software Engineering, or another relevant field  A minimum of 5 years of professional, hands-on data management/Operations and analytics experience, with at least 3 years of formal management experience leading highly developed data management and analytical professionals, ideally in fast-paced Fulfillment industry, Distribution, Logistics or Production/Manufacturing environment Extensive experience with data manipulation and data visualisation tools, such as Tableau for reporting and dashboarding is essential Extensive experience with data manipulation using SQL or other means to extract and transform data is a must Analytical mindset and experience working with business and technical teams to define key metrics, KPIs, definitions, and governance standards, along with the process to manage and maintain them over time is a must Experience with Operational SAAS systems and their reporting capabilities (pros and cons) is a plus Experience leading teams in information design principles and data visualisation methods, best practices, and software packages and APIs such as Tableau or equivalent analytics tools Strong written and verbal communication skills in English and French SKILLS Strong organisational and time management skills  Advanced data analysis skills, and an expert in using supporting tools Strong collaboration and prioritisation skills Ability to identify, prioritise and articulate high impactful initiatives The ability to translate operational issues into workable data solutions Creative out-of-the-box thinking with excellent problem-solving abilities Team player with solid leadership and interpersonal skills Strong communication skills, with an ability to influence cross-functional teams Additional Information WORLD CLASS TECHNOLOGY  Technology is at the core of everything we do at SSENSE. Driven by an engineering mindset and a problem-solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the SSENSE offering.  WORLD CLASS TEAM The SSENSE tech team is responsible for an international headless commerce platform. Working in an agile environment, our squads are made up of experienced innovators in Product Management, QA, Design, DevOps, Software Development, Machine Learning, Data Engineering, and Security. Headquartered in Montreal, our technology organization has been growing at a rate of 2X year-over-year and is doubling once again in 2021 as we expand across Canada, US, and Europe.   WORLD CLASS PLATFORM  The SSENSE platform runs on Amazon Web Services making use of serverless microservices across web, mobile and app. Our event-source architecture already achieves over 10,000 requests / second and growing at an unmatched pace, currently unseen across the industry.  Our data-driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in Machine Learning techniques. Our automated continuous improvement DevOps model (making use of both blue / green and canary deployments) results in an average of 50 production releases every day.   Read more about us on our SSENSE Tech Blog. L’entreprise agileDSS est une entreprise de service-conseil spécialisée en analytique avancé. Depuis plus d’une quinzaine d’années, nous accompagnons les grandes entreprises à tirer le meilleur parti de leurs données par le biais d’une expertise de pointe en analytique avancé à travers des projets en Business Intelligence, Cloud Analytique, Big Data et DataOps.  Description du Poste Nous sommes à la recherche d’une personne passionnée qui sera intéressée pour un stage rémunéré en Data Engineering. Vous interviendrez dans l’une de nos équipes projets directement en clientèle entouré des meilleurs dans le domaine.  Le contexte de ton stage : Intégré dans une équipe de conseillers de Data Engineers et encadré par un conseiller sénior, le stagiaire interviendra sur de véritables projets d’entreprise chez l’un de nos clients.  Tes principales missions seront les suivantes : Se former aux outils, techniques et normes de transformation de la donnée (Azure Data Factory, Databricks, Python/Spark, SQL) Se former aux outils de gestion de code / projet (IntelliJ IDEA, Git, Azure DevOps) Participer au développement des flux de données des différents projets sur lesquels il aura à intervenir Concevoir un algorithme de transformation de données en Python/Spark/Delta Analyser et résoudre des anomalies dans du code / données existant Participer aux différentes réunions d’équipe Requirements Les compétences requises pour ce stage sont : Bonnes notions dans un langage de programmation (SQL / Python / Cloud / Git …) Connaissances de base sur la transformation de données (Sélection, Filtres, Jointures, Group By, Agrégations) Curiosité, passion, enthousiasme, esprit d’équipe, relative autonomie Rigoureux, sens du service Tu as une bonne aisance relationnelle Tu es bilingue (atout)  agileDSS, c’est aussi… Une entreprise regroupant les meilleures personnes dans le domaine de la Data et du Data Engineering en particulier Un environnement stimulant et non hiérarchique qui prône l’autogestion, l’échange d’idées et le leadership Des horaires flexibles Un beau bureau lumineux et inspirant au cœur du Vieux Montréal (rue McGill) Un environnement qui encourage la formation et le développement de ses employés Des personnes extraordinaires qui mettent l’entraide au cœur de leurs interactions Des activités mensuelles de team building pour tous les goûts Plus que des collègues, une famille!  Condition du Stage Destiné aux étudiants résidants au Québec Stage de pré-embauche rémunéré : Selon le niveau d’étude / Diplôme Horaires : 37.5 heures par semaine, du lundi au vendredi Durée : 4 à 6 mois Début : Avril 2023 Présentiel / À distance : 2 jrs/semaine au bureau au minimum As a Technical GM for India, you will lead a leadership team managing technical field practitioners covering the end-to-end Databricks customer journey from Pre-Sales to Go-Live. Your teams will drive accountability for technical/business wins for the Databricks platform and accelerate the consumption of Databricks platform, and driving workloads to production for all customers in your segment. Hiring, coaching, and motivating the team to success will be critical. Included in the scope of management and accountability for the Technical GM will be : Solution Architects (SA's) Specialist Solution Architects (SSA's), and Delivery Solutions Architects (DSA's) , which is a new post-Technical Win role Tight alignment with Sales segmentation and strategy, coupled with resource prioritization and distribution across these three technical roles is paramount to the success of the Technical GM. You will report to the Leader of Field Engineering, APJ. You can be based either in Mumbai / Pune / Bengaluru / Delhi.   The impact you will have : Rapidly scale the Field Engineering team from scratch while maintaining a high bar for talent Build Databricks' brand in India, in partnership with the Marketing and Sales team. Drive a consistent & robust management operating rhythm to review KPI's (pipeline, Use Case progress, POC/POV status, velocity of Win to Production, etc.) Increase SA, SSA, and DSA efficiency in Sales and Consumption cycles Build a collaborative culture within a rapid-growth team. Manage & mentor leaders , recruit great people focusing on DEI and resiliency. Serve as a thought leader, consulting with strategic customer and partner contacts to position the strength of Databricks, the comprehensive solutions strategy, and build trust and credibility in the account.   What we look for : 10+ years experience building and scaling Pre-sales / Specialists / Customer Delivery / Customer facing teams Experience working with accounts - from Growth/Net New to Large and Complex accounts generating +$1M ARR. Experience in scaling and mentoring field and technical teams managing both in-person and remote working models Knowledgeable in AI, and Cloud software models with technical competence in Data Warehousing, Data Engineering, and Analytics/Machine Learning. Experience instituting processes for technical field members to improve operational efficiency   Benefits : Private medical insurance Accident coverage Employee's Provident Fund Equity awards Paid parental leave Gym reimbursement Annual personal development fund Work headphones reimbursement Business travel insurance About Databricks Databricks is the lakehouse company. More than 7,000 organizations worldwide — including Comcast, Condé Nast, H&M and over 50% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook. Our Commitment to Diversity and Inclusion At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics. Company Description Octopus  Octopus is a group of innovative, entrepreneurial businesses investing in the people, ideas and industries that will help to change the world. We are experts in financial services and energy, and we’re also a certified B Corp, meaning we care as much about the impact of our investments as the returns they generate. Today we manage more than £12.6* billion on behalf of retail and institutional investors. Our energy supply business is one of the fastest growing companies in the UK, reaching 3.1 million customers in just five years, and is the only supplier to be recommended by Which? four years in a row.  Octopus Energy, Octopus Giving, Octopus Moneycoach, Octopus Investments, Octopus Renewables, Octopus Real Estate, Octopus Ventures, Octopus Wealth and Seccl Technology are all part of Octopus Group. Visit octopusgroup.com.  *Funds Under Management data includes undrawn commitments, funds under advisory mandates, funds monitored and the Octopus Cash service as of 31st December 2021  Job Description We are looking for a Senior Power BI Developer to join the Data Insights team within Octopus Investments.  This is an opportunity to join a growing team in an exciting period of transformation where you will be at the forefront of shaping how the business uses data & insight.  You will be the ‘go-to PowerBI person’ in the team, spearheading the development and rollout of PowerBI across the business. Core responsibilities will include: Providing end-to-end delivery of enterprise-level Power BI solutions for OI. Gathering, clarifying, and developing requirements with stakeholders. Leading the architectural design, governance, and adoption of Power BI. Using a working knowledge of modern data warehousing frameworks to work closely with the Data Engineering team to define data solutions. Building and delivering Power BI training. Ownership of the Power BI development roadmap. Creating and maintaining complete and accurate solution design documents. Qualifications Essential experience & characteristics: Experience developing end-to-end Power BI reporting and analytics solutions Excellent knowledge SQL, DAX, and Power Query (M) Strong understanding of data modelling concepts Proficiency in data visualisation and report design Experience working in or alongside data engineering teams to deliver data solutions Experience of designing and delivering Power BI training. Great people skills - this role will involve working with lots of internal stakeholders both technical and non-technical. Desire to learn new technologies and continuously develop new skills and expertise. Nice to have: Working knowledge of DBT. Experience of coaching more junior team members. Experience working for a similar, fast paced Financial Services company. Additional Information Our Values  At Octopus we don't just focus on what we do but also how we do it. Everyone shares our values of being straightforward, helpful and bold. And while these are the principles that guide us as an organisation.  What we offer 💰  A competitive salary, bonus, pension and share incentive plan ✈️ Take what you need holiday 🏡 Flexible working  ⚓ Anchor (our wellness hub) which includes Headspace, one to one coaching through Sanctus, Parent Cloud, Digital GP, Shout & more 👪 Enhanced family leave policies ❤️ Life insurance, critical illness cover and income protection 🏥 Private medical insurance for you and your family 🚗 Electric vehicle leasing 🌍 The option to work overseas up to a month per year As a Solutions Architect (Analytics, AI, Big Data, Public Cloud), you will guide the technical evaluation phase in a hands-on environment throughout the sales process. You will be a technical advisor internally to the sales team, and work with the product team as an advocate of your customers in the field. You will help our customers to achieve tangible data-driven outcomes through the use of our Databricks Lakehouse Platform, helping data teams complete projects and integrate our platform into their enterprise Ecosystem. You'll grow as a leader in your field, while finding solutions to our customers' biggest challenges in big data, analytics, data engineering and data science problems. You will report to the Solutions Architect Manager. The impact you will have: You will be a Big Data Analytics expert on aspects of architecture and design Lead your clients through evaluating and adopting Databricks including hands-on Spark programming and integration with the wider cloud ecosystem Support your customers by authoring reference architectures, how-tos, and demo applications Integrate Databricks with 3rd-party applications to support customer architectures Engage with the technical community by leading workshops, seminars and meet-ups Together with your Account Executive, you will form successful relationships with clients throughout your assigned territory to provide technical and business value What we look for: Consulting, Pre-sales or post-sales experience working with external clients across a variety of industry markets Understanding of customer-facing pre-sales or consulting role with a core strength in either data engineering or data science advantageous 5+ years of experience demonstrating technical concepts, including demos, presenting and white-boarding 8+ years of experience designing architectures within a public cloud (AWS, Azure or GCP) 5+ years of experience with Big Data technologies, including Spark, AI, Data Science, Data Engineering, Hadoop, Cassandra, and others Coding experience in Python, R, Java, Spark or Scala Bachelor's degree in Computer Science, Information Systems, Engineering, or equivalent experience through work experience Benefits : Private medical insurance Accident coverage Employee's Provident Fund Equity awards Paid parental leave Gym reimbursement Annual personal development fund Work headphones reimbursement Business travel insurance Mental wellness resources About Databricks Databricks is the lakehouse company. More than 7,000 organizations worldwide — including Comcast, Condé Nast, H&M and over 50% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook. Our Commitment to Diversity and Inclusion At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics. About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to know our team: Partner Development is a team of creative entrepreneurs that develop solutions for Agoda’s accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. In this role you'll get to This role is designed to mainly growth opportunity identification among mid to long tail hotels, experiment execution and data tracking within Partner Development team for the global teams. You will get to work directly with the regional team to design and put in place global experimentation and initiatives to drive tangible impact in each market. Key activities involved include but not limit to: Apply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations Own end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development Build dashboards, identify new and track key metrics to closely monitor team’s performance and identify quick and long term opportunities for improvements Work closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified Support global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization What you'll need to succeed  Bachelor’s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline 4-8 years experience working in a business analysis, data analysis, reporting or business strategy role Excellent problem-solving skills including the ability to analyze and resolve complex problems using data Team player with strong interpersonal, relationship-building, and stakeholder management skills Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala) Data visualization tool experience such as with Tableau or your weapon of choice. Ability to work under pressure in a fast-paced and rapidly changing environment Excellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Ginkgo Introduction Our mission is to make biology easier to engineer. Ginkgo is constructing, editing, and redesigning the living world in order to answer the globe’s growing challenges in health, energy, food, materials, and more. Our bioengineers make use of an in-house automated foundry for designing and building new organisms.  Specific Role Description ● Ensure effective and high-quality development and support of Ginkgo Ag platform and programs● Drive digital research strategy definition and operationalization, effective storage and analysis of data for all studies supporting a smooth transition of projects through phases, including experimental design● Drive optimal externalization strategy and use of Ginkgo-wide capabilities. #LI-JH1 Responsibilities Manage, develop and lead two core functions: Decision Science, Genomics as well as outsourced functions As member of Ag Dept., partner with other senior team members and Ginkgo teams across the organization to facilitate data management, storage and analysis as well as training of users and promotion of biostatistics culture across Ag Dpt. Work closely with IT functions to leverage skills and resources of this function particularly around Project Management and IT systems implementation.  Participate in all necessary integration functions as organization matures. Ensure DSA excellence within Ag Dept. as well as across Ag Dept. functions. Formulate technical and strategic objectives that involve a high degree of planning and coordination so that numerous activities converge successfully at local and global levels, such as Data Management strategy Represent Ag Dept. at 3rd party and internal collaboration meetings, international conferences and commercial partnerships As a member of Ag Dept. Leadership Team, effectively plan and manage departmental budget (esp. capital and operational expenditure and training budget allocated to direct reports) and develop Ag Dept. innovation strategy. Minimum Requirements PhD with minimum of 8 years experience in Computational Biology, Bioinformatics, Genomics or related field Management experience supervising PhD level scientists with 5 years of demonstrated leadership skills Scientific, technical and social skills for the development of internal and external network contacts of global expert teams. Preferred Capabilities and Experience Expert domain knowledge of data science and bioinformatics incl. all actual developments like deep neural nets and machine learning.  Comprehensive technical understanding of relational databases, network design and systems, servers, and web-based software development.  Strong communication skills to translate technical and scientific information and to communicate departmental vision To learn more about Ginkgo, visit www.ginkgobioworks.com/press/ or check out some curated press below:What is it really like to take your company public via a SPAC? One Boston biotech shares its journey (Fortune)Ginkgo Bioworks resizes the definition of going big in biotech, raising $2.5B in a record SPAC deal that weighs in with a whopping $15B-plus valuation (Endpoints News)Ginkgo Bioworks CEO on scaling up Covid-19 testing: ‘If we try, we can win’ (CNBC)Ginkgo raises $70 million to ramp up COVID-19 testing for employers, universities (Boston Globe)Ginkgo Bioworks Redirects Its Biotech Platform to Coronavirus (Wall Street Journal)Ginkgo Bioworks Provides Support on Process Optimization to Moderna for COVID-19 Response (PRNewswire)The Life Factory: Synthetic Organisms From This $1.4 Billion Startup Will Revolutionize Manufacturing (Forbes)Synthetic Bio Pioneer Ginkgo Raises $290 Million in New Funding (Bloomberg)Ginkgo Bioworks raises $350 million fund for biotech spinouts (Reuters)Can This Company Convince You to Love GMOs? (The Atlantic) We also feel that it’s important to point out the obvious here – there’s a serious lack of diversity in our industry, and that needs to change. Our goal is to help drive that change. Ginkgo is deeply committed to diversity, equity, and inclusion in all of its practices, especially when it comes to growing our team. Our culture promotes inclusion and embraces how rewarding it is to work with people from all walks of life.   We’re developing a powerful biological engineering platform, so we must remain mindful of the many ways our technology can – and will – impact people around the world. We care about how our platform is used, and having a diverse team to build it gives us the best chance that it’s something we’ll be proud of as it continues to grow. Therefore, it’s critical that we incorporate the diverse voices and visions of all those who play a role in the future of biology. It is the policy of Ginkgo Bioworks to provide equal employment opportunities to all employees and employment applicants. Opis firmy   Opis oferty pracy Widełki wynagrodzenia przewidziane przy tym stanowisku to (umowa o pracę): mid: 12 300 - 17 600 PLN brutto senior: 16 100 - 23 200 PLN brutto Model pracy hybrydowej według ustaleń lidera i zespołu.  Ofertę kierujemy do osób, które: Bardzo dobrze znają SQL Posiadają doświadczenie z co najmniej jednym typem baz danych: Oracle, PostgreSQL, MySQL, BigQuery Biegle posługują się Google Sheets (Google Suite), MS Excel Posiadają doświadczenie z narzędziami raportowymi takimi jak: Google Data Studio, Tableau, Power BI, Cognos Potrafią sprawnie zarządzać czasem i pracować w zespole Oczekują pracy, która ma głębszy sens (nie tylko “management zlecił”) i realny wpływ na decyzyjność kadry zarządzającej Potrafią szukać efektywnych rozwiązań do wymagań stawianych przez użytkowników Chcą się ciągle rozwijać i aktualizować swoją wiedzę Dodatkowym atutem będzie: Podstawowa umiejętność programowania w języku Python Podstawowa znajomość Google Apps Script Wiedza oraz doświadczenie w modelowaniu, tworzeniu i utrzymaniu procesów ETL Znajomość zagadnień związanych Airflow, Google Composer, Dataproc, Spark Doświadczenie w pracy w środowisku GCP Dlaczego miał(a)byś z nami pracować? Zapewnisz dane niezbędne do rozwoju systemów wspomagających działalność zespołów finansów oraz kadry zarządzającej Będziesz odpowiadać za prezentację wybranych danych oraz automatyzację procesów raportowych w obszarze Technologii oraz Finansów  Będziesz wspierać automatyzację istotnych procesów biznesowych i back officowych Zajmiesz się tworzeniem i wsparciem utrzymania procesów ETL oraz przygotowaniem agregatów danych  Odpowiesz za rozwój procesów raportowych w oparciu o wymagania biznesowe przy użyciu Google Data Studio Będziesz mieć realny wpływ na kluczowe KPI Allegro Zaangażujesz się w zróżnicowane projekty z obszaru styku Finansów i Technologii, Otrzymasz możliwość rozwoju w obszarze BI i AI&ML oraz umiejętności związanych z programowaniem w języku Python Ze swojej strony oferujemy: Model pracy hybrydowej, który ustalisz z liderem i zespołem. Mamy świetnie zlokalizowane biura ( z w pełni wyposażonymi kuchniami i parkingami dla rowerów) i znakomite narzędzia pracy (podnoszone biurka, interaktywne sale konferencyjne) Bonus roczny do 10% wynagrodzenia rocznego liczony z kwoty brutto (zależny od Twojej oceny rocznej oraz wyników firmy) Bogaty pakiet świadczeń pozapłacowych w systemie kafeteryjnym – Ty decydujesz z czego korzystasz (do wyboru mamy m.in. pakiety medyczne, sportowe, lunchowe, ubezpieczenia, bony na zakupy) Zajęcia angielskiego opłacane przez nas i skoncentrowane na specyfice Twojej pracy Hackathony, turystykę zespołową, budżet szkoleniowy oraz wewnętrzna platforma MindUp (m.in. szkolenia z zakresu organizacji pracy, sposobu komunikacji, motywacji do pracy oraz różnych technologii i zagadnień merytorycznych) Wyślij nam swoje CV i sprawdź dlaczego #dobrzetubyć Binance is the global blockchain company behind the world’s largest digital asset exchange by trading volume and users, serving a greater mission to accelerate cryptocurrency adoption and increase the freedom of money. Are you looking to be a part of the most influential company in the blockchain industry and contribute to the crypto-currency revolution that is changing the world? Responsibilities Work across all aspects of data from engineering to building sophisticated visualizations, machine learning models and experiments Analyze and interpret large (PB-scale) volumes of transactional, operational and customer data using proprietary and open source data tools, platforms and analytical tool kits Translate complex findings into simple visualizations and recommendations for execution by operational teams and executives Processing confidential data and information according to guidelines Managing and designing the reporting environment, including data sources, security, and metadata Troubleshooting the reporting database environment and reports Requirements Bachelor’s degree from an accredited university or college in Computer Science or Math or Statistics Proficient in data engineering, modeling and ETL - preferred experience with data sourcing and working with APIs Experience with data querying using languages such as SQL, GraphQL, Python  Able to commit minimum 3 days per week for at least 6 months Understands project tokenomics and has good knowledge of the DeFi and Web 3.0 infrastructure landscape Experience in using tools such as Dune analytics, Nansen etc Understanding of addressing and metadata standards High-level written and verbal communication skills Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description This position is ideal for an engineer who is passionate about solving challenging business problems and building applications that provide an excellent user experience. You will be an integral part of the Payment Products Development team focusing on design and development of software solutions that leverage data to solve business problems. The candidate will be extensively involved in hands-on activities including POCs, design, documentation, development, and testing of new functionality. Candidate must be flexible and willing to switch tasks based on team's needs.  Responsible for the design, development, and implementation. Work on development of new products iteratively by building quick POCs and converting ideas into real products. Design and develop mission-critical systems, delivering high-availability and performance. Interact with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology. Develop code to ensure deliverables are on time, within budget, and with good code quality. Have a passion for delivering zero defect code and be responsible for ensuring the team's deliverables meet or exceed the prescribed defect SLA. Coordinate Continuous Integration activities, testing automation frameworks, and other related items in addition to contributing core product code. Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner. Perform other tasks on R&D, data governance, system infrastructure, and other cross team functions, on an as-needed basis This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs. Qualifications We are seeking team members that are passionate, visionary and insatiably inquisitive. Successful candidates frequently have a mix of the following qualifications:  • 2 or more years of work experience in building large-scale applications using open source technologies • Bachelor’s Degree or an Advanced Degree (e.g. Masters) in Computer Science/ Engineering, Information Science or a related discipline • Extensive experience with SQL and Big Data technologies (Hadoop, Java, Spark, Kafka, Hive etc.) tools for large scale data processing and data transformation • Experience with data visualization and business intelligence tools like Tableau, or other programs highly desired • Familiar with software design patterns • Experience working in an Agile and Test-Driven Development environment • Strong knowledge of API development is highly desired • Strategic thinker and good business acumen to orient data engineering to the business needs of internal and external clients • Demonstrated intellectual and analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style • Previous exposure to financial services is a plus, but not required  Please Note: Due to the COVID-19 pandemic and the evolving visa/travel restrictions in place, we are currently only able to extend offers to candidates with the right to work in Singapore. We are keeping the situation under close review and will adjust accordingly should the restrictive measures be lifted. Additional Information Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description This position is ideal for an experienced Software engineer who is passionate about solving challenging business problems and building applications that provide an excellent user experience. You will be an integral part of Loyalty & Marketing Services team focusing on design and build of software solutions that leverage data to solve business problems. Responsibilities Responsible for the architecture, design, development, and implementation. Work on development of new products iteratively by building quick POCs and converting ideas into real products. Design and develop mission-critical systems, delivering high-availability and performance. Interact with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology. Develop code and mentor junior developers to ensure delivery on time, within budget, and with good code quality. Have a passion for delivering zero defect code and be responsible for ensuring the team's deliverables meet or exceed the prescribed defect SLA. Help developer efficiencies by utilizing Continuous Integration/Development tools, test automation frameworks and other related items. Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner. Identify opportunities for future enhancements and refinements to products, standards, best practices, and development methodologies Collaborate with global and virtual teams on software development. This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs. Qualifications • Master’s Degree in Computer Science or related field with 6 years of relevant experience or Bachelor’s degree with 8 years of relevant experience. • Previous exposure to financial services is a plus, but not required. • Strong knowledge on Hadoop framework components (HDFS, Map Reduce, Spark, HBase, Kafka). • Strong knowledge in Java or Scala or Python. • Strong knowledge of database concepts, systems architecture, and data structures is a must. • Experience with one or more of the following database technologies: DB2, Postgres, MySQL, and NoSQL such as Hadoop, Hbase, MongoDB. • Proficient in GIT/Stash, Maven, Jenkins etc. • Java/J2EE/Angular, Spring Cloud, Microservices and strong knowledge on API development is a big plus. • Experience working in an Agile and Test-Driven Development environment. • Process oriented with strong analytical and problem-solving skills. • Work independently and mentor others in the team and with minimal supervision. • Ability to juggle multiple projects and change direction mid-course based on business drivers. • Demonstrated ability to work in a complex organization to determine business and customer needs, providing the best solution to meet those needs. • Ability to work independently in a high throughput environment. • Demonstrated intellectual and analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style. • Excellent presentation and communication skills required. Additional Information Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. Definitive Logic has a unique opportunity for a Mid-Level Business Intelligence (BI) Solution Developer to join our tightly knit team supporting the implementation and deployment of a Cloud software solution. We are an award-winning company that cares about its customers and its employees, and we are a recognized consulting leader in Corporate Performance Management services.  We offer great benefits, a casual work environment, volunteer hours to help the community, and training.  If you want to work with a great team that provides growth and training opportunities, we want to talk with you.  We are only looking for people who want to join our team as regular, full-time employees.  We want to continue building our corporate knowledge and invest in making our employees the best in the business. Responsibilities Apply standard industry practices and methodologies to develop, deploy, and maintain BI interfaces, those include query tools, data visualization and interactive dashboards, ad hoc reporting, and data warehousing tools Background development data solutions and can operate in a fast paced, highly collaborative environment Assist in the development of dashboards and other data visualizations Assist in all conversion, design, and training activities throughout program planning and execution Required Qualifications Bachelor's degree or higher in Computer Science, Engineering, Information Systems, Mathematics, Business, Accounting or related degree Experience consulting or delivering solutions to federal clients Minimum of 8 years of work experience in a technical field with at least 2 years of hands-on experience with BI platforms to include Tableau, Microsoft Power BI, Qlik, etc The ability to obtain a DoD Secret Security Clearance Desired Qualifications General knowledge of federal financial management processes and requirements SQL experience with Oracle databases or SQL Server, or other industry standard DB platforms Tableau development experience Experience working with Redshift, AWS or other Cloud Platforms Active DoD Secret Clearance About Definitive Logic Definitive Logic (DL) is a management and technology consulting firm known for delivering outcomes and ROI for agencies’ most complex business challenges.  DL delivers performance-based and outcome-driven technology consulting solutions that directly support the strategic intent of our Defense, Homeland Security, Emergency Management, Federal Civilian and Commercial clients. We’re the preferred technology integration partner for Federal agencies to apply the best of data science, app dev, DevSecOps, cyber and cloud solutions to improve decision support, empower front-line employees and enhance back-office operations. We serve as trusted advisors providing objective, fact-based, vendor & technology-neutral consulting services.  Definitive Logic is ultimately a team of problem solvers — thought leaders, domain experts, coders, data enthusiasts, and technophiles.  Our exciting projects and learning and sharing culture has consistently resulted in validation as a Great Place to Work: 2021 Washington Post Top Work Places (7-time winner) | 2022 Virginia Best Places To Work (9 years running, #1 midsize in 2019).  Definitive Logic is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable, or limited in your ability, to use or access our Careers page: https://www.definitivelogic.com/careers/open-opportunities/ as a result of your disability. You can request a reasonable accommodation by sending an e-mail to Recruiting@DefinitiveLogic.com or via phone: 703-955-4186. In order to quickly respond to your request, please use the words "Accommodation Request" as your e-mail subject line. DL BenefitsHealthDentalVisionLife/AD&D: Company paid STD/LTD:Company paidSupplemental Plans: TriCare Supplement, Pet Insurance through Nationwide, Legal Resources and hospital/accidental indemnity plans and Wellness initiatives. Compensation Benefits:Competitive Base SalaryAnnual performance based bonus401(k) & Roth option: You are fully (100%) vested on day 1 and DL matches up to 5%Spot Bonuses Referral Bonuses Additional Benefits:Flexible Time Off (FTO): Under our FTO plan, there is no cap in the amount of leave you choose to take, with proper coordination and prior approval.Volunteer Hours: DL allocates up to 8 hours for you to use every year to volunteer for a 501c3 organization of your choice and DL will donate to that charity based on how many hours you volunteer.Cell Phone Reimbursement: $80/monthLocation Specific Metro/Parking Tuition Reimbursement Training & Certifications Our mission is to connect and optimize the world’s commerce. That means the whole world. So we’re determined to nurture our culture of meritocracy where everyone can thrive, no matter what we look like, where we’re from, how we grew up, whom we love, the nature of our faith, or how our bodies or minds work. We’re committed to achieving equity in treatment and opportunity for everyone, where people are judged on the merits and quality of their work. It all starts with people. Inside every company, behind every brand­ - while business success is often measured in profit, it has always been powered by people. We firmly believe people are the heart of any organization - including our own. That’s why a career here provides much more than simple pay and perks. We’re dedicated to empowering people, solving tough problems, and helping careers flourish inside and out.    Position Summary: The Business Intelligence Engineer will be a critical contributor to enabling the Business Intelligence Team to identify opportunities for CommerceHub to use its own data, as well as data provided by third parties, to generate additional company revenue and derive valuable industry insights.   Responsibilities: Design and build dashboards for internal stakeholders and externally facing products Develop new and maintain existing reports using Looker, Tableau and PowerBI Work with stakeholders including Product, Marketing, Finance and Customer Support to design dashboards and reports Participate in full development life cycle including requirements development, implementation, peer review, source control, automated testing, deployment, and operations Enforce corporate policies around the evolution and enforcement of industry data standards, data governance and best practices   Requirements: Bachelor’s degree or higher and/or equivalent work experience Strong analytical skills related to working with both structured and non-structured datasets Strong data modeling skills and experience working with Star Schemas Strong working knowledge of highly scalable data warehouse products such as Amazon Redshift, Snowflake 2+ years’ experience with data visualization tools such as Looker, Tableau, PowerBI Experience working in Retail and Looker BI visualization tool is a plus 2+ years’ experience with SQL coding languages such as TSQL, LookML, PostgreSQL, Athena 2+ years’ experience with scripting languages such as Python and R Exceptional written and verbal communication skills Comfortable communicating across all levels of management Ability to prioritize tasks and work independently Excellent analytical, decision-making, and problem-solving skills Proven ability to work in a rapidly changing environment with keen attention to detail   What it’s like to work at ChannelAdvisor, a CommerceHub Company We take a whole-person approach to engage and support our global team. We believe the diversity of our global team is an advantage. If you’re curious, innovative, determined, and customer-focused, then you’ll love the challenge and rewards of collaborating as a team to help our customers win. We offer competitive compensation programs that recognize your hard work and results. Because when our customers win, we win.  And when we win, you win. We work to create an environment where everyone who is committed, works hard, and delivers results can thrive and grow. You can connect with one of our employee resource groups and support our diversity, equity and inclusion task force, network with like-minded team members, and showcase your leadership skills.    Benefits:  Enhanced Private Medical Insurance and a Health Cash Back Plan  Competitive time off package with 25 Days of PTO, 9 Holidays, 2 Wellness days and 1 Give Back Day Flexibility to choose where you work - at home, in the office, or both! Access to tools to support your wellbeing such as the Calm App, MoveSpring and an Employee Assistance Program Professional development stipend and learning and development offerings to help you build the skills and connections you need to move forward in your career Charitable contribution match per team member   ChannelAdvisor, a CommerceHub Company, is an Equal Employment Opportunity Employer. We celebrate diversity and are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need. Netflix is the world’s leading streaming entertainment service with 220 million paid memberships in over 190 countries, enjoying TV series, documentaries, and feature films across a wide variety of genres and languages. Members can watch as much as they want, anytime, anywhere, on any internet-connected screen. About the Engineering Support OrganizationThe aim of the Engineering Support Organization is to enable Platform Engineering to effectively and sustainably scale the support they provide to their customers. The team  is the frontline resource for the engineering support needs of our customers (i.e., our workforce) - handling, troubleshooting, and resolving customer requests and issues. In addition, the team will focus on ways of working, customer advocacy, support tooling, platform product offerings, documentation, and developer education.   Our Mission Deliver an excellent support experience to Netflix’s developer community. To advocate for our customers, follow through on issues and resolve them in a reasonable time. If blockers prevent immediate resolution, we communicate status and ensure there is visibility into why there is a delay.  Provide insights, feedback and champion customer sentiment about the tools we support to our partners across Productivity and Data Platform Engineering. Partner with Product Management, Developer Education and Engineering to track and maintain visibility into ongoing issues and communicate customer needs to ensure improving in these areas is prioritized. Drive collaboration efforts to reduce product friction and increase usability so that Platform Engineering can build, deploy and deliver highly functional solutions for the Developer Community.  The Role We are looking for a Technical Support Engineer with a passion for data platform infrastructure and tooling, customer service, and automation. You will be responsible for monitoring and handling our customers’ requests, troubleshooting, solving issues, automating support needs, developing support documentation and runbooks, improving and maintaining support tools and automation, understanding our product offerings, and continuously looking for ways to improve the engineering support experience.  Our ideal team member has first-hand experience working in customer-facing, engineering support roles, writing and building a comprehensive self-service knowledge base and has knowledge of infrastructure, internal tooling, platforms, and cloud computing. You are excellent at understanding and solving complex and ambiguous problems and constantly seek improvement. As an Engineer in this role, we need a candidate who can understand our complex offerings on a technical level, be hands-on in the development of our support automation tooling, and recommend product and operational improvements based on customer interactions. Location Our offices are located in Los Gatos. What you’ll need to be successful: You are skilled in providing superior customer support across a complex organization, ideally as part of a central team  You are passionate about customer experience You are a data-driven decision-maker You have excellent written and verbal communications skills and appreciate the importance of comprehensive documentation You are comfortable with at least one programming language; preferably Python and/or Java Ability to read and comprehend log files and Unix processes to identify and troubleshoot root causes of issues Prior experience supporting platforms built using open source technologies such as, Jupyter, Hadoop, Apache Airflow (or other workflow orchestration platform), Presto/Trino You  have worked with big data warehouse storage systems (e.g. Iceberg or Hive) You have experience working with data pipelines using Apache Spark framework or  technologies such as Flink, Kafka, Druid or Presto Ability to read and write SQL queries to pull required complex data to support any reported issues/product defects Experience with cloud infrastructure and/or container orchestration platform is a plus You have the desire and aptitude to learn how the pieces of big data platform work together Our culture is unique, and we tend to live by our values, allowing you to do your best work and grow. To learn more about Platform Engineering, feel free to listen to this podcast.  We are an equal-opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.  At Netflix, we carefully consider a wide range of compensation factors to determine your personal top of market. We rely on market indicators to determine compensation and consider your specific job family, background, skills, and experience to get it right. These considerations can cause your compensation to vary and will also be dependent on your location.   The overall market range for roles in this area of Netflix is typically $90,000 - $900,000  This market range is based on total compensation (vs. only base salary), which is in line with our compensation philosophy. Netflix is a unique culture and environment. Learn more here. Company Description REF25129J Job Description ciValue is the leading provider of AI-powered customer analytics, personalization, and brand collaboration platform. Serving dozens of retailers and brands across the world using cutting edge big-data, real-time analytics, and data-science automation.  Recently acquired by NielsenIQ, ciValue’s solution is disrupting existing data & media monetization model by enabling retailers to remain in control of their revenue.  We believe that building a great product and teams starts with amazing, diverse minded and bright people who make an impact, generate creative & innovative ideas and take on new perspectives.   The Big Data Software Engineer is responsible for building new data solutions for our rapidly expanding customer base and working with the top data ingestion technologies in an open, collaborative and innovative environment.  Responsibilities Be responsible for Data flow stages from definition to architecture, including Data acquisition, Data set acceptance criteria and Data Science integration  Architecture designing and customizing technological solutions for large scale data processing  Develop and deploy real-time and batch data processing infrastructures and pipelines  Take responsibility to explore technologies to scale up Data ecosystem to handle rapidly big Data growth  Work closely with Data science team to embed ML / AI algorithms into the product  Work with cloud, DevOps, application, and client teams to make sure your solution is solving significant business problems in a robust, scalable manner.  Use cutting edge technologies: Python, Airflow, Java, Kubernetes, Spark, Scala, Kafka  Qualifiications Bachelor's or Master’s degree in Computer Science, Computer Engineering or related field  4+ years of backend engineering work experience in production environments (Data environments, Big Data processing, Database techniques)  Proven experience with Java/Scala (Python/Go – advantage)  Experience in design and development of scalable big data solutions  Experience in Big Data – Spark / Kafka / Flink  Experience in Kubernetes, containers & Helm  Experience working with SQL & NO-SQL Databases – PostgreSQL, DataLake, Columnar DB  Ability to learn new technologies and work in a dynamic fast paced environment  Result-driven, pragmatic, and innovative  Experience with Cloud technology is an advantage  Excellent English communication skills spoken and written   Full-time position in our office in Yokneam (Hybrid)  Additional Information About NielsenIQ NielsenIQ is a global measurement and data analytics company providing the most complete and trusted view of consumers and markets in 90 countries covering 90% of the world’s population. Focusing on consumer-packaged goods manufacturers and FMCG and retailers, we enable customers to defy what’s possible. How? We combine unparalleled datasets, pioneering technology, and the industry’s top talent to create insights that unlock innovation. Join us and change the landscape. Learn more at: www.niq.com Want to keep up with our latest updates? Follow us on: LinkedIn | Instagram | Twitter | Facebook Our commitment to Diversity, Equity, and Inclusion NielsenIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion/ NielsenIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process. Company Description SSENSE (pronounced [es-uhns]) is a global technology platform operating at the intersection of culture, community, and commerce. Headquartered in Montreal, it features a mix of established and emerging luxury brands across womenswear, menswear, kidswear, and Everything Else. SSENSE has garnered critical acclaim as both an e-commerce engine and a producer of cultural content, generating an average of 100 million monthly page views. Approximately 80% of its audience is between the ages of 18 to 40. It is privately held and has achieved high double digit annual growth and profitability since its inception. Job Description Reporting to the Senior Director of Global Operational Excellence & Continuous Improvement, the Manager of Data Visibility, Governance, and Product is responsible for leading the design, development, and successful implementation of current and future data visualisation, reporting standards, and workflow data products for Operations. They will oversee a team of analysts that translate business requirements into technical reporting requirements across all end-to-end processes, define the metrics, and then build the data products and corresponding dashboards that will be a cornerstone of all Operational roles and training programs at SSENSE. The incumbent will ensure data visualisation, metric, and KPI standards are clearly defined ahead of our global network expansion plans over the coming 1-3 years. RESPONSIBILITIES Data visibility, governance, and product design (75%) Develop and lead the Operations Visualization & Data Governance transformation plan that will standardise and operationalize all data points related to physical and systemic movement of products within the SSENSE Network, spanning operational process paths to C-suite executive-level reporting Translate and develop standard metrics for reporting, and collaborate with the Product and Engineering, and Data Platform team to determine the right mechanism for delivering the reports and insights to maximize how they are used and actioned by Operational teams Develop, and implement reporting solutions with AWS tools like Athena, Tableau, and operational reporting capabilities available through operational systems Work closely with all Operational teams and executive leadership to ensure clear and consistent metric definitions, comprehensive capture and up-to-date documentation of operational reporting and analytical reporting requirements  Oversee all data, metric, and dashboard development by the direct team; define the internal development process and stakeholder engagement model, establishing quality measures for product delivery; achieve and maintain best-in-class benchmarks for adoption rates Develop prioritised roadmap for scaling visibility, maturity, automation, and real-time capability for all operational process paths in tandem with process maturity assessment; design agile approach for near-term output and ongoing, ad hoc request management Implement design principles and templates for data visualisation and governance across Operations that guides all dashboard development in current and future state Collaborate with the Product and Data Platform teams to define and demarcate data accessibility and tools for analysis vs. standardised user interface for operational process and reporting Partner with Business Process Owners and Operations leadership to implement standard metrics based on industry best practices to integrate with company-wide metric reporting  Implement continuous improvement processes for refining / streamlining data or visualisation standards, as well as change management practices for deployment; inclusive of scalable approach to deprecating and removing legacy reports and dashboards Pilot workflow tools that support predictive analytics and algorithmic recommendations Oversee successful migration of reporting, visualisation, and workflow tools with existing system or product changes (e.g., WMS); partner with Product teams to define requirements of new systems or product implementation (e.g., YMS, LMS); ensuring successful integration with data governance and reporting standards Partner directly with the Data Platform team and the Product and Engineering teams to develop a design of the future for these collaterals and corresponding data architecture People leadership and development (25%) Work with Senior Leadership to gauge and monitor team engagement and implement solutions to create a transparent, collaborative and productive work environment  Collaborate with Senior Leadership to establish the department short term objectives for the department and ensure the team's are engaged towards achieving them  Hold weekly one-on-ones, conduct performance reviews, analyze individual KPIs and assess promotion readiness to help each contributor evolve in their roles Provide mentorship and development opportunities to team members, catalyzing growth through coaching and team building Qualifications REQUIREMENTS Bachelors Degree in Computer Science, Information Systems, Mathematics, Statistics, Data Science, Software Engineering, or another relevant field  A minimum of 5 years of professional, hands-on data management/Operations and analytics experience, with at least 3 years of formal management experience leading highly developed data management and analytical professionals, ideally in fast-paced Fulfillment industry, Distribution, Logistics or Production/Manufacturing environment Extensive experience with data manipulation and data visualisation tools, such as Tableau for reporting and dashboarding is essential Extensive experience with data manipulation using SQL or other means to extract and transform data is a must Analytical mindset and experience working with business and technical teams to define key metrics, KPIs, definitions, and governance standards, along with the process to manage and maintain them over time is a must Experience with Operational SAAS systems and their reporting capabilities (pros and cons) is a plus Experience leading teams in information design principles and data visualisation methods, best practices, and software packages and APIs such as Tableau or equivalent analytics tools Strong written and verbal communication skills in English and French SKILLS Strong organisational and time management skills  Advanced data analysis skills, and an expert in using supporting tools Strong collaboration and prioritisation skills Ability to identify, prioritise and articulate high impactful initiatives The ability to translate operational issues into workable data solutions Creative out-of-the-box thinking with excellent problem-solving abilities Team player with solid leadership and interpersonal skills Strong communication skills, with an ability to influence cross-functional teams Additional Information WORLD CLASS TECHNOLOGY  Technology is at the core of everything we do at SSENSE. Driven by an engineering mindset and a problem-solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the SSENSE offering.  WORLD CLASS TEAM The SSENSE tech team is responsible for an international headless commerce platform. Working in an agile environment, our squads are made up of experienced innovators in Product Management, QA, Design, DevOps, Software Development, Machine Learning, Data Engineering, and Security. Headquartered in Montreal, our technology organization has been growing at a rate of 2X year-over-year and is doubling once again in 2021 as we expand across Canada, US, and Europe.   WORLD CLASS PLATFORM  The SSENSE platform runs on Amazon Web Services making use of serverless microservices across web, mobile and app. Our event-source architecture already achieves over 10,000 requests / second and growing at an unmatched pace, currently unseen across the industry.  Our data-driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in Machine Learning techniques. Our automated continuous improvement DevOps model (making use of both blue / green and canary deployments) results in an average of 50 production releases every day.   Read more about us on our SSENSE Tech Blog. Marco is a one-stop shop for all things business tech. Our employees are “movers and shakers” and our company is always striving to do what’s right. Does this sound like a culture you want to be a part of? We’re hiring a new team member to help take Marco’s technology further – working full-time, Monday - Friday, 8am-5pm. More about us. We do it all – from copy and print solutions to IT and managed services. We are an organization led by salespeople with 650+ engineers ready to fix any and all issues. We have offices in 12 states and service nationally. Join our growing team. You won’t regret it. The Senior Manager of BI and Data Analytics is responsible for gathering, analyzing, interpreting, and presenting information in ways that will help Marco make better decisions, solve business problems, improve business performance, support team decisions/ideas, challenge the status quo, and improve the customer journey. The Senior Manager of BI and Data Analytics, under the direction of the Chief Service and Automation Officer, will define the roadmap and priorities for the enterprise-wide Business Intelligence & Analytics function.The Senior Manager of BI and Data Analytics will leverage industry best practices to design and implement secure and scalable solutions to meet the evolving needs of Marco. This role leads a group of Data Analysts in support of all business intelligence requests (new requests, break-fix requests, and maintenance support requests) and is responsible for their growth, upskilling and ongoing development. The Senior Manager of BI and Data Analytics will work closely with business function and IS peers to align to a vision for BI and analytic services across all performance-based metrics and reporting at an enterprise-wide level.  Essential Functions Guide and develop assigned Data Analyst staff under the right agile analytic operating model (people, process and tools) Manage the assigned department team members as follows:       Lead, coach and train team members.       Develop and implement strategic initiatives for team.       Be an escalation point of contact to handle issues and involve direct leadership as needed.       Monitor team coverage, oversee personal time off approval, make sure back-ups are in place and redistribute work to cover when others are out. Monitor staffing and equipment needs.      Conduct performance reviews and make compensation decisions. Utilize the landscape of technology (both existing and emerging) to provide the optimal user experience for business leaders to interact with data and analytic insights Ensure data integrity across all performance-based metrics and reporting Work with a diverse group of C-level and cross-pillar stakeholders to understand business problems and surface digital solutions to address those problems Develop executable plans to achieve business needs on time and to internal business user expectations Stay informed on industry business intelligence & analytics innovations and best-in-class practices Provide thought-leadership with all matters related to business intelligence & analytics as a business partner Build strong cross-pillar relationships with business and IS stakeholders and teams Required Skills Expert knowledge of business intelligence platforms (i.e., Tableau, Power-BI) Expertise in industry-leading enterprise data practices/principles, platforms, and technologies (CI/CD, Automation – RPA, build-release engineering, advanced monitoring and data configuration management) from the customer value dimension (functionality, reliability, and convenience) Continuous expectation management around data & analytics program value through metrics that identify goals and progress being made organizationally Strong relationship management skills with the ability to influence technology vision/decisions at senior stakeholder level and across a global organization Demonstrated ability to work/manage both data analysts/engineers and broader IS teams across a global IS organization  Benefits: We’re not just competitive when it comes to business tech – we’re also pretty proud of what we offer our employees. Our benefits include medical, dental, and vision insurance. We also have paid holidays and vacation, 401k with generous company match, flexible spending accounts, employee purchase program, employer-paid life insurance, voluntary-term life insurance, short and long-term disability, critical illness and accident benefits, and pet insurance. Yes, we care about your furry family too. *all benefits are dependent on employment status    Equal Opportunity Employer /AA Employer/Minorities/Women/Protected Veterans/Individuals with Disabilities Applicant Labor Law Posters We are Assembly – and we’re not like the rest. We’re the modern alternative agency, bringing together industry-leading data, talent, and tech to Find the Change That Fuels Growth for the best brands on the planet, including LG, Adobe, Ralph Lauren, Moncler, Aesop, and more. Our diverse, global community of over 1,600 passionate experts combines global thinking with unmatched local expertise in more than 20 markets worldwide – enabling brands to engage and move consumers anywhere. We use STAGE, Assembly’s proprietary, privacy-centric data solutions platform, to surface powerful insights that transform into actionable brand opportunities. We’re at the cutting edge of new media, technology, and platforms embedded in the lives of today’s consumers, and we’re tapped into how culture and communities’ needs change. We do this while staying steadfast in our commitment to Leave the World Better Than We Found It through measurable social and environmental impact work. Assembly was named The Drum’s APAC Media Agency of the Year in 2021 This role is a central position for the Hong Kong office as that person supports all the existing team on data and analytics topics. The role is also part of a larger regional data team that includes Analytics, BI and Data Science. The role is focused on analytics but not limited to it, the person will have the opportunity to work with SQL servers and cloud platforms. Requirements WHAT YOU’LL BE DOING ON ANY GIVEN DAY  The BI Analyst will be responsible for; Support and coordinate with the web analytics team and BI team on day to day challenges encountered on datasets and perform different data analytics tasks on different platforms. Assist senior team members to troubleshoot data discrepancy issues and solve ad-hoc requests from the clients. With data managers’ guidance, manage reports and datasets from various channels and platforms, including (but not limited to) various mainstream media platforms such as Google and Bing, and analytics platform such as GA and AA. This includes setting up processes to pull data from platforms and channels, managing data sources, processing and manipulating the data and consolidating data across multiple data sources in SQL databases Work with the team to manage, modify, QA, and incorporate any additional data sources upon clients’ data requirements. Build, manage, modify and maintain dashboards. Support regular reports and presentations with key findings, observations, data insights and recommendation Create, manage and improve new or existing datasets where needed. Addressing challenges or opportunities presented by clients or teams and creating bespoke solutions using technology  The role will have the potential to span all existing channels (including but not limited to display, paid social, organic performance, affiliates, content creation and localisation) as well as working on standalone propositions and new services centred around the use of structured data. DOES THIS SOUND LIKE YOU? Must have good understanding of SQL and able to write queries Strong analytical individual who enjoys lateral thinking and problem solving Attention to detail with the ability to effectively troubleshoot issues across various data sources and platforms Data driven approach to optimisation and testing to show full value of changes Proactive individual who is confident taking the initiative and working with colleagues across teams and departments Experience working with and consolidating multiple data sources (direct from engines, google sheets, FTP, HTTP etc.) Proactive, motivated, self starter and willing to learn Fluent in English, any other language is a plus Benefits WHY ASSEMBLY? We’re part of Stagwell, the challenger network built to transform marketing. We’re nimble, smart, and digital-first, and we’re quickly growing to take on the biggest legacy hold cos. We care about your growth – we offer competitive salaries, annual compensation reviews, and keep detailed personal development plans to ensure you’re hitting your personal and company goals. We recognize and celebrate your success…all the time! Whether it’s through company meetups, employee recognition programs, or just a regular day, we make sure our people’s achievements are known and appreciated! We’re truly a people-first organization. That’s why we offer a Flexible Time Off policy that puts you in control of your work-life balance, as well as market-leading primary and secondary caregiver and parental leave policies. We care about social and environmental Impact – we have dedicated Impact Champions that collaborate globally to make sure we’re leaving the world better than we found it. We have an amazing group of employee resource groups committed to guiding the agency to become more inclusive, diverse, and representative of the world around us. Sound like the right role for you? Click to apply now! Unternehmensbeschreibung Die Bosch Sensortec GmbH ist ein international führender Anbieter von Sensorlösungen auf der Basis mikroelektromechanischer Systeme (MEMS) im Bereich der Unterhaltungselektronik. Wir entwickeln und vermarkten Schlüsseltechnologien für Smartphones und Tablets, Hearables, Wearables, Smartglasses, Augmented und Virtual Reality Anwendungen, Spielkonsolen und vieles mehr. Unsere Sensoren verbessern das Wohlbefinden und den Lebensstil der Menschen und ermöglichen Applikationen der Unterhaltungselektronik die Welt um uns herum wahrzunehmen. MEMS-Sensoren sind somit ein wesentlicher Bestandteil der Basis einer vernetzten Welt. Die Bosch Sensortec GmbH ist eine hundertprozentige Tochtergesellschaft der Robert Bosch GmbH.                                          Die Bosch Sensortec GmbH freut sich auf Ihre Bewerbung! Stellenbeschreibung Als Teil unseres Teams gewinnen Sie einen Einblick in unsere Abteilung, verantwortlich für die Entwicklung zukünftiger Intertialsensoren und Sensorsysteme im Bereich Consumer Electronics. Wir implementieren technische Innovationen und ermöglichen dadurch herausragende Sensorsystemeigenschaften und stellen die zuverlässige Systemintegration und Testdurchführung für die Serienproduktion sicher. Sie unterstützen bei Vorbereitung, Durchführungen und Auswertung von Inertial Sensor Messungen   Sie sind zuständig für die Definition und Implementierung der Auswertung von umfangreichen Charakterisierungs- und Erprobungsdaten mittels Werkzeugen aus dem Bereich Big Data Analytics & Data Science und entwickeln kreative Lösungen in Python, Knime, Tableau oder Power BI Sie unterstützen bei der Entwicklung datengetriebener Konzepte und Algorithmen zur Verbesserung von ausgewählten Leistungsmerkmalen und verifizieren diese anhand Labormessungen Sie verfolgen die Abstimmung und Harmonisierung der entwickelten Lösungen mit Abteilungs- und Firmenweiten Big Data Teams Sie sind Teil eines internationalen und multikulturellen Entwicklungsteams Qualifikationen Persönlichkeit: Kommunikative Kompetenz und kreatives Denken, sowie Teamgeist Arbeitsweise: Selbstständige, strukturierte und analytische Arbeitsweise Erfahrungen und Know-How: Erfahrung mit Big Data oder Machine Learning / KI. Qualifikation: Verständnis von Werkzeugen der Datenverarbeitung und Visualisierung (z.B. Knime, Power BI, Tableau). Gute Kenntnis einer Programmiersprache, bevorzugt Python. Sprachen: Gute Englischkenntnisse, Deutschkenntnisse sind wünschenswert Ausbildung: Laufendes Master-Studium der Informatik, Mathematiker, Physik oder eine vergleichbare Ausbildung Zusätzliche Informationen Das Bosch PreMaster Programm (GapYear Programm) ist ein zweistufiges Qualifizierungsprogramm für engagierte Bachelor-Absolventinnen und Absolventen, die das Ziel haben, ein Masterstudium zu absolvieren. Nach dem Bachelor bietet die erste Phase bis zu 12 Monaten praktische Erfahrung, um die fachlichen und unternehmerischen Zusammenhänge kennenzulernen. Die zweite Phase umfasst das Masterstudium und beinhaltet weitere Events und Seminare sowie persönliche Betreuung durch einen Mentor auf dem Weg zum erfolgreichen Abschluss. Beginn: nach Absprache Vielfalt und Inklusion sind für uns keine Trends, sondern fest verankert in unserer Unternehmenskultur. Daher freuen wir uns über alle Bewerbungen: unabhängig von Geschlecht, Alter, Behinderung, Religion, ethnischer Herkunft oder sexueller Identität. Sie haben Fragen zum Bewerbungsprozess? Samuel Zinn (Personalabteilung) +49 7121 35-33717 Sie haben fachliche Fragen zum Job? Holger Wüst (Fachabteilung) +49 7121 35-31522 Weitere Information auch online unter: https://www.bosch.de/karriere/dein-einstieg/absolventinnen-und-absolventen/premaster-program/ Who we are About Stripe Stripe is a financial infrastructure platform for businesses. Millions of companies—from the world’s largest enterprises to the most ambitious startups—use Stripe to accept payments, grow their revenue, and accelerate new business opportunities. Our mission is to increase the GDP of the internet, and we have a staggering amount of work ahead. That means you have an unprecedented opportunity to put the global economy within everyone’s reach while doing the most important work of your career. About the team Our mission is to deliver insightful analyses and durable data products to anticipate and inform the right decisions at the right time about Stripe's cloud, security and tech enablement infrastructures. What you’ll do You will work with our Security Analytics and Detection team, which is committed to promoting data security and protecting Stripe from internal and external threats to its assets and infrastructure.  We’re looking for talented candidates who can leverage data science to build out security capabilities with an emphasis on application security and vulnerability management. Your work will be critical to reducing risks and promoting trust and integrity within Stripe. Responsibilities  Research, develop, design, and build models for threat detection, guiding processes for signal ingestion, data analytics, and automation to improve detection and investigation of potentially malicious activity; Work cross-functionally with data science, software development, and security engineering teams to architect solutions for analyzing security events data at scale and protecting Stripe networks, systems, and data from external threats; Build statistical, machine learning, and simulation models on large datasets, including unstructured data from disparate sources; Drive the creation, collection and processing of new data and the enrichment of existing data sources (e.g., log data, network, host-based telemetry, etc.); Develop technical and functional requirements to deploy novel detection and vulnerability identification capabilities that mitigate emergent and current threats; Provide actionable insights to stakeholders to help identify, prevent, and detect anomalous usage of Stripe’s endpoints; Act as a force multiplier for quantitative methods in our Security organization and help train and mentor engineers on statistical techniques. Who you are We’re looking for a data scientist with security experience who is excited about applying their analytical skills to develop methods, systems and processes to protect Stripe from external threats and vulnerabilities. If you are naturally data curious, enjoy deriving insights from data, and motivated by the opportunity to build engineering solutions from the ground up that significantly impact the business, we want to hear from you! Minimum requirements 5+ years experience working with security-related information and analyzing large data sets to solve problems. A PhD or MS in a quantitative field (e.g., Applied Mathematics, Computer Science, Statistics, Engineering, Natural Sciences). A proven track record of translating large and ambiguous business problems in mathematical models and developing data scientific solutions. Existing experience with network security, digital forensics, and incident response. Expert knowledge of Python and SQL, and familiarity with other programming languages (R, Go, Scala). Proficiency with popular open-source machine learning frameworks (scikit-learn, MLlib, pytorch, tensorflow, xgboost, etc.). Strong knowledge of statistics and machine learning. Ability to communicate results clearly and focus on impact. Ability to think creatively and holistically about reducing risk in a complex environment. Experience developing foundational and diverse data sources, and generating metrics to measure service and program effectiveness. Passion for mentoring others and building a data science and security community. Preferred qualifications Experience influencing high-impact decisions. Strong project management and organizational skills. Proficiency in taking data-driven approaches to detection, building and automating solutions rather than relying on third party off-the-shelf products. Experience with data-distributed tools (Scalding, Spark, Hadoop, DataBricks, dbt, etc.). An adversarial mindset, understanding the goals, behaviors, and TTPs of threat actors. Familiarity with network observability or security software (Uptycs, Icebrg, Splunk, etc.). Knowledge of network protocols (DNS or HTTPS) and understanding of cloud computing services/deployment architecture. Working knowledge of complex distributed machine learning systems deployed at scale in a cloud computing environment. Experience in one or more of the following areas: security information event management (SIEM), enterprise risk management (ERM), common weakness enumeration (CWE), and/or fraud detection. Who We Are Founded in 2005, 2K Games is a global video game company, publishing titles developed by some of the most influential game development studios in the world. Our studios responsible for developing 2K’s portfolio of world-class games across multiple platforms, include Visual Concepts, Firaxis, Hangar 13, CatDaddy, Cloud Chamber, and HB Studios. Our portfolio of titles is expanding due to our global strategic plan, building and acquiring exciting studios whose content continues to inspire all of us! 2K publishes titles in today’s most popular gaming genres, including sports, shooters, action, role-playing, strategy, casual, and family entertainment. Our team of engineers, marketers, artists, writers, data scientists, producers, thinkers and doers, are the professional publishing stewards of our growing library of critically-acclaimed franchises such as NBA 2K, Battleborn, BioShock, Borderlands, The Darkness, Mafia, Sid Meier’s Civilization, WWE 2K, and XCOM. At 2K, we pride ourselves on creating an inclusive work environment, which means encouraging our teams to Come as You Are and do your best work! We are dedicated to diversity and inclusion, and want our community of candidates to reflect this commitment. We encourage all qualified applicants to explore our global positions. 2K is headquartered in Novato, California and is a wholly owned label of Take-Two Interactive Software, Inc. (NASDAQ: TTWO). What We Need As we grow our slate of mobile titles, we are growing our marketing data science group and looking for an experienced data scientist. This person will be focused on mobile marketing analytics and will be working on crunching data, building predictive models, extracting insights & sharing findings with broad audiences.  This role will be a 12-month contract with potential to go perm, but absolutely no guarantees.  What You Will Do Reporting into the Senior Manager of Mobile Analytics, you will Business Insight: Work closely with marketing teams, recognize the real problem our marketing teams want to solve for, and then define the right data, metrics, analysis and interpretation to lead to the right recommendations and decisions. Reporting: Develop and improve our marketing performance reporting platform; enabling teams across the company to make data informed decisions. Innovate: Define requirements for, create, continuously monitor and improve key statistical models needed for making marketing spend decisions. Communication: Design clear and unambiguous narratives, visualizations to report analyses, models and reports developed by the team. These solutions should be easy to understand and use for making decisions. What Will Make You (a Phenomenal Fit) The ideal candidate will be able to see the underlying story in the data, build sophisticated or simple models depending on the situation, and develop a compelling communication to the business. Someone who is hypothesis driven and has experience using data-driven techniques to test the hypotheses rigorously. Being a solution oriented, creative problem solver; a self-starter with the passion and enthusiasm to get results for substantial change is critical for this role. BSc, MSc or PhD in Mathematics, Statistics, Economics, Computer Science, Data Science, Engineering, Sciences (or in another quantitative field). 4+ years of experience in data mining & analytics, building models with sophisticated and multi-dimensional data sets using R or Python. Experience in relational databases, SQL data carpentry. We use Snowflake for our data warehouse. Excellent communication skills, with a proven track record of working across all levels of the organization. Demonstrated ability to work independently, rapidly prototyping and testing new insights with little mentorship. Drive to solve problems, meet expectations, and build whatever is vital along the way. Experience understanding the strengths and weaknesses of different modeling approaches and can effectively reason about when to apply different combinations and iterate. Bonus Points Experience with data visualization tools a plus, Tableau preferred. Mobile games industry experience and/or gaming familiarity. Experience working with paid and unpaid marketing channels is desirable. As an equal opportunity employer, we are committed to ensuring that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform their essential job functions, and to receive other benefits and privileges of employment. Please contact us if you need reasonable accommodation. Please note that 2K Games and its studios never uses instant messaging apps or personal email accounts to contact prospective employees or conduct interviews and when emailing, only use 2K.com accounts.     Please note that 2K Games and its studios never uses instant messaging apps or personal email accounts to contact prospective employees or conduct interviews and when emailing, only use 2K.com accounts.     #LI-Hybrid Descripción de la empresa Passionate about digital, data, IoT or AI and willing to join a dynamic and ambitious team on a human scale? For more than 15 years, we have been advising companies and administrations and supporting them in the implementation of their transformation projects in Spain and abroad., around Europe and overseas, with operations around the world with nearly 6,000 consultants so far. To do so, we rely both on technological leverage and on the strength of our DNA based on collective intelligence, agility and entrepreneurial spirit. With a presence on five continents and more than 3,500 employees, our goal is to reach more than a €1 billion revenue by 2024. Innovation is at the heart of our development, and we are involved in areas linked to the technological changes of major groups, such as Big Data, IoT, Blockchain and Artificial Intelligence. Talan is looking for a candidate willing to work in the banking field as a Solution Architect We are looking for a person with the commitment to stay long term with us, with a previous experience in the sector of +5 years of experience, aiming to start a new international challenge based in Malaga, southern Spain. Descripción del empleo Develop and implement pipelines that extract, transform, and load data into an information product that helps the organization reach its strategic goals Focus on ingesting, storing, processing, and analyzing large datasets Create scalable, high-performance web services for tracking data Translate complex technical and functional requirements into detailed designs  Investigate alternatives for data storing and processing to ensure implementation of the most streamlined solutions Serve as a mentor for junior staff members by conducting technical training sessions and reviewing project outputs Requisitos Required skills and qualifications Experience with Python, Spark, and Hive Understanding of data-warehousing and data-modeling techniques Knowledge of industry-wide visualization and analytics tools (ex: Tableau, R) Strong data engineering skills with Azure cloud platform Experience with streaming frameworks such as Kafka Knowledge of Core Java, Linux, SQL, and any scripting language  Good interpersonal skills and positive attitude Preferred skills and qualifications Degree in computer science, mathematics, or engineering Expertise in ETL methodology for corporate-wide solution design using DataStage Información adicional Responsibilities Develop and maintain data pipelines using ETL processes Take responsibility for Apache Hadoop development and implementation Work closely with data science team to implement data analytics pipelines Help define data governance policies and support data-versioning processes Maintain security and data privacy, working closely with data protection officer Analyze vast number of data stores to uncover insights We are looking for a Spark developer who knows how to fully exploit the potential of our Spark cluster. You will clean, transform, and analyze vast amounts of raw data from various systems using Spark to provide ready-to-use data to our feature developers and business analysts. This involves both ad-hoc requests as well as data pipelines that are embedded in our production environment. Requirements Roles and Responsibilities Responsible for systems analysis - Design, Coding, Unit Testing and other SDLC activities Requirement gathering and understanding, Analyze and convert functional requirements into concrete technical tasks and able to provide reasonable effort estimates Create Scala/Spark jobs for data transformation and aggregation Produce unit tests for Spark transformations and helper methods Design data processing pipelines Work proactively, independently and with global teams to address project requirements, and articulate issues/challenges with enough lead time to address project delivery risks  Requirements 10 - 12 Years hands on experience. Experience with Apache Spark streaming and batch framework Scala (with a focus on the functional programming paradigm) Experience in Azure cloud platform and Data Bricks Experience with Pyspark Scalatest, JUnit, Mockito Spark query tuning and performance optimization Experience with Mongoldb database Experience with Kafka, Storm, Zookeeper Deep understanding of distributed systems (e.g. CAP theorem, partitioning, replication, consistency, and consensus) Consistently demonstrates clear and concise written and verbal communication Ability to work in a fast-paced environment both as an individual contributor and a tech lead Experience in Git Company Description Guardant Health is a leading precision oncology company focused on helping conquer cancer globally through use of its proprietary tests, vast data sets and advanced analytics. The Guardant Health oncology platform leverages capabilities to drive commercial adoption, improve patient clinical outcomes and lower healthcare costs across all stages of the cancer care continuum. Guardant Health has commercially launched Guardant360®, Guardant360 CDx, Guardant360 TissueNext™, Guardant360 Response™, and GuardantOMNI® tests for advanced stage cancer patients, and Guardant Reveal™ for early-stage cancer patients. The Guardant Health screening portfolio, including the Shield™ test, aims to address the needs of individuals eligible for cancer screening. Job Description The Screening Bioinformatics team at Guardant Health is focused on the development of products for the early detection of cancer in average-risk populations. This team works in close collaboration with assay scientists. We develop bioinformatics frameworks and apply statistical and machine learning methods to process raw multi-omic biological signals, identify relevant biomarkers and build predictive models for the detection of early-stage cancer. About the Role: We are looking for a bioinformatics intern to join the algorithm development team within Screening Bioinformatics this summer. The successful candidate will work at the forefront of research and technological development within the interdisciplinary Screening Bioinformatics team and will make core contributions to evolving products designed to have a clinical impact on patients. Essential Duties and Responsibilities: The intern position is with the bioinformatics group and will work on developing computational models for the early cancer screening product. The major responsibilities include: Develop and analyze performance of novel statistical models Provide written documentation and specifications for transparency and reproducibility Qualifications Must be currently enrolled in a PhD program in computational biology/bioinformatics, biostatistics, statistical genetics, machine learning, or related fields Experience working with statistical models for genomic, epigenomic, or proteomic data Proficiency with a high-level scripting language (Python/R; Python preferred) Proficiency with Linux command-line and version control tools (git and GitHub) Familiar with high-performance computing infrastructures (e.g., SGE, SLURM, AWS, Spark) Effective at communicating findings to cross-functional teams Preferred Qualifications: Graduating within 1-2 years Experience in analyzing public genomic/epigenomic datasets (e.g. TCGA, ENCODE) Cancer biology background Ability to build reproducible and well-written code (or packages) for data analysis Experience working with single-cell data Additional Information Hybrid Work Model: At Guardant Health, we have defined days for in-person/onsite collaboration and work-from-home days for individual-focused time. All U.S. employees who live within 50 miles of a Guardant facility will be required to be onsite on Mondays, Tuesdays, and Thursdays. We have found aligning our scheduled in-office days allows our teams to do the best work and creates the focused thinking time our innovative work requires. At Guardant, our work model has created flexibility for better work-life balance while keeping teams connected to advance our science for our patients. Covid Vaccination Policy:  Guardant Health requires all employees to be fully vaccinated. We follow the CDC guidelines for the definition of “fully vaccinated”, meaning an employee is consider fully vaccinated against COVID-19 after receiving the second dose of a two-dose vaccine or one dose of a single-dose vaccination, and necessary booster vaccines. In addition, fully vaccinated employees will be required to maintain their fully vaccinated status under this policy by obtaining, if applicable, any FDA-approved boosters. Candidates may request and obtain an approved exemption from Guardant’s COVID-19 U.S. Vaccination Policy as a reasonable accommodation, as consistent with applicable laws.  Candidates will not be able to start their employment with Guardant until they show proof of vaccination or have an approved exemption. For positions based in Palo Alto, CA or Redwood City, CA, the hourly range for this full-time position is Undergraduate $27/hr., Graduate $32/hr., and Doctorate $40/hr. The range does not include benefits and, if applicable, overtime, bonus, commission, or equity. Within the range, individual pay is determined by work location and additional factors, including, but not limited to, job-related skills, experience, and relevant education or training. If you are selected to move forward, the recruiting team will provide details specific to the factors above. Employee may be required to lift routine office supplies and use office equipment. Majority of the work is performed in a desk/office environment; however, there may be exposure to high noise levels, fumes, and biohazard material in the laboratory environment. Ability to sit for extended periods of time. Guardant Health is committed to providing reasonable accommodations in our hiring processes for candidates with disabilities, long-term conditions, mental health conditions, or sincerely held religious beliefs. If you need support, please reach out to Peopleteam@guardanthealth.com Guardant Health is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability. All your information will be kept confidential according to EEO guidelines.  To learn more about the information collected when you apply for a position at Guardant Health, Inc. and how it is used, please review our Privacy Notice for Job Applicants. Please visit our career page at: http://www.guardanthealth.com/jobs/ #LI-CS4 Unternehmensbeschreibung Fashion und Lifestyle, 6.500 Mitarbeiter:innen, 13 Department Stores, Online-Shops in Deutschland, Polen, Österreich, Belgien, Luxemburg, Spanien, den Niederlanden und der Schweiz, über 2000 Marken, 25 Restaurants & Confiserien, 15 erstklassige Services, drei Friseur-Salons und stets ein besonderes Einkaufserlebnis – das ist Breuninger. Ein Traditionsunternehmen, das internationale Wege geht, seine Ziele klar definiert und innovative Möglichkeiten schafft. Stellenbeschreibung Als BI Data Analyst:in verantwortest Du ein wachsendes Portfolio an Datensichten im E-Commerce. Du ermöglichst für die Fachbereiche (u. a. Onlinemarketing, Web- und Marketing-Analytics, Category Merchandising) den effektiven und sinnvollen Zugang zu unseren Datenwelten Du stellst zentrale Daten nicht nur in Form von Dashboards und Reports zur Verfügung, sondern findest konsequent aus dem breiten Köcher an Möglichkeiten das richtige Mittel, um die individuellen Daten-Needs der Stakeholder zu beliefern Dabei berätst Du die Fachbereiche im Anforderungsmanagement und verbesserst kontinuierlich die Self-Service-Fähigkeiten der Stakeholder:innen Mit Deiner Expertise im Bereich Datenmodellierung bist Du gleichzeitig im Sattel, was den Unterbau deiner Datensichten betrifft und treibst die angeforderten Projekte selbstständig voran Darüber hinaus unterstützt Du mit Deinem Weitblick und Gespür für aktuelle Entwicklungen und für den Business Need bei der Verfeinerung und Operationalisierung unserer Daten-Strategie Qualifikationen Du verfügst über ein erfolgreich abgeschlossenes Studium der Wirtschaftswissenschaften, Wirtschafts-/ Medieninformatik, BWL, Mathematik, Statistik oder eine vergleichbare Qualifikation Du bringst einschlägige Berufserfahrung im Bereich Data Management oder Business Intelligence mit Du besitzt exzellente Fähigkeiten in der Analyse und Interpretation von komplexen Datenstrukturen Dich zeichnen eine hohe Expertise in SQL sowie gängigen Datenbank- und Visualisierungstools (PowerBI, Tableau, Sisense) aus Du bist ein:e Teamplayer:in, arbeitest eigenverantwortlich, ergebnisorientiert und übernimmst gerne Verantwortung für Veränderung Zusätzliche Informationen Bei uns erhältst Du die Möglichkeit, in einem modernen, agilen sowie wertschätzenden Umfeld zu arbeiten. Fühlst Du Dich angesprochen? Dann findest Du bei Breuninger ein Team, in dem Du Dich wohlfühlen und nachhaltig wirken kannst. Eine spannende Herausforderung in einem innovativen und gleichzeitig traditionsreichen Unternehmen Attraktives Gehaltspaket mit freiwilligen Sozialleistungen wie Urlaubs- und Weihnachtsgeld sowie 30 Tage Urlaub Eine große Verantwortung und Raum für eigenen Ideen 30% Mitarbeiterrabatt auf das gesamte Sortiment gemäß den aktuellen betrieblichen Bestimmungen Hochmotivierte Kolleg:innen in einem tollen Team Persönliche und fachliche Entwicklungsmöglichkeiten Haben wir Dein Interesse geweckt?  Dann sollten wir uns schnell kennenlernen! Wir freuen uns auf Deine aussagekräftige Online Bewerbung mit Angabe Deiner Verfügbarkeit sowie Gehaltsvorstellung. Impressum Want to be part of an amazing team, hell-bent on crafting a better future? We’re always looking for creative people who care! We are analysts. Creators. Designers. Doers. Dreamers. Explorers. Geeks. Hipsters. Leaders. Learners. Renegades. Seekers. Strategists. Visionaries. And we fundamentally believe that we’re better together. We are looking for an Power BI Developer to join our tech client’s reliability and quality team.  Would you like to…  Experience with Power Platform (specifically power apps and power automate).  Experience integrating multiple Power Apps. Experience with relational databases such as SQL and Dataverse.  Some Power BI experience.   Ability to work with multiple stakeholders as part of a Developer team and as an individual with our partner team process, technical and business managers.  working in workshops to be able influence the code and bridge the gap btwn requirement and technical solution We would like you to have… Power Automate and Power Apps Power Platform, integrating with Power Apps 3-5 years Relational Databases SQL, different data sources Power BI  Would you like to work for an organization that… Embraces work-life balance – our employees’ well-being remains a top priority for us Promotes a culture of learning and advocacy across the globe - diversity will enable us to strengthen our impact Offers a comprehensive benefits package effective Day 1. Options include health, vision, & dental insurance, FSAs, discounts on pet insurance, PTO, paid holidays, and more Encourages innovation and experimentation Emphasizes and rewards collaboration Works remotely. We continue to safeguard the health of our employees so our interviewing and on-boarding process will remain virtual until further notice Want to know more? Check us out at https://www.designit.com/. Just so you know, we don’t have a dress code, but we do have a strict no jerk policy. Designit is committed to ensuring that all candidates have an equal opportunity to be considered for employment. Please let us know if you need any reasonable accommodation to participate in the job application or interview process.  Company Description Wood Mackenzie is the global leader in data, analysis and consulting across the energy, chemicals, metals, mining, power and renewables sectors.   Founded in 1973, our success has always been underpinned by the simple principle of providing trusted research and advice that makes a difference to our customers. Today we have over 2,000 customers ranging from the largest global energy companies and financial institutions to governments as well as smaller market specialists.   Our teams are located around the world. This enables us to stay closely connected with customers and the markets and sectors we cover. Collectively this allows us to offer a compelling combination of global commodity analysis with detailed local market knowledge.   We are committed to supporting our people to grow and thrive. We value different perspectives and aspire to create an inclusive environment that encourages diversity and fosters a sense of belonging. We are committed to creating a workplace that works for you and encourage everyone to get involved in our Wellness, Diversity and Inclusion, and Community Engagement initiatives. We actively support flexible working and are happy to consider alternative work patterns, taking into account your needs and the needs of the team or division that you are looking to join.    Hear what our team has to say about working with us:   https://www.woodmac.com/careers/our-people/  We are proud to be a part of the Verisk family of companies!   At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.     Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.    But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.    It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.     At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.   At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career.  We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.   Job Description You will be a valuable member of the Wood Mackenzie’s Chemicals Global Analyst Team. This team sits within the Research function and helps produce detailed market supply-demand, cost and price forecasts at the regional and global levels. It is also a key enabler in Wood Mackenzie’s purpose to transform the way we power our planet. As a Research Analyst in the Chemicals Global Analyst Team, you will contribute to high-quality research in the form of thought-provoking reports,  presentations, and articles. You will be a valuable member of Wood Mackenzie’s Chemicals Global Analyst Team. You will also help build new products and services as we embark into the new wave of growth for the Chemicals business and Wood Mackenzie in general. Through your research and responding to client queries, you will expand your network of contacts at key companies and industry associations. You will develop a unique perspective and understanding of the chemicals industry, including the challenges and opportunities it is facing in facilitating the global energy transition. Your contribution to our industry-leading written reports, supply-demand models and presentations will be valued. #LI-GW1 Qualifications About you and how you can excel in this role You have a keen interest in commodity market dynamics and you want to develop further your understanding of the Plastics and Sustainability industry and related sectors. You have an analytical mindset and an eye for detail, which have been proven in your academic and/or work experience to date. You are comfortable collecting and interpreting data, articulating your findings in a clear and insightful manner. You are curious and seek to clarify and enhance your knowledge. You also have a flair for writing and communication and confidence in presenting to an audience. You are a highly adaptive team player and embrace fast-paced environments with frequent change. You are excited to be part of a team that gives you opportunities to work cross-functionally on a variety of tasks. The way in which you work is productive and driven, striving to be best in class. Ultimately, you are looking for an opportunity to develop the skills to become an industry-recognised subject matter expert. You have an excellent command of English, both written and spoken. Knowledge of at least one other language would be an advantage. You also have a good working knowledge of the Microsoft Office suite, particularly Excel and PowerPoint.  Additional Information Verisk Analytics is an equal opportunity employer. All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability. http://www.verisk.com/careers.html Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume. Unternehmensbeschreibung Möchten Sie Ihre Ideen in nutzbringende und sinnvolle Technologien verwandeln? Ob im Bereich Mobility Solutions, Consumer Goods, Industrial Technology oder Energy and Building Technology – mit uns verbessern Sie die Lebensqualität der Menschen auf der ganzen Welt. Willkommen bei Bosch.                                              Die Robert Bosch GmbH freut sich auf Ihre Bewerbung! Stellenbeschreibung Du verfügst über tiefgehendes Wissen in Technologie, Architektur und Betrieb von Big Data Plattformen in der Enterprise IT und in Public Clouds. Du steuerst den gesamten Produktlebenszyklus unserer Big Data Plattform und koordinierst ein globales Team. Die Industrialisierung neuer Big Data Technologien, -Funktionen und -Module, sowie die Evaluierung zukünftiger Big-Data-Plattformen liegt in Deiner Verantwortung. In enger Zusammenarbeit mit Product Service Ownern, Architekten, Kunden und Herstellern definierst Du die Big Data Strategie und entwickelst die bestehenden Big Data Services für Bosch weiter. Du begleitest die Projekte von der Konzeption über die Pilotphase bis hin zum Produktiveinsatz. Du berätst die Bosch-Stakeholder, das IT-Management sowie die Produkt- und Solution-Teams bei der Entwicklung von Big Data Technologien und -Architekturen. Qualifikationen Ausbildung: Abgeschlossenes Hochschulstudium (Master/Diplom/Promotion) in Informatik, Informationstechnologie, Ingenieurwesen oder vergleichbarer Fachrichtung Persönlichkeit: Kommunikativ, teamfähig, zielorientiert und interkulturell offen Arbeitsweise: Strukturiert, selbständig und analytisch Erfahrungen: Mehrjährige praktische Berufserfahrung als Big Data Experte, vorzugsweise im Hadoop Ökosystem, sowie mehrjährige Erfahrung in der Durchführung größerer internationaler Projekte oder Führung internationaler Team Know-How: Tiefgehende Erfahrung in Big Data Betrieb, -Design und -Architekturen, sowie in Cloud-basierten Big Data Anwendungen Sprachen: Sehr gute Deutsch- und Englischkenntnisse Zusätzliche Informationen In diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente. Bewirb Dich jetzt in nur 3 Minuten! Du willst Remote oder in Teilzeit tätig sein - wir bieten tolle Möglichkeiten des mobilen Arbeitens sowie unterschiedliche Teilzeitmodelle. Sie haben Fragen zum Bewerbungsprozess? Anna Haas (Personalabteilung) +49 711 811 52750 Sie haben fachliche Fragen zum Job? Hannes Hannak (Fachabteilung) +49 711 811 19094 What if… you could join an organization that creates, resources, and builds life sciences companies that invent breakthrough technologies in order to transform health care and sustainability? Metaphore Biotechnologies is an early-stage biotechnology company with an ambitious and exciting mission: to reimagine drug discovery and vaccine design. The company is developing a first-in-class platform for the intelligent design of molecular mimicry. Our platform integrates massively parallel assays with machine-learning-guided protein engineering to navigate the combinatorial space of molecular interactions and design protein-protein interfaces with exquisite precision. Metaphore Biotechnologies is a product of Flagship Pioneering's venture creation engine, which has also given rise to companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune’s “Change the World” list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies. Position Summary: Metaphore Biotechnologies is seeking an enthusiastic Senior Scientist to join our Computational Biology team and accelerate the design of protein-protein interfaces.  In this role, you will collaborate closely with members of the Computational Biology and Protein Engineering teams to advance our use of next-generation sequencing-based mutational assays to characterize and engineer molecular interactions.  Your scientific-rigor and creativity will advance our platform, unlocking the potential of molecular mimicry for therapeutic development.  The ideal candidate will bring experience in mutational screening, bioinformatic pipelines design and analysis, and experience implementing robust data standards.  This individual will have the opportunity to join a dynamic interdisciplinary team working at the interface of computational biology, protein engineering, functional genomics and machine learning. The candidate will also have an extraordinary opportunity to be part of the Flagship ecosystem of companies, providing unique networking benefits through regular meetups, collaboration, and an environment of development and discussion around new ideas shaping the fields of computational biology and ML/AI. Key Responsibilities: Provide scientific and technical expertise in the analysis and interpretation of NGS-based mutational screens. Contribute to the continuous development of scientifically rigorous next-generation sequencing (NGS) pipelines. Develop and implement computational frameworks to derive biological insights from data, such as mapping key residues for molecular interactions and estimating interaction kinetics. Collaborate on experimental design to establish and maintain high data quality standards and confidence in results. Leverage internal and external datasets to aid in interpretation and further develop our ML-guided protein engineering platform. Collaborate with computational and experimental scientists and engineers to execute on company goals. Communicate insights and conclusions to scientific colleagues and the leadership team. Qualifications: PhD or equivalent, plus 3+ years of experience in computational biology, bioinformatics, or a related field. Experience developing robust quantitative NGS-based pipelines in a cloud platform.  Familiarity with AWS, docker and snakemake is a plus. Experience with screening or highly parallel protein engineering workflows is highly desired. Prior experience in automated noise thresholding is a plus. Very strong programming skills in python and knowledge of software development best practices. Excellent communication skills and capable of clearly conveying technical information. Experience collaborating with wet lab scientists to jointly execute on goals. Strong organization and problem-solving skills. Experience with machine learning of biomolecules is a plus. Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto. Company Description At Palo Alto Networks® everything starts and ends with our mission: Being the cybersecurity partner of choice, protecting our digital way of life. We have the vision of a world where each day is safer and more secure than the one before. These aren’t easy goals to accomplish – but we’re not here for easy. We’re here for better. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are. We’re changing the nature of work. Palo Alto Networks is evolving to meet the needs of our employees now and in the future through FLEXWORK, our approach to how we work. From benefits to learning, location to leadership, we’ve rethought and recreated every aspect of the employee experience at Palo Alto Networks.  And because it FLEXes around each individual employee based on their individual choices, employees are empowered to push boundaries and help us all evolve, together. Job Description Your Career Prisma Access™ (formally GlobalProtect Cloud Service) provides protection straight from the cloud to make access to the cloud secure. It combines the connectivity and security you need - and delivers it everywhere you need it. Using cutting-edge public and private cloud technologies extending the next-generation security protection to all cloud services, customers on-premise remote networks and mobile users. We’re building a world-class data analytics platform for Prisma Access. Our software stack spans multiple platforms and technologies. If you have a proven data engineering background and a broad software development skill set, and enjoy working on products with a diverse tech-stack, then this position could be the perfect fit. Your opportunity: Create and maintain optimal big data pipeline architecture Identify, design, and implement data processing improvements - optimizing data delivery, re-designing infrastructure for greater scalability, etc Rapidly prototype ideas in an agile team with quickly evolving requirements Maintain high quality standards and promote best practices within the team Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and/or other cloud-provider (e.g. AWS, GCP) technologies Build analytics tools that utilise the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics Create data tools for analytics and data scientist team members that assist them in building and optimising our product into an innovative industry leader Work with data and analytics experts to strive for greater functionality in our data systems Qualifications Your Experience: We are looking for a candidate with 5+ years of experience in a Data Engineering role, who should also have experience using the following software/tools: Experience with relevant big data tools (e.g. Beam, Spark, Kafka, etc) Experience with relational SQL and NoSQL databases, e.g. MySQL, Postgres and MongoDB, etc. Experience with various, related AWS and GCP cloud services: EC2, EMR, RDS, Redshift, Pub/Sub, BigQuery, DataFlow In addition, we’re looking for candidates with the following experience and skills: 4 year Computer Science Bachelor's degree (or equivalent) Strong Java software-development expertise An excellent working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases Experience building and optimizing ‘big data’ data pipelines, architectures and data sets A conceptual thinker who can articulate and execute a vision from concept to production Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores Strong understanding of cloud infrastructure (e.g. AWS, GCP) products, services and technologies Strong analytic skills related to working with unstructured datasets Excellent communication skills (written and verbal) Experience supporting and working with cross-functional teams in a dynamic environment Excellent problem-solving skills Candidates with experience in multiple programming languages and other platforms will be highly regarded. Additional Information The Team Our engineering team is at the core of our products – connected directly to the mission of preventing cyberattacks. We are constantly innovating – challenging the way we, and the industry, think about cybersecurity. Our engineers don’t shy away from building products to solve problems no one has pursued before. We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment. Our Commitment We’re trailblazers that dream big, take risks, and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together. We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at accommodations@paloaltonetworks.com. Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics. Covid-19 Vaccination Information for Palo Alto Networks Jobs Vaccine requirements and disclosure obligations vary by country. Unless applicable law requires otherwise, you must be vaccinated for COVID or qualify for a reasonable accommodation if: The job requires accessing a company worksite The job requires in-person customer contact and the customer has implemented such requirements You choose to access a Palo Alto Networks worksite If you have questions about the vaccine requirements of this particular position based on your location or job requirements, please inquire with the recruiter. Kuda is a full service, app-based digital bank. Our mission is to be the go-to bank not just for those living on the African continent, but also for the African diaspora wherever they might live, anywhere in the world. Kuda is free of ridiculous banking charges and great at helping customers budget, spend smartly and save more. We raised the largest seed round ever seen in Africa, and completed a Series A funding round in February 2021, led by some of the world's smartest venture capital investors. With offices in London (our HQ), Lagos and Cape Town, and further offices opening across Africa during 2021, Kuda is fast becoming recognised as the leading 'Neobank' for Africans. To help us grow into the company that can bring meaningful change to the way people across Africa get access to great financial products and services in order to take control of their personal finances, we are actively looking for bright, talented, driven people who are excited by our mission. If this sounds like a great way to spend your valuable time, then please get in touch with us.  Role overview: We’re looking for a passionate BI Analyst that can apply their data Illustrative and reporting skills to translate complex information into meaningful insights. Excelling in critical thinking, ensuring all data problems are solved. You must be able to transform data, gain understanding and use that insight to dig deeper and present a straightforward data story. Must be conformable, communicating findings and insight across multiple business levels. If you are passionate about data and applying yourself to business challenges excites you, we would love to hear from you. Roles and Responsibilities: Design, build, and maintain business intelligence solutions to elevate and showcase data-to-decision across the entire business Collaborate with product and business stakeholders to define how best to measure, monitor and understand customer behavior and product performance Develop compelling information visualizations and dashboards Deliver strategic initiatives to improve the quality and timeliness of data insights Deliver continuous optimizations strategies that continuously re-invent data products and insights Analyze business processes and analytical requirements that assist with decision-making processes Requirements 3+ Years of experience in a Business Intelligence and/or Data Analyst role, with a focus on analyzing and understanding business problems Strong knowledge and proven experience using SQL Strong knowledge of and experience with tools like Looker, QlikView, Tableau or PowerBI Prior experience in designing and implementing performance measures to track business or product KPIs A fundamental in identifying patterns or regions in products or behaviors that indicate opportunities for business process improvement Excellent analytical and forecasting ability Strong written and verbal communication skills Understand current data protection and privacy laws, e.g., GDPR A degree in the information technology field (e.g., Statistics, Economics, Math, Science, Engineering) Advantageous: Experience working in AWS, Google Cloud or Azure Using dbt Cloud to perform data modelling. Experience using BigQuery data capabilities Good understanding of the software development process and best practices Benefits Why join Kuda? Become a part of one of the trailblazers in the challenger banking arena by joining the exciting and ambitious team at Kuda Bank as we work to become the neobank for ‘every African on the planet’. An exciting and flexible work environment Competitive pay Smart and kind coworkers Full pension contribution Reliable health insurance Payment Systems BI Data Analyst About the team: At the Capco Technology Delivery Center, we are dedicated to the financial services industries. Our professionals combine innovative thinking with unrivalled industry and domain expertise to offer our clients consulting expertise, complex technology and package integration, transformation delivery, and managed services, to move their organizations forward. Through our collaborative and efficient approach, we help our clients successfully innovate, increase revenue, manage risk and regulatory change, reduce costs, and enhance controls. Our teams stay at the forefront of industry trends and technologies that are driving innovation. From strategy to launch, we are adept at delivering across the full product lifecycle.  About the Job: As a member of the Capco Technology Delivery Team, you’ll bring practical knowledge of agile development methodologies and engineering best practices. As a Java Backend Developer, you’ll use your experience and skills to contribute to the quality and implementation of our software products for our customers. What You’ll Get to Do: Provide support for data requests from Compliance, Operations, Auditors and other parties. Focus will be on data related to payments systems and related ecosystems (e.g. Fed/Chips/Swift/Fircosoft).   Review and validate data requests.  Transform them into clear requirement documents. Generate data extractions and reports. Perform data analysis as required. Streamline the reporting process through the application of BI products.   Utilize query tools to confirm data quality and investigate questions. What You’ll Bring with You: 4+ plus years of relevant experience in BI Data Analyst role. Exposure to Payment systems including Swift, US clearing systems (FEDwire and CHIPS ) is preferred but not mandatory. Experience in Financial security  : Sanction filtering and AML is preferred but not mandatory. Should be well versed with reporting technologies like – MS SQL, Oracle, BI related tools (MS Power BI, Tableau, etc.) Exposure to audits on the domain would be a real plus. Willingness to work out of the NYC office 3 days per week. Why Capco? A career at Capco is a chance to help reshape the competitive landscape in financial services.  We launch new banks, transform existing ones, and help our clients navigate complex change.  As consultants, we work on the front-end business design all the way through to technology implementation. We are the largest Financial Services focused consultancy in the world, serving everyone from global banks to emerging FinTechs, from strategy through digital transformation, design, business consulting, data and analytics, cyber, cloud, technology architecture, and engineering. Capco is a young and growing firm. We maintain an entrepreneurial spirit and growth mindset, and have minimal bureaucracy. We have no internal silos that get in the way of your career opportunities or  ability to focus on our clients and make a difference to the business.  We offer the opportunity for everyone to learn rapidly, take on tough challenges, and get promoted quickly. We take pride in our creative, collaborative, diverse, and inclusive culture, where everyone can #BYAW. We offer highly competitive benefits, including medical, dental and vision insurance, a 401(k) plan, tuition reimbursement, and a work culture focused on innovation and creation of lasting value for our clients and employees.  Ready to take the Next Step  If this sounds like you, we would love to hear from you.  This is an opportunity to make a difference and contribute to a highly successful company with a significant growth trajectory. The estimated salary range for this position in NY is 87,000 – 105,000 plus bonus potential and benefits. Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value. Job Description As Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects: Data Ingestion, Transformation & Consumption, Data Storage and Computation Frameworks, Performance Optimizations, Infrastructure, Automation & Cloud Computing, Data Governance & Security The role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java / Scala / Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. Role & Responsibilities: 1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation. 2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality 3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality 4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies 5. Participate in workshops with clients and align client stakeholders to optimal solutions. 6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc. 7. People management, contributing to hiring and capability building #LI-REMOTE  Qualifications Overall 8+ years of IT experience with 3+ years in Data related technologies  3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS / Azure / GCP) and delivered at least 1 project as an architect. Mandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud.  Expert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions Expert in programming languages like Java/ Scala and good to have Python Expert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc. Expert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc. Should have worked on MPP style query engines like Impala , Presto, Athena, etc Should have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc. Should have a good understanding of how to set up Big data cluster security – Authorization/ Authentication, Security for data at rest, and data in Transit. Should have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager – Data Engineering Should have worked on any of Orchestration tools – Oozie, Airflow, Ctr-M, or similar. Worked on Performance Tuning, Optimization, and Data security   Competency 1. Excellent understanding of data technologies landscape/ecosystem. 2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases 3. Good Exposure in development with CI / CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage. 4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models 5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage. 6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions 7. Thought Leadership – blogs, keynote sessions, POV/POC, hackathon 8. Certification in either one of the cloud platforms or big data technologies Personal Attributes: Strong analytical and problem-solving skills Strong communication skills in verbal, written and visual presentations Strong coordination and negotiation skills Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Multi geo experience and distributed delivery experience in large programs Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements  Employee Assistance Programs to help you in wellness and well being Company Description At Experian Health, our employees have the opportunity to shape more than products – they shape the future of U.S. healthcare. Experian Health is a pioneer for innovations leading the way in revenue cycle management, identity management, patient engagement, and care management for hospitals, physician groups, labs, pharmacies and other risk-bearing entities. Our success relies on people who are given the freedom to imagine new frontiers in the rapidly changing healthcare space and push the boundaries of innovation. Help us realize our vision of applying data for good and changing the healthcare landscape for the better – for all of us. Our mission is to use data driven insights to simplify healthcare for all. Simply put, we want to make the healthcare system work better for us as consumers and for those who work in healthcare. Our ONE Experian Health culture is the centerpiece of making this happen. Our aspiration is to bring people together who are driven by purpose and want to make a difference.  We strive to have a diverse group of people and minds who are: OPEN: Have a growth mindset and collaborate often with others to make things happen NIMBLE:  Always embracing change and pushing the envelope on innovative ways to solve problems EFFECTIVE:  Accountable to themselves and to others Job Description 100% REMOTE (NOT HYBRID) - WORK ANYWHERE IN THE US The primary responsibility of the Data Analyst will be to support application development leveraging strong SQL skills, knowledge of relational databases, and the skills to ensure custom coordination of benefit software, containing over 400 million rows of data, only allows accurate data to be loaded, and data integrity is maintained after bug fixes and enhancements.  This position will ensure this software is thoroughly tested from all angles focusing primarily on the backend by developing custom test plans and executing them using SQL, analyzing production data, and writing custom reports.  Job duties: Fully understand custom built Healthcare Medical Eligibility/Coordination of Benefits software solution. Understand the technical design and be able to traverse through and fully test the system using custom developed test plans using SQL Work collaboratively at ground level with senior level development staff to fully understand product requirements. Be willing to ask questions, push back as necessary, and ultimately ensure the new code meets stringent customer expectations Identify software defects, conduct research, develop plan for resolution, and engage appropriate internal resources as necessary Perform data analysis as needed on production data (400+ million rows of data) Collaborate with team members on, and provide peer review of, test plans, test cases, test data, and automation/tool enhancements. Work collaboratively with development team to make technical judgments based upon understanding of the business process and customer/user needs whereby a design change or modification should (or needs to be) changed. Support inquiries from client, operations, and customer support on content related questions and monitor areas for improvement. Design and document test cases to ensure optimal system performance with new code releases Utilize QA best practices Tests will be executed at the database level, using SQL Build automated tests using tools such as Selenium Operate load testing on Web Based Portal Run smoke tests and regression tests Prepare appropriate test data Communicate and document testing results in appropriate tool Maintain defect reporting and tracking Maintain current test plans, test cases, test scripts, and test data. Availability for planned after hours deployments and unplanned issue resolution Planned deployments typically occur once a month on Thursday nights Qualifications Bachelor’s degree in Information Systems, Computer Science, or other related field OR equivalent experience required At least 3 years combined prior business analyst, SQL programming, software QA, SQL data analysis Minimum 3 years of SQL usage in a professional setting Experience working as an analyst with large datasets (1+ million records) highly desired Experience with SDLC and iterative development processes, specifically Agile work processes highly desired Experience in working in a highly competitive team environment Strong SQL skills required (Data Analyst SQL skill set, not necessarily SQL programming) Focus on relational databases Business analyst knowledge is highly preferred QA knowledge is preferred. Willingness to be trained on QA fundamentals is required Coordination of Benefits, and/or Healthcare Revenue Cycle knowledge a plus Effective communication and relationship building skills Self-motivated, team player, but who can work independently Ability to adapt to an Agile/Scrum environment Strong written and verbal communication skills Problem-solving as part of a distributed team Time management and organizational skills Knowledge of the HIPAA transaction sets and requirements is desirable Become an expert on highly complex custom software - willingness to self-study and learn through trial and error required.   Additional Information Experian is an Equal Opportunity Employer. Anyone needing accommodation to complete the interview process should notify the talent acquisition partner. The word "Experian" is a registered trademark in the EU and other countries and is owned by Experian Ltd. and/or its associated companies. EOE including Disability/Veterans. Experian is proud to be an Equal Opportunity and Affirmative Action employer. Our goal is to create a thriving, inclusive and diverse team where people love their work and love working together. We believe that diversity, equity and inclusion is essential to our purpose of creating a better tomorrow. We value the uniqueness of every individual and want you to bring your whole, authentic self to work. For us, this is The Power of YOU and and it reflects what we believe.  See our DEI work in action! Please contact us at JobPostingInquiry@experian.com to request the salary range of this position (please include the exact Job Title as it reads above in your email). In addition to a competitive base salary and variable pay opportunity, Experian offers a comprehensive benefits package including health, life and disability insurance, generous paid time off including 12 company paid holidays and parental and family care leave, an employee stock purchase plan and a 401(k) plan with a company match. Experian Careers - Creating a better tomorrow together Find out what its like to work for Experian by clicking here Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value Job Description As Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions. You will independently drive design discussions to ensure the necessary health of the overall solution. The role requires a hands-on technologist who has strong programming background like Java / Scala / Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.  Role & Responsibilities: Your role is focused on the Design, Development and delivery of solutions involving: Data Integration, Processing & Governance Data Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations Infrastructure & Cloud Computing Data Management Platforms Implement scalable architectural models for data processing and storage Build functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode Build functionality for data analytics, search and aggregation #LI-REMOTE  Qualifications Overall 5+ years of IT experience with 3+ years in Data related technologies Minimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS / Azure / GCP) Hands-on experience with the Hadoop stack – HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline. Strong experience in at least of the programming language Java, Scala, Python. Java preferable Hands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc  Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security   Competency 1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience 2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc 3. Knowledge on distributed messaging frameworks like ActiveMQ / RabbiMQ / Solace, search & indexing and Micro services architectures 4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 – Data Engineering 5. CI/CD – Infra provisioning on cloud, auto build & deployment pipelines, code quality 6. Cloud data specialty and other related Big data technology certifications Personal Attributes: Strong written and verbal communication skills Articulaion skills Good team player Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Process orientation and the ability to define and set up processe Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements Employee Assistance Programs to help you in wellness and well being Unternehmensbeschreibung Bei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch. Die Robert Bosch GmbH freut sich auf Deine Bewerbung! Stellenbeschreibung Für unser PreMaster Programm suchen wir engagierte Bachelorabsolvierende, die die Theorie eines Masterstudiums mit Unternehmenspraxis vereinen wollen. Darüber hinaus besteht die Möglichkeit, sich im Geschäftsbereich Bosch eBike Systems breit zu vernetzen und spannende Einblicke in die Bosch-Firmenkultur „Like A Bosch" zu erhalten. Das erwartet Dich: Zweistufiges Qualifizierungsprogramm Dauer der Unternehmensphase: Bis zu zwölf Monate Betreuung durch ein persönliches Mentoring Folgende Tätigkeitsfelder warten auf Dich: Du arbeitest in einem innovativen und zukunftsträchtigen Datenprojekt für eBikes. Du unterstützt die Projektleitung sowie das -management koordinativ als auch die Projektteams hands-on im operativen Tagesgeschäft. Du wirst ein Teil der Bosch eBike Erfolgsgeschichte und setzt erlerntes Wissen aus deinem Studium direkt in die Praxis um. Visuelle Aufbereitung von Ergebnissen inklusive managementgerechter Darstellung machen Dir Spaß. Implementierung, Umsetzung und Verfolgung von datengetriebenen Fragestellungen (Big Data, Analytics, KI, IoT) haben Dich schon immer interessiert. Du hast Lust, den Transformationsprozess hin zu einer datengetriebenen Organisation aktiv zu unterstützen. Werde ein aktiver Teil der "eBike Familie", vernetze Dich, übernehme Verantwortung, treibe und verfolge Deine Ergebnisse, lerne über unsere eBike Kultur und „shape future cycling" - Wir freuen uns auf Deine Bewerbung! Beginn: ab 01.04.2023. Qualifikationen Ausbildung: abgeschlossenes Bachelor-Studium in der Fachrichtung Wirtschaftsinformatik, Informatik, IT-Marketing, Digital-Marketing, Wirtschaftsingenieurwesen, Ingenieurwissenschaften, Naturwissenschaften oder eines ähnlichen Studienganges Persönlichkeit und Arbeitsweise: begeisterungsfähig, verantwortungsbewusst, eigenverantwortlich, zielorientiert, gute Auffassungsgabe, starke Hands-On Mentalität, strukturiert, selbstständig, kommunikativ und analytisch Erfahrungen und Know-how: Data Analytics, Visualisierung, Cloud Affinität, Programmierung, Backend-Services, managementgerechtes PowerPoint, Projektmanagement, strategisches Denken Sprachen: sehr gute Deutsch- und Englischkenntnisse in Wort und Schrift  Zusätzliche Informationen In diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente.  Vielfalt und Inklusion sind für uns keine Trends, sondern fest verankert in unserer Unternehmenskultur. Daher freuen wir uns über alle Bewerbungen: unabhängig von Geschlecht, Alter, Behinderung, Religion, ethnischer Herkunft oder sexueller Identität. Neugierig geworden? Dann finde weitere Informationen zum PreMaster Programm unter www.bosch-career.de. Wir freuen uns auf Deine Bewerbung. Dauer: ca. 1 Jahr  Du hast Fragen zum Bewerbungsprozess? Meike Weiland (Personalabteilung) +49 7121 35 6909 Du hast fachliche Fragen zum Job? Tim Dackermann (Fachabteilung) +49 7121 35 39478 Unternehmensbeschreibung Bei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch. Die Robert Bosch GmbH freut sich auf Deine Bewerbung! Stellenbeschreibung Im Geschäftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen – von hocheffizienten Antrieben über das erste serienreife ABS fürs Pedelec bis hin zu smarten Connectivity-Lösungen. Für eine nachhaltige Mobilität, die Spaß macht. Als Data Analyst und Scientist bist Du der Experte, der aus Big Data Smart Data für den Bosch eBike Service macht und dabei sowohl eigene komplexe Projekte als auch Teilprojekte verantwortet. Deine Ergebnisse stellen eine wertvolle Zuarbeit für andere Projekte und Services dar. Du analysierst die uns vorliegenden Datenmengen mit dem Ziel, unsere Prozesse sowie unsere Angebote an den Fachhandel und Endkunden zu verbessern, damit wir unseren Wettbewerbsvorsprung ausbauen. Du bist intrinsisch motiviert, aus unstrukturierten Daten unterschiedlicher Quellen und Systemen Muster zu erkennen. Durch die Verbindung von weiteren und der Erschließung neuer Datenquellen definierst Du Anwendungsfälle für den Bosch eBike Service. Gemeinsam mit den verschiedenen agilen Teams setzt Du diese Anwendungsfälle um und begeisterst unsere Kunden. Das Technology Scouting und Benchmarking bzgl. neuer Analysemethoden führst Du selbständig aktiv durch und leitest daraus mögliche Anwendungen für Bosch eBike Systems ab. Du stellst die Anforderungen zur Etablierung neuer Datenpipelines und die Realisierung sicher. Dabei agierst Du sowohl bereichsübergreifend als auch international und mit Zentralstellen von Bosch. Basierend auf Deinen Analysen führst Du datengetriebene Entscheidungen auf Leitungs- und Bereichsvorstandsebene herbei. Ein Berichtswesen u. a. mittels einprägsamer Visualisierungen gehört zu Deinem Methodenbaukasten. Zudem sind advanced und predictive Analytics oder KI für Dich keine kryptischen Kürzel. Du befähigst die eBike Kollegen in der Nutzung und Wiederverwendung Deiner Analysen und bereitgestellter Dashboards. Qualifikationen Ausbildung: abgeschlossenes Hochschulstudium (Master/Diplom/Promotion) der Informatik, der Wirtschaftsinformatik oder eines vergleichbaren Studienganges; idealerweise Master in Data Analytics Erfahrungen und Know-how: mehrjährige Berufserfahrung im IT-Bereich wie Software-, Datenbankentwicklung, Big Data und Analytics-Technologien sowohl on-Premise als auch in der Cloud; Erfahrung mit Machine Learning und von künstlicher Intelligenz getriebenen Anwendungen; KPI-Wissen im Web und App Kontext; Grundkenntnisse des Datenschutzes und den gesetzlichen Regularien im Umgang mit Data und Customer Analytics von Vorteil; Erfahrung in der abteilungs- und geschäftsbereichsübergreifenden Koordination in einem internationalen Umfeld Persönlichkeit und Arbeitsweise: Deine Arbeitsweise zeichnet sich durch Selbstständigkeit und Struktur aus; Du bist zielgerichtet, kommunikationsstark und überzeugend; Du arbeitest gerne im Team; Dein Handeln ist von unternehmerischem Denken getrieben Sprachen: verhandlungssicheres Deutsch und Englisch in Wort und Schrift Bewerbungsfrist bis einschließlich 08.03.2023. Zusätzliche Informationen In diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente. Wir bieten tolle Möglichkeiten des remoten Arbeitens sowie unterschiedliche Teilzeitmodelle bis hin zum Jobsharing. Sprich uns gerne dazu an.  Vielfalt und Inklusion sind für uns keine Trends, sondern fest verankert in unserer Unternehmenskultur. Daher freuen wir uns über alle Bewerbungen: unabhängig von Geschlecht, Alter, Behinderung, Religion, ethnischer Herkunft oder sexueller Identität.  Du hast Fragen zum Bewerbungsprozess? Nina Sier (Personalabteilung) +49 711 811 27525 Du hast fachliche Fragen zum Job? Patrick Millen (Fachabteilung) +49 7121 35 39465 Interessierst Du Dich für diese oder weitere Stellen? Dann bewerbe auf die Virtual JobFair@BOSCH und verschaffe Dir einen Überblick über die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de/events/                                         Company Description About Eurofins Eurofins Scientific is an international life sciences company, providing a unique range of analytical testing services to clients across multiple industries, to make life and the environment safer, healthier and more sustainable. From the food you eat to the medicines you rely on, Eurofins works with the biggest companies in the world to ensure the products they supply are safe, their ingredients are authentic and labelling is accurate. Eurofins is a global leader in food, environmental, pharmaceutical and cosmetic product testing and in agroscience CRO services. It is also one of the global independent market leaders in certain testing and laboratory services for genomics, discovery pharmacology, forensics, CDMO, advanced material sciences and in the support of clinical studies. In over just 30 years, Eurofins has grown from one laboratory in Nantes, France to 58,000 staff across a network of over 1,000 independent companies in 54 countries, operating 900 laboratories. Performing over 450 million tests every year, Eurofins offers a portfolio of over 200,000 analytical methods to evaluate the safety, identity, composition, authenticity, origin, traceability and purity of biological substances and products, as well as providing innovative clinical diagnostic testing services, as one of the leading global emerging players in specialised clinical diagnostics testing. Eurofins is one of the fastest growing listed European companies with a listing on the French stock exchange since 1997. In FY 2021, Eurofins achieved a record revenue of over EUR 6.7 billion. Eurofins IT Solutions India Pvt Ltd (EITSI) is a fully owned subsidiary of Eurofins and functions as a Global Software Delivery Center exclusively catering to Eurofins Global IT business needs. The code shipped out of EITSI impacts the global network of Eurofins labs and services. The primary focus at EITSI is to develop the next generation LIMS (Lab Information Management system), Customer portals, e-commerce solutions, ERP/CRM system, Mobile Apps & other B2B platforms for various Eurofins Laboratories and businesses. Young and dynamic, we have a rich culture and we offer fulfilling careers. Job Description TITLE:  BI Analyst REPORTING To: GSC IT Reporting Lead WORKING LOCATION: India (Bangalore or Chennai) OVERALL OBJECTIVES: Eurofins today is strengthening the IT Reporting team. The IT Reporting team is controlling governance and operational data and produces and maintains reports that are used by several IT departments (IT Quality Assurance, IT Service Management, IT Compliance, Information Security, IT Infrastructure). The data in scope is the performance of IT Services, compliance of IT Assets, and security posture of the IT environment as a whole. The role of the BI Analyst is to analyse the requirements, solution them, and then develop, maintain and support (level 3) the BI dashboards, in close collaboration with the Data Engineers in the same team. SPECIFIC ASSIGNMENTS: The BI analyst: Analyses approved requirements from stakeholders (across IT and business functions) Liaises with stakeholders and product owners in clarifying and detailing out requirements Works with the data engineers and the domain experts to extract and transform the data Designs, creates, and maintains the dashboards in the BI platform (Power BI Cloud) Demonstrates the accuracy of figures Deploys the dashboards to production Documents reporting user guides and data dictionary Implements BI ACLs Participates in the Agile SCRUM development process. Provides L2/L3 support for investigating & resolving incidents on the dashboards. Keeps the end users and stakeholders engaged by communicating new releases and maintenance windows Provide end user trainings/demonstrations REQUIRED PROFILE: Personal Skills: Data design, modelling, management and visualization Excellent graphical design skills (important) Excellent communication skills (in English, both orally and in the writing, including moderating meetings) At ease with distant & international communications through several technologies  (ticketing  tool,  documents  and forums, phone, instant messaging, e-mail), Microsoft End User computing tools Initial Education Background: Bachelor's degree or diploma Language skills and level expected: English (fluent) required Type and duration of previous experience 3+ year experience as BI engineer/expert Data design, modelling, management and visualization Power BI experience in creating data-rich dashboards, writing DAX expressions and implementing Row Level Security, Paginated Reports and other BI tools Experience in DataOps and/or Agile/SCRUM is a plus Technical knowledge: MS SQL MS Azure DevOps   Company Description Transforming businesses, driving success: SmarTek21 SmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients Job Description SmarTek21 is looking for a hands-on Big Data Solution Architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.   Qualifications • Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python. • Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks. • Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP). • Solid understanding of enterprise strategies for data security and data governance. • Experience in practice development, architecture, and consulting or product development. • Experience delivering data analytics projects and architecture guidelines. • Experience in engaging with enterprise architects. Non-technical Skills: • Excellent oral and written communication and presentation skills. • Ability to handle ambiguous situations and take trade-off decisions. • Strong problem solving and analytical skills to break down complex problems into smaller components. • Ability and willingness to perform in a team environment. Requirements: • Understand prospect/customer/partner technology landscape. • Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation. • Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers/partners. • Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints. • Collaborate with the engineering team to create proof-of-concepts (POCs). • Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices. • Demonstrate business value of proposed solutions or current products to prospects and customers. Salary Range: $200,000-$215,000 (may be subject to change outside of WA State) Additional Information What Is in It for You: Paid Time off – start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service. Paid Holidays - 8 paid holiday a year in addition to your PTO. Health Insurance for FT employees – we pay 100 % premium of medical, dental and vision. Health Insurance for FT employee’s family – we pay 50% of premium for medical, dental and vision for dependents. 401(k) – we administer 401(K) retirement contribution for FT employees. Life Insurance/Short Term and Long-Term Disability – at no cost to you Opportunities for internal promotions/career advancement Family friendly work hours (closed on weekends and paid holidays) SmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class. Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value Job Description As Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions. You will independently drive design discussions to ensure the necessary health of the overall solution. The role requires a hands-on technologist who has strong programming background like Java / Scala / Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.  Role & Responsibilities: Your role is focused on the Design, Development and delivery of solutions involving: Data Integration, Processing & Governance Data Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations Infrastructure & Cloud Computing Data Management Platforms Implement scalable architectural models for data processing and storage Build functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode Build functionality for data analytics, search and aggregation #LI-REMOTE  Qualifications Overall 5+ years of IT experience with 3+ years in Data related technologies Minimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS / Azure / GCP) Hands-on experience with the Hadoop stack – HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline. Strong experience in at least of the programming language Java, Scala, Python. Java preferable Hands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc  Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security   Competency 1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience 2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc 3. Knowledge on distributed messaging frameworks like ActiveMQ / RabbiMQ / Solace, search & indexing and Micro services architectures 4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 – Data Engineering 5. CI/CD – Infra provisioning on cloud, auto build & deployment pipelines, code quality 6. Cloud data specialty and other related Big data technology certifications Personal Attributes: Strong written and verbal communication skills Articulaion skills Good team player Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Process orientation and the ability to define and set up processe Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements Employee Assistance Programs to help you in wellness and well being Company Description Transforming businesses, driving success: SmarTek21 SmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients Job Description SmarTek21 is looking for a hands-on Big Data Solution Architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.   Qualifications • Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python. • Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks. • Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP). • Solid understanding of enterprise strategies for data security and data governance. • Experience in practice development, architecture, and consulting or product development. • Experience delivering data analytics projects and architecture guidelines. • Experience in engaging with enterprise architects. Non-technical Skills: • Excellent oral and written communication and presentation skills. • Ability to handle ambiguous situations and take trade-off decisions. • Strong problem solving and analytical skills to break down complex problems into smaller components. • Ability and willingness to perform in a team environment. Requirements: • Understand prospect/customer/partner technology landscape. • Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation. • Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers/partners. • Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints. • Collaborate with the engineering team to create proof-of-concepts (POCs). • Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices. • Demonstrate business value of proposed solutions or current products to prospects and customers. Salary Range: $200,000-$215,000 (may be subject to change outside of WA State) Additional Information What Is in It for You: Paid Time off – start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service. Paid Holidays - 8 paid holiday a year in addition to your PTO. Health Insurance for FT employees – we pay 100 % premium of medical, dental and vision. Health Insurance for FT employee’s family – we pay 50% of premium for medical, dental and vision for dependents. 401(k) – we administer 401(K) retirement contribution for FT employees. Life Insurance/Short Term and Long-Term Disability – at no cost to you Opportunities for internal promotions/career advancement Family friendly work hours (closed on weekends and paid holidays) SmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class. Company Description Handling billions of transactions annually, Nexi Group is among the top payment processors in Europe. We keep a tight focus on making it even easier and more intuitive for our customers to handle digital payments and related services. This has made us a trusted partner to more than 700,000 merchant outlets, including 140,000 online merchant outlets, more than 260,000 enterprises and over 250 banks across Europe. Changing the future of payments takes strong personalities At Nexi, you’ll develop in a fast-growing tech company in a high-paced, high-impact market. Working to change the future of payments, it’s not just skills and ambition that gets the job done, it’s the full package that makes the difference. Together, we impact the lives of everyone around us by powering an easier tomorrow for every citizen, bank, business and colleague. What powers you at work? Job Description Data Engineering team is focused on improving the process of identifying valuable data,collecting, structuring, and utilizing data to create comprehensive analytics to support different aspects of business streams. Main Responsibilities: To Build DWH/BI and Data analytics solutions and ensure continue growth of Data products Implementation of data mappings and design of data flows as well as ETL processes in an agile environment for different kind of Business intelligence solutions Creation of  secure and reliable ETL pipelines ingesting data sources To Implement batch and transactional ingestion patterns Collaboration with customer business teams to understand business problems and to implement scalable and sustainable data solutions Design data models for consumption by data scientists and business analysts. Conduct complex data analysis and report on results. Further development of the data and analytics platforms and conduct complex data analysis and report on results Proactively share know-how, insights and experiences across the organization To be able to provide a delivery and present its business value in an understandable way to all levels of stakeholders Create data quality flows as a part of Data Governance  Qualifications University degree in electrical engineering and computer science, mathematics, economics or other related discipline Minimum 3 years of experience with Data Engineering It will be considered as advantage if you have experience with card business or Financial Industry Coding using different program languages Knowledge of building Data warehousing Knowledge of BI tools( e.g.Cognos), Data analytics knowledge Critical thinking skills Willing to promote data culture not only in technical teams but across the organization Communication skills Improvement of BI customers processes including  the Machine learning principles Willing to understand  company's business processes and the industry at large Ability to understand technology-based business intelligence tools focused on improving the process of identifying valuable data  Additional Information Please apply with your CV latest until 28th of February If you are curious… …and you want to know more, you're welcome to contact our Recruitment Business partner, Marija Babić, on marija.babic@nexigroup.com   Company Description Publicis Media is one of Publicis Groupe’s four solution hubs, aligning all of Publicis Groupe’s media agencies and operations.  Publicis Groupe (Euronext Paris Exchange: FR0000130577; CAC 40 index), is the world’s third largest communications group.  The Data, Technology and Innovation Global Practice was created to deliver best-in-class programmatic solutions as well as to consolidate Publicis Media’s data and technology to transform our business from a service business to a platform business.  Job Description We are seeking a driven individual with a proven track record of scalable and innovative business intelligence solutions. He/she shines when serving as a consultant to the business and is genuinely interested in understanding the objectives of complex and evolving projects. In this role, you will champion and advocate the use of Alteryx and Tableau to create an environment of self-service analytics. The candidate must be a self-starter with a sense of urgency and a commitment to quality and professionalism.  Responsibilities: Analyze business needs and partner with stakeholders to provide a strategic solution Work independently on end to end solutions, from data analysis to ETL design and development through to the final visual dashboard Collaborate across the organization to build solutions that achieve business objectives Guide stakeholders with operational decisions that impact data structures and connectivity Bring best practices in data architecture and data visualization to the table Build tools in a generic fashion for reuse across other solutions Develop technical documentation for each solution Manage projects in an agile environment Qualifications Minimum Bachelor’s Degree in Computer Sciences, Information Technology, or its equivalent 3+ years’ experience with Tableau 1+ years’ experience with AWS core+ services (EC2, S3, Lambda, Redshift, Glue) 1+ years’ experience with Python 3+ years’ experience with data visualization Comfortable with data warehousing concepts, preparing data, and configuring automated workflows Excellent communication and presentation skills as well as an analytical mindset Experience with complex logic Strong data analysis skills Experience connecting and merging disparate datasets Strong organizational skills & attention to detail Possess a desire to work for a fast-paced, results-based company Experience managing multiple projects simultaneously  Desired Skills/Experience: Experience with media and ad tech platforms (Ad Servers, Media Planning and Buying systems, DSP’s, Programmatic, etc) SQL Adobe Site Catalyst Google Analytics Basic knowledge of ETL, data modeling, data warehouse, extracting and manipulating large record of data Additional Information Compensation Range: $106,500 - $167,500 annually. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. For this role, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off. All your information will be kept confidential according to EEO guidelines. Databases are the beating heart of every business in the world. We are looking for a Business Intelligence Engineer to join the Data & Analytics team at Cockroach Labs. As a member of the data organization, you will work closely with our Product and Engineering teams to uncover insights about how customers use CockroachDB, helping to inform the Product’s decision-making and focus Engineering efforts. You will also be responsible for long-running analytical initiatives marked by greater complexity and less structure that will yield substantial product enhancements. We’re looking for someone comfortable working on interesting growth, engagement, and retention-related problems in the SaaS space using cutting-edge and proven techniques. This is a strategic, high-impact role that will help shape the future of CockroachDB products and services. You Will Bring hands-on experience in creating curated data models, analytical approaches, and metrics strategies to deliver actionable insights Perform high-level ad-hoc analyses, quantitative and qualitative, to guide business improvement hypotheses and drive decisions Collaborate with senior management to develop goals, objectives, and strategies for improving business performance using BI tools Own the design, development, and support of the data models and visualization dashboard, extracting data from the data warehouse (Snowflake, Big Query / Oracle data warehouse) or other sources. Advocate for business intelligence solutions that will help the organization meet its goals Recommend changes to existing business intelligence processes or policies to improve efficiency Build a scalable data infrastructure that meets the needs of the business as it enters a period of rapid growth Establishing a robust and efficient business reporting process and building key management and workflow reports with input from management and executive leadership team Proactively identify trends in market trends and business performance, surfacing findings on a regular basis Be a hands-on leader that will leverage enterprise data to enable Cockroach Labs' enormous growth potential in a profitable and efficient manner. Develop analytic dashboards that are used to drive business operations across Finance, Sales, Planning, Manufacturing, and more. Develop analytical frameworks to measure and supervise the performance of our GTM efforts across multiple dimensions (product, geo, segment, etc.) The Expectations In your first month, you will go through the Cockroach Labs onboarding process and start to build relationships with stakeholders across the company. You will understand our current data architecture and the internal and external resources we use to maintain it. You will start to prioritize the current backlog of data requests. After 30 days, you will have a grasp on the major questions the product management team needs to answer, as well as the executive-level questions that require coordination between disparate data sets. You will update the roadmap priority and put in place key processes for building out this function. You will develop a point of view on the direction we need to take our data platform to support our product operations. After 90 days, you will be fully integrated into the team. You will put in place the major processes for supporting the Product and the broader organization, and make incremental improvements to our data platform that demonstrably improve our ability to make decisions. You will socialize a strategy for data in the Product team and how this will support the needs of other departments in the future. You Have BS, MS or Ph.D. in quantitative fields (e.g., Statistics, Math, Computer Science, Physics, Economics, Operations Research) 5+ years of experience in business intelligence,  building and architecting data solutions roles, SaaS experience is a plus Preferred experience  in tools such as Spark, Airflow, Presto/Hive, Spark, or any other streaming technologies to process incredible volumes of data, Looker, Tableau, or other reporting tools Experience working in GCP/AWS/Azure cloud platform and knowledge of cloud utilities/tools Advanced proficiency in data visualization tools (e.g. Tableau, Looker, Metabase) with hands-on experience in data modeling and reporting in data visualization tools such as Looker, or a similar tool Familiarity with sophisticated data architecture and tools (e.g. data warehouses, data pipelines) 5+ yrs of hands-on experience writing and optimizing advanced SQL queries, with large-scale, complex datasets Advanced proficiency in Python, Scala, Java, or similar scripting language is preferred  Skills to manage complex BI projects and teams, and work effectively across internal functional areas in ambiguous situations The Team Reporting to Veera Ilamurugu, Head of Data Veera Ilamurugu heads up the Data Analytics team at Cockroach Labs. He is responsible for our Product data strategy and is passionate about building and scaling businesses with data. Before joining Cockroach Labs, Veera was a Head of Analytics at Stitchfix, Leading an analytics team covering internal company strategy  When not at work, he enjoys watching Netflix, trying out new recipes in the kitchen, and listening to music. Our Benefits 100% health insurance coverage (for you and your dependents!) Paid parental leave (with baby bucks) Flex Fridays Flexible time off & flexible hours Education reimbursement Relocation support Cockroach Labs is proud to be an Equal Opportunity Employer building a diverse and inclusive workforce. If you need additional accommodations to feel comfortable during your interview process, please email us at accessibility@cockroachlabs.com. The annual anticipated base salary range for U.S. candidates for this role is USD $135,000 to $205,000, plus commission if a sales role. We set standard ranges for all U.S.-based roles based on function, level, and geographic location, benchmarked against similar stage growth companies. In order to be compliant with local legislation, as well as to provide greater transparency to candidates, we share salary ranges on all job postings regardless of desired hiring location.  Actual salaries may vary and fall outside of this range depending on factors such as a candidate’s qualifications, geographic location, skills, experience, and competencies. In addition, we are often open to a wide variety of profiles, and recognize that the person we hire may be less experienced (or more senior) than this job description as posted. Salary is one component of the Cockroach Labs’ total rewards package, which includes stock options, health insurance, life and disability insurance, funds towards professional development resources, unlimited PTO, paid holidays, and parental leave, to name a few! Salaries for candidates outside the U.S. will vary based on local compensation structures. Passionate about precision medicine and advancing the healthcare industry? Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus’ proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time. Our data accelerates the pace of innovation, empowering researchers to characterize disease, discover new opportunities, maximize clinical trial success, and ensure new therapies reach the right patients. As a Tempus employee you will have access to the world’s largest real-world patient clinical data set linked to transcriptomics and digital pathology. What you’ll do: Support partnership development between Tempus and the Life Sciences industry by identifying patient cohorts for Tempus’ oncology data licensing business Partner with Tempus’ Pharma Business Development and Life Sciences Strategy & Operations teams to generate fit-for-purpose cohorts supporting pharma research Support monitoring of the volume and profiles of inbound requests in order to generate insights into customer needs Support code maintenance and documentation Qualifications: 1+ years of relevant work experience, preferably in an analytical or consulting role within or in support of the Life Sciences or Healthcare industry Experienced in SQL and Proficient in R and/or Python Experience using Excel, Google Sheets, or equivalent spreadsheet software Strong interest in oncology, cancer genomics, molecular biology and/or clinical trials Experience building client-ready deliverables and other outputs Experience working with unstructured data and translating raw data into practical insights Experience with data manipulation and cleaning Strong communication skills Ability to take ownership of deliverables, navigate ambiguity and juggle multiple projects simultaneously Goal orientated, self motivated, and driven to make a positive impact in healthcare Thrive in a fast-paced environment and willing to shift priorities seamlessly #LI-GL1 #LI-Remote We are an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Company Description Block is one company built from many blocks, all united by the same purpose of economic empowerment. The blocks that form our foundational teams — People, Finance, Counsel, Hardware, Information Security, Platform Infrastructure Engineering, and more — provide support and guidance at the corporate level. They work across business groups and around the globe, spanning time zones and disciplines to develop inclusive People policies, forecast finances, give legal counsel, safeguard systems, nurture new initiatives, and more. Every challenge creates possibilities, and we need different perspectives to see them all. Bring yours to Block. Job Description We're building a bitcoin wallet for the next 100M bitcoin users - importantly for people around the world who likely haven't yet used bitcoin as a savings tool or for its payments capabilities yet. Our goal is economic empowerment -- starting with bringing easy-to-use, reliable wallet that helps people around the world own and manage their bitcoin, rather than having to rely on several tools and services that don't work well together and are challenging to use for a wide global audience. Our goal is to make the future of money intuitive, and safe while helping customers build a better financial future. We're assembling a team experienced in an extremely wide range of disciplines, including business, operations, design, software, hardware, security, and so many other aspects of product delivery. We are hiring our first Product Data Scientist to help our product, marketing, engineering and customer support teams make data-driven decisions about what and how we build for our customers when helping them manage their money. This is a unique opportunity to not only be embedded with an early stage team where you'll have close proximity to strategy and building so you can produce action-oriented analyses, but you'll also influence our data infrastructure and tooling decisions. Because you will work with bitcoin data across different sources (internal systems, blockchain, lightning network, etc.), an understanding of how these technologies function or demonstrated experience or interest working with this data is a big plus. You will report to our Head of Business within Bitcoin Wallet. You can be based anywhere remotely in the United States, as well as in several countries around the world including the UK, Ireland, the Netherlands, Germany, among other countries. Come build the future of money with us! Learn more through our newsletter here. You Will: Empower our team to use data to make business decisions as we build a global product from its earliest days- an opportunity to build data analysis into the infrastructure of a team from day 1 Develop both backwards-looking analysis on product performance, marketing effectiveness, monetization and pricing and other main product and business decisions, as well as forward-looking predictive models to help us better understand customers and their needs (e.g. cluster analysis that help us map customer segments back to product usage, retention models) Empower the teams with data and help them to make decisions on improving product features and building a meaningful roadmap (e.g. funnel metrics, analysis of churn and CS data, etc), as well as influencing important decisions like pricing based on acquisition and retention insights As a member of the Business team, you'll have the product and business context to be able to proactively spot trends and connect sometimes seemingly disconnected data sets to help the team develop and prove out hypotheses across the end to end lifecycle, forming cohort analysis on things like acquisition channels, etc. Navigate external data sets such as publicly available blockchain data insights (eg bitcoin blockchain analysis) to help us understand things like our total addressable market (TAM) as well as SAM and SOM Design and help run statistically-significant experiments across different cohorts of customers and ensure hygienic approach to things like causation vs correlation Create models that help us to analyze risk and security threats as well as optimize key decisions on our approach to money movement (i.e. transaction modeling) Support and guide in our early data infrastructure decisions with product and engineering - as we are a zero to one team, you will get to shape the data infrastructure decisions we make so we have scalable ways of working where data is easily accessible to the right people on our team, all while ensuring that data is secure and aligned with our privacy principles and commitment to customers and partners. Qualifications You Have: Background in working in product-driven organizations and building and sharing data-driven insights to help make decisions with 8+ years of experience Experience with cohort and funnel analyses, an understanding of statistical concepts such as selection bias, probability distributions, and conditional probabilities Experience telling stories and making relevant recommendations with data You've set up and run A/B tests and other types of experimentation designs and can help ensure statistical significance in the right testing environment With technical skills, you can automate complex processes and construct data pipelines Experience with data visualization tools (e.g. Looker, PowerBI, Tableau etc.) Work in collaborative team environments including Product, Marketing, Engineering, Design and Research Thrives in earlier stage environments - you're a self-starter who gets excited about complex, sometimes vague, or longer-term problems and can be creative on how to solve those problems with data and insights Familiarity or interest in learning blockchain analytics as we are building in the bitcoin space and external data sets will help you uncover richer trends and recommendations; ability to connect internal and external data sources Technical skills: Python or R, Advanced SQL  Additional Information Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.  Zone A: USD $184,100 - USD $225,000 Zone B: USD $174,900 - USD $213,700 Zone C: USD $165,700 - USD $202,500 Zone D: USD $156,400 - USD $191,200 To find a location’s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information.  Benefits include the following: Healthcare coverage Retirement Plans including company match  Employee Stock Purchase Program Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance  Paid parental and caregiving leave Paid time off Learning and Development resources Paid Life insurance, AD&D. and disability benefits  Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources  This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans. We’re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, veteran status, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.  We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible. Want to learn more about what we’re doing to build a workplace that is fair and square? Check out our I+D page.  Additionally, we consider qualified applicants with criminal histories for employment on our team, assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution. Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value Job Description As Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions. You will independently drive design discussions to ensure the necessary health of the overall solution. The role requires a hands-on technologist who has strong programming background like Java / Scala / Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.  Role & Responsibilities: Your role is focused on the Design, Development and delivery of solutions involving: Data Integration, Processing & Governance Data Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations Infrastructure & Cloud Computing Data Management Platforms Implement scalable architectural models for data processing and storage Build functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode Build functionality for data analytics, search and aggregation #LI-REMOTE  Qualifications Overall 5+ years of IT experience with 3+ years in Data related technologies Minimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS / Azure / GCP) Hands-on experience with the Hadoop stack – HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline. Strong experience in at least of the programming language Java, Scala, Python. Java preferable Hands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc  Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security   Competency 1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience 2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc 3. Knowledge on distributed messaging frameworks like ActiveMQ / RabbiMQ / Solace, search & indexing and Micro services architectures 4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 – Data Engineering 5. CI/CD – Infra provisioning on cloud, auto build & deployment pipelines, code quality 6. Cloud data specialty and other related Big data technology certifications Personal Attributes: Strong written and verbal communication skills Articulaion skills Good team player Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Process orientation and the ability to define and set up processe Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements Employee Assistance Programs to help you in wellness and well being Title: Big Data Solution Architect Type: Full-time Location: Switzerland (Lausanne or Zurich) 🧬 About us Visium is a fast-growing Swiss AI technology consultancy company founded in 20218. At Visium, we develop customized AI-powered solutions for our clients in order to help them achieve their business goals. With a team of 55+ Visiumees dedicated to accelerating the adoption of state-of-the-art Artificial Intelligence in traditional industries. We are the strategic AI partner of world-leading companies and we contribute to them with ethical AI solutions that have a massive positive impact on their business, customers and employees. 🧭 Role You will be our clients Data Engineering expert, helping them identify their opportunities and designing the projects we will develop for them. As the first point of contact for many of our prospects, you will establish a close, impactful, and long-lasting relationship with our clients and partners. More importantly, you will be the main technical reference when it comes to supporting the growth team in the design of Data Engineering solutions and during client meetings.  💡 What you will be responsible for As a Big Data Solution Architect you will be: Our technical expert to support our Sales team: Cooperate with our Sales team and senior stakeholders, during pre-sales stage, to construct a total solutioning proposal, including offering and pricing, high level scope of both functional and technical requirements, data and security. Identify potential Data Engineering use-cases and evaluate the value they would bring to our clients. Prepare proposal presentations for clients’ projects. A trusted technical advisor to clients and project members: Participate in or drive deep architectural discussions to build trust and rapport with clients during the implementation stage. Provide technological and architectural consulting to our clients, create strategic roadmaps, and advise on their execution. Solve complex technical challenges, and build deep relationships with senior technical individuals within internal and client organizations. Guide teams through the end-to-end project lifecycle, covering the initial conception, business requirements, software architecture, implementation, and delivery. Act as a technical lead and coach for the more junior team members. A resourceful leader to bring our Data Engineering practices to the next level: Promote the adoption of new initiatives on client side or internally. Run group-wide thought leadership initiatives to advance our architectural practices and sustain our technical excellence. Depending on your previous experiences and appetite to grow, you will have the opportunity to gain more responsibilities. Requirements 🔧 What we are looking for A trustful expert in Data Engineering with a strong technical knowledge that can be put at the best-use of our clients’ project. A client-centric person with strong consultative selling capabilities and commercial awareness to be a winning partner to close deals. A resourcefulness and a self-starter leader, always looking for constant self and collective improvements in his/her areas of expertise and beyond. Required qualifications: 2-5 years of experience in designing and implementing large scale data engineering projects, preferable from a consulting background. Strong expertise on data management and cloud architecture. Excellent leadership, stakeholder management and communication skills to speak and present in front of senior executives. Good communication skills, fluent in English, French or German is a plus. Benefits 📦 What we offer A yearly education budget to steep your learning curve A yearly sport budget because a fit body leads to a fit mind A position that enables you to have an impact on 1’000s of people A welcoming, international, and diverse team with a fun and dynamic spirit Opportunity to join a talented and experienced startup with proven traction in its journey Open and transparent culture Our culture The family culture we have built in our company is something we are very proud of. We truly value our people and encourage them to work and express themselves in the best possible way. You can always count on the people around you to help you get back on track. We always strive to do the right thing. Open discussion is welcomed and everyone is encouraged to share new ideas. We believe everyone can make a valuable impact no matter their role. We are united through the passion with which we approach our goals. 'Good-enough' is missing from our vocabulary because we stretch for amazing. Check our LinkedIn and Instagram to learn more about us & don’t hesitate to contact us if you have any questions. Job Description About This Role You will build and support the US Data Visualization & Reporting capability as part of the US Data Strategy for the US Commercial Organization at Biogen.  As part of the US Data team, you will enable the US Commercial digital and analytics strategies by developing data solutions that maximize the use of our data assets. As a partner to US Data Team, you will execute and streamline monthly reporting, lead ad hoc analytics use cases, and communicate with all TA’s to build end-to-end data management in close collaboration with stakeholders in CE&O, Finance and IT management.   What You’ll Do: Design, develop and publish new dashboards and work on enhancements Translate complex data sets into actionable reporting frameworks and models to enable key performance indicator (KPI) visualization that supports high performance for end users Use industry standard business intelligence (BI) tools (including Business Objects, QlikView, QlikSense) to formulate metrics and to create data quality management assessments and tools to perform ad hoc data inquiries Perform training to other PowerBI users, as needed Responsible for design and updating methodology and project documentation Collaborate with internal teams to understand business needs, and work to gain in-depth understanding of company processes and procedures Translate business needs to technical specifications Conduct unit testing and troubleshooting Collaborate with teams to integrate systems Develop and execute database queries and conduct analyses Follows quality assurance and control processes, and performs routine data management tasks, such as data validation and correction, queries and editing to ensure data accuracy, integrity, and completeness  Perform other duties as assigned Qualifications Who You Are You are an experienced with Pharmaceutical data assets & vendors professional, with great practical knowledge of BI tools and ability to integrate reporting components from multiple data sources. You know how to optimize dashboards with focus on usability, performance, flexibility and standardization. You have effective analytical, conceptual, and problem-solving skills  and you are passionate about data visualization.  Required Skills Min Bachelor’s degree in business or science related Proficient in English;  Technical capabilities with MS Office, in particular PowerPoint and Excel (including Pivot Tables, Charts, and vLookup). 1 - 3 years of practical experience working directly with Power BI; experience in developing, publishing and scheduling Power BI reports as per the business requirements 1-3 years’ practical experience with writing and debugging SQL queries Ability to integrate reporting components from multiple data sources Effective analytical, conceptual, and problem-solving skills Experience in optimizing dashboards with focus on usability, performance, flexibility and standardization  Analytical thinking for translating data into informative reports and visuals  Experience with Pharmaceutical data assets & vendors; knowledge of commercial analytics (Sales, Marketing, Managed Markets) in small specialty markets is a plus Passionate about data visualization Additional Information  Why Biogen? Our mission to find therapies for neurological and rare diseases is a unique focus within our industry and this shared purpose is what connects us as a team. We work together to overcome obstacles and to follow the science. We are resilient as we strive to make an impact on our patients’ lives and on changing the course of medicine. Together, we pioneer. Together, we thrive. More details: https://www.biogen.com/en_us/careers.html  Join our Global Business Services Center in Poland! The vision of GBS at Biogen is to be recognized as a world-class Global Business Services organization driven by the desire for excellence in its people, business solutions, execution and partnerships with internal and external customers.  We offer: Role in a dynamic and one of the oldest biotechnology company in the world  Company mission you can be really proud of Work with diverse and knowledgeable multinational teams Opportunities to learn and grow with GBS site in Poland Structured onboarding program Customized benefit package, e.g. MyBenefits cafeteria, annual bonus eligibility, medical care, hybrid work Why Biogen? Our mission to find therapies for neurological and rare diseases is a unique focus within our industry and this shared purpose is what connects us as a team. We work together to overcome obstacles and to follow the science. We are resilient as we strive to make an impact on our patients’ lives and on changing the course of medicine. Together, we pioneer. Together, we thrive. At Biogen, we are committed to building on our culture of inclusion and belonging that reflects the communities where we operate and the patients we serve. We know that diverse backgrounds, cultures, and perspectives make us a stronger and more innovative company, and we are focused on building teams where every employee feels empowered and inspired. Read on to learn more about our DE&I efforts Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description Visa Consulting and Analytics (VCA), the consulting arm of Visa, is a global team of industry experts in strategy, marketing, operations, risk and economics consulting, with decades of experience in the payments industry. Our VCA teams offers: Consulting services customized to the needs of Visa client's business objectives and strategy Business and economic insights and perspectives that impact business and investment decisions Self-service digital solutions Visa clients can leverage to improve performance in product, marketing and operations Proven data-driven marketing strategies to increase clients' ROI VCA team is looking for a passionate individual to join our consulting practice and play a role in the data engineering team. The ideal candidate is adept at using big data sets to understand our client's challenges and deploy targeted solutions to drive meaningful benefits, leveraging our world-class payment knowledge, in combination with our diverse service offerings to address key strategic needs for Visa's clients including issuers, acquirers and merchants. He/She must have experience using a variety of data mining/data analysis methods, using a variety of distributed data platforms, and leveraging the latest open-source technologies. He/She must have a proven ability to drive business results with their data-based insights. Adept at creative and critical thinking, be able to deconstruct problems and transform insights into large scale, state-of-the-art solutions. Responsibilities Automate and standardize data processes developed by team members. Leverage DevOps to create end-to-end streamline CI/CD data and ML pipelines. Review and manage data pipelines, branching, and deployment process. Work with partners on requirements and implementation designs of data solutions. Implement data quality framework at scale using open-source technologies. Create data monitoring dashboards with real-time notifications. Understand VisaNet data and platform ecosystem to deploy fully automatic data applications for internal and external clients. Unify data engineering and machine learning engineering pipelines. Apply spark optimization techniques to production jobs to accelerate data prep. Document process, designs, test results, and analysis. Ability to articulate complex architectures to non-technical audiences, management, and leadership. Continuously research industry best practices and technologies. Evangelize end to end automation and standardization across the organization. Partner with functional areas, and regional and global teams to leverage the breadth and depth of Visa’s resources. This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs. Qualifications Basic Qualifications  • BA/BS required, MBA or other relevant Master’s degree preferred (e.g. engineering, computer science, computer engineering, applied mathematics, or other related fields)  Preferred Qualifications  • At least 5 years of experience as data engineer or data scientist with open-source tools. • Experience in retail banking, payments, financial services, and/or technology industries is a plus. Strong interest in the future of payments is a must. • Strong technical competency and experience with shell-scripting and Linux systems. • Experience with CI/CD pipeline using Azure DevOps, GitHub actions, Jenkins, or Airflow. • Strong coding skills in Spark, Python and SQL to manipulate big data in distributed platforms. • Good to have experience in navigating in Linux/Unix/Container based apps such as Docker, Kubernetes, or Microservices environments. • Knowledge in how to leverage AI assistance tools like chatGPT for creating and debugging code. • Ability to interact with big data clusters using Jupiter Notebooks, terminal, or GUI. • Demonstrate experience leveraging open-source tools, libraries, and platforms. • Experience with data visualization and business intelligence tools like Tableau, PowerBI, Microstrategy, or Excel. • Problem solving ability and process creator with strategic focus on replicability, scalability, innovation, and governance. • Proficient with git for version control and code collaboration using branches and pull requests. • Must be passionate about automation and data and able to deliver high quality work. • Experience developing as part of Agile/Scrum team. • Fluency in English (spoken/written). Portuguese or Spanish is a plus. • Experience in developing integrated cloud applications with services like AWS, Azure Cloud, and GCP is a plus. Additional Information Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. Company Description The future. It’s on you. You & Western Digital. We’ve been storing the world’s data for more than 50 years. Once, it was the most important thing we could do for data. Now we’re helping the world capture, preserve, access and transform data in a way only we can. The most game-changing companies, consumers, professionals, and governments come to us for the technologies and solutions they need to capture, preserve, access, and transform their data. But we can’t do it alone. Today’s exceptional data challenges require your exceptional skills. It’s You & Us. Together, we’re the next big thing in data.  Western Digital® data-centric solutions are found under the G-Technology™, HGST, SanDisk®, Tegile™, Upthere™, and WD® brands. Job Description Do you love working with people and data? We are looking for a highly collaborative individual who is passionate about being part of a world-class People Analytics team. This is an exciting opportunity for an individual who believes in the power of inclusion and is enthusiastic about bringing an organization’s people data to life. The People Data Analyst will work closely with HR and business leaders to deliver insights based on quantitative and qualitative data that strengthens data-driven decision-making and evolves a culture of growth and innovation. If you thrive in a fast-paced, dynamic environment, are looking to be a part of a team that is developing exciting new processes, and you are eager to take on new opportunities and challenges with a sense of urgency and enthusiasm, then this could be an exciting opportunity for you. ESSENTIAL DUTIES AND RESPONSIBILITIES:  Partner with HR team members, leaders, and stakeholders across Western Digital to develop a deep understanding of current and emerging HR use cases and challenges, identify priorities for research and execute impactful research projects. Provide strategic support to the Human Resources function in the areas of people data, metrics, and reporting.  Creates, maintains, and ensures quality assurance of key people data sets, reports, and metrics.  Designs and implements self-service reporting tools and data management that reflects the complexity of the business Designs and implements dashboards that present data in a meaningful and actionable framework for leadership. Design, build and deploy the analytical/ BI reports like People Insights & Collaboration using enterprise-level tools and technologies. Connect and analyze multiple sources of organizational data to provide actionable insights on HR strategies Responsible for analyzing and visualizing the various domain-specific data. Provide subject matter expertise and advice on People analytics topics and data collection Communicate research findings to HR groups and senior leaders relating findings to technical and non-technical audiences Present research insights both internally and outside the organization to become a thought leader in this space Collaborate with People Analytics and IT team members to access data and explain data requirements Producing the weekly, monthly, and quarterly scheduled reports, including Executive Management Information and Workforce Metrics, in an accurate and timely manner Supporting the effort of data integrity and data governance Demonstrate ethics and judgment when dealing with confidential data and research with underrepresented communities Stay current on research and best practices, summarizing findings and recommendations for enhancing current processes and practices Qualifications 8-10 years of professional-level work experience with an emphasis on HR and People Analytics Deep subject-matter expertise in HR domain, and/or closely related areas. Expertise on migrating tableau dashboards to PowerBI. Enable all tableau features while converting to PowerBI. Excellent communication skills with demonstrated ability to build strong relationships within an organization Comfortable presenting information and ideas to HR and Business Leaders Advanced SQL Knowledge ( Oracle, Teradata ) Working experience and/or familiarity with PowerBI/Tableau, Python, R or related tools. 5+ years of experience with PowerBI/Tableau, OBIEE, Alteryx, or related tools Strong business and human resources acumen, understanding internal and external market forces, operating priorities and Finance/ROI Exceptional interpersonal skills with people across geographies, functions, and levels of the organization Strong Project Management skills, ability to prioritize and meet deadlines and measure progress and success and manage multiple projects with competing deadlines Ability to handle highly confidential data Thrives in a fast-paced, complex environment Highly motivated self-starter who takes initiative Goal-oriented, proactive, accountable, and passionate about driving results Maintains a positive attitude and forward-thinking approach despite challenges Shows personal commitment and acts to continuously learn and improve Actively seeks out information about a wide variety of cultures and viewpoints Strong organizational skills with exceptional attention to detail and a strong design instinct Preferred: Bachelor’s/Master’s degree, Ph.D. a plus, with a focus or specialization in HR and/or in a field emphasizing people research in organizations (e.g., Industrial/Organizational Psychology, Organizational Behavior, Management, Organizational Development) Experience conducting research in organizations, including research design, data collection, statistical analysis, interpretation of results, and making actionable recommendations Ability to select and apply appropriate statistical methods to people research problems in organizations Additional Information Because Western Digital thrives on the power of diversity and is committed to an inclusive environment where every individual can thrive through a sense of belonging, respect, and contribution, we are committed to giving every qualified applicant and employee an equal opportunity.  Western Digital does not discriminate against any applicant or employee based on their protected class status and complies with all federal and state laws against discrimination, harassment, and retaliation, as well as the laws and regulations set forth in the "Equal Employment Opportunity is the Law" poster. Part of creating a diverse and inclusive workplace includes ensuring that all qualified applicants and employees are provided equal consideration for any available opportunity.  Western Digital is committed to offering opportunities to applicants with a disability.  If you need a reasonable accommodation, email us at Careers.Accommodations@WDC.com.  In your email, please include a description of the specific accommodation you are requesting as well as the job title and requisition number of the position for which you are applying. Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value. Job Description As Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects: Data Ingestion, Transformation & Consumption, Data Storage and Computation Frameworks, Performance Optimizations, Infrastructure, Automation & Cloud Computing, Data Governance & Security The role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java / Scala / Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. Role & Responsibilities: 1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation. 2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality 3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality 4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies 5. Participate in workshops with clients and align client stakeholders to optimal solutions. 6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc. 7. People management, contributing to hiring and capability building #LI-REMOTE  Qualifications Overall 8+ years of IT experience with 3+ years in Data related technologies  3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS / Azure / GCP) and delivered at least 1 project as an architect. Mandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud.  Expert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions Expert in programming languages like Java/ Scala and good to have Python Expert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc. Expert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc. Should have worked on MPP style query engines like Impala , Presto, Athena, etc Should have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc. Should have a good understanding of how to set up Big data cluster security – Authorization/ Authentication, Security for data at rest, and data in Transit. Should have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager – Data Engineering Should have worked on any of Orchestration tools – Oozie, Airflow, Ctr-M, or similar. Worked on Performance Tuning, Optimization, and Data security   Competency 1. Excellent understanding of data technologies landscape/ecosystem. 2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases 3. Good Exposure in development with CI / CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage. 4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models 5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage. 6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions 7. Thought Leadership – blogs, keynote sessions, POV/POC, hackathon 8. Certification in either one of the cloud platforms or big data technologies Personal Attributes: Strong analytical and problem-solving skills Strong communication skills in verbal, written and visual presentations Strong coordination and negotiation skills Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Multi geo experience and distributed delivery experience in large programs Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements  Employee Assistance Programs to help you in wellness and well being Company Description At Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people’s lives. Our promise to our associates is rock-solid: We grow together, we enjoy our work, and we inspire each other. Welcome to Bosch. The Bosch Power Tools GmbH  is looking forward to your application! Job Description The team market & competitive intelligence owns the global responsibility for the contents and processes of the business development pillars market, competition & trends Your task mainly evolves around business intelligence in the fields of market & competition, for which you are in close interaction with global internal & external stakeholders Your biggest topics within the area of business intelligence: You actively drive our team target to develop our contents and data to intelligence Responsibility for all data science & intelligence projects evolving around market & competition Development and implementationg of AI & machine-based forecasting models (in close collaboration with your teammates The second pillar of your responsibilities lies within market intelligence: Responsibility for certain sub-markets for an even better understanding of the contents behind the data science projects Coordination of sub-market estimates in close collaboration with the business units, country responsibilities & further internal stakeholders Qualifications Education: Master degree in the field of business informatics or similar Personality: Analytical, structured & independent way of working. Team spirit & strong communication skills Working Practice: Relevant experience in data science, business intelligence and data visualization. Ideally: experience in market intelligence & knowledge about the relevant competitive landscape Experience and Knowledge: Profound knowledge in business intelligence & data science/visualization/modeling. Experienced in handling data analytics tools (i.e. Power BI) Languages: Business fluent in German & English Additional Information You want to work remotely or part-time - we offer great opportunities for mobile working as well as different part-time models or job-sharing. Feel free to contact us. Diversity and inclusion are not just trends for us but are firmly anchored in our corporate culture. Therefore, we welcome all applications, regardless of gender, age, disability, religion, ethnic origin or sexual identity. Need support during your application? Julia Schöffler (Human Resources) +49 711 811 4261 Need further information about the job? Andreas Leinfelder (Functional Department)   Description de l'entreprise Cabinet d’expertises numériques créé en 1993, ASI accompagne les ETI et les grandes entreprises dans la concrétisation de leur stratégie digitale dans les domaines d'expertises suivants :   Data & Intelligence Artificielle Stratégie digitale & Expérience Client   Plateformes & Applications Process & Agilité Implantée dans 7 villes en France (Nantes, Rennes, Paris, Lyon, Brest, Niort et Bordeaux) ASI compte 500 collaborateurs. Labelisée "Happy At Work" depuis 2016, 64% du capital de l'entreprise sont détenues par les salariés cadres (actionnariat salarial). L’agence ASI Lyon, fait preuve de créativité pour sans cesse se réinventer et diversifier ses savoir-faire tout en développant des expertises techniques et métiers, lui permettant d’adresser les besoins 360 de ses clients.  🧑‍🚀  L’équipe est aujourd’hui constituée d’environ 60 spécialistes qui interviennent dans les évènements de l’écosystème numérique local. En recherche constante de nouveaux talents et de leaders passionné(e)s par la concrétisation de projets innovants au service de nos clients. ASI Lyon, ce sont aussi des sourires, de la bonne humeur et des moments pour se retrouver entre nous parce qu’on aime ça !  Description du poste (Dans un souci d’accessibilité et de clarté, les termes employés au masculin se réfèrent aussi bien au genre féminin que masculin).  Véritable architecte ou expert cloud et de la Big Data, vous contribuez à la définition de l’orientation technologique des activités, en alignement direct avec la stratégie de l'entreprise. Le challenge vous anime, vous mettez en place, développez l’offre Cloud/Big Data et constituez votre équipe pour accompagner nos clients dans leurs programmes de transformation IT vers les solutions innovantes et vous évangélisez les enjeux Cloud en lien avec leurs cœurs de métier. 🦸🏽‍♀️   Votre rôle, très complet, passe par le lead d’équipe, la contribution à la dynamique de croissance du pôle, par la maîtrise du design d’architecture en passant par des problématiques data dans le cadre de vos missions. Doté d’une vision technique pointue, vous serez acteur incontournable en phases d’avant-vente permettant de proposer des architectures Cloud performantes, fiables, sécurisées et évolutives aux projets stratégiques. Dans le cadre de l’animation du pôle Data, vous êtes vecteur de communication de l’empreinte technologique au travers de séminaires, conférences et de webinars. Qualifications Vous êtes diplômé d’une école d’ingénieur ou d’un parcours universitaire technique. Vous justifiez d’au minimum de 5 ans d’expérience professionnelle en tant qu’expert ou architecte cloud. Vous avez une expérience en pilotage opérationnel réussie et vous souhaitez poursuivre ou évoluer dans des environnements Agile & DevOps Doté de véritables qualités relationnelles et d’un leadership naturel, vous savez insuffler une véritable dynamique d’équipe et savez accompagner dans la mise en place des bonnes pratiques Toujours en quête de savoir, vous assurez une veille prospective et concurrentielle. Compétences techniques : Connaissances multicloud Azure, AWS et/ou Google Cloud Platform (GCP) Systèmes de gestion des bases de données : SQL, Synapse, Snowflake Langages de programmation : java, python, Spark/scala  Outils de construction et de virtualisation : Jenkins, Docker, Kubernetes, Ansible  Repository de code : Git, GitHub, SVN, Méthodes Agile et approche DevOps Informations supplémentaires Vous bénéficierez bien sûr d’un package avantageux mais rejoindre ASI, c’est surtout intégrer une entreprise : Signataire de la Charte de la diversité : nous faisons en sorte que chacun, quelles que soient ses particularités, se sente appartenir à la société et soit toujours reconnu pour ses compétences.  A l’écoute de ses collaborateurs : ASI est triplement labellisée HappyAtWork, TechAtWork et Impact RSE. Ces labels sont décernés par Choose My Company aux entreprises respectant notamment les principes de traitement éthique et de respect de l’environnement et où les salariés sont le plus motivés et heureux. 😃    A l’offre de formation riche : grâce à la "ASI Academy", vous aurez la possibilité de participer à des formations en présentiel ou distanciel, par le biais d’un parcours à plusieurs niveaux (découverte, approfondissement, évaluation). 40 Asiens ont été certifiés l’an dernier. Ayant à cœur de maintenir constamment la convivialité et la cohésion entre ses collaborateurs au travers de séminaires annuels, soirées d’agence, afterworks ou encore événements internes.  Porteuse d’une démarche RSE VRAIMENT active : ASI a fait partie des 30 premières entreprises à avoir rejoint la Convention des Entreprises pour le Climat (CEC). Notre Team RSE est composée de 30 collaborateurs volontaires et engagés sur les sujets de préservation de l’environnement, le numérique responsable, le bien-être au travail ! Company Description Ocorian is a global leader in corporate and fiduciary services, fund administration and capital markets. Wherever our clients hold financial interests, or however they are structured, we provide compliant, tailored solutions that are individual to their needs. We manage over 17,000 structures for 8000+ clients with a global footprint operating from 18 locations. Our scale offers all our people great opportunities to develop their knowledge and skills and to progress their careers. Job Description Purpose of the job To assist in the development of business intelligence and management information solutions for Ocorian taking information from the financial, HR, corporate administration systems, and Cloud-based solutions to create a reporting base for the business, the single source of truth Delivery of key dashboards and reporting requirements from the BI/MI solutions with appropriate robust security models Assist with data cleansing and data loading exercises, which may extend to jurisdictional and regulatory filing requirements Documentation of solutions, handover to BAU Teams, and supporting solutions Prior experience of creating/supporting ETL, data warehouses and Tabular data models. Ocorian utilises Microsoft SQL Server technologies, including SSIS, SSAS, SSRS and Power BI and the successful candidate should have delivered projects using aspects of this technology stack in recent times The individual will be expected to work across all levels of the Business to liaise with key stakeholders to ensure the design, development and documentation meets the requirements of the Business. The role will work extensively with IT functions and the role may be matrix-managed when required with tasks assigned by the BAU BI Team  Main responsibilities Design and implement data warehouse solutions and Tabular data models Develop dashboards and reporting to meet business reporting needs Deliver approved projects within timeframe Provide regular updates to management Make recommendations for potential improvement or changes Promote the use of core systems for data capture aligned to standards and initiatives Qualifications TECHNICAL SKILLS SQL Server 2016 onwards SQL Server BI stack – SSAS / SSIS / SSRS Microsoft Power BI Experience of data cleansing tools and methodologies BUSINESS SKILLS Demonstrated ability to apply IT in solving business problems Good written, oral, and interpersonal communication skills Ability to present ideas in business-friendly and user-friendly language Highly self-motivated, proactive and attentive to detail Ability to effectively prioritise and execute tasks in a high-pressure environment Extensive experience working in a team-oriented, collaborative multi-jurisdictional environment Experience of working in project teams with mixed skillsets and levels of technical knowledge Energy and enthusiasm to support the future growth and success of the business Additional Information All staff are expected to embody our core values that underpin everything that we do and that reflect the skills and behaviours we all need to be successful.  These are: We are AMBITIOUS - We think and act globally, seizing every opportunity to support our clients and staff - wherever in the world they may be. We are AGILE - Our independence from any financial institution gives us the flexibility and freedom to keep things simple, efficient and effective. We are COLLABORATIVE - We take the time to understand our clients' needs so that we can deliver personalised solutions every time. Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value. Job Description As Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects: Data Ingestion, Transformation & Consumption, Data Storage and Computation Frameworks, Performance Optimizations, Infrastructure, Automation & Cloud Computing, Data Governance & Security The role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java / Scala / Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. Role & Responsibilities: 1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation. 2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality 3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality 4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies 5. Participate in workshops with clients and align client stakeholders to optimal solutions. 6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc. 7. People management, contributing to hiring and capability building #LI-REMOTE  Qualifications Overall 8+ years of IT experience with 3+ years in Data related technologies  3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS / Azure / GCP) and delivered at least 1 project as an architect. Mandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud.  Expert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions Expert in programming languages like Java/ Scala and good to have Python Expert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc. Expert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc. Should have worked on MPP style query engines like Impala , Presto, Athena, etc Should have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc. Should have a good understanding of how to set up Big data cluster security – Authorization/ Authentication, Security for data at rest, and data in Transit. Should have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager – Data Engineering Should have worked on any of Orchestration tools – Oozie, Airflow, Ctr-M, or similar. Worked on Performance Tuning, Optimization, and Data security   Competency 1. Excellent understanding of data technologies landscape/ecosystem. 2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases 3. Good Exposure in development with CI / CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage. 4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models 5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage. 6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions 7. Thought Leadership – blogs, keynote sessions, POV/POC, hackathon 8. Certification in either one of the cloud platforms or big data technologies Personal Attributes: Strong analytical and problem-solving skills Strong communication skills in verbal, written and visual presentations Strong coordination and negotiation skills Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Multi geo experience and distributed delivery experience in large programs Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements  Employee Assistance Programs to help you in wellness and well being About Us: SentinelOne is defining the future of cybersecurity through our XDR platform that automatically prevents, detects, and responds to threats in real-time. Singularity XDR ingests data and leverages our patented AI models to deliver autonomous protection. With SentinelOne, organizations gain full transparency into everything happening across the network at machine speed – to defeat every attack, at every stage of the threat lifecycle.  We are a values-driven team where names are known, results are rewarded, and friendships are formed. Trust, accountability, relentlessness, ingenuity, and OneSentinel define the pillars of our collaborative and unified global culture. We're looking for people that will drive team success and collaboration across SentinelOne. If you’re enthusiastic about innovative approaches to problem-solving, we would love to speak with you about joining our team! What our team does: The Ingestion team is responsible for SentinelOne's highly scalable ingest of data from all kinds of endpoints into our Data Platform. Ingesting billions of events every day, handling billions of objects and enabling customers to search and gain insight into their data. All with the ability to scale up and down as needed, minimising costs, maximising efficiency, maintaining high availability at petabyte scale. Our team solves non-trivial scale and data problems with a unique blending of cloud, distributed systems, and software optimisation techniques and services. Your duties : Software Development (70-80% of time) Lead implementations of new specifications; Write tests to cover new code or newly found issues; Implement with consistent coding patterns with a focus on stability and security Review Code Raise the quality, stability and security of the code for entire team codebase Provide guidance and meaningful feedback, understanding broader patterns and downstream and upstream dependencies Build and Review Technical Specifications Document trade-offs in solutions/implementations; Document critical implementation details/pipelines; Review and provide feedback on other specs Deeply understands architecture of Ingestion pipelines and connected features Architect end-to-end solution for a complex feature with loose problem definition Support/On-Call Rotation Respond/troubleshoot to outage incidents; Fix newly found issues Teamwork Help team members solve problems; Provide feedback; Attend weekly team sync; Provide Daily Standup in Slack Your tools: Primarily modern Java, Go, Python, Scala, Rust; AWS, GCP, FedRAMP Kafka, Splunk, S3, Kubernetes, Terraform, Docker, Jenkins, GitHub; Flink; You enjoy and your passion: You’re passionate about building high-scale elegant and simple distributed systems - and during the past several years you’ve successfully designed & implemented them (using Java or similar), to solve complex problems You enjoy a collaborative development process using design discussions and code review You’re looking for the technical challenges of ingesting and processing petabytes of data daily We’d appreciate / You’d learn & gain: You possess solid foundation on building ingestion pipelines, experience with solving high volume streaming challenges and scaling You can identify relevant improvements/solutions in the literature & bring them into production when they fit You enjoy writing modern Java, Scala, Go and you want to learn Rust Deep understanding of technology trade-offs and costs of different options, to keep the system stable and scalable Hands-on experience with Kafka What we offer you Salary from 5000 EUR/month. Yearly % bonus depending on the performance of the company, paid out in 2 installments. *The final base salary component can be increased accordingly to individual skills and experience of the selected candidate. On top of that you may look forward to: Flexible working hours & Full remote within Slovakia; optional membership in Regus co-working spaces; in Czechia we also have offices in Prague or Brno Generous employee stock plan in the form of RSUs (restricted stock units) Flexible Time Off (on top of the standard 5 weeks of vacation) Flexible Paid Sick Days Fully Paid Short Term Sick/Short Term Nursing Leave Global gender-neutral Parental Leave (16 weeks, beyond the leave provided by the local laws) & Grandparent Leave Volunteering paid day off & Additional paid Company holidays and Wellness days off (e.g. 6 days in 2022) Pension insurance contribution Premium Life Insurance covered by S1 Cafeteria points (5.000 CZK/month), which you can spend on leisure & sports, kindergarten/school fees, travel etc.  Private medical care membership Global Employee Assistance Program (confidential counseling related to both personal and work life matters) High-end MacBook or Windows laptop, Home-office-setup gear & on top of that additional WFH Allowance Udemy Business platform for Hard/Soft skills Training & Support for your further educational activities/trainings Above-standard referral bonus Yearly bonus depending on the performance of the company On top of RSUs, you can benefit also from our attractive ESPP (employee stock purchase plan) Refreshments & snacks at the offices (+weekly massages & yoga at Prague office) Optional company events for those who like to meet outside of work too (sport, BBQ, charity, offsite etc.) SentinelOne is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. SentinelOne participates in the E-Verify Program for all U.S. based roles.  About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Overview: The Agoda Content department is currently looking for a curious and questioning self-starter and proactive analyst, who will help drive decision making with insights from content, marketing and partner performance data. You will get the opportunity to own analytical projects to direct our department’s focus, and prioritize our actions. By joining Agoda, you will become part of a truly international team, with leading experts of different backgrounds coming from 50+ countries around the world. This is a genuine opportunity to gain valuable experience in a challenging and cutting-edge tech environment. The ideal candidate would have a passion for high-converting content, great user-experience, data and analysis tools and methods. This position reports to the Associate Director of Content Operations, in Bangkok, Thailand.   Main responsibilities: Understand Content goals and KPIs and be able to align reports and insights based on them. Identify and investigate trends, anomalies and opportunities to improve Agoda’s Content strategy. Identify content opportunities that drive customer value, bookings and conversion Help build business cases around the opportunity and get buy-in from stakeholders Ensure appropriate data/tools/dashboards to measure execution and enable deeper analysis Track execution and report up in regular updates Work with product, data/BI team and IT to create data resources and build appropriate reporting Work with Content team leads to understand their business needs and identify opportunities in terms of team actions prioritization and focus. Use multiple data sources to report Content projects insights and impact; support Content tests and experiments. Encourage and train the Content team in best practice use of Agoda data, analysis techniques and interpretation. Coordinate with other Cross Functional departments like Analytics, Partner Services, and Product Owners Use Web-Analytics for Research and Analysis Requirements: Bachelor degree or higher 2+ years of relevant experience Experience / knowledge in statistics, SQL, Python/R, Tableau and advanced Excel – required Ability to demonstrate data manipulation using data warehouse and create meaningful insight and visualization Experience / knowledge in Vertica and / or Impala – advantage Experience in generating data and / or preparing experiments for product development – advantage Professional characteristics: Attentive to detail and committed to data integrity Keen and curious nature; able and willing to share your opinion Organized; able to manage multiple, competing priorities and deliver results under tight deadlines Able to communicate effectively; fluent in English – both spoken and written #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Our Engineering community is growing, and we’re now looking for a (Senior) Big Data Engineer to join our team supporting our global growth.  As Big Data Engineer, you design and optimize data processing algorithms on a talented, cross-functional team. You are familiar with the Apache open-source suite of technologies and want to contribute to the advancement of data engineering.  WHAT WE OFFER A chance to accelerate your career and work with outstanding colleagues in a supportive learning community split across 3 continents Contribute your ideas to our unique projects and make an impact by turning them into reality Balance your work and personal life through our workflow organization and decide yourself if you work at home, in the office, or on a hybrid setup Annual performance review, and regular feedback cycles, generating distinct value by connecting colleagues through networks rather than hierarchies Individual development plan, professional development opportunities Educational resources such as paid certifications, unlimited access to Udemy Business, etc. Local, virtual, and global team events, in which UT colleagues become acquainted with one another Requirements WHAT YOU’LL DO You make data useful. You build program code in Java or similar languages, test and deploy to various environments, design and optimize data processing algorithms for clients You work on feature implementation, and you automate testing of data-driven applications, using open-source and cloud-native technologies You organize your workflow independently in an agile setting and contribute to your team with high quality code in alignment with the project vision You communicate primarily in English with your team members  WHAT YOU’LL BRING 2+ years of hands-on experience in the development of software using Java or a comparable language Experience with data ingestion, analysis, integration, and design of big data applications using Apache open-source technologies, such as Hadoop, Spark, or Flink. Experience with Kafka, Docker, Kubernetes also good Solid computer science fundamentals (algorithms, data structures, and programming skills in distributed systems) and work experience in agile environments Professional communications skills in English   Did we pique your interest, or do you have any questions? We want to hear from you: contact us at recruit@ultratendency.com  ABOUT US Ultra Tendency is an international premier Data Engineering consultancy for Big Data, Cloud, Streaming, IIoT and Microservices. We design, build, and operate large-scale data-driven applications for major enterprises such as the European Central Bank, HUK-Coburg, Deutsche Telekom, and Europe’s largest car manufacturer. Founded in Germany in 2010, UT has developed a reliable client base and now runs 8 branches in 7 countries across 3 continents. We do more than just leverage tech, we build it. At Ultra Tendency we contribute source code to +20 open-source projects including Ansible, Terraform, NiFi, and Kafka. Our impact on tech and business is there for anyone to see. Enterprises seek out Ultra Tendency because we solve the problems others cannot. We love the challenge: together, we tackle diverse and unique projects you will find nowhere else. In our knowledge community, you will be a part of a supportive network, not a hierarchy. Constant learning and feedback are our drivers for stable development. With us you can develop your individual career through work-life balance. We evaluate your application based on your skills and corresponding business requirements. Ultra Tendency welcomes applications from qualified candidates regardless of race, ethnicity, national or social origin, disability, sex, sexual orientation, or age. Data privacy statement: Datenschutzerklärung für Bewerber – Ultra Tendency Unternehmensbeschreibung Bei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch. Die Robert Bosch GmbH freut sich auf Deine Bewerbung! Stellenbeschreibung Im Geschäftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen – von hocheffizienten Antrieben über das erste serienreife ABS fürs Pedelec bis hin zu smarten Connectivity-Lösungen. Für eine nachhaltige Mobilität, die Spaß macht. Du bist Expert:in für den Bereich Data Engineering bei Bosch eBike Systems und stellst die relevanten Daten den Nutzern unserer Cloud-basierten Datenplattform zur Verfügung. Du programmierst gerne und beherrschst Python und SQL. Zu Deinem Repertoire zählen außerdem ausgeprägte Kenntnisse über die performante Verarbeitung und Speicherung großer Datenmengen sowohl in Data Lakes als auch in Data Warehouse Systemen. Im Rahmen Deiner Tätigkeit führst Du Code-Reviews durch und definierst Best Practices und Leitplanken für die Entwicklung von Data Pipelines.  Wir unterstützen Dich, damit Du Deine Kreativität in dem Bereich entfalten kannst und bieten Design Reviews mit anderen erfahrenen Kolleg:innen und Interessengruppen an. Du baust Deine Data Pipelines robust und mit einem hohen Fokus auf Observability, um eine einfache Fehleranalyse zu ermöglichen. Zudem übernimmst Du Verantwortung für deine entwickelten Daten Pipelines auch während des Betriebs und entwickelst diese kontinuierlich weiter, um eine optimale Qualität und Zuverlässigkeit sicherzustellen. Du hast Spaß daran, dein Wissen weiterzugeben und agierst als Mentor:in für Junior Kolleg:innen im Team. Es macht Dir Spaß mit dem Daten-Team, den Fachbereichen, der IT und den Kolleg:innen im fachlichen Diskurs die beste Lösung zu identifizieren. Qualifikationen Ausbildung: abgeschlossenes Hochschulstudium (Master/Diplom/Promotion) der Wirtschaftsinformatik oder eines vergleichbaren Studienganges Persönlichkeit und Arbeitsweise: kommunikativ, selbstreflektiert, getting-things-done-Mindset, stetig lernbereit, Interesse für Innovationen im Arbeitsgebiet, eigenverantwortlich, lösungs- und kundenorientiert, pragmatisch und problembewusst Erfahrungen und Know-how: 5 Jahre Berufserfahrung als Data Engineer sowie Erfahrung im Aufbau von zuverlässigen Data Pipelines; Erfahrung in der agilen Softwareentwicklung (SCRUM, Kanban) und Erfahrung in der Datenmodellierung sowie in unterschiedlichen Ansätzen für Daten Architekturen; Erfahrung im Arbeiten in multinationalen Teams Know-How: Breites Wissen über unterschiedliche Technologien im Bereich Big Data Engineering (z.B. Databricks /Spark, Snowflake, Apache Airflow, dbt, Kafka) sowie fundierte Kenntnisse in relevanten Programmiersprachen (Python, SQL, Scala) und CI/CD (Gitlab CI/CD, Jenkins); Außerdem Kenntnisse der Daten-Analyse, des Daten-Managements und der Softwareentwicklung Begeisterung: Spaß daran, Wissen an andere zu vermitteln Sprachen: sehr gute Deutsch- und Englischkenntnisse in Wort und Schrift Zusätzliche Informationen In diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente.  Bewirb Dich jetzt in nur 3 Minuten! Du möchtest Remote oder in Teilzeit tätig sein - wir bieten tolle Möglichkeiten des mobilen Arbeitens sowie unterschiedliche Teilzeitmodelle. Sprich uns gerne dazu an. Du hast Fragen zum Bewerbungsprozess? Nelly Ehrmann (Personalabteilung) +49 711 811 27525 Du hast fachliche Fragen zum Job? Daniel Grimm (Fachabteilung) +49 7121 35 18668 Interessierst Du Dich für diese oder weitere Stellen? Dann bewerbe Dich auf die Virtual JobFair@BOSCH und verschaffe Dir einen Überblick über die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de/events/                                         About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to Know our Team:  Partner Development is a team of creative entrepreneurs that develop solutions for Agoda’s accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. In this role you'll get to As a Data Analyst in the PD Analytics team, you will be using data and modeling techniques to identify opportunities and build models and tools to improve efficiency and effectiveness for Agoda's supply team.  Key activities involved include but not limit to: Apply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations Own end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development Build dashboards, identify new and track key metrics to closely monitor team’s performance and identify quick and long term opportunities for improvements Work closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified Support global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization What you'll need to succeed  Bachelor’s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline 3-6 years experience working in a business analysis, data analysis, reporting or business strategy role Excellent problem-solving skills including the ability to analyze and resolve complex problems using data Team player with strong interpersonal, relationship-building, and stakeholder management skills Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala) Data visualization tool experience such as with Tableau or your weapon of choice. Ability to work under pressure in a fast-paced and rapidly changing environment Excellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Company Description Bosch Sensortec GmbH is a technology leader in sensing solutions based on microelectromechanical systems (MEMS) and dedicated to the consumer electronics world. We develop and market key technologies for smartphones and tablets, hearables, wearables, smartglasses, augmented and virtual reality applications, gaming devices and many more. Our sensors improve people’s well-being and lifestyle and enable consumer electronic devices to sense the world around us. MEMS sensors are therefore an essential part of the foundation for a connected world. Bosch Sensortec GmbH is a wholly owned subsidiary of Robert Bosch GmbH.      Bosch Sensortec GmbH is looking forward to your application! Job Description As part of our team you get an insight into our department being responsible for the development of our next generation consumer inertial sensors and sensing systems. We implement technological innovations enabling advanced sensor system performance and ensure reliable system integration and testing for high volume and high-quality mass production. You support in preparation, execution and evaluation of inertial sensor measurements You are responsible for the definition and implementation of evaluation templates for large characterization and qualification datasets, by applying tools of the big data and data science domain and you develop creative solutions in Python, Knime, Tableau or Power BI You support the development of data driven concepts and algorithms for the improvements of selected sensor key performance parameters and verify those by dedicated lab measurements You align and harmonize your solutions with other department and company stakeholders You are part of an international and multicultural development team Qualifications Personality: Positive team player with good communication skills, creative thinking Working Practice: Experience in Big Data and Machine Learning / AI. Experience and Knowledge: Understanding of statistics and visualization tools e.g. Knime, Power BI, Tableau. Mastering of a programming language, preferable Python Languages: Very good spoken and written English skills, German is a plus Education: Current Master studies in Computer or Data Science, Mathematics, Physics or similar major Additional Information The Bosch PreMaster Program (Gap Year Program) is a two-stage qualification program for committed graduates with Bachelor's degrees who want to complete a Master's degree. After the Bachelor's degree, the first phase provides up to 12 months' practical experience for familiarization with technical and business interrelationships. The second phase comprises the Master's course and includes additional events and seminars as well as personal mentoring on the road to successful completion.  Need support during your application? Samuel Zinn (Human Resources)  +49 7121 35-33717 Need further information about the job? Holger Wüst (Functional Department) +49 7121 35-31522  Further information can be found online: https://www.bosch.de/en/career/your-entry/graduates/premaster-program/ About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to Know our Team:  The Supply Analytics team is a team of creative entrepreneurs that develop solutions for Agoda’s non-accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek.  Utilizing our strong brand and resources, we build new channels to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.  The Opportunity:   The role sits within the Supply Analytics team under Central Supply Team, where new business ideas, and partnership types are incubated and scaled. We are looking for a Senior BI Analyst whose main focus areas are providing visibility and insights for people-related issues through Business Intelligence tools like Tableau and SQL, managing data warehouses, building ETL processes, and helping build other tools to optimize the business. This role will be involved in strategic projects and work closely with commercial owners and business stakeholders, using data to identify and translate business needs and opportunities into actionable initiatives. In this Role, you’ll get to: Translate internal briefs into analytical projects (to include refining the initial brief and asking the ‘right questions’, working through potential hypotheses and storyboarding the output) Use and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders. Proactively identify opportunities for growth within supply and the wider business. Drive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply. Identify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence. Automate manual operational processes and present back on time savings gained through modernization of business operations What you’ll Need to Succeed: 4+ years of experience in analytics/data science/insights/strategy. Bachelor’s degree ideally in a business or quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance). 3+ years of experience with BI & analytics tools (SQL, Tableau, Metabase, Data Studio, or similar technologies) 2+ years of solid project management Good stakeholder management experience. Comfortable presenting to senior leadership and C-suite. Strong experience in finding data insights and provide business recommendation to the business A hacker’s mindset – the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping. Excellent communicator with superior written, verbal, presentation and interpersonal communication skills. Data driven in both decision making and performance measurement. Extreme comfort in ambiguous, fast-paced environment. Ability to multi-task, prioritize and coordinate resources. It’s Great if you Have:   Travel industry / e-commerce / tech / consulting experience. Experience in conducting A/B testing experimentation (a plus) A good understanding of statistical modelling knowledge or any machine learning technique knowledge is a plus (regression, logistic regression, random forest, etc.)   #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Job Description GlobeMed Group, the largest Healthcare Benefits Management company in the MENA region is looking for a (Senior) BI Developer to develop and test Business Intelligence applications integrated with the enterprise data warehouse and the source databases. In addition, he/she will be coordinating with the Business Intelligence Team Leader and his team to ensure timely completion of projects’ deliverables to the end user.  Duties & Responsibilities: Develops and maintains business intelligence applications based on technical requirements and designs following Business intelligence development standards and guidelines. Performs testing of all components of BI applications. Coordinates with other ICT teams. Determines requirements feasibility by evaluating analysis, problem definition, solution development, and proposed solutions. Demonstrates solutions by creating or updating documentations, Guidelines, flowcharts, layouts, code comments and clear code. Work closely with the Team Leader for understanding of the functional and technical requirements Develop the atomic/semantic layers, metadata, reports and analytic dashboards Assist the team leader in the design of databases and data warehouses to ensure interoperability with business intelligence applications. Conduct job duties and responsibilities according to the organization’s business intelligence development methodology Troubleshoot BI tools and applications. Conduct research related to Business Intelligence projects. Qualifications Experience in BI tools development (Qlik) or experience in ETL (Talend or Informatica) development Experience in Data Warehouse fundamentals. SQL experience is a must (PL/SQL development experience is a plus) Bachelor Degree in computer science or related fields. Analytical thinking and strong troubleshooting skills Fluent in English and Arabic About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to know our team: Partner Development is a team of creative entrepreneurs that develop solutions for Agoda’s accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. In this role you'll get to This role is designed to mainly growth opportunity identification among mid to long tail hotels, experiment execution and data tracking within Partner Development team for the global teams. You will get to work directly with the regional team to design and put in place global experimentation and initiatives to drive tangible impact in each market. Key activities involved include but not limit to: Apply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations Own end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development Build dashboards, identify new and track key metrics to closely monitor team’s performance and identify quick and long term opportunities for improvements Work closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified Support global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization What you'll need to succeed  Bachelor’s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline 4-8 years experience working in a business analysis, data analysis, reporting or business strategy role Excellent problem-solving skills including the ability to analyze and resolve complex problems using data Team player with strong interpersonal, relationship-building, and stakeholder management skills Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala) Data visualization tool experience such as with Tableau or your weapon of choice. Ability to work under pressure in a fast-paced and rapidly changing environment Excellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description This position is ideal for an engineer who is passionate about solving challenging business problems and building applications that provide an excellent user experience. You will be an integral part of the Payment Products Development team focusing on design and development of software solutions that leverage data to solve business problems. The candidate will be extensively involved in hands-on activities including POCs, design, documentation, development, and testing of new functionality. Candidate must be flexible and willing to switch tasks based on team's needs.  Responsible for the design, development, and implementation. Work on development of new products iteratively by building quick POCs and converting ideas into real products. Design and develop mission-critical systems, delivering high-availability and performance. Interact with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology. Develop code to ensure deliverables are on time, within budget, and with good code quality. Have a passion for delivering zero defect code and be responsible for ensuring the team's deliverables meet or exceed the prescribed defect SLA. Coordinate Continuous Integration activities, testing automation frameworks, and other related items in addition to contributing core product code. Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner. Perform other tasks on R&D, data governance, system infrastructure, and other cross team functions, on an as-needed basis This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs. Qualifications We are seeking team members that are passionate, visionary and insatiably inquisitive. Successful candidates frequently have a mix of the following qualifications:  • 2 or more years of work experience in building large-scale applications using open source technologies • Bachelor’s Degree or an Advanced Degree (e.g. Masters) in Computer Science/ Engineering, Information Science or a related discipline • Extensive experience with SQL and Big Data technologies (Hadoop, Java, Spark, Kafka, Hive etc.) tools for large scale data processing and data transformation • Experience with data visualization and business intelligence tools like Tableau, or other programs highly desired • Familiar with software design patterns • Experience working in an Agile and Test-Driven Development environment • Strong knowledge of API development is highly desired • Strategic thinker and good business acumen to orient data engineering to the business needs of internal and external clients • Demonstrated intellectual and analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style • Previous exposure to financial services is a plus, but not required  Please Note: Due to the COVID-19 pandemic and the evolving visa/travel restrictions in place, we are currently only able to extend offers to candidates with the right to work in Singapore. We are keeping the situation under close review and will adjust accordingly should the restrictive measures be lifted. Additional Information Visa has adopted a COVID-19 vaccination policy. As a condition of employment, all employees based in Singapore are required to be fully vaccinated for COVID-19, unless a reasonable accommodation is approved or as otherwise required by law. Company Description At Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people’s lives. Our promise to our associates is rock-solid: We grow together, we enjoy our work, and we inspire each other. Welcome to Bosch. The Robert Bosch GmbH is looking forward to your application! Job Description As DevOps Engineer for Cloud Data Platform services you act as IT Operation/Infrastructure Specialist. You drive industrialization of the cloud based Manufacturing Data Platform through further automation of deployment, configuration, upgrade, and maintenance processes. Part of your work also entails developing new Manufacturing Data Platform features supporting workload automation, monitoring, and enhanced usability. In your responsibility lies the development of scripts for automation (deployment, configuration) and monitoring, as well as providing expert product support to Bosch business units (e.g. root-cause analysis of non-standard issues). Your tasks also include testing and evaluating new product features in close alignment with project stakeholders, internal customers, and vendors. Furthermore, you consult internal customers on technical level regarding tool selection, code quality, connectivity topics and workload performance. Qualifications Education: completed university degree in Computer Science, Information Technology, Engineering, Natural Science or related fields Personality: resilient, team-oriented Working Practice: initiative, goal-oriented Experience: experience (hands-on) as Software or DevOps engineer in cloud based Data Lake and Analytics environments; experience in Big Data designs, architectural blueprints, in the cloud concept IaC (infrastructure as code e.g. Terraform); experience working in larger projects, including multiple customers and international teams Knowledge: knowledge in data processing with Big Data frameworks (e.g. Spark), in version control tools (GIT, Bitbucket) and in CI/CD Pipeline tools (e.g. Jenkins, Azure DevOps), in in scripting languages (e.g. Python, C, Scala) and in Microsoft Azure Analytics ecosystem (ADLS, Functions, EventHub); ability to move easily between conceptual and implementation level Languages: good English and German Additional Information You want to work remotely or part-time - we offer great opportunities for mobile working as well as different part-time models or job-sharing. Feel free to contact us. Diversity and inclusion are not just trends for us but are firmly anchored in our corporate culture. Therefore, we welcome all applications, regardless of gender, age, disability, religion, ethnic origin or sexual identity. Need support during your application? Anna Haas (Human Resources) +49 711 811 27525 Need further information about the job? Johannes Epple (Functional Department) +49 711 811 14417 Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description This position is ideal for an experienced Software engineer who is passionate about solving challenging business problems and building applications that provide an excellent user experience. You will be an integral part of Loyalty & Marketing Services team focusing on design and build of software solutions that leverage data to solve business problems. Responsibilities Responsible for the architecture, design, development, and implementation. Work on development of new products iteratively by building quick POCs and converting ideas into real products. Design and develop mission-critical systems, delivering high-availability and performance. Interact with both business and technical stakeholders to deliver high quality products and services that meet business requirements and expectations while applying the latest available tools and technology. Develop code and mentor junior developers to ensure delivery on time, within budget, and with good code quality. Have a passion for delivering zero defect code and be responsible for ensuring the team's deliverables meet or exceed the prescribed defect SLA. Help developer efficiencies by utilizing Continuous Integration/Development tools, test automation frameworks and other related items. Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner. Identify opportunities for future enhancements and refinements to products, standards, best practices, and development methodologies Collaborate with global and virtual teams on software development. This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office two days a week, Tuesdays and Wednesdays with a general guidepost of being in the office 50% of the time based on business needs. Qualifications • Master’s Degree in Computer Science or related field with 6 years of relevant experience or Bachelor’s degree with 8 years of relevant experience. • Previous exposure to financial services is a plus, but not required. • Strong knowledge on Hadoop framework components (HDFS, Map Reduce, Spark, HBase, Kafka). • Strong knowledge in Java or Scala or Python. • Strong knowledge of database concepts, systems architecture, and data structures is a must. • Experience with one or more of the following database technologies: DB2, Postgres, MySQL, and NoSQL such as Hadoop, Hbase, MongoDB. • Proficient in GIT/Stash, Maven, Jenkins etc. • Java/J2EE/Angular, Spring Cloud, Microservices and strong knowledge on API development is a big plus. • Experience working in an Agile and Test-Driven Development environment. • Process oriented with strong analytical and problem-solving skills. • Work independently and mentor others in the team and with minimal supervision. • Ability to juggle multiple projects and change direction mid-course based on business drivers. • Demonstrated ability to work in a complex organization to determine business and customer needs, providing the best solution to meet those needs. • Ability to work independently in a high throughput environment. • Demonstrated intellectual and analytical rigor, strong attention to detail, team oriented, energetic, collaborative, diplomatic, and flexible style. • Excellent presentation and communication skills required. Additional Information Visa has adopted a COVID-19 vaccination policy. As a condition of employment, all employees based in the country where this job is located are required to be fully vaccinated for COVID-19, unless a reasonable accommodation is approved or as otherwise required by law. Company Description At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.  With more than 7,400+ customers, we serve approximately 80% of the Fortune 500, and we're proud to be one of FORTUNE's 100 Best Companies to Work For® and World's Most Admired Companies® 2022. Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow. Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates. Job Description Job Description The Big Data team plays a critical and strategic role in ensuring that ServiceNow can exceed the availability and performance SLAs of the ServiceNow Platform powered Customer instances deployed across the ServiceNow cloud and Azure cloud.  Our mission is to: Deliver state of the art Monitoring, Analytics and Business Insights by employing new tools, Big Data systems, AI and Machine Learning methodologies that improve efficiencies across a variety of functions in the company: Cloud Operations, Customer Support, Product Usage Analytics, Product Upsell Opportunities enabling to have an significant impact both on the topline and bottomline growth   The Big Data team is responsible for: Collecting, storing and providing real-time access to large amount of data Provide real-time analytics tools and reporting capabilities for various functions including: Machine Learning and Anomaly detection Monitoring, alerting and troubleshooting Capacity planning Data analytics and deriving Business Insights Role Responsibilities Responsible for Building, Maintaining and Supporting BigData infrastructure on ServiceNow Private Cloud and Azure. Automate deployment, maintenance, and monitoring of BigData components. Implement security for our Hadoop clusters. Capacity planning for BigData clusters. Performance tuning for various Hadoop components. Responsible for enforcing data governance policies. Help with various Big Data and cloud automation projects. Application code deployment, maintenance and troubleshooting Spark, Hbase, Kudu applications, API’s, Python, and shell scripts. Perform On-Call production monitoring and support for Big Data infrastructure and Big Data applications in ServiceNow private cloud and Azure cloud.   Qualifications Technical Skills Expert level experience in a Hadoop administration (preferably Cloudera CDP) role. Expert level experience working on Azure or AWS. Experience with performing Hadoop and Azure/AWS performance tuning. Experience with Ansible, Terraform, Puppet and similar technologies. CI/CD automation leveraging Docker/Kubernetes orchestration. In-depth knowledge of Hadoop components such as Spark Streaming, HDFS, HBase, YARN, Hive, Impala, Atlas, and Kudu. Experience securing Hadoop stack with Sentry, Ranger, LDAP, Kerberos KDC. In-depth knowledge of Centos 7.x and shell scripts. Working knowledge of Java, Python, Shell. Ability to learn quickly in a fast-paced, dynamic team environment. Highly effective communication and collaboration skill. Required Bachelors or master’s degree in computer science or equivalent. 7+ years of overall experience with at least 2 in Big Data related positions.  JV20 Additional Information ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law. At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office. If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance. For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government. Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.   From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license. Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow. Company Description Our brand Deutsche Telekom IT Solutions Slovakia entered the life of Košice region in 2006 under the name of T-Systems Slovakia and ever since has been inextricably linked with the region when became one of the founding members of Košice IT Valley. We have managed to grow from scratch to the second largest employer in the eastern part of the country with more than 3900 employees. Our goal is to proactively find new ways to improve and continuously transform into the type of company providing innovative information and communication technology services. Job Description Purpose The senior data engineer develops, constructs, tests and maintains architectures, such as databases and large-scale processing systems, and ensures that architecture fully supports requirements of the business. Plays a collaborative role where he/she works closely with the business’s Data and Analytics teams, gathering technical requirements for exceptional data governance. Key accountabilities As a Senior Software Engineer in the field of Data & Analytics, you will develop complex software solutions for the IT landscape of tomorrow's telecommunications in agile teams. You will take over the further development of software for complex products and services along the entire development process (lifecycle). We use the following technologies: Cloudera, Kafka, NiFi, Flink, Spark, Informatica, Unix/Linux, Java, REST, SOAP, PL SQL, DB2 (Unix), Perl, Scala, Python. Together as a team, you will implement customer requirements, develop prioritized user stories and ensure the quality of your solutions 1.    As an experienced Big Data Software Engineer, you will give guidance to less experienced colleagues, keep an eye on the big picture and thus ensure the implementation of the vision with the team 2.    You will program, take over the installation and configuration of the software as well as the creation and maintenance of the software documentation 3.    You will design and define system tests and test automation and support team members during error analysis up to error elimination 4.    You will also take over the technical last level support for other teams for the supervised systems and service Team Description As a Senior Data Engineer in the field of data analytics, data engineering technologies and the development of data analytics solutions are your passion. You feel at home when it comes to developing data pipelines, implementing microservices, and building databases/data lakes. You quickly understand complex data analytics architectures and are eager to contribute your experience in modern data analytics technologies and cloud technologies (AWS, Snowflake) to transform DT into a data-driven company. Then we, the Chapter Software Engineer Data & Analytics of Deutsche Telekom IT, are exactly the right workplace for you. Qualifications You have a university degree or a comparable qualification and already have several years of professional experience in the field of big data. Furthermore, you are characterized by the following knowledge and skills:   •    Expertise in technology and methodologies: streaming processing, ideally with Cloudera, and hands-on experience with Kafka, NiFi, and REST •    Expert knowledge in relevant description languages and (object-oriented) programming languages, Java, Python, Perl •    Knowledge and experience in the classic BI/DWH environment: SQL, DB2 (Unix) as well as with data integration tools such as Informatica •    Knowledge in hardware sizing and in the solution of security requirements as well as software engineering know-how in agile methods in design, architecture, development, testing •    Practical experience in the use of appropriate tools for development change management and configuration management, GIT, JIRA •    Intercultural experience in offshore projects •    Experience in agile methods Scrum and SAFE Languages English - advanced (C1) German - advantage Additional Information Benefits We believe in balance between work and personal life. An attractive and extensive work-life balance portfolio guarantees lasting motivation for employees and thus a better quality of life, promotes physical and mental well-being and contributes to a positive work environment. All this with the aim of providing more freedom in reconciling work, career growth, private life and individual lifestyle. Therefore we offer to our employees over 25 different benefits to improve their personal and professional life in these areas: Financial benefits Benefits with focus on learning and development Benefits with focus on health and sport Benefits with focus on family and work – life balance Other benefits For more information about our benefits click to Benefits Salary Final salary is negotiable. We are offering base salary depending on seniority level and previous experience of candidate. In addition to base salary we provide variable part and other financial benefits. Base salary will not be lower than 2000 € /brutto. Additional information * Please be informed that our remote working possibility is only available within Slovakia due to European taxation regulation. Company Description We organise over 500 large-scale branded and transaction-oriented events in 14 specialist markets. These are typically not-to-be-missed annual events where buyers and sellers build relationships, see and show products and do business. We also provide year-round online platforms where companies showcase their businesses and products and buyers conduct research, generating valuable leads, and we provide data and digital content that supports the flow of knowledge and transactions in markets. Job Description 6-month fixed term contract with a likely extension based on project work. The role is almost 100% working remotely. Informa Markets are looking to bring on a technically minded individual, who is interested in combining the analytical intelligence from data and developing technical solutions to problems in data systems. The key applications are PowerBI and SQL Server Analysis Services. With a background in project work, they will be able to demonstrate the ability to meeting tight deadlines with system familiarity. They will be comfortable in both running their own projects and working alongside other developers on larger projects. What you’ll be doing: The PowerBI Developer is responsible for developing and supporting the Reporting Hub. This is new project currently in the development stage. The team is currently using IBM Planning Analytics for financial, FTE and KPI planning and reporting and would like to use PowerBI as the reporting front end for internal customers. This role is going to be the team expert on PowerBI and will help upskilling other members of the team.  What we’re looking for: Tasks are likely to include: Using best practice, develop the Product Tracker PowerBI reporting used by hundreds of people Help develop the Finance standard reporting suite in PowerBI, which will service finance and business users across multiple Portfolios and Divisions. Develop a series of prioritised dashboards based on prioritisation  Optimise the data flow from the source systems to PowerBI Challenges current processes and ways of working, striving for an optimal level of output which delivers on requirements in a timely fashion Qualifications Strong experience in a PowerBI development role BS Degree or equivalent professional qualifications Has a good knowledge of a wide area of information systems concepts and practice, both within and beyond own organization. Including all stages of systems development. Familiarity with TM1 would be beneficial but not essential. Can demonstrate a rational and organized approach to the tasks undertaken and an awareness of the need to achieve quality Our Engineering community is growing, and we’re now looking for a (Senior) Big Data Engineer to join our team supporting our global growth.  As (Senior) Big Data Engineer, you design and optimize data processing algorithms on a talented, cross-functional team. You are familiar with the Apache open-source suite of technologies and want to contribute to the advancement of data engineering.  WHAT WE OFFER A chance to accelerate your career and work with outstanding colleagues in a supportive learning community split across 3 continents Contribute your ideas to our unique projects and make an impact by turning them into reality Balance your work and personal life through our workflow organization and decide yourself if you work at home, in the office, or on a hybrid setup Annual performance review, and regular feedback cycles, generating distinct value by connecting colleagues through networks rather than hierarchies Individual development plan, professional development opportunities Educational resources such as paid certifications, unlimited access to Udemy Business, etc. Local, virtual, and global team events, in which UT colleagues become acquainted with one another Requirements WHAT YOU’LL DO You make data useful. You build program code in Java or similar languages, test and deploy to various environments, design and optimize data processing algorithms for clients You work on feature implementation, and you automate testing of data-driven applications, using open-source and cloud-native technologies You organize your workflow independently in an agile setting and contribute to your team with high quality code in alignment with the project vision You communicate primarily in English with your team members  WHAT YOU’LL BRING 2+ years of hands-on experience in the development of software using Java or a comparable language Experience with data ingestion, analysis, integration, and design of big data applications using Apache open-source technologies, such as Hadoop, Spark, or Flink. Experience with Kafka, Docker, Kubernetes also good Solid computer science fundamentals (algorithms, data structures, and programming skills in distributed systems) and work experience in agile environments Professional communications skills in English   Did we pique your interest, or do you have any questions? We want to hear from you: contact us at recruit@ultratendency.com  ABOUT US Ultra Tendency is an international premier Data Engineering consultancy for Big Data, Cloud, Streaming, IIoT and Microservices. We design, build, and operate large-scale data-driven applications for major enterprises such as the European Central Bank, HUK-Coburg, Deutsche Telekom, and Europe’s largest car manufacturer. Founded in Germany in 2010, UT has developed a reliable client base and now runs 8 branches in 7 countries across 3 continents. We do more than just leverage tech, we build it. At Ultra Tendency we contribute source code to +20 open-source projects including Ansible, Terraform, NiFi, and Kafka. Our impact on tech and business is there for anyone to see. Enterprises seek out Ultra Tendency because we solve the problems others cannot. We love the challenge: together, we tackle diverse and unique projects you will find nowhere else. In our knowledge community, you will be a part of a supportive network, not a hierarchy. Constant learning and feedback are our drivers for stable development. With us you can develop your individual career through work-life balance. We evaluate your application based on your skills and corresponding business requirements. Ultra Tendency welcomes applications from qualified candidates regardless of race, ethnicity, national or social origin, disability, sex, sexual orientation, or age. Data privacy statement: Datenschutzerklärung für Bewerber – Ultra Tendency As a mid-level or senior-level Business Intelligence Developer, you’ll play a crucial role in fostering collaboration and building partnerships across the organization. Your main goals will be to develop BI reporting solutions and drive operational efficiency and effectiveness. Your expertise in BI reporting solutions will be invaluable in co-developing products and sharing knowledge with other teams. By providing insights and valuable predictive information, you’ll equip business teams and leaders with the tools to highlight potential risks and opportunities that drive the need for change. Your contributions will have a significant impact on the company’s success, and you’ll be a vital part of a team dedicated to delivering innovative solutions that drive business growth. You’ll achieve this by enabling data-driven decisions and empowering stakeholders to make informed choices based on actional insights from your reports and dashboards and by: Designing and developing reporting solutions using IBM Cognos and Tableau as per business requirements Providing expertise in data visualization and graphical report design Participating in upgrade and migration projects from legacy to future state Working closely with business and data development teams to drive requirements to completion Maintaining and supporting existing business intelligence solutions Maintaining knowledge of industry standards, best practices, and upcoming product releases Identifying new opportunities to leverage data, integrate and enhance business value Mentoring other developers in utilizing the tools Assisting in other areas of the department and company as necessary Supporting enterprise BI strategy and organizational change management Defining, setting up, and executing test cases to validate that the solution meets business requirements Providing consultative support and advice on technology projects led by business partners Working with business partners to understand BI reporting and analytical requirements Providing technical support on ad-hoc queries on the usage of the BI application Assisting users in building ad-hoc reports and analysis Envisioning future use cases for reporting and analytical solutions  Requirements Bachelor’s in IT, Computer Science, or related field or equivalent experience Mid-level: 3-5 years experience in BI development Senior-level: 6-10 years experience in enterprise BI development Experience creating complex reports, dashboard applications, and scorecards Experience with 2-3 of the following tools: Microstrategy - AWS Enterprise Version 2021; Tableau; Informatica - Power Center Version & DEI - Version; IBM Cognos Analytics; SAS Experience with SQL, with proven ability to write efficient queries Experience working directly with business teams to address ad-hoc queries and provide guidance on challenges they are facing Experience writing reports over various data sources, including Oracle, Teradata, SQL Server databases, etc. Experience working with AWS, Azure, Databricks Strong problem-solving and data analysis skills Ability to follow processes and execute project deliverables in a timely manner Experience capturing business requirements and providing solutions Experience coordinating with the team across the geographical regions Strong written and verbal communication skills Strong analytical and problem-solving skills with the ability to effectively negotiate with other teams to create a mutually beneficial solution Solid understanding of data modeling concepts Ability to manage and prioritize multiple requests Proven ability and desire to grow technical skill set Experience with or desire to learn and work with mobile reporting solutions Experience with Agile development methodology THIS POSITION REQUIRES RESIDENCY IN MARYLAND OR NORTHERN VIRGINIA and is PARTIAL REMOTE 2 DAYS A WEEK. THIS POSITION IS NOT ELIGIBLE FOR A FULL REMOTE SCHEDULE. Hiring candidates with a permanent residence within commuting distance to Columbia, MD. Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future. Must be able to obtain a Public Trust Clearance. Fully-vaccinated status for COVID-19 is required as a condition of employment. The salary range for this role takes into account the wide range of factors that are considered in making compensation decisions, including but not limited to skill sets; experience and training; education and certifications; and other business and organizational needs.  ABOUT NEXT PHASE SOLUTIONS AND SERVICES, INC. Innovation. It’s What Defines Us. Next Phase Solutions and Services, Inc. provides insights and solutions for healthcare, engineering and science research. Next Phase commits to creating an environment where our employees achieve their full potential, increase their productivity, and expand their professional and personal horizons. We look for bright, innovative people that achieve results, understand the importance of being a productive and supportive team member, and put the customer’s satisfaction first. Next Phase leadership is looking for new leaders, scientific and technical subject matter experts, and technically savvy people that are interested in putting forth the effort and commitment needed to grow our company. Will you join us to share in the success? Next Phase Solutions and Services, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. Benefits We offer a competitive total compensation and benefits package. Benefits include, but are not limited to: HEALTH AND WELLNESS BENEFITS Medical Insurance (three healthcare plans to choose from), Dental Insurance, and Vision Insurance Flexible Spending Account (FSA) and Health Savings Account (HSA) Company-sponsored Wellness Program WELL-BEING PROGRAM Our Well-being programs offer a variety of benefits that support our employee’s physical, financial and lifestyle wellness. Enjoy walks around a beautiful lake, work out in our on-site gym, grab a healthy snack, enjoy bagel Fridays and lunches, attend yoga, benefit from a hybrid flex schedule, join a Fitbit group or sports team, or get some great financial advice – just to name a few of the well-being program benefits. PERSONAL INSURANCE BENEFITS Company-paid Life Insurance Company-paid AD&D Insurance Company-paid Short-term and Long-term Disability Insurance PAID LEAVE Competitive paid-time-off programs Paid holidays Paid Maternity leave for mothers recovering from the birth of a child RETIREMENT 401K plan with 5% employer contribution (employee contributions are not required to receive 5% employer contribution) PROFESSIONAL DEVELOPMENT Employees are reimbursed for professional development activities including classes, books, technical certification/testing fees, professional dues/subscriptions, professional licenses required for a position PET INSURANCE Choose from two options to help keep your pets happy and healthy Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto “Building Success Together®,” Nisum has grown to over 1,800 professionals across the United States, Chile,Colombia, India, Pakistan and Canada. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today’s world, with immersive and seamless experiences across digital and physical channels. What You'll Do Candidate should be able to design, build and deploy BI Solutions Experience with requirements gathering, technical analysis, and writing technical specifications/documentation Good Communication skills & Capability to work in a distributed team environment with minimal supervision are required. Exposure to Dot Net or equivalent programming languages is a plus What You Know Minimum 8 + years of experience Must have strong knowledge of Power BI, SQL, SSIS, ADF, and Cubes Must have a strong understanding of Stored procedures, designing data models, and ETL process Should have real-time work experience on MSBI (SSIS), and Azure Data Factory Services(ADF) and will be responsible for hands-on design and development on ADF & model creation on SQL server database. Should have expert knowledge in writing SQL commands, queries, and stored procedures. Ability to improve SQL performance: analyzing SQL joins and table structures Analyze and benchmark reporting and ETL performance; Evaluate and improve existing BI systems. Knowledge of Azure cloud and experience on Azure SQL DB and Azure analysis server is preferred. BI development background and coding experience in Azure stack - Migrate to Azure / Work with Azure services Experience with Azure Data bricks is a plus Experience working with programming languages like JS Framework is plus.   Education Bachelor’s / Master’s degree in specific technical fields like computer science, math, statistics preferred, or equivalent practical experience. Benefits In addition to competitive salaries and benefits packages, Nisum India offers its employees some unique and fun extras: Continuous Learning - Year-round training sessions are offered as part of skill enhancement certifications sponsored by the company on an as need basis. We support our team to excel in their field. Parental Medical Insurance - Nisum believes our team is the heart of our business and we want to make sure to take care of the heart of theirs. We offer opt-in parental medical insurance in addition to our medical benefits. Activities -From the Nisum Premier League's cricket tournaments to hosted Hack-a-thon, Nisum employees can participate in a variety of team building activities such as skits, dances performance in addition to festival celebrations. Free Meals - Free snacks and dinner is provided on a daily basis, in addition to subsidized lunch. Nisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace. Company Description Our mission as a company providing IT services is to provide our clients all over the world with the best solutions. We manage to do this by analyzing the needs of our clients and matching them to the skills and aspirations of our employees. Therefore, one of our main motivations is to provide each Employee and Consultant with a satisfying experience. Joining us means being part of a community with diverse personalities. Start your adventure with ALTER SOLUTIONS! Job Description Development of ETL/ELT flows on the on-premise - as well as the cloud platform Design data models Provide daily support and maintain solutions for our customers Participate in knowledge sharing cross team and domain Qualifications Must have Data warehouse technologies SQL ELT/ETL tools Databases Nice to have Wherescape Data Vault 2.0 Microsoft Azure tech stack Additional Information Hybrid model (3 days in Warsaw office) Type of contract: B2B or employment contract Access to local and international projects - Clients from France, Germany, Portugal, UK and Benelux Professional development support -trainings, technical certificates, conference participation, foreign language classes and soft skills trainings are subsidized up to 2 000 PLN Flexibility - You choose form of cooperation: employment or business-to-business contract Bonus for recommending Candidates up to 6 000 PLN Fully paid Medicover healthcare card Multisport card Regular integration events and gifts Psychological support program WellBee Mobility Program Long term cooperation If You applied for this position the Controller of your personal will be  ALTER SOLUTIONS POLSKA Sp. z o.o., with its registered office at ul. Emilii Plater 10/47, Warsaw. The personal data provided by you will be processed for the purpose of the recruitment process and for future recruitment processes. You will have the right too choose one or both options on next page. You have the right to access the content of your data, request their rectification, erasure, restriction of processing, the right to data portability, the right to object to the processing of your data and the right to lodge a complaint to the President of the Personal Data Protection Office. Netcetera Spring Internship Program is now open! Deciding on how you work is totally up to you. You will get to build your skills with the support of our experts and dedicated mentor, either in our Netcetera office or from the comfort of your home. You will have the opportunity to work on real client projects and use the latest technology and tools, guided by our team of dedicated experts. Apart from expanding your knowledge and skills, you will also get the chance to be part of every Netcetera event and enjoy our fringe benefits. Our onboarding program will provide all the information to get you started. You will be supported with all the necessary equipment, engaging and fun activities, learning, and remote training. Take the initiative and bring your knowledge and skills to the next level. We invite you to experience our culture, which fosters innovation, personal development, recreation, and respect for individuality. Apply and experience Netcetera! Your tasks: Learn all about a selected specialization: Build, implement, evaluate, and optimize data driven models (involving various machine learning approaches) Do detailed research in an area of interest, keep up to date on trends, tools and emerging technologies Perform ad-hoc analysis and present results in a clear manner Get familiar with the assigned project eco-system and mission Participate in the team coordination meetings and events Requirements You are a student in computer science, like to work in a team, have good communication skills, and are familiar with or interested in some of the following areas: Machine learning, reinforcement learning, computer vision, deep learning, natural language processing Probability and statistics (e.g., hypothesis testing, regressions) Python and relevant packages (Scikit-Learn, Pandas, Pytorch, NumPy) General computer science and software development skills are considered as an advantage This internship round will last for 3 months (combination of half and full time based on your obligations). Within legal and company policies, Netceterians/you can choose whether to work remotely or from a Netcetera office and enjoy flexible working hours. This hybrid working model demonstrates our commitment to achieving the best suitable private and professional life balance. This will be, of course, based on the interns’ preferences, and agreed with their mentors. Expected start: beginning of April Valid until 05.03.2023 Benefits Flexibility: Adjust your time to work efficiently, be it working hours, part-time options, home office, or unpaid leave Extra vacation days: Need to take some extra time off? With us, you have the possibility to activate 5 additional paid days per year on top of your vacation plan Private health & Family Insurance: The company policy covers a private health insurance plan for you and your family Yearly Education Fund: We strongly believe in continuous development and would love to see you enrich your knowledge. Ever Netceterian has a dedicated yearly fund to invest in their professional and personal development through conferences, courses, lectures or long-term education Meals & Snacks: Enjoy a lunch allowance each working day, free fruit and drinks in the office Codete is not just a software company, it’s a place where tech-enthusiasts can grow by doing what they love and feel valued for what they are. We’re experienced, agile and versatile: we work with a wide range of technologies in projects from many different industries, and the majority of our team are senior-level specialists. At Codete, there’s always something new to learn! Our client is a leader in consulting services with excellence competences in the areas of Digital Transformation and Data Strategy, focusing on Analytics, Big Data, Data Science, Artificial Intelligence, Data Visualizations, CPM and Software Engineering. Through a unique experience and extensive knowledge of the various business sectors and functions, they help organizations of all sizes thrive and improve the way their business operates. We are looking for Data Engineer Professionals!  Location: Remote from Poland Tech stack: PySpark, Apache Airflow, Kafka, Grafana, AWS, Azure Salary: PLN 23,000.00 - PLN 30,000.00 per month for B2B Requirements What we are looking for 3 years+ of proven experience for Mid level Engineers and 5 years+ for Senior Engineers Bachelor’s or Master’s degree in information systems/engineering, computer science and management or related Proficiency in modelling and maintaining Data Lakes with PySpark – preferred basis Experience with Big Data technologies (e.g. Databricks) Ability to model and optimize workflows (e.g. Azure Data Factory, Apache Airflow) Experience with Streaming Analytics services (e.g. Kafka, Grafana) Analytical, innovative and solution-oriented mindset Teamwork, strong communication and interpersonal skills Rigor and organizational skills Fluency in English (spoken and written) - B2 Nice to have Ability to implement custom APIs and connectors Knowledge of automation services (e.g. Terraform, Azure DevOps, AWS CodeBuild, Jenkins) Knowledge of visualization technologies (e.g. Microsoft PowerBI, Looker) – Cloud certifications Experience in AGILE methodologies Benefits Values & Atmosphere • flexible attitude (including working hours) • international business trips • social events & awaydays • support for your ideas Personal development • external conferences • technical & soft skills training • switching between projects/technology • English classes • internal library Health & Relax • Employee Wellbeing Platform • private health care • multisport card • sports events • chill-out room • fresh fruits & juicer Knowledge & Culture • open source initiatives • Codete Mentorship Program • R&D department  The data controller of your personal data is Codete Global Sp. z o.o. with its seat in Kraków (30-527), Poland, ul. Na Zjeździe 11. The data will be processed for recruitment purposes. To learn more please read an appropriate section of our Privacy Policy (Personal data provided for recruitment purposes). Have you ever ordered a product on Amazon and when that box with the smile arrived you wondered how it got to you so fast? Have you wondered where it came from and how much it cost Amazon to deliver it to you? If so, the WW Amazon Logistics, Last Mile team is for you. We manage the delivery of tens of millions of products every week to Amazon’s customers, achieving on-time delivery in a cost-effective manner to deliver a smile for our customers.  This position will be responsible for building out analysis and visualization tools and processes’ to support our growing Amazon Logistics business in Japan and Worldwide. We are is looking for a customer focused, innovative and technically skilled Sr. Business Intelligence Engineer to drive effective performance measurement and management, innovation and execution in last mile delivery.  The successful candidate will be able to effectively retrieve, integrate, visualize and present critical data to improve the efficiency of the package delivery network, and enable efficient management of a large global logistics system. They will work with technical and business teams to optimize planning, execution, process improvement and track progress against goals. This role requires excellent analytical abilities as well as excellent business acumen and comfort with technical teams and systems.  Core Job Responsibilities include: Lead and develop a team of Business Intelligence Engineers and Business Analysts. Partner with internal stakeholders across multiple teams, gathering requirements and delivering end to end solutions. Partner with Data Engineering and Software Development Engineers to prioritize and define AMZL data and BI development needs. Work with in-house scientists, global supply chain, transportation and logistics teams to identify new BI capabilities and projects. Conduct deep dive investigations into operations execution and business problems, identify opportunities, and lead or support implementation. Analyze and visualize large scale geo-spatial logistics and transaction data to articulate user behavior or delivery process problems, and output solid analysis report with recommendation  Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, visit https://www.amazon.jobs/disability/jp Basic Qualifications  5+ yrs of experience in analytic skills to integrate data into operational planning Advanced level of SQL and ETL; ability to write and tune complex SQL scripts and ETL development 5+ yrs of experience in Operational Excellence initiatives, working with data warehousing and data quality (MySQL and Redshift)/ 5+ yrs of experience in visualization tools such as GIS visualization, Tableau, QlikView, QuickSight Business Level of English (written & verbal). Bachelor's degree in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field.  Preferred Qualifications 3+ years of relevant work experience building end to end solutions to performance measurement and process improvement in a transportation, logistics or supply chain setting. 3+ yrs of experience implementing basic software solutions to automate data source, visualization and/or data modeling application. Project Management experience and/or Tech product management experience. Ability to understand operations at a detailed, practical level and also to think big / strategically. MBA/MS in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field.   Please check the website below for measures to eliminate unwanted second-hand smoking in each facility: https://www.amazon.jobs/en/landing_pages/passivesmoking 就業の場所における受動喫煙を防止するための措置に関する事項については、下記リンク先をご覧ください。 https://www.amazon.jobs/jp/landing_pages/passivesmoking  The salary information can be provided individually prior to the 1st interview 賃金に関する条件は、１次面接の前に個別にご案内することができます With over 35 nationalities and a range of backgrounds represented in our Benevolent team, we aim to build an inclusive environment where our people can bring their authentic selves to work, be respected for who they are and the exceptional work they do. We welcome and actively encourage applications from all sections of society and are committed to offering equal employment opportunities regardless of sex, race, religion or belief, ethnic or national origin, marital, domestic or civil partnership status, sexual orientation, gender identity, parental status, disability, age, citizenship, or any other basis. We see our diversity as an asset as we tackle challenging problems that bridge the gap between drug discovery and technology.  The Role We are seeking bioinformatics data scientists to join our London teams and apply advanced bioinformatics methods and data analytics to real-world drug discovery challenges. We have identified 3 projects across our Product Areas at BenevolentAI, which each give successful candidates the opportunity to learn more about leveraging biomedical data, developing targeting identification processes and establishing precision medicine workflows, all within an industry setting.  Product Area We have one role available in each of the following three product areas: As part of the Target Identification product area, you will work to: Develop programmatic tools and workflows that enable the construction and optimisation of biological questions for target identification Use scientific methods to validate new tools/workflows developed Identify opportunities for further work in current biological question data pipelines using the latest scientific literature to help potential solutions Collaborate and communicate with members of the Bioinformatics, Data Science, Drug Discovery, Artificial Intelligence, Engineering, UX and Product teams to deliver BenevolentAI corporate strategic goals As part of the Precision Medicine product area: You will explore and analyse the multi-omics data available in house to evaluate different integration models; You will develop programmatic tools and workflows that enable the integration of bulk or single-cell omics data; You will apply advanced statistical methods to multiple datasets and integrate multi-omics data to generate robust evidence to inform mechanism-specific patient subgroups and personalised drugs recommendations; You will validate new tools/workflows developed computationally and qualitatively in collaboration with biology experts; Identify opportunities for further work in current multi-omics integration pipelines using the latest scientific literature to help potential solutions. As part of the Knowledge product area, based on FAIR data principles (Findable, Accessible, Interoperable and Reusable), you will: Get access to the tissue-specific network data Inspect the data content to understand the features of the data Design and implement a standardisation pipeline Define the data model based on internal use cases Ingest the data into the Knowledge Graph  Primary Responsibilities Pursue a research project to investigate new approaches in applying tech-driven methods for drug discovery and development. Work as a member of a cross-functional team comprising specialists in informatics, engineering, AI, drug discovery and product for applied research.  We're looking for someone with Preference for candidates with a PhD/MSc/MSci in bioinformatics/data science or who are working towards any of those qualifications but will consider candidates with relevant experience without formal higher education qualifications; Good programming skills in Python and/or R; Comfortable applying common data science concepts, running statistical analysis and training machine-learning models (unsupervised and/or supervised) or eager to learn; Good communication skills who enjoy working in a collaborative team environment;  Nice to haves For Target Identification product area: Bonus points if familiar with the drug discovery process For Precision Medicine product area: Experience in working with large-scale genetic datasets. Experience in post-GWAS analysis and interpretation, statistical methods for causal inference (e.g. Colocalisation, Mendelian randomisation) and gene prioritisation. For Knowledge product area: Experience with databases.  Notes Applications close on Wednesday 1st March 2023. Our interview process will commence after applications close and will take place over 3-4 weeks. Internships can commence anytime from Monday, June 5th 2023 In addition to your CV, please send us a cover letter.  About us BenevolentAI (AMS: BAI) is a leading, clinical-stage AI-enabled drug discovery and development company listed on the Euronext Amsterdam stock exchange. Through the combined capabilities of its AI platform, scientific expertise, and wet-lab facilities, BenevolentAI is well-positioned to deliver novel drug candidates with a higher probability of clinical success than those developed using traditional methods. The Benevolent Platform™ powers a growing in-house pipeline of 13 named drug programmes and over 10 exploratory programmes, and it maintains successful collaborations with AstraZeneca, as well as leading research and charitable institutions. BenevolentAI is headquartered in London, with a research facility in Cambridge (UK) and a further office in New York.  Want to do a little more research before you apply? Head over to our Glassdoor page to learn about our benefits, culture and to find out what our team think about life at Benevolent. You can also find out more about us on LinkedIn and Twitter.  Terms and Conditions Salary: We offer remuneration for the duration of the internships. However, remuneration remains subject to the University regulations & T&C’s - should they not comply with our policy, we reserve the right to review the salary allowance. Please note that by applying for a job you agree that we will collect and process your personal data submitted in your job application in accordance with our Privacy Policy. Location: Delhi, Gurgaon, Bangalore, Chennai,Indore, Ahmedabad, Jaipur, Kolkata,Pune.,None,None About Material Material is a global strategy, insights, design, and technology partner to companies striving for true customer centricity and ongoing relevance in a digital first, customer-led world. By leveraging proprietary, science-based tools that enable human understanding, we inform and create customer-centric business models and experiences + deploy measurement systems – to build transformational relationships between businesses and the people they serve. About Srijan Srijan is a global engineering firm that builds transformative digital paths to better futures for Fortune 500 enterprises to nonprofits all over the world. Srijan brings advanced engineering capabilities and agile practices to some of the biggest names across FMCG, Aviation, Telecom, Technology, and others. We help businesses embrace the digital future with cloud, data, API and platform centric technologies and adapt to changing business models and market demands. Srijan leads in Drupal with 350+ Drupal engineers, 80+ Acquia certifications. Srijan is also a Drupal Enterprise Partner & Diamond Certified Job Description About the Role As a Senior Data Engineer, you will have the opportunity to work in a dynamic environment with plenty of opportunities to experiment with new technologies and solutions. Our team is highly collaborative and works closely with both the engineering organization and the business. We are agile in our approach to technology and always seek to improve and innovate within our platform and ways of working.  What you will do Build a large-scale, highly performant self-service data platform using cutting-edge technologies Minimize technical debt by continuously revisiting and finding improvements to existing implementations Maintain and rethink existing datasets and data pipelines to optimize performance and accessibility Drive internal tooling and process development to continuously increase data quality and constantly improve the engineering experience of our users Implement effective data governance across the business Collaborate with other engineers, data analysts, data scientists, and decision makers to tackle data challenges and gain novel insights Mentor and coach other engineers on data engineering best practices Be technical leader within the team you work with and across Storytel in general  About You 3+ years of professional experience as a Data Engineer or Software Engineer, with hands-on coding experience in Python and SQL Several years of experience in design and architecture of scalable and reliable complex systems Strong background in data pipelining, distributed data processing, software engineering components, and data modeling concepts Experience with cloud infrastructure (GCP) and cloud data warehousing, preferably BigQuery. Experience with designing and developing pipelines and data integration solutions using ELT tool. Experience with Infrastructure as Code and remote configuration tools Experience in operating, maintaining and ensuring quality of production grade software Experience in data privacy and sensitive data management You have strong communication skills to partner with stakeholders effectively You have an innovative mindset and are always striving for improvements, making sure that each workday is value driven, collaborative and rewarding. You embrace knowledge sharing and have an eagerness to continuously learn and develop yourself and team   Apply to this job Our mission is to connect and optimize the world’s commerce. That means the whole world. So we’re determined to nurture our culture of meritocracy where everyone can thrive, no matter what we look like, where we’re from, how we grew up, whom we love, the nature of our faith, or how our bodies or minds work. We’re committed to achieving equity in treatment and opportunity for everyone, where people are judged on the merits and quality of their work. It all starts with people. Inside every company, behind every brand­ - while business success is often measured in profit, it has always been powered by people. We firmly believe people are the heart of any organization - including our own. That’s why a career here provides much more than simple pay and perks. We’re dedicated to empowering people, solving tough problems, and helping careers flourish inside and out.    Position Summary: The Business Intelligence Engineer will be a critical contributor to enabling the Business Intelligence Team to identify opportunities for CommerceHub to use its own data, as well as data provided by third parties, to generate additional company revenue and derive valuable industry insights.   Responsibilities: Design and build dashboards for internal stakeholders and externally facing products Develop new and maintain existing reports using Looker, Tableau and PowerBI Work with stakeholders including Product, Marketing, Finance and Customer Support to design dashboards and reports Participate in full development life cycle including requirements development, implementation, peer review, source control, automated testing, deployment, and operations Enforce corporate policies around the evolution and enforcement of industry data standards, data governance and best practices   Requirements: Bachelor’s degree or higher and/or equivalent work experience Strong analytical skills related to working with both structured and non-structured datasets Strong data modeling skills and experience working with Star Schemas Strong working knowledge of highly scalable data warehouse products such as Amazon Redshift, Snowflake 2+ years’ experience with data visualization tools such as Looker, Tableau, PowerBI Experience working in Retail and Looker BI visualization tool is a plus 2+ years’ experience with SQL coding languages such as TSQL, LookML, PostgreSQL, Athena 2+ years’ experience with scripting languages such as Python and R Exceptional written and verbal communication skills Comfortable communicating across all levels of management Ability to prioritize tasks and work independently Excellent analytical, decision-making, and problem-solving skills Proven ability to work in a rapidly changing environment with keen attention to detail   What it’s like to work at ChannelAdvisor, a CommerceHub Company We take a whole-person approach to engage and support our global team. We believe the diversity of our global team is an advantage. If you’re curious, innovative, determined, and customer-focused, then you’ll love the challenge and rewards of collaborating as a team to help our customers win. We offer competitive compensation programs that recognize your hard work and results. Because when our customers win, we win.  And when we win, you win. We work to create an environment where everyone who is committed, works hard, and delivers results can thrive and grow. You can connect with one of our employee resource groups and support our diversity, equity and inclusion task force, network with like-minded team members, and showcase your leadership skills.    Benefits:  Enhanced Private Medical Insurance and a Health Cash Back Plan  Competitive time off package with 25 Days of PTO, 9 Holidays, 2 Wellness days and 1 Give Back Day Flexibility to choose where you work - at home, in the office, or both! Access to tools to support your wellbeing such as the Calm App, MoveSpring and an Employee Assistance Program Professional development stipend and learning and development offerings to help you build the skills and connections you need to move forward in your career Charitable contribution match per team member   ChannelAdvisor, a CommerceHub Company, is an Equal Employment Opportunity Employer. We celebrate diversity and are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need. Have you ever ordered a product on Amazon and when that box with the smile arrived you wondered how it got to you so fast? Have you wondered where it came from and how much it cost Amazon to deliver it to you? If so, the Worldwide (WW) Amazon Logistics, Last Mile team is for you. We manage the delivery of tens of millions of products every week to Amazon’s customers, achieving on-time delivery in a cost-effective manner to deliver a smile for our customers.  Amazon Logistics is looking for a customer focused, innovative and technically skilled Business Intelligence Engineer to drive effective performance measurement and management, innovation and execution in last mile delivery. This position will be responsible for building out analysis and visualization tools and processes’ to support our growing Amazon Logistics business in Japan and Worldwide.  The successful candidate will be able to effectively retrieve, integrate, visualize and present critical data to improve the efficiency of the package delivery network, and enable efficient management of a large global logistics system. This individual will work with technical and business teams to optimize planning, execution, process improvement and track progress against goals. This role requires an individual with excellent analytical abilities as well as excellent business acumen and comfort with technical teams and systems. The successful candidate will be a self-starter comfortable with ambiguity, with strong attention to detail, and enjoy working with large scale of data.   【More Information】 Last Mile: https://www.amazon.co.jp/b?node=5637343051 BIE Job: https://www.amazon.co.jp/b?node=5609906051 Tokyo office: https://www.amazon.co.jp/b?node=5589794051   Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, visit https://www.amazon.jobs/disability/jp  Key job responsibilities Partner with internal stakeholders across multiple teams, gathering requirements and delivering end to end solutions. Partner with Data Engineering and Software Development Engineers to prioritize and define AMZL data and BI development needs. Work with in-house scientists, global supply chain, transportation and logistics teams to identify new BI capabilities and projects. Conduct deep dive investigations into operations execution and business problems, identify opportunities, and lead or support implementation. Analyze and visualize large scale geo-spatial logistics and transaction data to articulate user behavior or delivery process problems, and output solid analysis report with recommendation. Liaise between Planning, Analytics and Operations teams to achieve actionable insights into current performance, and conduct ad hoc investigations into future improvements or innovations. Develop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting. Basic Qualifications  Bachelor's degree in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field. 2+ yrs of experience in analytic skills to integrate data into operational planning. Advanced level of SQL and ETL; ability to write and tune complex SQL scripts and ETL development. 2+ yrs of experience in Operational Excellence initiatives, working with data warehousing and data quality (MySQL and Redshift). 2+ yrs of experience in visualization tools such as GIS visualization, Tableau, QlikView, QuickSight Business Level of English (written & verbal).  Preferred Qualifications MBA/MS in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field. Business level of Japanese. 3+ years of relevant work experience building end to end solutions to performance measurement and process improvement in a transportation, logistics or supply chain setting. 3+ yrs of experience implementing basic software solutions to automate data source, visualization and/or data modeling application. Project Management experience and/or Tech product management experience. Organized, operational mindset with track record of delivering projects within scope, time, budget and quality. Ability to understand operations at a detailed, practical level and also to think big / strategically.   Please check the website below for measures to eliminate unwanted second-hand smoking in each facility: https://www.amazon.jobs/en/landing_pages/passivesmoking 就業の場所における受動喫煙を防止するための措置に関する事項については、下記リンク先をご覧ください。 https://www.amazon.jobs/jp/landing_pages/passivesmoking  The salary information can be provided individually prior to the 1st interview 賃金に関する条件は、１次面接の前に個別にご案内することができます Company Description Transforming businesses, driving success: SmarTek21 SmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients Job Description SmarTek21 is looking for a hands-on architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.   Qualifications • Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python. • Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks. • Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP). • Solid understanding of enterprise strategies for data security and data governance. • Experience in practice development, architecture, and consulting or product development. • Experience delivering data analytics projects and architecture guidelines. • Experience in engaging with enterprise architects. Non-technical Skills: • Excellent oral and written communication and presentation skills. • Ability to handle ambiguous situations and take trade-off decisions. • Strong problem solving and analytical skills to break down complex problems into smaller components. • Ability and willingness to perform in a team environment. Requirements: • Understand prospect/customer/partner technology landscape. • Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation. • Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers/partners. • Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints. • Collaborate with the engineering team to create proof-of-concepts (POCs). • Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices. • Demonstrate business value of proposed solutions or current products to prospects and customers. Salary Range: $200,000-$215,000 (may be subject to change outside of WA State) Additional Information What Is in It for You: Paid Time off – start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service. Paid Holidays - 8 paid holiday a year in addition to your PTO. Health Insurance for FT employees – we pay 100 % premium of medical, dental and vision. Health Insurance for FT employee’s family – we pay 50% of premium for medical, dental and vision for dependents. 401(k) – we administer 401(K) retirement contribution for FT employees. Life Insurance/Short Term and Long-Term Disability – at no cost to you Opportunities for internal promotions/career advancement Family friendly work hours (closed on weekends and paid holidays) SmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class. Job Description About You We are looking for a Big Data Engineer to work with large data volumes read from scattered information sources in an organization's technology infrastructure. You bring to Applaudo the following competencies: 2+ years of experience with Scala and Spark 3+ years of data delivery, ETL (extract, transform and load) and data warehouse design, analysis, and programming experience. Experience with Apache Hive and Apache Hudi. Experience with Google Cloud Platform (Big Query). Experience with an excellent grasp of relational and dimensional data modeling. Strong mathematical, statistical, and analytics skills. 1+ year of Agile experience. English is required, as you will work directly with US-based clients. You will be accountable for the following responsibilities: Extracting data from different data sources and transferring it into a data warehouse environment. Designing, maintaining, and implementing transactional and analytical data storage structures. Design, build and maintain data pipelines, consuming for multiple sources, and servicing multiple tenants. Elaborate informative, expressive, and meaningful reports that support business decision-making processes through the information provided. Reporting and subsequently translating the emanating results into good technical and consistent data designs. Work schedule from 9:30am until 7:30pm India Standard Time  Qualifications Technical Skills: 2+ years of experience with Scala and Spark (Apache Hive and Apache Hudi). Experience with Google Cloud Platform (Big Query). Additional Information Here at Applaudo Studios values as trust, communication, respect, excellence and team work are our keys to success. We know we are working with the best and thus treat each other with respect and admiration without asking. Submit your application today, and don't miss this opportunity to join the Best Digital team in the Region! We truly appreciate all the hard and outstanding work our team makes every day at Applaudo Studios, and that's why the perks that we offer, are deeply thought and designed as a way to thank them for their commitment and excellence. Some of our perks and benefits: Work from home Flexible schedule Celebrations Special discounts Entertainment area Flexible work spaces Great work environment Private medical insurance *Benefits may vary according to your location and/or availability. Request further information when applying. Company Description Writing the future. Together.   Avaloq is a value driven, fast-paced financial technology and services company and we are committed to developing the banking solutions of tomorrow.   By joining Avaloq, you’ll become a key part of our effort to power the digital transformation of the financial services industry. Our ambition is big and bold – to provide full end-to-end digital solutions by combining our leading efficiency with a flexible, responsible digital user experience. Headquartered in Zurich, Avaloq has over 2,000 employees globally. More information is available at www.avaloq.com   Job Description We are the Analytics domain teams helping financial institutions to easily adopt and use, as well as gather and analyze data from our Avaloq products, within a wide ecosystem. We believe our colleagues comes first, thinking different is an asset and innovation comes by putting customer experience first in our design thinking. We are looking for a strong resource who has both business acumen and technical experience, to become part of these domains, driving the interactions and collaboration with existing and potential clients. Your mission Closely collaborate with the Product Owner, Business Analysts and other Software Engineers distributed worldwide Implement Data Pipelines in Java Implement Data Analytics -  Big data exploration, extraction, processing and ingestion to different SQL and NonSQL storage systems Design, develop and maintain new/existing solutions within the team’s responsibility Improve and optimize existing functionalities Develop and maintain automated tests Take ownership and responsibility for your area of expertise Ensure high quality on the delivery and efficient communication Qualifications What you need University degree in Computer Science/Physics/Engineering/Mathematics or comparable education At least 2-3 years of work experience in the fintech or financial sector Practical experience implementing container platforms, preferably OpenShift / Kubernetes Familiarity in streaming technology like Kafka, Kafka Connect Analytical, problem solving and conceptual skills Competent in one or more programming and scripting languages Fluent in spoken and written English Experience in Big Data / Data Analytics productive environments, using technologies such as distributed SQL engines / file systems Experience in Stream Processing, Streaming Data, and Data Pipelines You will get extra points for Experience with Distributed SQL engines Experience in implementing Microservices Hands-on experience with Snowflake Understanding of data visualization using software like Tableau, Qlik, PowerBI, Yellowfin Practical experience on Infrastructure as code like Terraform Banking know-how or experience working on financial solutions Knowledge of JavaScript and Python Work Experience in team with Agile Scrum Expertise in data warehousing, modelling and data management tools Knowledge and experience on Avaloq Banking Suite Additional Information What you can expect:  It’s all about getting to know our teams and to e-meet with us. We will use video interviews to give you the opportunity to meet your future colleagues and get a first insight into Avaloq’s unique culture.  What we will offer you  We have a hybrid work week model, giving colleagues flexibility in how they work, as well as ensuring we create our unique Avaloq culture in our office locations. Our base salaries are competitive and you can be recognised for outstanding effort with an extraordinary achievement reward – the pinnacle of recognition. Avaloq aims to share its success with all its colleagues by paying out “Success Share Units” depending on its performance in a given year. At Avaloq we embrace diversity, we embrace difference. We are whole-heartedly committed to equal employment opportunities and we foster an inclusive culture where everyone’s' contributions are valued and their voices are listened to. We hire, compensate and promote regardless of origin, age, sexual orientation, gender identity or any other fascinating characteristics that make us different. Please note that our job descriptions are intended to be written in an inclusive and gender neutral language.  Don’t be shy – apply!  Please only apply online, preferably with pdf documents. Description de l'entreprise Avec plus de 30 ans d’histoire, ALTEN accompagne en France et dans le monde entier la stratégie de développement de ses clients dans les domaines de l’innovation, de la R&D et des systèmes d’information. Être la maison des ingénieurs, telle est l'ambition d'ALTEN.  Description du poste Rattaché(e) aux consultants ALTEN, vous serez amené(e) à travailler chez les clients finaux et évoluerez au sein d’équipes pluridisciplinaires.  Nous recherchons pour l'un de nos clients Grands Comptes, un(e) Data Analyst qui sera chargé(e) des missions suivantes :  Accompagnement et suivi projets métiers : Collaborer avec les équipes opérationnelles métiers pour connaître le contexte d’intervention ; Collecter et manipuler les données ; Réaliser des études statistiques et analytiques ; Valoriser l’information, la restituer et la présenter aux clients  Déploiement de reportings : Construire des requêtes SQL Implémenter des dashboards sous Power BI Migrer et transformer des reportings existants (Power BI, Dataiku)  De manière générale, vous êtes aussi amené à assurer la Data Quality en suivant les anomalies, en validant les corrections... Qualifications Des fondamentaux théoriques acquis en cursus école d’ingénieurs informatique ou universitaire avec une spécialisation IT, avec une expérience d’au minimum 3 ans post-diplôme sur des fonctions Analyse/Dataviz. Connaissance solide d’au moins un outil de visualisation : Power BI Compétence avérée en Gestion de Projets Informations supplémentaires En plus de vos missions remplis de challenges au quotidien, vous pourrez entreprendre, être formé et surtout certifié. Tracez votre trajectoire de carrière avec votre manager de proximité et révélez le meilleur de vous-même !  Rémunération attractive : salaire fixe + variable, participation, mutuelle, TR, prestations CE. Ce projet est une opportunité unique de toucher plusieurs domaines concurrents au sein d’un projet. Vous disposerez de l’appui d’une communauté d’experts pour mener votre mission ! ALTEN entreprise handi-accueillante. Poste à pourvoir en CDI. Why you want to join us Here at Datacom, we connect people and technology in order to solve challenges, create opportunities and discover new possibilities for the communities we live in. We’ve maintained our local family feel whilst expanding globally, across Australia, ASIA, US and the UK. Working together, we strive to imagine the possible, challenge the status quo and put forward fresh, diverse thinking. We offer our staff a competitive salary package, fantastic perks and benefits like healthcare, life insurance, discounts at local retailers and a supportive, flexible working environment. Are you ready to make a difference in Australasia's largest homegrown technology company? Apply within today! About the role The Group Data BI Developer is a position with the Group Data & Analytics team within Datacom Group focused on designing and developing reports, dashboards and analytics outcomes on the reporting and analytics platform at Datacom, and providing reliable, coherent information. The role is responsible for the requirements, design, implementation, maintenance and stability of the reports. The role includes close collaboration with other development and support roles in the team using best practice data management life cycles. The role reports into the GM Analytics. Role Responsibilities Design, development, test and support of standard analytics and reporting artefacts, including but not limited to Power BI reports, dashboards, paginated reports, Excel pivots, etc. Follow best practices as provided by the GM Analytics and CDO to extend, maintain and support the enterprise reporting platform so that it can provide reliable, timely, performant and accurate information to business users. Provide assistance and support to all Datacom users with respect to the reporting platform, including internal users who are using and manipulating data Adhere to report design and quality best practices as defined, using modern UX standards and conforming to Kimball best practices Support and further a group wide awareness of the benefit of analytics and centralized reporting and see encouraging signs of adoption of business intelligence and analytics. Increasing business confidence in the accuracy, veracity, reliability and value of data to help guide business decision making and exploit commercial opportunities with our data. Skills Requirements Strong communication skills working in a team environment. Will be interacting with business, corporate users and stakeholders throughout the enterprise across New Zealand and Australasia. Requires strong technical skills using the technologies in use (Power BI, Analysis Services, DAX, MDX, Paginated Reporting Services SSRS, etc.). Demonstrable experience designing, implementing and managing complex reporting environments in a corporate context Requires strong technical skills using the technologies in use (SQL Server, Azure Data Factory, SQL Server Integration Services, BIML, DETL Framework). Appropriate tertiary education in Business Information Systems and Computer Science, as well as strong background and knowledge with data transformation and data management concepts. 5 years or more experience in the field. Company Summary: Tessera Therapeutics is pioneering Gene Writing™— a new biotechnology designed to offer scientists and clinicians the ability to write small and large therapeutic messages into the genome, thereby curing diseases at their source. Gene Writing holds the potential to become a new category in genetic medicine, building upon recent breakthroughs in gene therapy and gene editing while eliminating important limitations in their reach, utilization, and efficacy. Tessera Therapeutics was founded by Flagship Pioneering, a life sciences innovation enterprise that conceives, resources, and develops first-in-category companies to transform human health and sustainability. Position Summary: Tessera is seeking a talented and motivated Computational Biologist to join our expanding Data Sciences team.  You will tackle challenging bioinformatics and computational biology problems to advance our understanding of Gene Writing and help accelerate programs to the clinic.  You will contribute scientific, technical, and leadership expertise to a multidisciplinary team, emphasizing conceptualization, experimentation, data analysis, presentation, and strategic planning.    Key Responsibilities: Work collaboratively with our platform and Biology teams to enable scientific discovery and progression through data analysis, data visualization and data integration Build and implement data analysis pipelines and storage solutions for various forms of sequencing including Amplicon sequencing, long-read sequencing (Pac Bio) and related methods Identify and acquire relevant public and third-party ‘omics data and perform integrative data analyses to generate insights that address strategic biological questions critical to Tessera’s core mission. Develop computational methods that provide project support to gene therapy project teams Operationalize data analysis aspects of relevant molecular assays to maximize the design, build, test cycle for platform and pipeline candidates Structure and store data to enable data reuse, data mining and machine learning Create compelling data visualizations for internal and external presentations    Basic Qualifications: Ph.D./M.S. in Computational Biology, Bioinformatics, or related quantitative discipline.  3+ years of industry experience in discovery research. Proficient with experimental design, data processing, statistical analysis, and bioinformatics analysis/reporting of next-generation sequencing data. Experience analyzing gene therapy, gene editing, in vitro/vivo assay, genetics, genomics and cell biology data Experience using comparative genomics as a tool for gene discovery Strong grounding in biology or medicine Strong data visualization skills and experience Fluency in one or more programming languages with bioinformatics applications (R, Python). Track record of success working in a fast-paced, cross-functional, and rapidly growing organization. Outstanding written and verbal communication skills, ability to work with colleagues from diverse scientific backgrounds and cultures.   Preferred Qualifications: Experience with recent advances in gene therapy and development of gene editing platforms as therapeutics. Strong competency in sequence analysis methods including gene identification, functional annotation, or comparative genomics. Familiarity with short and long read next-generation sequencing platforms (Illumina, PacBio, Nanopore). Proficiency in handling large scale sequencing data in a cloud environment (AWS preferred). Proficiency in statistics and machine learning. Experience in virology or mobile genetic elements.   More About Flagship Pioneering Flagship Pioneering has conceived of and created companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune’s “Change the World” list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies.  Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.  Recruitment & Staffing Agencies:  Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates.  The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team.   Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.    Company Description Our brand Deutsche Telekom IT Solutions Slovakia entered the life of Košice region in 2006 under the name of T-Systems Slovakia and ever since has been inextricably linked with the region when became one of the founding members of Košice IT Valley. We have managed to grow from scratch to the second largest employer in the eastern part of the country with more than 3900 employees. Our goal is to proactively find new ways to improve and continuously transform into the type of company providing innovative information and communication technology services. Job Description Purpose We are seeking a skilled and experienced Power BI Developer with an innovative mindset to join our Finance International Business Intelligence Team working in a Scrum environment. The ideal candidate will have the opportunity to work remotely from anywhere in Slovakia and will be responsible for designing and implementing data-driven solutions in a Microsoft BI cloud environment to support business intelligence needs across multiple foreign countries, with a focus on automation and implementing predictions, artificial intelligence and self-service BI in the future. If you have a passion for data analysis and visualization, are comfortable working in a Scrum environment, have an innovative mindset, and possess the required skills and experience, we would love to hear from you! Join our Finance International BI Team and work from the comfort of your own home in Slovakia. Key accountabilities Develop and maintain Power BI reports, dashboards, and data models within the Microsoft Azure cloud environment, using Power BI Desktop and Power BI Service Collaborate with stakeholders to gather requirements and provide insights and recommendations based on data analysis, using SQL, data warehousing concepts, and data modeling techniques Implement data visualization techniques to effectively communicate complex data concepts, using DAX language and advanced Power BI visualizations such as tables, matrices, pie charts, bar charts, line charts, scatter plots, maps, and more Ensure data accuracy, integrity, and security in all Power BI solutions by implementing data validation and data quality checks Develop and maintain technical documentation and training materials, including user guides, process flows, and training presentations Stay current on new Power BI features and updates and apply them to ongoing projects in a Scrum environment, while adhering to project timelines, budgets, and quality standards Support automation of processes and contribute to the implementation of predictions and artificial intelligence in future projects, using machine learning algorithms and predictive analytics Qualifications Education Bachelor's degree in Computer Science, Information Technology, or related field Experience At least 2-3 years of experience in Power BI development and data visualization, with a proven track record of delivering high-quality, data-driven solutions that meet business needs IT Technical Skills Experience with Power BI Desktop, Power BI Service in a Microsoft Azure environment Proficient in SQL and data warehousing concepts Experience with data modeling and DAX language, with the ability to write complex DAX expressions and implement data transformation techniques Soft skills Strong problem-solving and analytical skills, with the ability to understand and interpret complex data and identify patterns and trends Excellent communication and interpersonal skills, with the ability to effectively communicate with both technical and non-technical stakeholders Ability to work independently and as part of a team in a remote and Scrum environment, with the ability to manage multiple tasks and priorities Innovative mindset with a passion for exploring and implementing new technologies and solutions, and a strong interest in machine learning and artificial intelligence Languages English – Upper intermediate (B2) German - Advantage – Intermediate (B1) Additional Information Benefits We believe in balance between work and personal life. An attractive and extensive work-life balance portfolio guarantees lasting motivation for employees and thus a better quality of life, promotes physical and mental well-being and contributes to a positive work environment. All this with the aim of providing more freedom in reconciling work, career growth, private life and individual lifestyle. Therefore we offer to our employees over 25 different benefits to improve their personal and professional life in these areas: Financial benefits Benefits with focus on learning and development Benefits with focus on health and sport Benefits with focus on family and work – life balance Other benefits For more information about our benefits click to Benefits Salary Final salary is negotiable. We are offering base salary depending on seniority level and previous experience of candidate. In addition to base salary we provide variable part and other financial benefits. Base salary will not be lower than 2000 - 2650 € /brutto. Additional information * Please be informed that our remote working possibility is only available within Slovakia due to European taxation regulation. As part of the development team create and DEVELOP reports that meet agreed specification/design Supports a high performing culture that achieves results by: Developing reports according to functional and technical design specifications and maintain a “common sense” approach that serves to recognise potential technical gaps and provide insight into closing them whilst adhering to Fantastic Furniture IT standards and conventions. Developing, configuring, and testing Power BI reports Supporting and resolving production issues for developed reports. Creating and update schema’s, views, stored procedures, T-SQL statements with a “best practices” approach to keys, indexes and relationships in Microsoft SQL Design documentation must be updated to include any design changes made throughout the development process. Learning new technologies and adding valuable suggestions. As part of the IT team DEVELOP & DEPLOY reports & SQL queries using Power BI or ZAP with SQL Supports a high performing culture that achieves results by: Developing reports using Power BI connected to on-prem SQL, Azure SQL, Azure data lake etc to meet business requirements. Develop and configure reports/paginated reports/dashboards/visuals using Power BI. Solid working experience in Power BI tool. Good understanding Azure services such as Azure SQL, Azure data lake. Good understanding of security and governance. Good understanding of data modelling and data warehousing concepts Good understanding SQL server components such as database/stored procedures/indexing/jobs/SSIS etc.  Requirements Essential Degree in Information Technology, expert in SQL, Reporting platform, Data warehousing. Very strong and solid working experience on Power BI Minimum 5 - 7 years hands-on development experience in designing & configuring reports in Power BI & SQL Minimum 5 - 7 years’ experience in writing SLQ queries, transformations for reports, dashboards, visuals in Power BI. Experience in SQL (stored procedure, SSAS, Views, trigger, index, SQL Jobs etc) Working experience and good understanding on Cloud environment using Azure services Solid understanding of the SDLC & Agile Scrum Desirable Experience in Retail business Experience in Power Apps & Power Automate Experience with Azure services & Azure Dev-Ops Benefits Standard Job Benefits: - HMO on Day 1 - Temporary Work from Home Set Up - Paid Time-Off - Quarterly Sick-Leave conversion - Paid Government-Mandated Benefits (SSS, PHIC, Pag-IBIG) - Equipment provided  Standard Job Highlights: • Work-life balance • Career growth and development opportunities • Stable organization and industry leader • Collaborative and fruitful company culture  SALARY RANGE: PHP 100,000 – 160,000 Amazon Music reimagines music listening by enabling customers to unlock millions of songs, podcast episodes, and thousands of curated playlists and stations with their voice. Amazon Music provides unlimited access to new releases and classic hits across iOS and Android mobile devices, PC, Mac, Echo, and Alexa-enabled devices including Fire TV and more. With Amazon Music, Prime members have access to ad-free listening of 2 million songs at no additional cost to their membership. Listeners can also enjoy the premium subscription service, Amazon Music Unlimited, which provides access to more than 75 million songs and the latest new releases. Amazon Music Unlimited customers also now have access to the highest-quality listening experience available, with more than 75 million songs available in High Definition (HD), more than 7 million songs in Ultra HD, and a growing catalog of spatial audio. Customers also have free access to an ad-supported selection of top playlists and stations on Amazon Music. All Amazon Music tiers now offer a wide selection of podcasts at no additional cost, and live streaming in partnership with Twitch. Engaging with music and culture has never been more natural, simple, and fun. For more information, visit amazonmusic.com or download the Amazon Music app.  Love music? The Amazon Music team is looking for a brilliant, creative, and passionate professional to join our Business Intelligence team. Responsibilities include: developing customer insights and segmentation to enhance and drive acquisition and engagement marketing, optimization of Amazon Music signup funnels on all devices and platforms, evaluation and optimization of marketing and content, and developing self-serve analytical tools for use by the Digital Music product and business teams.    Key job responsibilities In this role, you will work to create and surface critical datasets to the Music org for self-service analysis and reporting in order to facilitate business and product team ability to identify marketing, product and content opportunities. You will help lead the way in defining and optimizing how we measure and value customer acquisition and engagement.  Our ideal candidate has a combination of strong technical skills, superb analytical capabilities, outstanding business insight, and excellent verbal and written communication skills. As a member of our team, you will have the opportunity to work with one of the largest and most complex data warehouses in the world to gather insights using data from across Amazon. You will work closely with the marketing, merchandising, product, and development teams to solve unique problems and find answers to questions that require tenacious problem solving and creativity.  Data-driven decision making is at the core of Amazon’s culture, and your work will have a direct impact on decision making and strategy for the Amazon Music Team. Working with product management and engineering to identify and scope analysis of most common customer behavioral questions. Partnering with our Data Engineering team to enhance data infrastructure, data availability, and broad access to customer insights made available through . Join large and growing BI/ Science team to leverage extensive music listening to better understand customers and contribute to product and marketing strategy. Defining and developing tests to identify the best way to reach, convert, and retain customers. Reporting to senior leadership and the team at large, on customer, product and marketing insights and trends. Proactively developing new metrics and studies to quantify customer behavior. Partnering with Alexa teams to unlock insights on our voice platform. Quickly build a thorough understanding of the Digital Music industry, its seasonality and global business trends and continually monitor the impact of important industry developments.  ** Please note this role can sit either in SFO or SEA Basic Qualifications  - Bachelor’s degree in a quantitative area such as math, statistics, computer science, engineering or equivalent experience - 5+ years of relevant experience in analytics, business intelligence, data engineering, or related field - 2+ years of relevant work experience in a role requiring application of analytic skills - Proficient in SQL working with large-scale, complex datasets from multiple sources - Experience with data modeling, ETL development, and data warehousing - Advanced skills in Excel as well as additional data visualization tools like Tableau, Amazon QuickSight or similar BI tools - Advanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as required  Preferred Qualifications MBA or Master’s degree in Computer Science, Engineering, Statistics, Mathematics or related field Expert in writing and tuning SQL scripts Experience working in large data warehouse environments 5+ years of experience in a BIE or data engineer role with a technology company Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams Ability to deliver on ambiguous projects with incomplete or dirty data   Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.  Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.   Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $104,300/year in our lowest geographic market up to $202,800/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. Applicants should apply via our internal or external career site. Company Description At Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people’s lives. Our promise to our associates is rock-solid: We grow together, we enjoy our work, and we inspire each other. Welcome to Bosch. The Robert Bosch GmbH is looking forward to your application! Job Description Be part of our team and develop novel electrically actuated braking systems for future product generations. Together with experts from R&D and from the business divisions you are involved in the predevelopment process from the specification of requirements until the tryout of prototypes. Your field of responsibility is the thermal design, modeling and assessment of components as well as the analysis of prototypes regarding their thermal characteristics. Furthermore, you are responsible for the identification, creation as well as evaluation of concepts for heat transfer and thermal management in electrified mobility. The modeling and simulation of heat transfer by using common simulation tools (FEM/CFD/network models) is part of your responsibility as well. Also, you are working on the conception of application-specific simulation tools and models for electrical mobility including electrically actuated brakes. You plan, execute and evaluate thermal validation experiments on component prototypes including the selection of suitable measurement techniques. Last but not least, you cooperate with internal and external research partners, e.g. in publicly funded projects (pfp). Qualifications Education: Master in Mechanical-, Computational- or Electrical Engineering, Physics or comparable, a PhD is beneficial Experience and Knowledge: profound knowledge in thermal management technology, applications and systems, experience in the simulation of heat transfer by using common simulation tools and/or knowledge of experimental heat transfer testing methods including the validation of simulations, programming and scripting experience (C++, Python etc.) is beneficial Personality and Working Practice: team player, communicative, independent, analytical as well as structured with good organizational skills, cooperative, team-, solution-, and outcome-oriented Enthusiasm: open and agile mindset to create as well as drive new ideas and transfer them to innovative products Languages: excellent communication skills in German and English Additional Information www.bosch.com/research https://www.bosch-ai.com Please submit all relevant documents (CV, letter of motivation, certificates, transcript of records). Diversity and inclusion are not just trends for us but are firmly anchored in our corporate culture. Therefore, we welcome all applications, regardless of gender, age, disability, religion, ethnic origin or sexual identity. Need support during your application? Diana Stüber (Human Resources) +49(711)811-10356 Need further information about the job? Christine Meyer (Functional Department) +49(711)811-54929 Description de l'entreprise Chez TRIGO, nous sommes convaincus que la Qualité est essentielle à la performance de l’Industrie et à sa durabilité. C’est pourquoi nous déployons des solutions qui optimisent les productions industrielles, à l'échelle mondiale. Nous sommes 10 000 collaborateurs dans 26 pays, offrant un portefeuille complet de services à de nombreuses chaînes d'approvisionnement et de fabrication. De l'inspection et la retouche au conseil et à l’ingénierie, nous nous engageons pour la qualité de nos partenaires industriels. Nous nous appuyons sur nos solutions technologiques en développement, basées sur l'industrie 4.0, l'analyse de données et l'intelligence artificielle. Au sein d'une entreprise à l'esprit start-up et à la culture internationale, vous contribuerez et améliorerez l'efficacité de nombreuses chaines de montage et d’assemblage. Grâce à des missions engageantes et responsabilisantes, vous constaterez l'impact de vos efforts. Rejoignez une équipe engagée qui vise l'excellence ! Description du poste Au sein de l’équipe digital France en charge de toutes les solutions digitales (terrain, support et client), nous t'offrons la possibilité de participer en autonomie à des projets d'innovation monde. Tu travailleras en collaboration constante avec ton manager, le responsable digital France. Tes principales missions seront : - La gestion de projet : Définition des besoins des métiers (visite sur sites et ateliers de travail) Définition d’une solution (développement interne, externe, définition d’un nouveau process ou d’une nouvelle méthode de travail) Animation des réunions de suivi de projet (réunion de travail avec l’équipe opérationnelle, et réunion de suivi avec l’équipe projet) Exemples de projets : mise en place d’une application de contrôle de pièces via scan, création de power BI pour tous métiers, création d’une application de suivi d’activité pour le suivi du coût de main d’œuvre, définition de outils digitaux aux postes à déployer sur la France entière, lancement de projets de RPA, etc. - La partie technique : En fonction de tes appétences et de besoins, tu seras guidé sur l’apprentissage de la suite Power Platform de Microsoft (Power Apps, Automate et Power BI essentiellement) afin de répondre directement aux besoins de nos clients internes via la création d’applications et de rapports simples - Le support : En soutient de l’équipe Digital, tu accompagneras et formera les utilisateurs aux nouveaux rapports et applications créées. Tu participeras également à la création des différents contenus (guides utilisateurs, processus, etc.) sous PowerPoint ou SharePoint. Qualifications De formation minimum Bac+5, vous préparez un diplome d'ingénieur. Vous avez une appétence pour le digital et la gestion de projet. En plus de savoir maitriser le pack office (word, excel...), vos qualités relationnelles et managériales, ainsi que votre réactivité vous permettront de réussir à ce poste. En nous rejoignant vous aurez l’opportunité de vous voir confier des responsabilités clés et de contribuer aux challenges des acteurs majeurs industriels tout en développant vos compétences. Pré-requis: Bonne maitrise d'excel PowerApps et PowerBI serait un plus Informations supplémentaires Les 3 raisons de rejoindre TRIGO : •Vous intégrez le leader de la Qualité Industrielle en contribuant à des projets d’envergures et à forte valeur ajoutée en France et à l’International. •Vous évoluez dans un cadre bienveillant. Nous considérons que la qualité des prestations démarre par l’épanouissement de chaque collaborateur, notre management de proximité et le suivi régulier en sont des piliers. •Nous rendons votre réussite professionnelle possible en vous donnant les moyens de devenir un véritable expert qualité. Description de l'entreprise Chez TRIGO, nous sommes convaincus que la Qualité est essentielle à la performance de l’Industrie et à sa durabilité. C’est pourquoi nous déployons des solutions qui optimisent les productions industrielles, à l'échelle mondiale. Nous sommes 10 000 collaborateurs dans 26 pays, offrant un portefeuille complet de services à de nombreuses chaînes d'approvisionnement et de fabrication. De l'inspection et la retouche au conseil et à l’ingénierie, nous nous engageons pour la qualité de nos partenaires industriels. Nous nous appuyons sur nos solutions technologiques en développement, basées sur l'industrie 4.0, l'analyse de données et l'intelligence artificielle. Au sein d'une entreprise à l'esprit start-up et à la culture internationale, vous contribuerez et améliorerez l'efficacité de nombreuses chaines de montage et d’assemblage. Grâce à des missions engageantes et responsabilisantes, vous constaterez l'impact de vos efforts. Rejoignez une équipe engagée qui vise l'excellence ! Description du poste Au sein de l’équipe digital France en charge de toutes les solutions digitales (terrain, support et client), nous t'offrons la possibilité de participer à des projets d'innovation monde. Tu travailleras en collaboration constante avec ton manager, le responsable digital France. Tes principales missions seront : - La gestion de projet : Définition des besoins des métiers (visite sur sites et ateliers de travail) Définition d’une solution (développement interne, externe, définition d’un nouveau process ou d’une nouvelle méthode de travail) Animation des réunions de suivi de projet (réunion de travail avec l’équipe opérationnelle, et réunion de suivi avec l’équipe projet) Exemples de projets : mise en place d’une application de contrôle de pièces via scan, création de power BI pour tous métiers, création d’une application de suivi d’activité pour le suivi du coût de main d’œuvre, définition de outils digitaux aux postes à déployer sur la France entière, lancement de projets de RPA, etc. - La partie technique : En fonction de tes appétences et de besoins, tu seras guidé sur l’apprentissage de la suite Power Platform de Microsoft (Power Apps, Automate et Power BI essentiellement) afin de répondre directement aux besoins de nos clients internes via la création d’applications et de rapports simples - Le support : En soutient de l’équipe Digital, tu accompagneras et formera les utilisateurs aux nouveaux rapports et applications créées. Tu participeras également à la création des différents contenus (guides utilisateurs, processus, etc.) sous PowerPoint ou SharePoint. Qualifications De formation Bac+5, vous préparez un diplome d'ingénieur. Vous avez une appétence pour le digital et la gestion de projet. En plus de savoir maitriser le pack office (word, excel...), vos qualités relationnelles et managériales, ainsi que votre réactivité vous permettront de réussir à ce poste. En nous rejoignant vous aurez l’opportunité de vous voir confier des responsabilités clés et de contribuer aux challenges des acteurs majeurs industriels tout en développant vos compétences. Pré-requis: Bonne maitrise d'excel PowerApps et PowerBI serait un plus Informations supplémentaires Les 3 raisons de rejoindre TRIGO : •Vous intégrez le leader de la Qualité Industrielle en contribuant à des projets d’envergures et à forte valeur ajoutée en France et à l’International. •Vous évoluez dans un cadre bienveillant. Nous considérons que la qualité des prestations démarre par l’épanouissement de chaque collaborateur, notre management de proximité et le suivi régulier en sont des piliers. •Nous rendons votre réussite professionnelle possible en vous donnant les moyens de devenir un véritable expert qualité. The world of payment processing is rapidly evolving, and businesses are looking for loyal and strategic partners, to help them grow. Nuvei (Nasdaq: NVEI) (TSX: NVEI) is bringing payments up to speed. Our future-proof technology allows businesses to accept cutting-edge payment options, optimize new revenue streams, and get the most out of their stack. We believe in turning payment barriers into accelerants, propelling businesses forward with tailored solutions. With a single integration and advanced customization tools, Nuvei delivers unsurpassed flexibility that enables businesses to adapt quickly and enter new markets seamlessly. At Nuvei, we live our core values, and we thrive on solving complex problems. We’re dedicated to continually improving our product and providing relentless customer service. We are always looking for exceptional talent to join us on the journey!  Your Mission We are looking for a self-driven intelligence analyst to join our international sales team. The person on this position will manage analysis and prepare complex presentations. This function requires a highly organized, self-motivated, willing-to-learn, resourceful, and solutions-oriented individual who execute well in a dynamic environment while working on multiple projects. Key responsibilities include, but are not limited to: Collaborate with other teams to understand their needs and work with them to provide reporting efficiencies and analyses to achieve set goals. Use BI/analytics tools and CRM tools (SQL precisely). Use BI tools to manipulate and summarize data and design dashboards to present information in a visually compelling way. Coordinate with other team members on data collection, analyses, and synthesis of information. Able to manage time, workload, and responsibilities effectively. Be actively engaged in learning about the fintech industry and finding relevant insights.  Key responsibilities include, but are not limited to: 2+ years working experience in a data centric role. Knowledge & expertise in analytics. Good verbal communication skills. Ability to organize complex information in a concise and user-friendly way. Superior Excel skills. Comfortable interfacing with people at all levels within the organization and in various locations. Strong organization skills and detail oriented. Ability to multi-task in a dynamic environment is essential. Aggressive self-starter, ability to work both independently and as a team member. Proficient English.  Nuvei is an equal-opportunity employer that celebrates collaboration and innovation and is committed to developing a diverse and inclusive workplace. The team at Nuvei is comprised of a wealth of talent, skill, and ambition. We believe that employees are happiest when they’re empowered to be their true, authentic selves. So, please come as you are. We can’t wait to meet you. Benefits Long Term Incentive Plan that creates an opportunity for all employees to financial benefit from Nuvei’s growth 2.5 additional days of annual leave a quarter, if company hit quarterly targets A challenging job in a fast developing, international company. Friendly work environment where you can thrive and develop your skills. Career advancement possibilities. Competitive remuneration package. Nuvei offers a wide variety of additional benefits which include Additional Health insurance incl Dentist, Sport card, Food vouchers, Employee discounts card, Seminars and conferences tickets, Playroom, and many others additional perks. Working Language English (written and spoken) is the language used most of the time, as work colleagues, clients, and strategic suppliers are geographically dispersed.  Please send your resume in English.    Company Summary: Tessera Therapeutics is pioneering Gene Writing™— a new biotechnology designed to offer scientists and clinicians the ability to write small and large therapeutic messages into the genome, thereby curing diseases at their source. Gene Writing holds the potential to become a new category in genetic medicine, building upon recent breakthroughs in gene therapy and gene editing while eliminating important limitations in their reach, utilization, and efficacy. Tessera Therapeutics was founded by Flagship Pioneering, a life sciences innovation enterprise that conceives, resources, and develops first-in-category companies to transform human health and sustainability. Position Summary: Tessera is seeking a talented and motivated Computational Biologist to join our expanding Data Sciences team.  You will tackle challenging bioinformatics and computational biology problems to advance our understanding of Gene Writing and help accelerate programs to the clinic.  You will contribute scientific, technical, and leadership expertise to a multidisciplinary team, emphasizing conceptualization, experimentation, data analysis, presentation, and strategic planning.    Key Responsibilities: Work collaboratively with our platform and Biology teams to enable scientific discovery and progression through data analysis, data visualization and data integration Build and implement data analysis pipelines and storage solutions for various forms of sequencing including Amplicon sequencing, long-read sequencing (Pac Bio) and related methods Identify and acquire relevant public and third-party ‘omics data and perform integrative data analyses to generate insights that address strategic biological questions critical to Tessera’s core mission. Develop computational methods that provide project support to gene therapy project teams Operationalize data analysis aspects of relevant molecular assays to maximize the design, build, test cycle for platform and pipeline candidates Structure and store data to enable data reuse, data mining and machine learning Create compelling data visualizations for internal and external presentations    Basic Qualifications: Ph.D./M.S. in Computational Biology, Bioinformatics, or related quantitative discipline.  3+ years of industry experience in discovery research. Proficient with experimental design, data processing, statistical analysis, and bioinformatics analysis/reporting of next-generation sequencing data. Experience analyzing gene therapy, gene editing, in vitro/vivo assay, genetics, genomics and cell biology data Experience using comparative genomics as a tool for gene discovery Strong grounding in biology or medicine Strong data visualization skills and experience Fluency in one or more programming languages with bioinformatics applications (R, Python). Track record of success working in a fast-paced, cross-functional, and rapidly growing organization. Outstanding written and verbal communication skills, ability to work with colleagues from diverse scientific backgrounds and cultures.   Preferred Qualifications: Experience with recent advances in gene therapy and development of gene editing platforms as therapeutics. Strong competency in sequence analysis methods including gene identification, functional annotation, or comparative genomics. Familiarity with short and long read next-generation sequencing platforms (Illumina, PacBio, Nanopore). Proficiency in handling large scale sequencing data in a cloud environment (AWS preferred). Proficiency in statistics and machine learning. Experience in virology or mobile genetic elements.   More About Flagship Pioneering Flagship Pioneering has conceived of and created companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune’s “Change the World” list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies.  Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.    Recruitment & Staffing Agencies:  Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates.  The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team.   Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.    Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value Job Description As Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions. You will independently drive design discussions to ensure the necessary health of the overall solution. The role requires a hands-on technologist who has strong programming background like Java / Scala / Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.  Role & Responsibilities: Your role is focused on the Design, Development and delivery of solutions involving: Data Integration, Processing & Governance Data Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations Infrastructure & Cloud Computing Data Management Platforms Implement scalable architectural models for data processing and storage Build functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode Build functionality for data analytics, search and aggregation #LI-REMOTE  Qualifications Overall 5+ years of IT experience with 3+ years in Data related technologies Minimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS / Azure / GCP) Hands-on experience with the Hadoop stack – HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline. Strong experience in at least of the programming language Java, Scala, Python. Java preferable Hands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc  Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security   Competency 1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience 2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc 3. Knowledge on distributed messaging frameworks like ActiveMQ / RabbiMQ / Solace, search & indexing and Micro services architectures 4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 – Data Engineering 5. CI/CD – Infra provisioning on cloud, auto build & deployment pipelines, code quality 6. Cloud data specialty and other related Big data technology certifications Personal Attributes: Strong written and verbal communication skills Articulaion skills Good team player Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Process orientation and the ability to define and set up processe Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements Employee Assistance Programs to help you in wellness and well being Farfetch is unlike anything in the world of fashion and technology.Our mission: to revolutionize the way the world shops.To do it, we need innovators. People who challenge convention and dare to dream.We’ve gone from a start-up to a billion-dollar business. But we’re not done yet. Far from it.Be bold.Be brilliant.Together, we can be extraordinary We have rapidly grown into a truly global company since our launch in 2008 and we’re continuing to grow. Our family now includes partner boutiques and brands across Europe, North and South America, and Asia; we demonstrate our ‘Think Global’ value in everything we do. We are a global team of over 1,500 people and have offices based in London, New York, L.A., Porto, Guimaraes, Lisbon, Sao Paulo, Shanghai, Moscow, Hong Kong & Tokyo.We are a company with an entrepreneurial spirit and innovative culture. We are positive and passionate, and live our values: Be Human, Be Brilliant, Todos Juntos, Be Revolutionary, Think Global, and Amaze Customers day to day. The Team Farfetch’s Data Teams are focused on everything related to data. Their main purpose is to harness the power of Farfetch’s data to deliver insights and reports that support business decisions and also analyze and discover new ways to amaze our customers. These teams cover multiple areas related to data, such as  Business Intelligence, Software and Data Engineering, Data Science, and Data Analytics. Just like the rest of Farfetch, Data Teams are committed to turning the company into a leading e-commerce platform. As so, they are constantly looking for brilliant people who like the challenges that a fast-growing, data-driven company faces on its path to becoming a market leader.   The RoleYou will be integrated into the Data Engineering team, being responsible for helping maintain and improve the BI architecture and tools.   What you’ll do Design and build scalable & reliable data pipelines (ETLs) for our data platform Constantly evolve data models & schema design of our Data Warehouse to support self-service needs Work cross functionally with various teams, creating solutions that deal with large volumes of data. Work with the team to set and maintain standards and development practices; Be a keen advocate of quality and continuous improvement; Who you are You have experience building and maintaining data pipelines in a custom or commercial ETL tool (eg. SSIS, Talend, Informatica, Airflow) (plus); You have worked in a Data Warehouse environment (plus);  Background in working with cloud environments (eg. AWS, GCP, Azure) (plus); Basic experience in SQL; You have basic knowledge of Hadoop/BigData ecosystem (HDFS, Hive) (plus); You have basic skills in one of the following programming languages: C#, Java, Python; Knowledge in distributed computing (Spark) (plus); Experience in working with a BI reporting tool (eg. Tableau, QlikView, PowerBI, Looker) (plus); You are familiar with in continuous delivery principles: version control, unit and automated tests (plus); You have an intermediate level in English, both written and spoken; You have good analytical and problem solving skills, the ability to work in a fast moving operational environment and you are enthusiastic and with a positive attitude; We can’t wait to receive your application. But before you send it to us, here are some helpful tips to make sure your application is as strong as it can be. Have you set out why this role is a good match for your career aspirations and that you have the skills and experience required? We want you to be as clear about your future ambitions as we are and whilst we encourage people to learn, develop and grow, you will need to hit the ground running. Have you checked spelling and grammar? We have high standards and you don’t want to miss out because of something as easily correctable as a typo. Company Description Welcome to This Australian Life.   From the millions of Australians we protect, to those that make it happen every day at TAL, people really are what we’re all about. We want to grow with you. Achieve with you. And support you to do your best work. That's why we're focused on developing leadership, promoting diversity, rewarding excellence and retaining great talent.  We're always looking for people who want to go further with us. People who do what’s right, aim high, and work smart.  Why not see where we can go?  Job Description The BI Developer role is a critical role within the Data and Analytics team ensuring that new and existing ways of producing information products are understood and documented so that operational risks are within TAL’s risk appetite. You will engage with various business analysts within the Data and Analytics team to understand stated / unstated customer needs and requirements specific to Group Life’s reporting needs. This position will have a primary focus on the delivery of periodic, ad-hoc and/or new requests relating to Group Life and Investments data to external industry regulators, fund partners, partnership team and governing bodies. Qualifications Minimum of 2 years' experience in BI space  Must have experience in translating business requirements to technical/analytical specifications.  Must have experience working with and documenting workflow and business processes Proficiency with SQL, MS BI Stack (SSIS), Azure Data factory and Power BI. Life Insurance or Banking experience including knowledge of financial / actuarial valuation methods and processes  Demonstrable ability and attributes such as; assertiveness, resilience, and flexibility in times of change. Experience in process improvement and change You’re always accountable for your actions. You never give up. You strive to find the best outcomes for customers and partners. And you value working together to find the best solutions for problems.   Additional Information Work is a big part of this Australian life, and we work hard to make it one of the best parts. We don’t just say it; we do it.  We offer a workplace that’s inclusive and flexible, supporting our people with options that let them make the most of their careers.  We know the value of having different people from all walks of life, with varied points of view and attributes regardless of their age, ethnicity, religion, sexual orientation, gender identity, intersex status or any disabilities they might be living with. We strive for a diverse and inclusive workplace where a sense of belonging encourages people to bring their full selves to work.   #LI-Hybrid  #LI-REMOTE  Everyone at TAL has a responsibility to do the right thing and is accountable for the way they conduct themselves. Our expectations are that you follow the principles set out in our Code of Conduct when you come to work every day. Risk management is everyone’s responsibility. If you are already a TAL employee please apply via the SmartRecruiters button in Workday and navigate to the Employee Portal. This is important to ensure that your application is recorded accurately. Enroute is about being exceptional. We deliver IT services and solutions by tech-savvy problem solvers, constantly looking for innovative approaches to everyday problems. Enrouters have unique ideologies, principles, and incredible life stories. Everyone is welcome at Enroute. We take pride in our culture. We want every Enrouter to enjoy working with us and become part of a great community of highly driven, responsible, respectful, and happy people. We offer outstanding benefits, compensation, flexible schedules, and policies that balance work and personal life. We strive to be involved and know our people to improve continuously. We seek a talented and experienced BI Developer - Visualizations Expert (Tableau) to join our dynamic and growing team. As a key member of the Business Intelligence team, you will be responsible for designing and developing interactive dashboards, reports, and visualizations to provide insights and support data-driven decision-making across the organization. Requirements Bachelor's degree in Computer Science, Information Technology, or a related field 5+ years of experience in business intelligence and data visualization, with a strong focus on Tableau Proficient in Tableau Desktop, Server, and Tableau Public (minimum of Tableau 2021.3 version) Experience with data modeling, data warehousing, and ETL processes Strong SQL skills Ability to work with large datasets and create scalable and efficient dashboards Excellent communication and collaboration skills, with the ability to work effectively with both technical and non-technical stakeholders A self-starter with the ability to take the initiative and work independently Excellent problem-solving skills and the ability to think creatively  Responsibilities Design and develop advanced Tableau dashboards, reports, and visualizations Work with stakeholders to gather requirements and translate them into data-driven insights. Collaborate with cross-functional teams to ensure the delivered solution meets business requirements. Stay up-to-date with Tableau technologies and trends to ensure the solution is always current. Participate in code reviews and ensure the code is maintainable and scalable. Troubleshoot and resolve issues with existing Tableau dashboards and reports Participate in training and mentoring junior team members. Benefits Monetary compensation Year-end Bonus IMSS, AFORE, INFONAVIT Major Medical Expenses Insurance Minor Medical Expenses Insurance Life Insurance Funeral Expenses Insurance Preferential rates for car insurance TDU Membership Holidays and Vacations Sick days Bereavement days Civil Marriage days Maternity & Paternity leave English, Japanese, and Spanish classes Performance Management Framework Certifications TALISIS Agreement: Discounts at ADVENIO, Harmon Hall, U-ERRE, UNID Taquitos Rewards Amazon Gift Card on your Birthday Work-from-home Bonus Laptop Policy Equal employment Enroute is committed to providing equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training. Company Description Welcome to This Australian Life.   From the millions of Australians we protect, to those that make it happen every day at TAL, people really are what we’re all about. We want to grow with you. Achieve with you. And support you to do your best work. That's why we're focused on developing leadership, promoting diversity, rewarding excellence and retaining great talent.  We're always looking for people who want to go further with us. People who do what’s right, aim high, and work smart.  Why not see where we can go?  Job Description The Senior BI Developer role is a critical role within the Data and Analytics team ensuring that new and existing ways of producing information products are understood and documented so that operational risks are within TAL’s risk appetite. You will engage with various business analysts within the Data and Analytics team to understand stated / unstated customer needs and requirements specific to Group Life’s reporting needs. This position will have a primary focus on the delivery of periodic, ad-hoc and/or new requests relating to Group Life and Investments data to external industry regulators, fund partners, partnership team and governing bodies. Qualifications Minimum of 5 years experience in BI space Must have experience in translating business requirements to technical/analytical specifications.  Must have experience working with and documenting workflow and business processes. Proficiency with SQL, MS BI Stack (SSIS), Azure Data factory and Power BI. Ability to build strong commercial acumen, problem solving and analytical skills Ability to communicate proactively and effectively with stakeholders (written and verbal) You’re always accountable for your actions. You never give up. You strive to find the best outcomes for customers and partners. And you value working together to find the best solutions for problems.   Additional Information Work is a big part of this Australian life, and we work hard to make it one of the best parts. We don’t just say it; we do it.  We offer a workplace that’s inclusive and flexible, supporting our people with options that let them make the most of their careers.  We know the value of having different people from all walks of life, with varied points of view and attributes regardless of their age, ethnicity, religion, sexual orientation, gender identity, intersex status or any disabilities they might be living with. We strive for a diverse and inclusive workplace where a sense of belonging encourages people to bring their full selves to work.   #LI-Hybrid  #LI-REMOTE  Everyone at TAL has a responsibility to do the right thing and is accountable for the way they conduct themselves. Our expectations are that you follow the principles set out in our Code of Conduct when you come to work every day. Risk management is everyone’s responsibility. If you are already a TAL employee please apply via the SmartRecruiters button in Workday and navigate to the Employee Portal. This is important to ensure that your application is recorded accurately. Company Description It all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app, bringing a better way to send, spend, invest, borrow and save to our millions of monthly active users. With a mission to redefine the world's relationship with money by making it more relatable, available and accessible, at Cash App you'll have the opportunity to make a real-world impact with your career. Today, Cash App has thousands of employees around the world with a culture geared toward creativity, collaboration and impact. We’ve been a distributed team since day one, and continue to value working across time zones and continents both remotely and in our Cash App offices. Our offices are great, but many of our roles can be done remotely from the countries where Block operates. We tailor our experience to champion our employees’ creativity and productivity wherever they are.  Job Description The BI Team at Cash App enables our teams to make impactful business decisions. Our BI Engineers handle everything from data architecture and modeling to data pipeline tooling and dashboarding. As a Senior BI Engineer at Cash App, you will report to the BI Manager and work with Analysts, Data Scientists, Software Engineers and Product Managers to lay the foundation for analyzing our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, to informing product development. You will build, curate, document, and manage key datasets and ETLs to increase the impact of the entire team.  You will: Create brand new and optimize existing data models for the most widely used Cash App events, entities, and processes Standardize business and product metric definitions in curated and optimized datasets Build pipelines out of our data warehouse Teach (and encourage) others to self-serve while building tools that make it simpler and faster for them to do so Promote data, analytics, and data model design best practices Create dashboards that help our teams understand the performance of the business and help them make decisions Qualifications You have: Background/knowledge in Computer Science, Applied Math, Engineering, Stats, Physics, or a something comparable 3+ years of industry experience building complex, scalable ETLs for a variety of different business and product use cases An interest in advancing Cash App's vision of building products for economic empowerment - this should be something that legitimately excites you Technologies we use and teach: SQL (MySQL, Snowflake, BigQuery, etc.) Airflow, Looker and Tableau Python and Java Additional Information Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.  Zone A: USD $152,100 - USD $185,900 Zone B: USD $144,500 - USD $176,700 Zone C: USD $136,900 - USD $167,300 Zone D: USD $129,300 - USD $158,100 To find a location’s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information.  Benefits include the following: Healthcare coverage Retirement Plans including company match  Employee Stock Purchase Program Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance  Paid parental and caregiving leave Paid time off Learning and Development resources Paid Life insurance, AD&D. and disability benefits  Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources  This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans. We’re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, veteran status, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.  We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible. Want to learn more about what we’re doing to build a workplace that is fair and square? Check out our I+D page.  Additionally, we consider qualified applicants with criminal histories for employment on our team, assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution. Company Description At Experian Health, our employees have the opportunity to shape more than products – they shape the future of U.S. healthcare. Experian Health is a pioneer for innovations leading the way in revenue cycle management, identity management, patient engagement, and care management for hospitals, physician groups, labs, pharmacies and other risk-bearing entities. Our success relies on people who are given the freedom to imagine new frontiers in the rapidly changing healthcare space and push the boundaries of innovation. Help us realize our vision of applying data for good and changing the healthcare landscape for the better – for all of us. Job Description 100% REMOTE (NOT HYBRID) - WORK ANYWHERE IN THE US The primary responsibility of the Data Analyst will be to support application development leveraging strong SQL skills, knowledge of relational databases, and the skills to ensure custom coordination of benefit software, containing over 400 million rows of data, only allows accurate data to be loaded, and data integrity is maintained after bug fixes and enhancements.  This position will ensure this software is thoroughly tested from all angles focusing primarily on the backend by developing custom test plans and executing them using SQL, analyzing production data, and writing custom reports.  Job duties: Fully understand custom built Healthcare Medical Eligibility/Coordination of Benefits software solution. Understand the technical design and be able to traverse through and fully test the system using custom developed test plans using SQL Work collaboratively at ground level with senior level development staff to fully understand product requirements. Be willing to ask questions, push back as necessary, and ultimately ensure the new code meets stringent customer expectations Identify software defects, conduct research, develop plan for resolution, and engage appropriate internal resources as necessary Perform data analysis as needed on production data (400+ million rows of data) Collaborate with team members on, and provide peer review of, test plans, test cases, test data, and automation/tool enhancements. Work collaboratively with development team to make technical judgments based upon understanding of the business process and customer/user needs whereby a design change or modification should (or needs to be) changed. Support inquiries from client, operations, and customer support on content related questions and monitor areas for improvement. Design and document test cases to ensure optimal system performance with new code releases Utilize QA best practices Tests will be executed at the database level, using SQL Build automated tests using tools such as Selenium Operate load testing on Web Based Portal Run smoke tests and regression tests Prepare appropriate test data Communicate and document testing results in appropriate tool Maintain defect reporting and tracking Maintain current test plans, test cases, test scripts, and test data. Availability for planned after hours deployments and unplanned issue resolution Planned deployments typically occur once a month on Thursday nights Qualifications Bachelor’s degree in Information Systems, Computer Science, or other related field OR equivalent experience required At least 3 years combined prior business analyst, SQL programming, software QA, SQL data analysis Minimum 3 years of SQL usage in a professional setting Experience working as an analyst with large datasets (1+ million records) highly desired Experience with SDLC and iterative development processes, specifically Agile work processes highly desired Experience in working in a highly competitive team environment Strong SQL skills required (Data Analyst SQL skill set, not necessarily SQL programming) Focus on relational databases Business analyst knowledge is highly preferred QA knowledge is preferred. Willingness to be trained on QA fundamentals is required Coordination of Benefits, and/or Healthcare Revenue Cycle knowledge a plus Effective communication and relationship building skills Self-motivated, team player, but who can work independently Ability to adapt to an Agile/Scrum environment Strong written and verbal communication skills Problem-solving as part of a distributed team Time management and organizational skills Knowledge of the HIPAA transaction sets and requirements is desirable Become an expert on highly complex custom software - willingness to self-study and learn through trial and error required.   Additional Information Experian is an Equal Opportunity Employer. Anyone needing accommodation to complete the interview process should notify the talent acquisition partner. The word "Experian" is a registered trademark in the EU and other countries and is owned by Experian Ltd. and/or its associated companies. EOE including Disability/Veterans. Experian is proud to be an Equal Opportunity and Affirmative Action employer. Our goal is to create a thriving, inclusive and diverse team where people love their work and love working together. We believe that diversity, equity and inclusion is essential to our purpose of creating a better tomorrow. We value the uniqueness of every individual and want you to bring your whole, authentic self to work. For us, this is The Power of YOU and and it reflects what we believe.  See our DEI work in action! Please contact us at JobPostingInquiry@experian.com to request the salary range of this position (please include the exact Job Title as it reads above in your email). In addition to a competitive base salary and variable pay opportunity, Experian offers a comprehensive benefits package including health, life and disability insurance, generous paid time off including 12 company paid holidays and parental and family care leave, an employee stock purchase plan and a 401(k) plan with a company match. Experian Careers - Creating a better tomorrow together Find out what its like to work for Experian by clicking here Binance is the global blockchain company behind the world’s largest digital asset exchange by trading volume and users, serving a greater mission to accelerate cryptocurrency adoption and increase the freedom of money. Are you looking to be a part of the most influential company in the blockchain industry and contribute to the crypto-currency revolution that is changing the world? About Binance Accelerator Programme Binance Accelerator Programme is a concise 3 - 6 months programme designed to have an immersive experience in the rapidly expanding Web3 space.  You will be given the opportunity to experience life at Binance and understand what goes on behind the scenes of the worlds’ leading blockchain ecosystem. Alongside your job, there will also be a focus on networking and development, which will expand your professional network and build transferable skills to propel you forward in your career.  Who may applyCurrent students, fresh graduates, and candidates who are mid-career switchers. About the roleAs a data scientist in Sanctions Compliance team, you will have the opportunity to leverage rich data (PB-level scalability) and state-of-art machine learning infrastructure to provide collation and analysis of data, research and background information to support the day-to-day operations of the Sanctions and AB&C Risk and Compliance Team. You will collaborate with a strong team of compliance experts, engineers, data analysts, to define and build solutions for the compliance department based on our rich data and cutting-edge machine learning technology. Responsibilities Provide support to the heads of Global Sanctions and AB&C Risk and Compliance Programme in all data related request Develop dashboard in monitoring Sanctions and AB&C Risk and Compliance team in monitoring operational risk, efficiency and productivity Data quality control: Understand operational process and ensure data quality and correctness for internal controls and compliance analysis Leverage our PB-scale data warehouse to perform in-depth analysis and build personalised services for Sanctions and AB&C Risk Data driven sanctions risk analysis: leverage of machine learning techniques to understand customers’ demographics and sanctions exposure with proven data evidence and analysis Coordinate automations and system improvement projects Promote data-driven culture within the Sanctions and AB&C Risk and Compliance team in making compliance decisions Develop training and procedures to team members in understanding data, using excel / SQL to conduct data analysis Navigate and build strong stakeholder relationships across Binance’s global functions and teams Horizon scans for regulatory and internal developments, that affect Binance globally Confidently raises challenges, providing different perspectives, whilst maintaining and building professional relationships. Requirements University degree in computer science, statistics or data science related programs Good experience in developing dashboards for operations and risk monitoring Good project experience with developing machine learning modelsGood experience with processing large size data is preferred Good experience with Python, SQL and any data visualization tools is preferred Deep understanding of modern machine learning techniques and mathematical underpinning, such as classifications, recommendation systems, optimization etc. Fluent in English - a second language is preferred  Strong analytical and writing skills, and sound judgement Ability to work across functional and geographic lines You are pragmatic and energetic, with an ability to think ‘outside the box’ in a fast-paced dynamic environment  You have strong learning agility as well as a critical and innovative mindsetYou are people-focused You are a good communicator verbally and in writing, being able to convey complex messages in a simple way to bring an understanding to “why” change is required  You are confident, result driven and seek to find innovative and new creative solutions Working at Binance• Do something meaningful; Be a part of the future of finance technology and the no.1 company in the industry• Fast moving, challenging and unique business problems• International work environment and flat organisation• Great career development opportunities in a growing company• Possibility for relocation and international transfers mid-career• Competitive salary• Flexible working hours, Casual work attire By submitting a job application, you confirm that you have read and agree to our Candidate Privacy Notice. Computational Biologist  Vesalius Therapeutics is seeking a highly motivated and collaborative Computational Biologist driven to leverage single-cell genomics data to reveal biological mechanisms of health and disease.  The candidate will participate in the statistical design and analysis of genomic experiments (e.g. single-cell RNA-seq, ATAC-seq, CRISPR screens, etc.) in collaboration with wet-lab biologists.  The role requires the ability to interpret experiments that deliver testable hypotheses that integrate clinical and biological endpoints using cutting edge methods and technologies.  The candidate should have a solid foundation in applied statistics, deep generative models, computational biology, molecular biology paired with a strong work ethic and the ability to work independently and in highly matrixed teams. The candidate will leverage publicly available data and integrate with internally generated data. This is an exciting and interdisciplinary role that will collaborate with statistical geneticists, biomedical informaticists and wet-lab biologists to support the development of novel therapeutics.     Responsibilities  Computational analysis of large, complex, single cell genomics datasets from in vitro cellular model systems   Deliver testable hypotheses/insights from complex high-dimensional data to inform target selection   Linking results and insights between internal and public data, as well as orthogonal data such as human genetics.   Identify and validate approaches to improve quality and efficiency of hypothesis generation from model systems   Maintain awareness of emerging methods in computational biology and applications for novel omics technologies   Provide ad-hoc bioinformatics support to cross-disciplinary project teams   Reporting results to scientific team and management.     Qualifications  PhD in Bioinformatics, Biostatistics, Computer Science, Computational Biology, Genetics, Mathematics, Physics, Statistics or other related discipline   2-3 years post PhD experience applying quantitative approaches to solve biological problems   Knowledge and experience of single-cell transcriptomic data and analyses; additional modalities such as histone modification data analysis considered a plus.   Strong knowledge of applied statistics and machine learning (in particular deep generative models)   Strong statistical and scripting programming skills (Python/R/etc.)   Knowledge of molecular biology, neuroscience experience a plus   Demonstrated experience in design and interpretation of in vivo and/or in vitro biological experiments.   Demonstrated expertise in delivering insights/hypotheses from complex high-dimensional biological data   Demonstrated ability to collaborate with biologists to communicate results and discuss follow-up experiments   Exceptional communication skills (oral and written) as demonstrated by publications & presentations.   Demonstrated ability to work in a dynamic environment as a team player with a strong work ethic.  Demonstrated ability to work in a dynamic environment with a sense of urgency and creativity and focus on deliverables. Team player with a strong work ethic, able to work both independently and collaboratively  Continuously learns and adapts quickly to new information Authentic, proactively appreciative of different points of view, backgrounds and perspectives   What We’ll Offer You:  Comprehensive, competitive healthcare (PPO) and dental coverage through Blue Cross Blue Shield, vision coverage through VSP, family leave, three weeks’ paid time off with additional holidays, 401k retirement plan, disability and life insurance, and commuter benefits.  A dynamic early-stage work environment and highly interdisciplinary, talented, and collaborative team.  Participate in the development and growth of a company with enormous potential impact on human health Professional growth opportunities through mentoring, training, immersion in cross-functional projects, and opportunities to learn and try new things.      Who We Are:     Vesalius Therapeutics is a Flagship Pioneering platform company with a bold and critical mission to revolutionize drug development for the diseases that cause 90% of global morbidity and mortality.    The company was founded in 2019 in Flagship Labs, Flagship Pioneering’s innovation foundry.  Vesalius is led by CEO Christopher Austin, M.D., Flagship Managing Partner, Doug Cole, M.D., and a leadership team with decades of experience working at some of the most renowned pharma and biotech companies in the industry.  Vesalius’s ContinuumDiscovery™ platform harnesses a combination of human clinical data and genetics, artificial intelligence and machine learning, and patient-derived experimental models into a uniquely potent discovery engine.    You can read more about our mission here.  Are you looking to be in a workplace where colleagues inspire one another? Are you interested in competitive and impactful benefits? Do you prefer flexible work arrangements?  We are seeking a talented and experienced Product Owner to join our team of experts focused on designing and building microservices that leverage Big Data and Artificial Intelligence (AI) to identify and act on personal information in the RelativityOne platform. This successful candidate will lead the development and execution of the product roadmap to ensure the commercial success of both Text IQ for Data Breach and Text IQ for Personal Information offerings.  Responsibilities: Develop and execute on the product roadmap that supports the Text IQ for Data Breach and Text IQ for Personal Information offerings.  Collaborate with cross-functional teams (including engineering, operations, marketing, sales, and customer success) to ensure successful product delivery and customer adoption.  Identify market trends, customer needs, and competitive insights to inform product strategy and roadmap.  Create user stories and prioritize the product backlog to align with the overall product vision and goals.  Work closely with the engineering team to deliver high-quality product features and functionality, and ensure timely product delivery.  Define and measure product success metrics, and use data to continuously improve product performance and user satisfaction.  Communicate product strategy, roadmap, and progress to internal and external stakeholders.  Collaborate with the go-to-market teams to develop effective product positioning, messaging, and launch plans.  Collect, analyze, and summarize data from disparate sources to drive conclusions and recommendations.  Work independently and effectively in a results-oriented, efficient environment.  Deliver products and ensure customer success through strong project management and team leadership.  Communicate effectively with stakeholders at all levels, including senior leadership.  Manage and prioritize multiple tasks and projects simultaneously.  Your skills: BS or BA degree; 7+ years of work experience, with at least 5 in product management.  Strong problem-solving skills, including ability to dissect complicated technical problems, simplify experiences, and innovate on behalf of our customers.  Strong technical acumen and working knowledge of software architectures and AI/ML.  Strong business knowledge to help build go-to-market machinery for existing and new products.  Solid understanding of software development lifecycle and agile methodologies.  Ability to collaborate with and lead teams of all levels and disciplines within an organization, from engineers to senior leadership.  A history of developing and owning product roadmaps to drive business outcomes.  Experience collecting, analyzing, and summarizing data from disparate sources to drive conclusions and recommendations.  Entrepreneurial spirit and ability to work independently and effectively in a results-oriented, efficient environment.  Strong track record of delivering products and ensuring customer success.  Organized, with the ability to communicate effectively with stakeholders.  Excellent written and verbal communication skills.  Experience working with international teams is a plus.  Relativity is a diverse workplace with different skills and life experiences—and we love and celebrate those differences. We believe that employees are happiest when they're empowered to be their full, authentic selves, regardless how you identify. Benefit Highlights:Comprehensive health, dental, and vision plansParental leave for primary and secondary caregivers Flexible work arrangementsTwo, week-long company breaks per yearUnlimited time offLong-term incentive programTraining investment program All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law. Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description The Marketing, Sales, Services Technology Systems (MSST) Team manage the Customer Relationship Manager (CRM) systems, Business process management (BPM) applications and custom applications for Sales, Services, Marketing and Product teams. The Analytics team within this team integrate data from multiple applications like CRM, Contact Center applications, Appian and build executive and operational reports as well as enable self-service reporting and insights from to empower Business to monitor and track KPIs and make data driven decisions. The Sr. Data Engineer (ETL/Power BI/SQL) within the Analytics Delivery team will be responsible for solution design, development and implementation of Data integration and Analytics solutions on data platforms (SQL server) and Hadoop. This position requires designing database schemas for reporting, perform data engineering activities using ETL tools like Pentaho and/or scripts to ingest data from multiple applications on the cloud and on premise, build Power BI data sets and enable self- service reporting on Power BI and Hadoop. This position requires close collaboration with Global Sales Business partners and Product owners to understand Business goals and requirements and implement Data Analytics solutions following agile methodologies. This position requires collaboration with multiple global IT teams including application teams, database teams, Infrastructure and Platform teams and respond to changing Business priorities with agility. This position provides Production support for applications, data analysis and requires investigation and resolution of issues. Responsibilities: Participate in Technology project delivery activities such as gathering Business requirements, conceptual technology approach, design, development, enhance and build scalable solutions and support systems in production in a DevOps model. Work as a member of Sales domain scrum teams and provide solutions for complex reporting requirements. Work as a Subject matter expert on data from Sales and Marketing domain. Architect solutions and build data management systems – on premise or on cloud. Understand application systems, architect solution, develop the source to target mapping documents and ETL code to load data from Cloud applications (MS Dynamics) other CRM applications to databases on premise. Develop workflows using ETL tools like Pentaho. Develop database components on premise databases (SQL Server) and/or Hadoop for reporting. Develop Power BI data models and dashboards. Support QA, UAT and performance testing phases of development cycle and implement DevOps principles from development to deployment to production Partner with IT groups such as Engineering, Product, Cybersecurity, and Infrastructure on project delivery activities and security findings remediation. Own Operational support for multiple applications Perform POC and build prototypes based on business and technology requirements. This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs. Qualifications Basic Qualifications: • 2 or more years of work experience with a Bachelor’s Degree or an Advanced Degree in Computer Science/ Engineering, Information Science or a related discipline with strong technical experiences (e.g. Masters, MBA, JD, MD, or PhD). Preferred Qualifications: • Minimum of 2-3 years’ experience with Master’s degree or 4-5 years' experience with Bachelor’s degree in Computer Science/ Engineering, Information Science or a related discipline • Experience of at least four years in building data pipelines and utilizing data engineering techniques like ELT or ETL for building and scaling reporting and Analytical solutions • Strong expertise in Data analysis, writing SQL scripts and hands on experience working on Relational data bases like SQl Server required • Experience building Power BI data models and dashboards required • Extensive experience with ingesting and transforming data using ETL tools like Pentaho, Informatica is required • Experience using FetchXML, DAX functions, implementing Power BI security features required • Experience using MS Dynamics Sales and Services modules nice to have • Experience in provisioning databases and managing application servers (on premise or on cloud) nice to have • Experience with ensuring data quality for reporting and implementing data observability metrics highly desirable • Experience using Hadoop (Hive, Presto, Spark) highly desirable • Experience in Python, PowerShell, job scheduling (Control M) and version control (bitbuket, GitHub), implementing CI/CD for Reporting components nice to have • Experience with embedding dashboards in MS Dynamics, Power apps, Power Automate nice to have • Experience working in Agile methodology owning end to end product solutions • Experience with cloud infrastructure like Azure data lake, Synapse, Snowflake on Azure nice to have • Good Presentation skills and communication skills presenting ideas and insights to Business is highly desired • Experience on Sales and Marketing domain nice to have • Demonstrated analytical rigor, strong attention to detail, team oriented, collaborative, agile and flexible style Additional Information Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. We offer a hybrid work environment. Most US-based positions can also be performed remotely (any exceptions will be noted in the Minimum Qualifications below.) For Israel-based positions, we encourage working from our Saarona, Tel Aviv office a few days a week, meeting your colleagues, and having a flexible work environment. Our Mission:  To actively connect people to their next great opportunity.  Who We Are:  ZipRecruiter is a leading online employment marketplace. Powered by AI-driven smart matching technology, the company actively connects job seekers with millions of businesses of all sizes through innovative mobile app, web, and email services, as well as partnerships with the best job sites on the web. ZipRecruiter has the #1 rated job search app on iOS & Android.  Summary of Job ZipRecruiter is changing the way job seekers get hired and how small businesses manage their HR. Our R&D center in Tel Aviv offers an empowering, fun and collaborative culture where talented individuals who think like business owners and entrepreneurs are invited to join our growing team.   We use models and algorithms of machine-learning and deep-learning to find candidates for a job, and get the job information to reach the candidate as quickly as possible to allow the employer to reach the best candidates in the least possible time. We are looking for a passionate Big Data Engineer with expertise in cloud technologies, big data, and distributed systems to join our data engineering team. This exciting role requires the experience and skills to design and build key components and infrastructure for our data science and engineering team.  Key focuses: Build infrastructure to empower fellow engineers and data scientists to build together best-in-class machine-learning based products Working in a high volume production environment that gets bigger and bigger Mastering scalability and enterprise-grade production services implementation Sense of ownership - leading design for new products and initiatives as well as integrating with currently implemented best-practices Working with a number of off-the-shelf tools including Spark, Airflow, Kafka, DynamoDb, SQS, S3, RedShift, Mysql, but often push them past their limits Collaborating and working as part of a highly skilled team that enjoys doing the impossible together every day Minimum Requirements: At least 5+ years of coding experience with at least one of the following: Java, Python, Scala. End to end experience - owning feature from an idea stage, through design, architecture, coding, integration and deployment stages A deep understanding of software engineering with at least 5+ years of hands-on coding experience at a senior level in high-volume production environments Experience with one or more of these technologies Spark, MapReduce, Airflow, Kafka, Key/Value Stores like DynamoDB, SQL DB’s, SQS Dealing with data on high volume, high availability production systems Fluent with SQL Bachelor’s degree or higher in Computer Science or equivalent professional Software Engineering experience Cloud - AWS, Azure, Google Cloud - an advantage Experience in algorithm design and implementation or Machine learning As part of our team you’ll enjoy: Competitive salary Exceptional benefits package ZipRecruiter is proud to be an equal opportunity employer and provides equal employment opportunities (EEO) to all employees and applicants without regard to race, color, religion, sex, national origin, age, disability, veteran status, sexual orientation, gender identity or genetics. Privacy Notice: For information about ZipRecruiter's collection and processing of job applicant personal data for this job, please see our Privacy Notice at: https://www.ziprecruiter.com/careers/job-applicant-privacy-notice Company Description Publicis Media is one of Publicis Groupe’s four solution hubs, aligning all of Publicis Groupe’s media agencies and operations.  Publicis Groupe (Euronext Paris Exchange: FR0000130577; CAC 40 index), is the world’s third largest communications group.  The Data, Technology and Innovation Global Practice was created to deliver best-in-class programmatic solutions as well as to consolidate Publicis Media’s data and technology to transform our business from a service business to a platform business.  Job Description We are seeking a driven individual with a proven track record of scalable and innovative business intelligence solutions. He/she shines when serving as a consultant to the business and is genuinely interested in understanding the objectives of complex and evolving projects. In this role, you will champion and advocate the use of Alteryx and Tableau to create an environment of self-service analytics. The candidate must be a self-starter with a sense of urgency and a commitment to quality and professionalism.  Responsibilities: Analyze business needs and partner with stakeholders to provide a strategic solution Work independently on end to end solutions, from data analysis to ETL design and development through to the final visual dashboard Collaborate across the organization to build solutions that achieve business objectives Guide stakeholders with operational decisions that impact data structures and connectivity Bring best practices in data architecture and data visualization to the table Build tools in a generic fashion for reuse across other solutions Develop technical documentation for each solution Manage projects in an agile environment Qualifications Minimum Bachelor’s Degree in Computer Sciences, Information Technology, or its equivalent 3+ years’ experience with Tableau 1+ years’ experience with AWS core+ services (EC2, S3, Lambda, Redshift, Glue) 1+ years’ experience with Python 3+ years’ experience with data visualization Comfortable with data warehousing concepts, preparing data, and configuring automated workflows Excellent communication and presentation skills as well as an analytical mindset Experience with complex logic Strong data analysis skills Experience connecting and merging disparate datasets Strong organizational skills & attention to detail Possess a desire to work for a fast-paced, results-based company Experience managing multiple projects simultaneously  Desired Skills/Experience: Experience with media and ad tech platforms (Ad Servers, Media Planning and Buying systems, DSP’s, Programmatic, etc) SQL Adobe Site Catalyst Google Analytics Basic knowledge of ETL, data modeling, data warehouse, extracting and manipulating large record of data  Additional Information All your information will be kept confidential according to EEO guidelines.   Company Summary: Each day, the lives of more than 2 billion people across the globe are impacted by chronic diseases. Moreover, the economic burden on society of treating chronic disease is spinning out of control. Today, this dire situation appears unlikely to change as >95% of global healthcare costs are spent on treating rather than preventing chronic diseases. FL84, Inc. is a privately held early-stage company that is applying advanced biological and computational platforms to discover breakthroughs in detection of and intervention against the etiologies that drive progression from health to disease. Our goal is to leverage our proprietary platforms to disrupt the current approach of treating chronic disease too late. We endeavor to provide true health care rather than sick care to individuals that are at risk of progressing to disease. FL84 was founded by Flagship Pioneering, an innovation enterprise dedicated to originating and developing first-in-category life sciences companies. Flagship Pioneering conceives, creates, resources, and develops first-in-category life sciences companies to transform human health and sustainability. Since its launch in 2000, the firm has applied a unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures, resulting in over $30 billion in aggregate value. The current Flagship ecosystem comprises 37 transformative companies, including: Moderna Therapeutics (NASDAQ: MRNA), Rubius Therapeutics (NASDAQ: RUBY), Indigo Agriculture, and Sana Biotechnology. Position Summary: We are seeking a Scientist/Sr. Scientist of Computational Biology/Bioinformatics who is enthusiastic about developing, learning and applying computational skills to understand complex biological systems and their relationship to clinical state changes. The candidate will design and implement novel approaches to handling biological data, initially focused on single-cell/nuclei RNAseq but rapidly expanding to multiple types of biological and clinical data.  The role will focus on two main areas: (1) application of machine-learning to uncover novel targets; and (2) exploration of large, multimodal datasets to develop pipelines for preemptive clinical discovery.  An ideal candidate will pride themselves on their ability to craft scientifically logical and creative stories out of complex data and convert them into executable experiments. The position will provide a unique opportunity to play a foundational role in the development of FL84’s preclinical platform and treat diseases before they become a burden to the patient or the healthcare system. Key Responsibilities: Develop and apply bioinformatics, computational biology, and machine learning tools to generate insights and hypotheses from high-dimensional molecular datasets, with an initial focus on time-series snRNA-seq and genomic data Work with FL84 team to develop and apply novel ML models on heterogenous biological data Identify and explore internal and external datasets to address questions critical to FL84’s core objectives and generate testable hypotheses Ideate on how to align time-series biological data with clinically relevant inflection points identified in electronic health records, clinical trials, or other sources Establish pipelines to prioritize targets for biological validation Develop clear, intuitive visualizations and communicate analysis results via presentations to a multi-disciplinary audience Cultivate a data-centric company philosophy by helping to maintain best practices for software development, data management, and infrastructure Monitor and evaluate new and emerging technologies and models and identify opportunities for collaboration within Flagship Pioneering companies, academia, and third parties Basic Requirements: PhD with 3+ years of experience or equivalent level of experience in quantitative biology.  Ph.D. may be in Computational Biology, Bioinformatics, Computer Sciences, Applied Mathematics, Applied Physics, or related Practical programming and scripting skills, preferably in Python and R Breadth of experience applying deep learning (DL) models to biological data Motivated and team oriented, with an ability to thrive in an entrepreneurial and multidisciplinary environment Ability to independently lead and run research projects, while maintaining close communication with team members Excellent communication and presentation skills. Must be able to speak and ideate with multi-disciplinary team including biologists. Must be able to think independently, work collaboratively and contribute to an active intellectual environment Preferred Requirements: Experience with biological, medical, and chemical data Experience with emergent behavior in complex systems, time series analysis, causal inference, domain adaptation, transfer learning, multi-modal deep learning, geometric deep learning (learning on graphs and/or manifolds) Experience working with reference biological databases and datasets (e.g., TCGA, UK Biobank) is a strong plus Experience with CMAP, LINCS or other perturbagen (e.g., small molecule, CRISPT, etc.) induced transcriptomic databases Experience running genome wide association studies (GWAS) Familiarity with AWS, GCP, or similar cloud-computing services Ability to Google error messages and seek resolution from self-investigation Flagship Pioneering is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.   Company Description Publicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients’ businesses through creating the products and services their customers expect. Job Description As Senior Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.  Your role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.  As a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration. Qualifications  Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS / Azure / GCP) Experience delivering end to end Big Data solutions on premise and/or on Cloud Knowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases Expertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions Proficiency in Java and Scala programming languages (Python a plus) Expertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.) Experience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub/Sub etc.) Expertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc. Knowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding Knowledge of performance tuning, optimization and scaling solutions from a storage/processing standpoint Experience building DevOps pipelines for data solutions, including automated testing You’ll Also Likely Have Some Of The Following  Knowledge of containerization, orchestration and Kubernetes engine An understanding of how to setup Big data cluster security (Authorization/ Authentication, Security for data at rest, data in transit) A basic understanding of how to manage and setup Monitoring and alerting for Big data clusters Experience of orchestration tools – Oozie , Airflow , Ctr-M or similar Experience of MPP style query engines like Impala, Presto, Athena etc. Knowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models Exposure to data governance, catalog, lineage and associated tools would be an added advantage A certification in one or more cloud platforms or big data technologies Any active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV/POC, hackathon) Additional Information There is a superb package of benefits waiting for you at Publicis Sapient. We cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension. The learning opportunities here are endless. Most importantly, of course, there’s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine. Flexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services. Opis oferty pracy Na czym będzie polegać Twoja praca?  Będziesz odpowiadać za analitykę biznesową w eBilet w obszarze hurtowni danych, procesów przetwarzania danych, procesów raportowych, które  dostarczają danych wspierających tworzenie strategii i wyznaczanie kierunków działań Weźmiesz odpowiedzialność za kształtowanie strategii BI, wybór narzędzi analitycznych jak i tworzenie raportów niezbędnych dla organizacji Weźmiesz odpowiedzialność za pozyskiwanie informacji i przygotowywanie analiz oraz produktów analitycznych Będziesz współpracować z właścicielami różnych procesów przy opracowywaniu optymalnych rozwiązań dla danego obszaru Przygotujesz analizy po wdrożeniu nowych rozwiązań, zbudujesz wnioski i rekomendacje Będziesz analizować duże zbiory danych w poszukiwaniu prawidłowości i zależności, które wpływają na kluczowe dla firmy obszary Będziesz miał okazję pracować nad autorskimi rozwiązaniami z zakresu ML Ze swojej strony oferujemy: Stabilną pracę w firmie ze startupową kulturą organizacyjną, która jest częścią grupy Allegro Możliwość uczestnictwa w wybranych wydarzeniach kulturalnych, rozrywkowych i sportowych z oferty eBilet.pl Model pracy hybrydowej Bogaty pakiet świadczeń pozapłacowych w systemie kafeteryjnym – Ty decydujesz z czego korzystasz (do wyboru mamy m.in. pakiety medyczne, sportowe, lunchowe, ubezpieczenia, bony na zakupy) Zajęcia angielskiego opłacane przez nas i skoncentrowane na specyfice Twojej pracy Pracę w zespole, na którego wsparcie zawsze możesz liczyć -  na pokładzie mamy najlepszych specjalistów i ekspertów w swojej dziedzinie Turystykę zespołową, budżet szkoleniowy oraz wewnętrzna platforma MindUp (m.in. szkolenia z zakresu organizacji pracy, sposobu komunikacji, motywacji do pracy oraz różnych technologii i zagadnień merytorycznych) Jeśli chcesz wiedzieć więcej - sprawdź sam/a Ta oferta jest dla Ciebie, jeśli: Posiadasz doświadczenie w analizie dużych wolumenów danych i potrafisz łączyć dane z wielu różnych źródeł Masz doświadczenie z pracą w hurtowni danych Wiesz jak dobierać techniki statystyczne i metody wizualizacji danych adekwatne do problemu badawczego (must have = Tableau, nice to have = Data Studio) Bardzo dobrze znasz SQL (Oracle, GCP, Spark) oraz masz doświadczenie w pracy z rozproszonymi systemami baz danych (częścią procesu rekrutacji będzie test z SQL) Potrafisz jasno komunikować wyniki analiz i rekomendacje z nich płynące Potrafisz współpracować z wieloma interesariuszami, wypracowując przy tym efektywne sposoby komunikacji Potrafisz zidentyfikować problem i zaproponować skuteczne rozwiązanie Znasz język angielski na poziomie min. B2  Mile widziane: znajomość Pythona oraz narzędzi takich jak: GA4, GTM, AUTO ML. Wyślij nam swoje CV i sprawdź dlaczego #dobrzetubyć Chcesz nas lepiej poznać? Posłuchaj Allegro Podcast Company Description Publicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients’ businesses through creating the products and services their customers expect. Job Description As a  Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.  Your role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.  As a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration. Qualifications  Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS / Azure / GCP) Experience delivering end to end Big Data solutions on premise and/or on Cloud Knowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases Expertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions Proficiency in Java and Scala programming languages (Python a plus) Expertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.) Experience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub/Sub etc.) Expertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc. Knowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding Knowledge of performance tuning, optimization and scaling solutions from a storage/processing standpoint Experience building DevOps pipelines for data solutions, including automated testing You’ll Also Likely Have Some Of The Following Knowledge of containerization, orchestration and Kubernetes engine An understanding of how to setup Big data cluster security (Authorization/ Authentication, Security for data at rest, data in transit) A basic understanding of how to manage and setup Monitoring and alerting for Big data clusters Experience of orchestration tools – Oozie , Airflow , Ctr-M or similar Experience of MPP style query engines like Impala, Presto, Athena etc. Knowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models Exposure to data governance, catalog, lineage and associated tools would be an added advantage A certification in one or more cloud platforms or big data technologies Any active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV/POC, hackathon) Additional Information There is a superb package of benefits waiting for you at Publicis Sapient. We cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension. The learning opportunities here are endless. Most importantly, of course, there’s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine. Flexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services. Company Description Publicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients’ businesses through creating the products and services their customers expect. Job Description As a  Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.  Your role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.  As a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration. Qualifications  Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS / Azure / GCP) Experience delivering end to end Big Data solutions on premise and/or on Cloud Knowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases Expertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions Proficiency in Java and Scala programming languages (Python a plus) Expertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.) Experience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub/Sub etc.) Expertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc. Knowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding Knowledge of performance tuning, optimization and scaling solutions from a storage/processing standpoint Experience building DevOps pipelines for data solutions, including automated testing You’ll Also Likely Have Some Of The Following Knowledge of containerization, orchestration and Kubernetes engine An understanding of how to setup Big data cluster security (Authorization/ Authentication, Security for data at rest, data in transit) A basic understanding of how to manage and setup Monitoring and alerting for Big data clusters Experience of orchestration tools – Oozie , Airflow , Ctr-M or similar Experience of MPP style query engines like Impala, Presto, Athena etc. Knowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models Exposure to data governance, catalog, lineage and associated tools would be an added advantage A certification in one or more cloud platforms or big data technologies Any active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV/POC, hackathon) Additional Information There is a superb package of benefits waiting for you at Publicis Sapient. We cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension. The learning opportunities here are endless. Most importantly, of course, there’s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine. Flexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services. Hello!! We are thrilled to have you here!!! We are growing and we would love to have you in our company but it´s fair to say we´ll have great people in the right places as soon as we have an open spot! Our open positions on the website are a talent pool vacancies and we´ll reach out whenever we get an opening that fits better for you! So please, apply for the best opportunity you have for you and in the right moment, we´ll be in touch!!   About us We are part of ABInBev’s ecosystem, the biggest brewer in the world, and we work to help our costumer’s life using a range of BEES Applications. As a tech cell of our organization, we have a simple goal: to grow. Grow as people, as professionals, as a company. To achieve it, we use the technology creating digital solutions that make our costumers lives simpler, their decisions smarter and their business more profitable.   What you´ll do: Responsible for creating and producing forecasts, reports, ad hoc requests, dashboards, etc. in order to provide insights to determine operational impact, trends, and opportunities.  Design and create data visualizations (reports and dashboards) that tell a compelling narrative as required to support business needs.  Integrate data from multiple sources to produce requested or required data elements  Create and maintain report forms and formats, information dashboards, data generators, canned reports and other end-user information portals or resources  Ensure compliance with deliverable reporting requirements by performing quality data audits and analysis  Reviewing and improving existing dashboards and collaborating with teams to integrate new  systems.  What you´ll need: 5+ years of Tableau Desktop Experience, Tableau dashboards, visualizations, and performing advanced analytics  3- 5 years of experience writing complex SQL queries to build Tableau data sources.  Able to monitor scheduled Tableau extract jobs and proactively fix and rerun failed processes, notify team, automate notifications, etc  Ability to analyze and interpret data.  Ability to work independently, as well as in a collaborative and dynamic team environment  Excel knowledge is a plus.  Bachelor's degree in business or related field What We Offer: Performance based bonus* Fourteen annual salaries* Private pension plan Meal Allowance Casual office and dress code Days off* Health, dental, and life insurance Medicines discounts Gympass partnership Zenklub partnership Childcare subsidies Discounts on Ambev products* Newvalue partnership Scholarship* School materials assurance Language and training platforms Transport allowance *Rules applied Equal Opportunity & Affirmative Action: Bees is proud to be an Equal Opportunity and Affirmative Action employer. We do not discriminate based upon of race, color, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other applicable legally protected characteristics. The following fields are optional, but anticipate the information for your registration*. Remember: your data will never be used as elimination criteria in selection processes. With them, Bees is able to analyze diversity and reduce biases in selection processes. We want to contribute to changing this reality by being an inclusive company. For more information: www.bees.com     Company Description Pushing the Edge VANTIVA, headquartered in Paris, France and formerly known as Technicolor, is a global technology leader in designing, developing and supplying innovative products and solutions that connect consumers around the world to the content and services they love – whether at home, at work or in other smart spaces. VANTIVA has also earned a solid reputation for optimizing supply chain performance by leveraging its decades-long expertise in high-precision manufacturing, logistics, fulfillment and distribution. With operations throughout the Americas, Asia Pacific and EMEA, VANTIVA is recognized as a strategic partner by leading firms across various vertical industries, including network service providers, software companies and video game creators for over 25 years. Our relationships with the film and entertainment industry goes back over 100 years by providing end-to-end solutions for our clients. VANTIVA is committed to the highest standards of corporate social responsibility and sustainability across all aspects of their operations. For more information, please visit www.vantiva.com and follow us on LinkedIn and Twitter. Job Description Within Vantiva Broadband & Video, located in Rennes R&D site, and as part of the Operations Global Sourcing team, under the Systems, Processes and Strategy department, the candidate will be responsible for supply chain sustainability data, management, and reporting in support of Product and Component Part Regulatory Compliance.  Responsibilities: Maintain knowledge of European Environmental and Human Rights Regulations and Decrees that may impact the supply chain of our products ; Collaborate with Vantiva’s R&D Product Compliance team on other new customer requirements for products which impact the supply chain ; Use company tools and 3rd party compliance platforms to manage supplier part Declarations of Compliance (DoCs) and related data: review documents for accuracy, update our part and supplier database, ensure all parts are compliant, and create reports ; Resolve supplier issues such as incomplete, outdated or missing Declarations, inaccurate reporting of substances, use of banned or restricted substances, etc ; Manage EU Waste Framework Directive actions to ensure that Vantiva’s European Products are registered in the SCIP Database, in collaboration with Vantiva’s supply chain compliance management partner, ASSENT ; Collaborate with internal sourcing managers for supplier management and issue escalations ; Provide Ad hoc support of Product Teams, New Product Development groups, Customers, Legal, and others as required, for supply chain compliance data and reports ; Support the Supply Chain Sustainability’s Team KPIs and objectives, to ensure that Vantiva products and BOM parts meet all compliance requirements.  To do so, you will be asked to use your knowledge of : Regulatory agency requirements on banned and restricted substances such as EU Directives on RoHS, REACH, CRM (Critical Raw Materials) and POPs, and Flame Retardants found in plastics and PCBs ; Managing project activities independently and collaborating with a variety of internal and external teams (which include suppliers, manufacturing partners, and compliance partner (ASSENT) team members). Qualifications Candidate Profile: Degree in Electrical or Mechanical Engineering, Chemistry, Environmental Science, or similar ; Previous relevant experience (+5 years) with environmental / sustainability compliance regulations and reporting for electronic products, data management, and reporting ; Relevant previous experience in Project Management skills and ability to work independently ; Knowledge of tools such as PLM (Agile), Power BI, Sharepoint, Excel, and Microsoft TEAM is desired.  Familiarity with any third party Regulatory Compliance Data Management tool is a plus ; Good communications skills, ability to collaborate with global internal and external cross-functional teams, as well as global supplier network ; Fluent English (verbal and written) is required ; Knowledge of Corporate Social Responsibility (CSR) topics such as Conflict Minerals, Human Rights, Forced Labor Prevention and Due Diligence is a plus ; Travel may be required during this mission. Additional Information    Company Description Through Columbia University's Pre-College Programs, high schoolers from around the globe prepare for the college experience through exploratory coursework and community activities over seven weeks in the summer. This highly selective program is open to academically exceptional high school students, entering grades 9–12 and freshman year of college. Job Description Columbia University’s Pre-College Programs for High School Students is seeking qualified candidates to develop and teach online courses during Summer ’23.  Please Note: Course(s) and course availability is subject to change.   2 Week Courses: (Sessions 1& 2) Big Data, Machine Learning, and their Real World Applications 1 Week Courses: (Session 3) Big Data, Machine Learning, and their Real World Applications Course descriptions and schedule information can be found via the links above.  Online Course Dates: All classes meet Monday-Friday Session 1: July 3rd- July 14th (8 -11am or 12-3pm or 5-8pm) Session 2: July 17th- July 28th (8 -11am or 12-3pm or 5-8pm) Session 3: August 7th- August 11th (10 -12pm & 1-3pm) Responsibilities: Develop course content, syllabus, lesson plans, and assigned work Lead and attend all online class sessions Establish and maintain a dynamic in-class environment tailored for our high school population Evaluate student work and write a holistic evaluation of each participant after the course ends Monitor and address student concerns and inquiries (you will have around 20-24 students) Attend and complete all required online trainings Qualifications Graduate degree or equivalent professional or academic background Expertise in the pertinent subject matter Aptitude for teaching Additional Information Hiring Salary Ranges: Sessions 1 & 2 Online: $3,300 - $4,200 Session 3 Online:  $2,200 - $2,800 Additional Information: Please specify which courses you would be interested in teaching.  Course descriptions and schedule information are available via the links above Please submit a resume inclusive of teaching experience as well as formal teaching evaluations (if available) Applicants must have U.S. work authorization and will need to be in the U.S. while teaching Applicants may not hold a concurrent appointment with Columbia for the duration of their appointment Once hired, applicants are required to submit to a third party background check and complete Protection of Minors training in addition to other training(s) mandated by the University All Columbia University faculty and staff must follow the COVID-19 vaccination protocol. Learn more about the vaccination requirements here: https://covid19.columbia.edu/ All your information will be kept confidential according to EEO guidelines. Columbia University is an Equal Opportunity/Affirmative Action employer. Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description Visa Consulting and Analytics (VCA), the consulting arm of Visa, is a global team of industry experts in strategy, marketing, operations, risk and economics consulting, with decades of experience in the payments industry. Our VCA teams offers: Consulting services customized to the needs of Visa client's business objectives and strategy Business and economic insights and perspectives that impact business and investment decisions Self-service digital solutions Visa clients can leverage to improve performance in product, marketing and operations Proven data-driven marketing strategies to increase clients' ROI VCA team is looking for a passionate individual to join our consulting practice and play a role in the data engineering team. The ideal candidate is adept at using big data sets to understand our client's challenges and deploy targeted solutions to drive meaningful benefits, leveraging our world-class payment knowledge, in combination with our diverse service offerings to address key strategic needs for Visa's clients including issuers, acquirers and merchants. He/She must have experience using a variety of data mining/data analysis methods, using a variety of distributed data platforms, and leveraging the latest open-source technologies. He/She must have a proven ability to drive business results with their data-based insights. Adept at creative and critical thinking, be able to deconstruct problems and transform insights into large scale, state-of-the-art solutions. Responsibilities Automate and standardize data processes developed by team members. Leverage DevOps to create end-to-end streamline CI/CD data and ML pipelines. Review and manage data pipelines, branching, and deployment process. Work with partners on requirements and implementation designs of data solutions. Implement data quality framework at scale using open-source technologies. Create data monitoring dashboards with real-time notifications. Understand VisaNet data and platform ecosystem to deploy fully automatic data applications for internal and external clients. Unify data engineering and machine learning engineering pipelines. Apply spark optimization techniques to production jobs to accelerate data prep. Document process, designs, test results, and analysis. Ability to articulate complex architectures to non-technical audiences, management, and leadership. Continuously research industry best practices and technologies. Evangelize end to end automation and standardization across the organization. Partner with functional areas, and regional and global teams to leverage the breadth and depth of Visa’s resources. This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs. Qualifications Basic Qualifications • BA/BS required, MBA or other relevant Master’s degree preferred (e.g. engineering, computer science, computer engineering, applied mathematics, or other related fields) Preferred Qualifications • At least 5 years of experience as data engineer or data scientist with open-source tools. • Experience in retail banking, payments, financial services, and/or technology industries is a plus. Strong interest in the future of payments is a must. • Strong technical competency and experience with shell-scripting and Linux systems. • Experience with CI/CD pipeline using Azure DevOps, GitHub actions, Jenkins, or Airflow. • Strong coding skills in Spark, Python and SQL to manipulate big data in distributed platforms. • Good to have experience in navigating in Linux/Unix/Container based apps such as Docker, Kubernetes, or Microservices environments. • Knowledge in how to leverage AI assistance tools like chatGPT for creating and debugging code. • Ability to interact with big data clusters using Jupiter Notebooks, terminal, or GUI. • Demonstrate experience leveraging open-source tools, libraries, and platforms. • Experience with data visualization and business intelligence tools like Tableau, PowerBI, Microstrategy, or Excel. • Problem solving ability and process creator with strategic focus on replicability, scalability, innovation, and governance. • Proficient with git for version control and code collaboration using branches and pull requests. • Must be passionate about automation and data and able to deliver high quality work. • Experience developing as part of Agile/Scrum team. • Fluency in English (spoken/written). Portuguese or Spanish is a plus. • Experience in developing integrated cloud applications with services like AWS, Azure Cloud, and GCP is a plus. Additional Information Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. Unternehmensbeschreibung Wir bei rheindata beraten unsere Kunden in den Bereichen Big Data, Business Intelligence und Data Science. Wir sind ein buntes Team aus den unterschiedlichsten Fachbereichen wie z.B. Mathematik, VWL, Informatik oder Physik. Uns ist wichtig, dass wir uns weiterbilden können und offen sind, unser Wissen zu teilen. Bei uns gibt es wenig Bürokratie, stattdessen kurze und flache Entscheidungswege und großes Mitspracherecht. Wenn du also Lust hast, uns kennenzulernen… los geht´s! Stellenbeschreibung Als BI Berater ETL/ELT (m/w/d) arbeitest du in unterschiedlichen BI Projekten bei unseren Kunden und entwickelst kreative und innovative BI Lösungen, entwickelst du ETL/ELT Strecken und zudem orchestrierst und parallelisierst du Ladestrecken, erstellst du SQL-basierte Datenbank-Abfragen, arbeitest du mit strukturierten und unstrukturierten Daten und bist du offen für neue Technologien und gibst dein Wissen auch gerne weiter. Qualifikationen Das bringst du mit: Einige Jahre praktische Erfahrung im BI Bereich, ein abgeschlossenes Studium in einem MINT (Mathematik, Informatik, Wirtschaftsinformatik, -mathematik, Physik o.ä.)- oder wirtschaftswissenschaftlichen (BWL, VWL, o.ä.) Fach, Kommunikationsstärke, Deutschkenntnisse auf muttersprachlichem Niveau (C2), Englisch fließend in Wort und Schrift. Zudem verfügst du über Kenntnisse z.B. in: SSIS, Talend oder Informatica SQL Erfahrung in Cloud-Plattformen wie Azure, AWS oder GCP Zusätzliche Informationen Das bieten wir dir: 6 Wochen Urlaub im Jahr und in jedem fünften Jahr sogar 10 Wochen eine deinen Bedürfnissen entsprechende Einarbeitungsphase mit Begleitung deines Mentors, die Möglichkeit zu individuell gestaltbaren Sabbaticals, die Teilnahme an unserem Mitarbeiter-Beteiligungsprogramm, eine kostenlose M-Mitgliedschaft bei Urban Sports Club und vergünstigte Konditionen bei L- und XL-Tarifen neben einem attraktiven Vergütungspaket erhältst du natürlich ein Notebook und ein Smartphone sowie weitere Zusatzleistungen wie z.B. Jobticket, JobRad oder betriebliche Altersvorsorge je nach Projektgegebenheiten, die Möglichkeit im Homeoffice zu arbeiten – wobei du in unserem Büro im belgischen Viertel natürlich auch immer willkommen bist. Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value. Job Description As Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects: Data Ingestion, Transformation & Consumption, Data Storage and Computation Frameworks, Performance Optimizations, Infrastructure, Automation & Cloud Computing, Data Governance & Security The role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java / Scala / Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. Role & Responsibilities: 1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation. 2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality 3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality 4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies 5. Participate in workshops with clients and align client stakeholders to optimal solutions. 6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc. 7. People management, contributing to hiring and capability building Qualifications Overall 8+ years of IT experience with 3+ years in Data related technologies  3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS / Azure / GCP) and delivered at least 1 project as an architect. Mandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud.  Expert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions Expert in programming languages like Java/ Scala and good to have Python Expert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc. Expert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc. Should have worked on MPP style query engines like Impala , Presto, Athena, etc Should have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc. Should have a good understanding of how to set up Big data cluster security – Authorization/ Authentication, Security for data at rest, and data in Transit. Should have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager – Data Engineering Should have worked on any of Orchestration tools – Oozie, Airflow, Ctr-M, or similar. Worked on Performance Tuning, Optimization, and Data security   Competency 1. Excellent understanding of data technologies landscape/ecosystem. 2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases 3. Good Exposure in development with CI / CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage. 4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models 5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage. 6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions 7. Thought Leadership – blogs, keynote sessions, POV/POC, hackathon 8. Certification in either one of the cloud platforms or big data technologies Personal Attributes: Strong analytical and problem-solving skills Strong communication skills in verbal, written and visual presentations Strong coordination and negotiation skills Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Multi geo experience and distributed delivery experience in large programs Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements  Employee Assistance Programs to help you in wellness and well being Company Description Welcome to SMG Swiss Marketplace Group AG We are a pioneering network of online marketplaces and a leading European digital company that simplifies people's lives with forward-looking products. Job Description As the new Business Intelligence Developer, you will be part of the Group Data Team (GDT). You will work together with data engineers, data architects, data product owners and diverse business domain stakeholders to make group-wide data more accessible, well-governed and understood. As a contributor to the GDT, you will be responsible for delivering data products for our internal customers. To be effective in this position, you must be comfortable working with various business domains, a bottom-up management approach and be able to get up to speed with new technologies quickly.  Role Ratio: 60% Backend - data extraction, loading and transformation (ELT) 40% Frontend - data visualization (charts and dashboard building)  Your Responsibilities: Make use of the cloud infrastructure created by data engineers to extract, load and transform (ELT) data from different sources/domains into the Group Business Intelligence platform Develop reusable data assets (marts, reports, metrics, metadata) that reflect the business's needs and follow data protection guidelines Apply data warehousing best practices to the data assets and monitor them to guarantee data completeness, uniqueness, consistency, validity, accuracy and timeliness Follow naming standards guidelines and perform technical data documentation in order to have data assets metadata flowing into the group data catalogue and downstream tools Version code, deploy using continuous integration and continuous delivery tools, review code and test changes assuring data quality and business requirements satisfaction. Implement business-defined metrics and key performance indicators as a single source of truth Work closely with the BI Team Lead, Data Product Owner and Stakeholders to understand their needs/requirements in order to design data visualizations that bring value, business insights capabilities and help the teams measure the impact of their work Develop charts and dashboards using a cloud data visualization tool incorporating usability best practices and following SMG branding guidelines when designing it Collaborate with the remote teams making transparent your activities' progress and keeping Kanban board updated to keep track of tasks and documentation for future support on troubleshooting Participate and collaborate with the data engineering, data product enablement and business intelligence teams in different workshops to define objectives and key results (OKRs) that are achievable in order to promote innovation and learning Qualifications  You have a Bachelor’s or Master’s Degree in Information Technology, Data Analytics, Management Information Systems, Computer Science, Artificial Intelligence, Data Science or a related technical/data field You have at least 2 years of professional experience working with Structured Query Language (SQL ansi) You have at least 2 years of professional experience working with one data warehousing architecture (E.g. Star schema, Snowflake schema, One Big Table, Data Vault, Data Lake, etc) You have at least 1 year of professional experience working with business intelligence or/and analytics engineering or/and data engineering or/and data analysis You have experience with at least one modern cloud data warehousing tool. E.g. BigQuery (preferably), Azure, Redshift, Snowflake, etc.  You have experience with at least one data visualization tool. E.g. Looker (preferably), Tableau, Power BI, etc. You have experience with at least one code versioning tool. E.g. git (preferably), svn, etc. You have experience with at least one code repository platform. E.g. Github (preferably), Bitbucket, etc. You have strong interpersonal and collaboration skills, organization and attention to detail You have the ability to take initiative and engage in discussions related to requirements and data products Good verbal and written communication skills in English. German is a plus.   Nice to have experience with: Online marketplaces and/or digital businesses Google Cloud Platform data warehousing and business intelligence tools (BigQuery sql syntax, Looker as a LookML developer) Data Build Tool (dbt core) as a data transformation tool The git protocol and Github for code versioning and repository platforms Agile methodologies (E.g. Kanban, Scrum, Lean, etc) Continuous integration and continuous delivery (CI/CD) Atlan data catalogue tool Data mesh decentralized data architecture Python Notion Jira  Additional Information Benefits you'll love and why you should join us Your new team and the people you work with will consist of an international and diverse group of fantastic people. We live a hybrid working model without fixed office days. You are welcome to work in our modern and spacious office in Zurich, or from your home base in Switzerland.  In addition, SMG offers you: 6 weeks of holidays (with the possibility to buy up to 10 additional days) 40-hour week (flexitime) We take work-life balance seriously 4 months' notice after the probationary period SBB Half-Fare Card You travel 1st class by train between SMG sites in Switzerland 18 weeks maternity and 6 weeks paternity leave (also in case of adoption) Professional accident and supplementary insurance (100% covered by SMG) No fixed office days (teams organize themself regarding onsite presence) Independent counselling centre for personal and psychological problems Gender-neutral fair pay with clearly defined career profiles Choose your hardware (Mac or Windows + 2 monitors for home) Choose your mobile phone (iPhone, Samsung or Pixel) Free Gym Facilities (Flamatt office only)  Apply Now! We are looking forward to getting to know you!   SMG Swiss Marketplace Group Ltd. is a pioneering network of online marketplaces and an innovative European digital company that simplifies people’s lives with groundbreaking products.  SMG Swiss Marketplace Group Ltd. provides customers with the best tools to meet their life decision needs. The portfolio includes Real Estate (ImmoScout24, Homegate, Immostreet.ch, home.ch, Acheter-Louer.ch), Automotive (AutoScout24, MotoScout24, CAR FOR YOU), General Marketplaces (anibis.ch, tutti.ch, Ricardo) and Finance & Insurance (FinanceScout24). The company is owned by TX Group AG (31%), Ringier AG (29.5%), La Mobilière (29.5%), and General Atlantic (10%). Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value Job Description As Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions. You will independently drive design discussions to ensure the necessary health of the overall solution. The role requires a hands-on technologist who has strong programming background like Java / Scala / Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.  Role & Responsibilities: Your role is focused on the Design, Development and delivery of solutions involving: Data Integration, Processing & Governance Data Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations Infrastructure & Cloud Computing Data Management Platforms Implement scalable architectural models for data processing and storage Build functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode Build functionality for data analytics, search and aggregation Qualifications Overall 5+ years of IT experience with 3+ years in Data related technologies Minimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS / Azure / GCP) Hands-on experience with the Hadoop stack – HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline. Strong experience in at least of the programming language Java, Scala, Python. Java preferable Hands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc  Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security   Competency 1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience 2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc 3. Knowledge on distributed messaging frameworks like ActiveMQ / RabbiMQ / Solace, search & indexing and Micro services architectures 4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 – Data Engineering 5. CI/CD – Infra provisioning on cloud, auto build & deployment pipelines, code quality 6. Cloud data specialty and other related Big data technology certifications Personal Attributes: Strong written and verbal communication skills Articulaion skills Good team player Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Process orientation and the ability to define and set up processe Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements Employee Assistance Programs to help you in wellness and well being Company Description Publicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients’ businesses through creating the products and services their customers expect. Job Description As Senior Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.  Your role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.  As a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration. Qualifications  Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS / Azure / GCP) Experience delivering end to end Big Data solutions on premise and/or on Cloud Knowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases Expertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions Proficiency in Java and Scala programming languages (Python a plus) Expertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.) Experience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub/Sub etc.) Expertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc. Knowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding Knowledge of performance tuning, optimization and scaling solutions from a storage/processing standpoint Experience building DevOps pipelines for data solutions, including automated testing You’ll Also Likely Have Some Of The Following  Knowledge of containerization, orchestration and Kubernetes engine An understanding of how to setup Big data cluster security (Authorization/ Authentication, Security for data at rest, data in transit) A basic understanding of how to manage and setup Monitoring and alerting for Big data clusters Experience of orchestration tools – Oozie , Airflow , Ctr-M or similar Experience of MPP style query engines like Impala, Presto, Athena etc. Knowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models Exposure to data governance, catalog, lineage and associated tools would be an added advantage A certification in one or more cloud platforms or big data technologies Any active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV/POC, hackathon) Additional Information There is a superb package of benefits waiting for you at Publicis Sapient. We cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension. The learning opportunities here are endless. Most importantly, of course, there’s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine. Flexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services. Project Description We occupy a unique position in the market because we are vertically integrated. We have both a PBM platform (RxAgile) that provides enterprise solutions to B2B players in the healthcare space and a direct to consumer product (SingleCare) with a mission to make prescription medication more affordable. Responsibilities Primary Duties and Responsibilities: Design and develop BI dashboards and reports in Qlik Sense Develop and schedule Reports using NPrinting in Qlik Sense Work with Analysts and Stakeholders to develop requirements Create Data Models that optimize performance and extensibility Create Visualizations by translating requirements and finding innovative solutions Work with developers, BI engineers, business end users, UX designers and IT teams (DBA, Source system Developers, Data Analysts, QA Testers) for data accuracy and performance Work with a geographically diverse team. Escalate work progress and bottlenecks (if any) to the Lead Developer Minimum of 3 years overall Qlik experience Minimum of 4 years overall BI experience Requirements Proficient in building Qlik Sense load Scripts and Qlik Sense Apps Strong knowledge of Qlik techniques and complex functions (ex: set analysis, aggregation, date & string functions, formatting, mapping & conditional statements, etc.) Loading data in Qlik Sense using Web Connectors Strong SQL skills Data model optimization is a plus Strong experience and backend knowledge of Qlik Sense is preferred and is a plus Other Skills Must be a critical thinker who can successfully troubleshoot and solve data quality/performance issues Ability to understand business needs and translate into technology solutions Ability to manage key project milestones with limited direct supervision. Work in a fast-paced, self-managed environment and juggle priorities based on project needs Ability to work in an agile environment Planned, tracked, and managed agile development via Software (Ex. JIRA) Must have worked with BI tools in a development, and production support capacity Should be able to demonstrate a consistent progression of Qlik-related skill sets Experience working in Data Warehouse environments Rewards Payment in USD. Free credentials for e-learning platforms. Remote workshops & activities. Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value. Job Description As Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects: Data Ingestion, Transformation & Consumption, Data Storage and Computation Frameworks, Performance Optimizations, Infrastructure, Automation & Cloud Computing, Data Governance & Security The role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java / Scala / Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. Role & Responsibilities: 1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation. 2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality 3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality 4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies 5. Participate in workshops with clients and align client stakeholders to optimal solutions. 6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc. 7. People management, contributing to hiring and capability building Qualifications Overall 8+ years of IT experience with 3+ years in Data related technologies  3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS / Azure / GCP) and delivered at least 1 project as an architect. Mandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud.  Expert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions Expert in programming languages like Java/ Scala and good to have Python Expert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc. Expert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc. Should have worked on MPP style query engines like Impala , Presto, Athena, etc Should have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc. Should have a good understanding of how to set up Big data cluster security – Authorization/ Authentication, Security for data at rest, and data in Transit. Should have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager – Data Engineering Should have worked on any of Orchestration tools – Oozie, Airflow, Ctr-M, or similar. Worked on Performance Tuning, Optimization, and Data security   Competency 1. Excellent understanding of data technologies landscape/ecosystem. 2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases 3. Good Exposure in development with CI / CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage. 4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models 5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage. 6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions 7. Thought Leadership – blogs, keynote sessions, POV/POC, hackathon 8. Certification in either one of the cloud platforms or big data technologies Personal Attributes: Strong analytical and problem-solving skills Strong communication skills in verbal, written and visual presentations Strong coordination and negotiation skills Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Multi geo experience and distributed delivery experience in large programs Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements  Employee Assistance Programs to help you in wellness and well being Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value Job Description As Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions. You will independently drive design discussions to ensure the necessary health of the overall solution. The role requires a hands-on technologist who has strong programming background like Java / Scala / Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.  Role & Responsibilities: Your role is focused on the Design, Development and delivery of solutions involving: Data Integration, Processing & Governance Data Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations Infrastructure & Cloud Computing Data Management Platforms Implement scalable architectural models for data processing and storage Build functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode Build functionality for data analytics, search and aggregation Qualifications Overall 5+ years of IT experience with 3+ years in Data related technologies Minimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS / Azure / GCP) Hands-on experience with the Hadoop stack – HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline. Strong experience in at least of the programming language Java, Scala, Python. Java preferable Hands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc  Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security   Competency 1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience 2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc 3. Knowledge on distributed messaging frameworks like ActiveMQ / RabbiMQ / Solace, search & indexing and Micro services architectures 4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 – Data Engineering 5. CI/CD – Infra provisioning on cloud, auto build & deployment pipelines, code quality 6. Cloud data specialty and other related Big data technology certifications Personal Attributes: Strong written and verbal communication skills Articulaion skills Good team player Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Process orientation and the ability to define and set up processe Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements Employee Assistance Programs to help you in wellness and well being Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting, and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of the next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value. Job Description As Manager, of Data Engineering, you will be responsible for translating client requirements into design, architecting, and implementing Cloud & Non-Cloud based big data solutions for clients. Your role will be focused on delivering high-quality solutions by independently driving design discussions related to below aspects: Data Ingestion, Transformation & Consumption, Data Storage and Computation Frameworks, Performance Optimizations, Infrastructure, Automation & Cloud Computing, Data Governance & Security The role requires a hands-on technologist with expertise in Big Data solution architecture and with a strong programming background in Java / Scala / Python, should have experience in creating Data Ingestion pipelines for streaming and batch datasets, creating ETL/ELT data pipelines using distributed computing frameworks like Spark, Strom, Flink, etc, orchestrating data pipelines, should have experience in setting up secure big data platform. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms. Role & Responsibilities: 1. Provide technical leadership and hands-on implementation role in the areas of data engineering including data ingestion, data access, modeling, data processing, visualization, design, and implementation. 2. Lead a team to deliver high-quality big data technologies-based solutions either on-premise or on Cloud. Manage functional & non-functional scope and quality 3. Help establish standard data practices like governance and address other non-functional issues like data security, privacy, and quality 4. Manage and provide technical leadership to a data program implementation based on the requirement using agile technologies 5. Participate in workshops with clients and align client stakeholders to optimal solutions. 6. Consulting, Soft Skills, Thought Leadership, Mentorship, etc. 7. People management, contributing to hiring and capability building Qualifications Overall 8+ years of IT experience with 3+ years in Data related technologies  3+ years of experience in Big Data technologies and expertise of 1+years in data-related Cloud services (AWS / Azure / GCP) and delivered at least 1 project as an architect. Mandatory to have knowledge of Big Data Architecture Patterns and experience in the delivery of end-to-end Big data solutions either on-premise or on the cloud.  Expert in Hadoop eco-system with one or more distributions like Cloudera and cloud-specific distributions Expert in programming languages like Java/ Scala and good to have Python Expert in one or more big data ingestion tools (Sqoop, Flume, NiFI etc), distributed messaging and ingestion frameworks (Kafka,Pulsar, Pub/Sub, etc), and good-to-know traditional tools like Informatica, Talend, etc. Expert in at least one distributed data processing framework: Spark (Core, Streaming, SQL), Storm or Flink, etc. Should have worked on MPP style query engines like Impala , Presto, Athena, etc Should have worked on any of NoSQL solutions like Mongo DB, Cassandra, HBase, etc, or any of Cloud-based NoSQL offerings like DynamoDB, Big Table, etc. Should have a good understanding of how to set up Big data cluster security – Authorization/ Authentication, Security for data at rest, and data in Transit. Should have a basic understanding of how to manage and set up Monitoring and alerting for Big data clusters. Job Title: Manager – Data Engineering Should have worked on any of Orchestration tools – Oozie, Airflow, Ctr-M, or similar. Worked on Performance Tuning, Optimization, and Data security   Competency 1. Excellent understanding of data technologies landscape/ecosystem. 2. Well-versed with the pros and cons of various database technologies like Relational, NoSQL, MPP, and Columnar databases 3. Good Exposure in development with CI / CD pipelines. Knowledge of containerization, orchestration and Kubernetes engine would be an added advantage. 4. Well-versed in in multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models 5. Exposure to data governance, catalog, lineage, and associated tools would be an added advantage. 6. Well-versed with Software as a service, Platform as a service, and Infrastructure as a service concept and can drive clients to a decisions 7. Thought Leadership – blogs, keynote sessions, POV/POC, hackathon 8. Certification in either one of the cloud platforms or big data technologies Personal Attributes: Strong analytical and problem-solving skills Strong communication skills in verbal, written and visual presentations Strong coordination and negotiation skills Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Multi geo experience and distributed delivery experience in large programs Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements  Employee Assistance Programs to help you in wellness and well being Company Description Our culture is defined by our values and our deep commitment to help our clients succeed. We are a division of the 38th largest company in the world and bring to bear the strength of a very large network of interconnected Hitachi companies. At the same time we remain absolutely committed to the nimble agility that helped us grow Hitachi Solutions from three founding partners to nearly 2,000 consultants, developers and support personnel all around the globe. Hitachi Solutions is a leader in providing industry solutions based on Microsoft Dynamics AX and Microsoft Dynamics CRM. Hitachi Solutions provides its customers with industry focus, software industry domain expertise, and proven tier-1 people. Hitachi Solutions works with its customers to understand their unique formula for success and develops solutions that improve their business and attain measurable results.2011, 2009, 2006 & 2005 Microsoft Dynamics Partner of the Year (Finalist 2008, 2007). Microsoft Global Dynamics Award (Global Dynamics Partner of the year) 2014.  Hitachi Solutions is a core IT company of the Hitachi Group, which employs some 400,000 people worldwide. Through systems integration, we provide ideal solutions and products for customers. Headquartered in Tokyo, Japan, Hitachi Solutions' reach extends to group companies in Japan and abroad, working with a worldwide network of alliance partners. We bring solutions and products to diverse countries and regions including Asia, the United States and Europe. The flagship company in the Hitachi Group's information and communication system solutions business, Hitachi Solutions also offers solutions for social innovation such as smart cities.   For more information on Hitachi Solutions, please visit: https://web.hitachi-solutions.com Job Description Requirements: A minimum of 5+ years full-time experience using VertiPaq Able to quickly provide both M and DAX solutions Hands-on experience working in Business Intelligence, Data Engineering or Data Science Unwavering ability to quickly propose solutions by recalling the latest best practices learned from MVP & Product Team articles, MSFT documentation, whitepapers, and community publications A passion for understanding and integrating business semantics into technology solutions Excellent communication, presentation, influencing, and reasoning skills Ability to lead projects Familiarity with the Azure data platform, e.g., ADLS, SQL Server, ADF, Databricks etc.  We would like to see a blend of the following technical skills: Information Design DAX, M, PowerShell, and T-SQL VertiPaq and MashUp engine knowledge Power BI Desktop, Power BI Dataflows, Tabular Editor, DAX Studio, and VertiPaq Analyzer Power BI Service architecture design and administration Data modelling using the Kimball methodology Azure Data Factory , Azure Data Leak, Azure Services. At Jamf, people are at the core of everything we do. We do what’s right for our customers, our employees, our communities and our world. We take pride in simplifying technology for tens of thousands of customers around the globe and helping organizations succeed with Apple.   Jamf operates as a choice-based office model. Choose to work in the office, connect 100% remote from your home, or find the blend that works best for you.   What you’ll do at Jamf:  At Jamf, we empower people to be their best selves and do their best work.The Business Intelligence Data Analyst collaborates with members of the primary business functions to provide key insights, reports, and visibility to the goals of the organisation. They work with the leaders of the key business functions to understand data visibility needs and create effective ways to share that data on a regular basis. The Business Intelligence Data Analyst works in conjunction with members of the Business Intelligence team to create, adapt, and grow our access and availability of data based on the needs of the organization. This role is remote in the United Kingdom. We are only able to accept applications for those based in the UK or have sponsorship to live and work in the UK.  Responsibilities:  Collaborates with other Data Analysts and business leaders in multiple business functions to understand visibility/reporting needs. Collaborates with BI team members to create innovative ways to deliver data and insights to internal customers. Creates engaging, accurate, and effective reports and dashboards. Explains trends across data/reports, potential opportunities, and caveats when looking at descriptive, diagnostic, predictive and prescriptive data analysis. Helps build better understanding of that data leading to wider use and data intelligence across the organisation. Helps to drive growth of our data warehouse as well as documenting the lifecycle of data in our Data catalog. Monitors and provides solutions to issues submitted through the Business Operations ticketing system. Performs the role of a Data stewards to improve data health, quality, and governance. Understands and executes within the data quality metrics set by the Data stewards. Other duties and special projects as assigned.  Skills & Requirements: 4 Year / Bachelor’s Degree in Science, Engineering, Technology, Mathematics, or related field (Required). A combination of relevant experience and education may be considered. Minimum of 1 year of data reporting/analysis experience (Required). Minimum of 1 year of experience with business intelligence tools such as DOMO or Tableau (Required). Ability to write complex SQL including multi-table joins, grouping, aggregation, common table expressions and conditional filters (Required). Fluency in English. Experience working with a variety of data sources. Such as Salesforce, Marketo, Google suites, APIs, etc (Preferred). Able to communicate complex business logic, technical requirements, and design recommendations clearly and concisely. Experience cleaning and modelling raw or disorganised data. Effective management of tasks and clear communication of status of work. Comfortable working in an agile environment and taking an iterative approach to solutioning. Self-starter with a passion for solving problems. Highly Organised and detail-oriented. Ability to build strong relationships with team members across various departments. Ability to work in situations with changing priorities and parallel projects. Ability to prepare high-level summaries and reports. Ability to prioritise and execute on highest priority first.  How we help you reach your best potential: Named a Fortune Best Workplace in Technology, 2021. We know that big ideas can come from anyone, so we empower everyone to make an impact. Our more than 90% employee retention rate agrees! You will have the opportunity to make a real and meaningful impact for more than 60,000 global customers with the best Apple device management solution in the world. We put people over profits – which is why our customers keep coming back to us. Our volunteer time off allows employees to support and give back to our communities. We encourage you to simply be you. We constantly seek and value different perspectives to ensure Jamf is a place where everyone feels comfortable and can be successful. 23 of 25 world’s most valuable brands rely on Jamf to do their best work (as ranked by Forbes). Over 100,000 Jamf Nation users, the largest online IT community in the world. What is a Jamf? You go above and beyond for others, are willing to help, and support the team around you. You value and learn from different perspectives. You are curious and resourceful, a problem-solver, self-driven and constantly improving. You are excited by not knowing what may lie ahead. You are willing to take risks, try new things, even fail just to do it better next time. You’re not a jerk. You are someone who cares about doing the right thing.  What does Jamf do? Jamf extends the legendary Apple experience people enjoy in their personal lives to the workplace. We believe the experience of using a device at work or school should feel the same, and be as secure as, using a personal device. With Jamf, IT and security teams are able to confidently manage and protect Mac, iPad, iPhone and Apple TV devices, easing the burden of updating, deploying and securing the data used by their end-users. Jamf’s purpose is to simplify work by helping organizations manage and secure an Apple experience that end-users love and organizations trust.   We are free-thinkers, can-doers and problem crushers with a passion for helping customers empower their workforce to focus on their jobs, not the hassles of managing technology – freeing nurses to care, teachers to teach and businesses to thrive. We have over 2,500 employees worldwide who are encouraged to bring their whole selves to work each and every day.   Get social with us and follow the conversation at #OneJamf   #LI-REMOTE Senior Software Engineer, Big Data Location: Remote Romania - This role can be performed anywhere in Romania About Data Science Engineering (DSE)  DSE at GoPro is responsible for our in-house data platform infrastructure, data engineering, automated data analytics reporting, and ML Ops platform. We are responsible for enabling and empowering our partners in product engineering, software engineering, product analytics, marketing, and subscription business to make data-driven decisions by providing infrastructure, tools, services, and visualization to access data and business reports. We also prepare data and metrics to support data scientists and business operations. About the role:  The ideal candidate is an experienced software engineer focused on understanding business requirements and designing & developing data solutions in a big-data ecosystem. The candidate with a passion for analyzing the data, understanding its relationship and sharing insights with the combination of building & optimizing data systems and software engineering best practices. What you will likely do: Understand business requirements, assess the level of effort, and break down the development solution to the granular task level. Work with business and engineering/solution teams to understand the upstream data sources / raw datasets and develop data models to build quality datasets. Plan, design, develop, test, deploy, document and support data pipeline solution for ingesting, storing, processing, and querying data at scale. Create and maintain documentation and technical specification. Create metrics and graphs to visualize and validate datasets. Contribute to successful project completion by participating in the resolution of issues Skills We’re excited About: We are looking for a candidate with 5+ years of demonstrable ability in designing & developing highly scalable, and fit-for-purpose data solutions, who has attained a degree in Computer Science, Information Systems, or another quantitative field. Strong software development experience with proficiency in Scala or Java. You are passionate about the architecture of the Big Data Technology stack consisting of layers: Data Modeling, Data Lakehouse, Data Pipeline, and Data Analytics. Have experience in designing and building scalable/reliable data pipelines using the Big Data ecosystem (Hive/Spark/Databricks/Presto/Kafka/Airflow or equivalents). Experienced in creating, modifying, and querying database entities (tables, views) using optimized SQL for performance and knowledge in data warehouse data models. Experienced in the design/implementation of scalable and reliable services using AWS or other cloud services. Knowledge of Machine Learning Model Operationalization (MLOps) is a plus. You have the capability to synthesize business requirements and construct technical requirements. You are a strong problem solver with meticulous attention to detail and can tackle loosely defined problems. Skilled in written and verbal communication skills with an ability to communicate in a clear, collaborative, open-minded, and effective manner with both technical and non-technical peers. Why Work With Us? Create your own destiny. GoPro enables you and trusts you to get your own job done, because we believe that autonomy in role brings out the best in our employees. Live your best life. We’ve adopted remote and flexible work arrangements to support work at GoPro alongside our commitment to supporting employee wellbeing, belonging and connection with one another. Work with leading edge technologies. We encourage employees to cultivate and use the latest and greatest technology, to provide the best solutions to serve our customers. We celebrate creative solutions that bring innovation to GoPro technology. GoPro Highlights Get your very own GoPro camera + gear; Generous time off policy Comprehensive healthcare benefits Competitive salary and discretionary annual performance-related bonus Gym fee compensation Discounted employee stock purchase plan (ESPP) LiveHealthy monthly wellness reimbursement Innovative remote-friendly wellness classes and events Flexible work arrangements We strive for the day that no group can be described as underrepresented at GoPro – whether as part of our brand or in our workforce. We are committed to providing a more inclusive, representative, equal, just and happy world. GoPro is proud to be an Equal Opportunity Employer. #LI-Remote #flexible #LI-CS1 #Data #Scala #Java #Python #SQL #ETL #BigData Pattern is a leading eCommerce data and growth company located in the Silicon Slopes tech hub with global offices in Europe, China, Australia, the Middle East and Canada. Named one of the fastest growing companies in the US by Inc. 500, Pattern has made its mark in the industry. Some of the biggest consumer brands like Skullcandy, Nestle, Clorox, Kong, Panasonic, Tumi and Popsockets trust Pattern with their eCommerce management. Pattern has recruited top talent from brands like Amazon, eBay, Adobe, Pepsico, Apple, Google and Oracle. Think you have what it takes to work at Pattern? If you have a whole lot of hustle and a touch of nerd, Pattern is the place for you. We are looking for an experienced Business Intelligence developer to join our analytics team in Pattern’s Pune office. This role will create a data model, develop the data transformation in Fivetran, write efficient SQL and create a stunning visualization in Tableau to tell a story using data. Essential Duties and Responsibilities: Receive ad-hoc requests for information and promptly respond with accurate information Translate business needs to technical specifications Write efficient SQL queries to interrogate data Create stunning graphs/reports/dashboards using Tableau Proven abilities to take initiative and be innovative Coordinate with BI team in US with weekly planning Forecast, analyze data and trends and create reports that highlight areas in need of performance improvement Work with all levels of end users, including executive staff Dive into data issues when questions arise and offer solutions Conduct unit testing and troubleshooting. Qualifications: 10+ years developing reports/dashboards using common analytics tools A Bachelor's degree in Computer Science, Information Systems, or related analytic field. Strong SQL skills Expert level with Tableau Expertise in data analysis and report design/development Expertise in presentation/interface creation Understanding of E-commerce fundamentals including Supply Chain, Advertising, and Sales Strong problem solving, analytical and diagnostic skills Ability to interact well in a team environment Excellent documentation and communication skills Snowflake or Fivetran experience is preferred Strong attention to detail. Experience in data warehouse design Proven ability to write ETL transformations What We're About Data Fanatics: Our edge is always found in the data Partner Obsessed: We are obsessed with partner success Team of Doers: We have a bias for action Game Changers: We encourage innovation About us Here at GoCardless, we’re building the world’s bank payment network. Bringing simple and secure direct bank payment solutions for people and businesses everywhere, as well as making open banking more accessible. GoCardless is used by 75,000+ organisations and counting, processing more than $30 billion of payments across 30 countries.  We’re an award-winning London based fintech, with additional offices in Riga, Paris, Melbourne and New York. The Role We are looking for experienced Business Intelligence Engineers to help support our growing business and build out our data capabilities. You will be working with the BI Engineering team to define and build GoCardless’s core data models which provide the foundations for BI excellence and downstream data-hungry teams and tools. You’ll create the underpinning models that enable deep insight into a fast-growing business and do so with scale and resilience in mind from day one. You’ll help people in all areas of GoCardless make better, faster, more data-driven decisions and develop an expert knowledge of all areas of our operation.  You’ll sit in our Product Development division and will work with technical and non-technical people across the whole company. You’ll collaborate closely with our team of talented BI Analysts, designing and implementing the foundations they need to provide first class analysis to the business. The main elements of this role will involve: Developing coherent and performant data models that transform large, complex and disparate datasets into explorable, understandable and accurate data products Building end-to-end BI solutions from ETL through to data modelling and on to front end dashboards Collaborating with engineers to prototype, design and build pipelines which take raw data from production systems and deliver them in a format suitable for analytic workloads Supporting people across the company to enable them to self-serve Business Intelligence through BI tools - we’re using dbt and Looker at GoCardless.  Building BI tooling that fully leverages the capabilities of Google Cloud Platform and BigQuery Collaborating with BI Analysts and other data teams to create a data architecture that powers their deep-dive analysis to both test specific hypotheses and generate new business insights Collaborating with our team of Data Infrastructure Engineers to design and implement ingestion pipelines for new data sources, leveraging their tooling to expand the breadth of the GoCardless data warehouse What excites you  You can point to a solid track record as a developer of first class data tooling You’re a self-starter - you take initiative in spotting opportunities and finding ways to solve problems with data You’re used to sharing your technical work in a clear way to others around you You can turn complex business requirements into scalable, robust, explorable data products You’re good at quickly getting a grasp of any dataset that you’re working with You’ll be able to demonstrate how you have automated repetitive tasks and built robust ETL pipelines What excites us   You have excellent SQL skills and experience of scripting languages like Python Experience with Big Data technologies (e.g. BigQuery, Snowflake) and working with data at significant scale You have a firm grasp of self-serve data tools like Looker, Tableau or similar. We’re using Looker at GoCardless. You have experience working in an agile environment at pace You can communicate your work clearly to both technical and non-technical audiences You are as comfortable sourcing data from third party APIs as you are with discussing data modelling approaches Salary Range: €3,420 - €3,780 (some of) The good stuff Wellbeing - stay healthy with dedicated support and medical cover Work away scheme - gives you the option to work away from your country of residence for up to 90 days in any 12 month period. Adaptive Working - allows you to work flexibly, around your lifestyle Equity - all permanently employed GCs get equity to help you make a valuable contribution  Parental leave - to suit everyone embarking on life's great adventure Learning Budget - lead your own development with an annual learning budget  Time off - generous holiday allowance, + 3 annual volunteer days, + 4 annual business-wide wellness days (‘GC Fridays’) Life at GoCardless   We're an organisation defined by our values; We start with why before we begin any project, to ensure it’s aligned with our mission. We act with integrity, always. We care deeply about what we do and we know it's essential that we be humble whilst we do it. Working this way creates the GC magic- the reason we all love showing up to work.  Diversity & Inclusion We’re building the bank payment network of the future and our ambition is to move money anywhere, for anything, for anyone. If we’re going to achieve this goal, we need to build a team of ‘GeeCee’s’ that is as wonderfully diverse as the world we live in - with a multitude of perspectives, experiences & backgrounds. We’ve got a long way to go, but here’s how we’re doing as of June 2022; Female Employees - 46% Ethnic background - 32% Identify as LGBTQIA - 10% Neurodivergent - 9% We’re rooting for you during your application and GoCardless aims to provide reasonable adjustments to make our recruitment process as remarkable and accessible as we can. Please speak to your Talent Partner if you need extra support. If you want to learn more, you can read about our Employee Resource Groups and objectives here as well as our latest D&I Report  Sustainability  We’re committed to reducing our impact on the environment, leaving a more sustainable world for future generations. In 2021 we became co-founders of the Tech Zero coalition, a group of businesses committed to taking climate action as part of the UNFCCC Race to Zero. We aim to reduce our impact and to create positive change on the natural world. Check out our sustainability action plan here.  Find out more about Life at GoCardless via Twitter, Instagram and LinkedIn.  ABOUT THE ROLE The Business Intelligence Engineer will be the lead who can take ownership of projects and provide technical design expertise. They should have strong experience in building data models to support the BI projects. They should also have working experience on more than one BI platforms ( Looker, Sigma, Tableau, Power BI etc).  HOW YOU'LL SPEND YOUR TIME Create dashboards and reports using data visualization tools such as Looker, sigma Build data models to support the BI projects Provide analytics support to cross functional teams with data understanding and insights,  thus helping our clients grow Coordinate with data engineering and product team on product and data understanding and creating data models or Dashboards Use business intelligence data and tools to analyze product performance, conversion funnels and bring in actionable insights and recommendations for product improvement Maintain current knowledge of industry and business trends through communication with professional organizations, suppliers, customers, competitors, and other informed individuals Summarize product performance and financial data reports for review by executives, managers, clients, and stakeholders WHO YOU ARE Minimum 5-8 years of experience in the field of data and business analytics Excellent verbal and written communication skills Bachelor's degree in Engineering Proficient in SQL, Excel and scripting languages such as Python or R  Strong working experience with BI tools (Looker, Sigma ,Power BI, Tableau) Working experience in Looker is preferred Extremely organized with great attention to detail Excellent ability to analyze information and think systematically Strong business analysis skills Works well independently and as part of a team Thorough understanding of the company's business and product Ability to handle databases and understand technology-driven business intelligence tools WHAT CAN HELP YOU STAND OUT Experience in eCommerce and/or ad-optimization is preferred ABOUT TEIKAMETRICS  Teikametrics’ AI-powered Marketplace Optimization Platform helps sellers and brand owners maximize their potential on the world’s most valuable marketplaces. Founded in 2015, Teikametrics uses proprietary AI technology to maximize profitability in a simple SaaS interface. Teikametrics optimizes more than $8 billion in GMV across thousands of sellers around the world, with brands including Munchkin, mDesign, Clarks, Nutribullet, Conair, Nutrafol, and Solo Stove trusting Teikametrics to unlock the full potential of their selling and advertising on Amazon, Walmart, and other marketplaces. The job description is representative of typical duties and responsibilities for the position and is not all-inclusive. Other duties and responsibilities may be assigned in accordance with business needs. We are proud to be an equal opportunity employer. A background check will be conducted after a conditional offer of employment is extended. #LI-Remote Company Description Handling billions of transactions annually, Nexi Group is among the top payment processors in Europe. We keep a tight focus on making it even easier and more intuitive for our customers to handle digital payments and related services. This has made us a trusted partner to more than 700,000 merchant outlets, including 140,000 online merchant outlets, more than 260,000 enterprises and over 250 banks across Europe. Changing the future of payments takes strong personalities At Nexi, you’ll develop in a fast-growing tech company in a high-paced, high-impact market. Working to change the future of payments, it’s not just skills and ambition that gets the job done, it’s the full package that makes the difference. Together, we impact the lives of everyone around us by powering an easier tomorrow for every citizen, bank, business and colleague. What powers you at work? Job Description Data Engineering team is focused on improving the process of identifying valuable data,collecting, structuring, and utilizing data to create comprehensive analytics to support different aspects of business streams. Main Responsibilities: To Build DWH/BI and Data analytics solutions and ensure continue growth of Data products Implementation of data mappings and design of data flows as well as ETL processes in an agile environment for different kind of Business intelligence solutions Creation of  secure and reliable ETL pipelines ingesting data sources To Implement batch and transactional ingestion patterns Collaboration with customer business teams to understand business problems and to implement scalable and sustainable data solutions Design data models for consumption by data scientists and business analysts. Conduct complex data analysis and report on results. Further development of the data and analytics platforms and conduct complex data analysis and report on results Proactively share know-how, insights and experiences across the organization To be able to provide a delivery and present its business value in an understandable way to all levels of stakeholders Create data quality flows as a part of Data Governance  Qualifications University degree in electrical engineering and computer science, mathematics, economics or other related discipline Minimum 3 years of experience with Data Engineering It will be considered as advantage if you have experience with card business or Financial Industry Coding using different program languages Knowledge of building Data warehousing Knowledge of BI tools( e.g.Cognos), Data analytics knowledge Critical thinking skills Willing to promote data culture not only in technical teams but across the organization Communication skills Improvement of BI customers processes including  the Machine learning principles Willing to understand  company's business processes and the industry at large Ability to understand technology-based business intelligence tools focused on improving the process of identifying valuable data  Additional Information Please apply with your CV latest until 28th of February If you are curious… …and you want to know more, you're welcome to contact our Recruitment Business partner, Marija Babić, on marija.babic@nexigroup.com  Have you ever ordered a product on Amazon and when that box with the smile arrived you wondered how it got to you so fast? Have you wondered where it came from and how much it cost Amazon to deliver it to you? If so, Amazon Logistics (AMZL), Last Mile team is for you. We manage the delivery of tens of millions of products every week to Amazon’s customers, achieving on-time delivery in a cost-effective manner to deliver a smile for our customers.  Amazon Logistics is looking for a customer focused, analytically and technically skilled Business Intelligence Engineer to drive effective performance measurement and management, innovation and execution in last mile delivery. This position will be responsible for playing a key role in our Analytics team building out analysis and visualization tools and processes’ to support our growing Amazon Logistics business in Japan.  The successful candidate will be able to effectively retrieve, integrate, visualize and present critical data to improve the efficiency of the package delivery network. This individual will work with technical and business teams to optimize planning, execution, process improvement and track progress against goals. This role requires an individual with excellent analytical abilities as well as outstanding business acumen and comfort with technical teams and systems. The successful candidate will be a self-starter comfortable with ambiguity, with strong attention to detail, and enjoy working with large scale of data.  [More Information] Last Mile Department Data Analyst/BI Engineer Tokyo Office  *Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, visit https://www.amazon.jobs/disability/jp  Key job responsibilities Partner with internal stakeholders across multiple teams, gathering requirements and delivering complete solutions Partner with Data Engineering teams to prioritize and define AMZL JP data and BI development needs Work with in-house scientists, global supply chain, transportation and logistics teams to identify new BI capabilities and projects Conduct deep dive investigations into operations execution and business problems, identify opportunities, and lead or support implementation Analyze and visualize large geospatial datasets to uncover trends or issues relevant to last mile logistics, and output solid analysis report with recommendation Develop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting  About the team Last Mile Execution Analytics (LMEA) team of JP works as an integral part of Amazon Logistics to ensure that its business intelligence, analytics, tools and planning needs are met. By providing information, insight, and decision support, we strive to enable success of all parts of AMZL. Our customer set includes senior management, station operations, external vendors, long-term planning, Ops technology (Voice of the Delivery Station, Voice of the Customer), network planning, and pretty much every BI and Ops teams.  Voice of Employee  [Work Life Harmony] We believe, it is important to spend private time such as spending time with your family or doing anything you like to spur innovation. Amazon promotes a fulfilling and flexible work style according to the work volume and lifestyle of each employee. Basic Qualifications  Bachelor's degree in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field 2+ yrs of experience in analytical skills to integrate data Advanced level of SQL and ETL, ability to write and tune complex SQL scripts and ETL development Experience using Python 2+ yrs of experience in visualization tools such as GIS visualization, Tableau, QlikView, Quick Sight Business Level of English  Preferred Qualifications MBA/MS in Engineering, Statistics, Computer Science, Operations Research, Business Analytics, Information Systems or related field Business Level of Japanese 3+ years of relevant work experience building end - to end solutions to performance measurement and process improvement in a transportation, logistics or supply chain setting 3+ yrs of experience in Operational Excellence initiatives, working with data warehousing and data quality (MySQL and Redshift) 3+ yrs of experience implementing basic software solutions to automate data source, visualization and/or data modeling application Project Management experience and/or Tech product management experience Organized, operational mindset with track record of delivering projects within scope, time, budget and quality Ability and interest in working in a fast-paced and rapidly-changing environment Ability to understand operations at a detailed, practical level and also to think big / strategically Experience with analyzing geospatial/location data in SQL and/or via a programming language Excited about working in a diverse group and contributing to an inclusive culture.   Please check the website below for measures to eliminate unwanted second-hand smoking in each facility: https://www.amazon.jobs/en/landing_pages/passivesmoking 就業の場所における受動喫煙を防止するための措置に関する事項については、下記リンク先をご覧ください。 https://www.amazon.jobs/jp/landing_pages/passivesmoking  The salary information can be provided individually prior to the 1st interview 賃金に関する条件は、１次面接の前に個別にご案内することができます Job Description Responsibilities: Designing, developing, troubleshooting, evaluating, deploying, and documenting data management and business intelligence systems, enabling stakeholders/PO’s to manage the business and make effective decisions. Work with business customers and product managers in understanding the business requirements and implementing Solutions to support analytical and reporting needs with highly scalable code repos. Design and implement an analytical environment using third-party and in-house reporting tools, modelling metadata, building reports & dashboards and providing our stakeholders timely, flexible and structured access to their data. Ensuring completeness and compatibility of the technical infrastructure to support system performance, availability and architecture requirements. Reviewing and participating in testing of the data design, tool design, data extracts/transforms, networks and consulting data driven solutions. Implement training and documentation solutions that enable business stakeholders to get the most out of our self-serve reporting tools. Qualifications Requirements: Bachelor's Degree in Computer Science or a related technical field, and solid years of relevant experience. A strong grasp of SQL/Presto and at least one scripting (Python, preferable) or programming language. Experience with an enterprise class BI tools and it's auditing along with automations using REST API's. Experience with reporting tools – QuickSight (preferred, at least 2 years hands on). Tableau/Looker (both or anyone would suffice with at least 5+ years of hands on). 5+ years of experience with and detailed knowledge of data warehouse technical architectures, data modelling, infrastructure components, ETL/ ELT and reporting/analytic tools and environments, data structures and hands-on SQL coding. 5+ years of demonstrated quantitative and qualitative business intelligence. Experience with significant product analysis based business impact. 4+ years of large IT project delivery for BI oriented projects using agile framework. 2+ years of working with very large data warehousing environment. Experience in designing and delivering cross functional custom reporting solutions. Excellent oral and written communication skills including the ability to communicate effectively with both technical and non-technical stakeholders. Proven ability to meet tight deadlines, multi-task, and prioritize workload. A work ethic based on a strong desire to exceed expectations. Strong analytical and challenge process skills. Additional Information Why work with us? SIXT is the company with legacy of more than a century offering healthy work environment, friendly work culture and continuous learning. The leadership here believes in team empowerment and challenging opportunities are offered to solve real world problems. Sixtians take care of Sixtians through various programs related to Learning, Fitness, Fun activities, Inclusion etc. which are driven by Passion. About the department: Engineers take note: cutting edge technology is waiting for you! We don't buy, we primarily do it all ourselves: all core systems, whether in the area of car sharing, car rental, ride hailing and much more, are developed and operated by SIXT itself. Our technical scope ranges from cloud and on-site operations through agile software development. We rely on state-of-the-art frameworks and architectures and strive for a long-term technical approach. Exciting? Then apply now! About us: We are a leading global mobility service provider with sales of €1.53 billion and around 7,000 employees worldwide. Our mobility platform ONE combines our products SIXT rent (car rental), SIXT share (car sharing), SIXT ride (cab, driver and chauffeur services), SIXT+ (car subscription) and gives our customers access to our fleet of 205,400 vehicles, the services of 1,500 cooperation partners and around 1.5 million drivers worldwide. Together with our franchise partners, we are present in more than 110 countries at 2,070 rental stations. At SIXT, a first-class customer experience and outstanding customer service are our top priorities. We focus on true entrepreneurship and long-term stability and align our corporate strategy with foresight. Want to take off with us and revolutionize the world of mobility? Apply now! Job Description This is a new role for a BI Developer to develop Business Intelligence Solutions for internal customers. Solutions developed are used to aid process and drive business decisions in all departments.  Interacting with key stakeholders at all levels of business the role has a strong customer focus. The successful candidate is expected to work collaboratively with their internal customers to provide solutions that are accurate, have integrity and are of value to the business.  What does the job involve? The key responsibilities of the role are as follows: Identifying and refining data and reporting requirements from key stakeholders. Develop reporting. Visualising and reporting data findings creatively in a variety of formats. Thinking strategically about uses of data and how data use interacts with data design. Performing data studies and data discovery around new data sources or new uses for existing data sources. Data extraction from multiple sources for reporting purposes. Core Competencies and skills:  Microsoft BI Stack - SSRS, SSIS SQL Server 2014-2019 Visual Studio Data Warehouse knowledge Comfortable commenting code and documenting solutions Comfortable with source controlling developments (Git/Bucket) Able to adhere to coding and development standards Good knowledge of IT products and systems Good analytical and problem-solving skills Good communication skills and comfortable working with both technical and non-technical teams Able to prioritise work effectively and multitask MS Office including Word, Excel, Outlook, and PowerPoint Customer focused Flexible approach to work - team player Adaptable to changing environment. Embraces continuous self-learning Desirable competencies and skills: Knowledge and experience of creating Data Marts Power BI – DAX, Power Query Python Power Shell Performance Tuning JIRA / Confluence. Analysis of large data sets AJ Bell is one of the fastest-growing investment platform businesses in the UK offering an award-winning range of solutions that caters for everyone, from professional financial advisers, to DIY investors with little to no experience. We have over 449,000 customers using our award-winning platform propositions to manage assets totalling more than £71.5 billion. Our customers trust us with their investments, and by continuously striving to make investing easier, we aim to help even more people take control of their financial futures. Having listed on the Main Market of the London Stock Exchange in December 2018, AJ Bell is now a FTSE 250 company. Headquartered in Manchester with offices in central London and Bristol, we now have over 1100 employees and have been named one of the Sunday Times ‘100 Best Companies to Work For’ for five consecutive years. There are opportunities for growth and professional development for employees wanting to progress within their career including induction training and our study support scheme which is part of our benefits package. There is an active programme of social events throughout the year, which are open to all employees. In return we will provide all the training and support you need in order to develop within your role. What we offer: Competitive starting salary Generous holiday allowance of 25 days, increasing up to 30 days with service, plus bank holidays Holiday buy/sell scheme Hybrid working policy Casual dress code Discretionary bi-annual bonus Contributory pension scheme Buy as you earn share scheme Free shares scheme Paid study support for qualifications Enhanced maternity/paternity scheme from day one Bike loan Season ticket loan portal Discounted PMI and Dental On-site gym and personal trainer led classes Paid volunteering opportunities Free social events and more AJ Bell is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and all employees are empowered to bring their whole self to work. We do not discriminate on the basis of race, sex, gender identity, sexual orientation, age, pregnancy, religion, physical and mental disability, marital status and any other characteristics protected by the Equality Act 2010. All decisions to hire are based on qualifications, merit and business need. Company Description Amwell is a leading telehealth platform in the United States and globally, connecting and enabling providers, insurers, patients, and innovators to deliver greater access to more affordable, higher quality care. Amwell believes that digital care delivery will transform healthcare. We offer a single, comprehensive platform to support all telehealth needs from urgent to acute and post-acute care, as well as chronic care management and healthy living. With over a decade of experience, Amwell powers telehealth solutions for over 150 health systems comprised of 2,000 hospitals and 55 health plan partners with over 36,000 employers, covering over 80 million lives. Brief Overview Working closely with cross-functional business partners, the Sr. Business Intelligence Developer will proactively identify, define and lead development of BI reporting solutions. The role will work closely with Data Analysts and Data Scientists to ensure the solutions built surface insight and analytics up to the user base in the best way possible. The ideal candidate is a self-starter with insatiable curiosity.  S/he must be able to proactively identify and lead opportunities to improve processes and deliverables while demonstrating quality and accuracy of data assets and analytic deliverables through close attention to detail and strong follow-through. The role is expected to thrive in a cross functional environment, working closely with other BI Developers, Data Scientists, Data Engineers and Data Analysts. Core Responsibilities Build intuitive and modern analytic dashboards, while adhering to data visualization best practices Interpret data, analyze results and provide ongoing analysis to key stakeholders as needed Identify and lead development of scalable and automated analytic processes and workflows Ensure quality and accuracy of data assets and analytic deliverables Identify and lead initiatives to improve processes for, and quality of, data assets and analytic deliverables Analyze data for anomalies and early indication of bugs in reporting Stay abreast of analytic technologies Document programming scripts, processes, and deliverables Develop internal network of colleagues, based on a reputation for collaboration, execution, and high-quality work Identify and lead development of ETL data flows Qualifications Bachelors or higher in an Informatics or Quantitative field (e.g. Mathematics, Statistics, Economics, Engineering, Computer Science, Information Management, Data Analytics) 5+ years of experience in business intelligence, data analysis and data engineering 5+ years of SQL, including complex queries of multiple data sources 5+ years of developing scalable and automated ETL processes 3+ years of experience in the SaaS industry (preferably in a data analyst type role) is a plus Expert level experience with Business Intelligence tools (Power BI, Looker, Tableau, etc.) Expert level data visualization skills Basic to intermediate proficiency with general purpose programming languages (e.g. JavaScript, VB, PHP, C++) Knowledge of R or Python is a plus Capable of working on multiple projects and context shift quickly in a fast-paced environment Ability to translate incomplete or immature objectives into well-defined requirements Excellent verbal and written communication Familiarity with the health care industry is a plus Additional information Working at Amwell Amwell is changing how care is delivered through online and mobile technology. We strive to make the hard work of healthcare look easy. In order to make this a reality, we look for people with a fast-paced, mission-driven mentality. We’re a culture that prides itself on quality, efficiency, smarts, initiative, creative thinking, and a strong work ethic.  Our Core Values include One Team, Customer First, and Deliver Awesome. Customer First and Deliver Awesome are all about our product and services and how we strive to serve. As part of One Team, we operate the Amwell Cares program, which brings needed assistance to our communities, whether that be free healthcare for the underserved or for people affected by natural disasters, support for equality, honoring doctors and nurses, or annual Amwell-matched donations to food banks. Amwell aims to be a force for good for our employees, our clients, and our communities. Amwell cares deeply about and supports Diversity, Equity and Inclusion. These initiatives are highlighted and reflected within our Three DE&I Pillars - our Workplace, our Workforce and our Community. Amwell is a "virtual first" workplace, which means you can work from anywhere, coming together physically for ideation, collaboration and client meetings. We enable our employees with the tools, resources and opportunities to do their jobs effectively wherever they are!  Amwell has collaboration spaces in Boston, Tysons Corner, Portland, Woodland Hills, and Seattle. Unlimited Personal Time Off (Vacation time) 401K match Competitive healthcare, dental and vision insurance plans Paid Parental Leave (Maternity and Paternity leave) Employee Stock Purchase Program Free access to Amwell’s Telehealth Services, SilverCloud and The Clinic by Cleveland Clinic’s second opinion program Free Subscription to the Calm App Tuition Assistance Program Pet Insurance Company Description Dynatrace exists to make the world’s software work perfectly. Our unified software intelligence platform combines broad and deep observability and continuous runtime application security with the most advanced AIOps to provide answers and intelligent automation from data at an enormous scale. This enables innovators to modernize and automate cloud operations, deliver software faster and more securely, and ensure flawless digital experiences. That is why the world’s largest organizations trust Dynatrace® to accelerate digital transformation.   We're an equal opportunity employer and embrace all applicants. Dynatrace wants YOU—your diverse background, talents, values, ideas, and expertise. These qualities are what make our global team stronger and more seasoned. We're fueled by the diversity of our talented employees.   Job Description Developing the Dynatrace Software Intelligence Solution in Java (Apache Spark, Apache Kafka, Lucene, Kubernetes, Git, Jenkins, Eclipse/IntelliJ) Backend specialization (big data, cluster technologies, horizontal scale, storage, analytics)  Independent design and implementation of the Dynatrace Platform Collaborate with local and international development teams Qualifications Technical study related to Software Engineering A minimum of 5 years experience in Java development, including architectural design Excited to learn new technologies Teamplayer with proactive approach Additional Information A one-product software company creating real value for the largest enterprises and millions of end customers globally, striving for a world where software works perfectly.  Working with the latest technologies and at the forefront of innovation in tech on scale; but also, in other areas like marketing, design, or research.  Working models that offer you the flexibility you need, ranging from full remote options to hybrid ones combining home and in-office work.  A team that thinks outside the box, welcomes unconventional ideas, and pushes boundaries.   An environment that fosters innovation, enables creative collaboration, and allows you to grow.  A globally unique and tailor-made career development program recognizing your potential, promoting your strengths, and supporting you in achieving your career goals.   A truly international mindset with Dynatracers from different countries & cultures all over the world, and English as the corporate language that connects us all   A culture that is being shaped by the diverse personalities, expertise, and backgrounds of our global team.     A relocation team that is eager to help you start your journey to a new country, always there to support and by your side.  If you need to relocate for a position you are applying for, we offer you a relocation allowance and support with your visa, work permit, accommodation, language courses, as well as a dedicated buddy program.   Compensation and rewards Attractive compensation packages and stock purchase options with numerous benefits and advantages.  Due to legal reasons we are obliged to disclose the minimum salary for this position, which is € 56,000 gross per year based on full-time employment (38.5 h/week). We offer a higher salary in line with qualifications and experience. Company Description It all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app, bringing a better way to send, spend, invest, borrow and save to our millions of monthly active users. With a mission to redefine the world's relationship with money by making it more relatable, available and accessible, at Cash App you'll have the opportunity to make a real-world impact with your career. Today, Cash App has thousands of employees around the world with a culture geared toward creativity, collaboration and impact. We’ve been a distributed team since day one, and continue to value working across time zones and continents both remotely and in our Cash App offices. Our offices are great, but many of our roles can be done remotely from the countries where Block operates. We tailor our experience to champion our employees’ creativity and productivity wherever they are.  Job Description The BI Team at Cash App enables our teams to make impactful business decisions. Our BI Engineers handle everything from data architecture and modeling to data pipeline tooling and dashboarding. As a Senior BI Engineer at Cash App, you will report to the BI Manager and work with Analysts, Data Scientists, Software Engineers and Product Managers to lay the foundation for analyzing our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, to informing product development. You will build, curate, document, and manage key datasets and ETLs to increase the impact of the entire team.  You will: Create brand new and optimize existing data models for the most widely used Cash App events, entities, and processes Standardize business and product metric definitions in curated and optimized datasets Build pipelines out of our data warehouse Teach (and encourage) others to self-serve while building tools that make it simpler and faster for them to do so Promote data, analytics, and data model design best practices Create dashboards that help our teams understand the performance of the business and help them make decisions Qualifications You have: Background/knowledge in Computer Science, Applied Math, Engineering, Stats, Physics, or a something comparable 5+ years of industry experience building complex, scalable ETLs for a variety of different business and product use cases An interest in advancing Cash App's vision of building products for economic empowerment - this should be something that legitimately excites you Technologies we use and teach: SQL (MySQL, Snowflake, BigQuery, etc.) Airflow, Looker and Tableau Python and Java Additional Information Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.  Zone A: USD $152,100 - USD $185,900 Zone B: USD $144,500 - USD $176,700 Zone C: USD $136,900 - USD $167,300 Zone D: USD $129,300 - USD $158,100 To find a location’s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information.  Benefits include the following: Healthcare coverage Retirement Plans including company match  Employee Stock Purchase Program Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance  Paid parental and caregiving leave Paid time off Learning and Development resources Paid Life insurance, AD&D. and disability benefits  Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources  This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans. We’re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class. We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible.  Learn more about our efforts to promote inclusion and diversity at block.xyz/inclusion Additionally, we consider qualified applicants with criminal histories for employment on our team, assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution. Description de l'entreprise ALTER SOLUTIONS est une société de conseil et d’expertise en technologies créée en 2006. Notre vocation est d’accompagner nos clients sur leurs enjeux de transformation numérique. Notre offre s’articule autour des expertises suivantes : Software Delivery Infrastructure & Cloud Computing Agile IT Performance Business Performance Nous sommes un groupe international implanté dans plus d’une dizaine de pays et comptant 750 collaborateurs. Notre succès passant par le développement et l’épanouissement de chaque collaborateur, nous attachons beaucoup d’importance à offrir les meilleures conditions de travail possibles : Télétravail disponible sur une grande partie de nos missions Un environnement de travail en Flex Office disponible pour tous et tout le temps pour favoriser la communication et la collaboration Des communautés d’experts pour partager et diffuser les compétences au sein du groupe Un encadrement projet et un suivi RH de proximité Des formations et certifications proposées annuellement Une valorisation des parcours d’expertise de nos consultants Une ouverture forte sur la mobilité internationale ponctuelle ou de longue durée Des possibilités d’intrapreneuriat Description du poste Vous intégrerez, au sein de notre Pôle Transformation Numérique, une équipe d’experts en développement de solutions logicielles. Vous serez détaché(e) chez un acteur majeur du secteur Bancaire, pour intervenir sur de la migration de projets existants mais également sur la création de nouvelles applications. Vos missions seront les suivantes : Réaliser conjointement avec les autres membres de l'équipe l'architecture logicielle et technique Réaliser la conception des applications Etre le lead de l'équipe d'un point de vue technique Participer aux activités de développement Etre force de proposition sur les technologies adoptées Qualifications Quel profil pour ce poste : Vous êtes issu(e) d’une formation Bac+5 (École d’ingénieur, Université ou équivalent …) en informatique Vous justifiez d’une expérience significative (supérieure à 3 ans) au sein d’une équipe de développement dans un environnement Big Data à l’échelle du SI d’un grand groupe Vous êtes un bon communiquant et disposez de capacités d’analyse et de synthèse éprouvées Vous accordez de l’importance (et du temps) à la veille  Quelles compétences/connaissances pour ce poste : Compétences en Spark, Hadoop, Nexus, Ansible, Hive et en développement Java Anglais courant impératif Si vous souhaitez relever de nouveaux défis et même si vous ne disposez pas de toutes ces compétences, n’hésitez pas à postuler. Nous nous engageons à être très réactif dans la gestion des candidatures. Informations supplémentaires Au-delà de vos expertises et compétences, nous recrutons aussi des personnalités, qui vont participer au développement d’ALTER SOLUTIONS. Chez ALTER SOLUTIONS, vous pourrez être sollicités pour : Intervenir sur des phases de recrutement Participer à des projets de R&D et veille Rédiger des articles techniques et de publications diverses Participer à des phases d’avant-vente Animer des formations en interne Participer à nos évènements mensuels d’Alter Campus, rendez-vous techniques de partages et d’échanges Représenter ALTER SOLUTIONS dans le cadre d’évènements (Devoxx, Hackathon, Cloud Expo Europe…) Notre processus de recrutement se décompose ainsi : Un premier entretien à distance Test technique Rencontre avec un Directeur Opérationnel et un Consultant Sénior Si tout se passe bien, contractualisation RH Informations complémentaires  Contrat : CDI Temps de travail : Temps plein Rémunération : à partir de 58 k€ Avantages Primes vacances Remboursement 50% Pass Navigo / Prime « vélo » Tickets restaurant (Carte Sodexo) Politique de cooptation Compte Epargne Temps Comité d’Entreprise Mutuelle de qualité  Formation annuelle Début : ASAP Localisation : Nanterre Télétravail : envisageable en fonction des contraintes des projets If you applied for this position the Controller of your personal will be  ALTER SOLUTIONS France, with its registered office at 6 avenue du Général de Gaulle 78000 Versailles. The personal data provided by you will be processed for the purpose of the recruitment process and for future recruitment processes. You have the right to access the content of your data, request their rectification, erasure, restriction of processing, the right to data portability, the right to object to the processing of your data and the right to lodge a complaint to the DPO (privacy@alter-solutions.com). Company Description We organise over 500 large-scale branded and transaction-oriented events in 14 specialist markets. These are typically not-to-be-missed annual events where buyers and sellers build relationships, see and show products and do business. We also provide year-round online platforms where companies showcase their businesses and products and buyers conduct research, generating valuable leads, and we provide data and digital content that supports the flow of knowledge and transactions in markets. Job Description 6-month fixed term contract with a likely extension based on project work. The role is almost 100% working remotely. Informa Markets are looking to bring on a technically minded individual, who is interested in combining the analytical intelligence from data and developing technical solutions to problems in data systems. The key applications are PowerBI and SQL Server Analysis Services. With a background in project work, they will be able to demonstrate the ability to meeting tight deadlines with system familiarity. They will be comfortable in both running their own projects and working alongside other developers on larger projects. What you’ll be doing: The PowerBI Developer is responsible for developing and supporting the Reporting Hub. This is new project currently in the development stage. The team is currently using IBM Planning Analytics for financial, FTE and KPI planning and reporting and would like to use PowerBI as the reporting front end for internal customers. This role is going to be the team expert on PowerBI and will help upskilling other members of the team.  What we’re looking for: Tasks are likely to include: Using best practice, develop the Product Tracker PowerBI reporting used by hundreds of people Help develop the Finance standard reporting suite in PowerBI, which will service finance and business users across multiple Portfolios and Divisions. Develop a series of prioritised dashboards based on prioritisation  Optimise the data flow from the source systems to PowerBI Challenges current processes and ways of working, striving for an optimal level of output which delivers on requirements in a timely fashion Qualifications Strong experience in a PowerBI development role BS Degree or equivalent professional qualifications Has a good knowledge of a wide area of information systems concepts and practice, both within and beyond own organization. Including all stages of systems development. Familiarity with TM1 would be beneficial but not essential. Can demonstrate a rational and organized approach to the tasks undertaken and an awareness of the need to achieve quality Additional Information Contingent worker Company Description Our mission as a company providing IT services is to provide our clients all over the world with the best solutions. We manage to do this by analyzing the needs of our clients and matching them to the skills and aspirations of our employees. Therefore, one of our main motivations is to provide each Employee and Consultant with a satisfying experience. Joining us means being part of a community with diverse personalities. Start your adventure with ALTER SOLUTIONS! Job Description Development of ETL/ELT flows on the on-premise - as well as the cloud platform Design data models Provide daily support and maintain solutions for our customers Participate in knowledge sharing cross team and domain Qualifications Must have Data warehouse technologies SQL ELT/ETL tools Databases Nice to have Wherescape Data Vault 2.0 Microsoft Azure tech stack Additional Information Hybrid model (3 days in Warsaw office) Type of contract: B2B or employment contract Access to local and international projects - Clients from France, Germany, Portugal, UK and Benelux Professional development support -trainings, technical certificates, conference participation, foreign language classes and soft skills trainings are subsidized up to 2 000 PLN Flexibility - You choose form of cooperation: employment or business-to-business contract Bonus for recommending Candidates up to 6 000 PLN Fully paid Medicover healthcare card Multisport card Regular integration events and gifts Psychological support program WellBee Mobility Program Long term cooperation If You applied for this position the Controller of your personal will be  ALTER SOLUTIONS POLSKA Sp. z o.o., with its registered office at ul. Emilii Plater 10/47, Warsaw. The personal data provided by you will be processed for the purpose of the recruitment process and for future recruitment processes. You will have the right too choose one or both options on next page. You have the right to access the content of your data, request their rectification, erasure, restriction of processing, the right to data portability, the right to object to the processing of your data and the right to lodge a complaint to the President of the Personal Data Protection Office. Location: Gurgaon, Noida, Hyderabad, Chennai, Bangalore, Pune, Kolkata, Indore, Jaipur, Ahmedabad,None,None About Material Material is a global strategy, insights, design, and technology partner to companies striving for true customer centricity and ongoing relevance in a digital first, customer-led world. By leveraging proprietary, science-based tools that enable human understanding, we inform and create customer-centric business models and experiences + deploy measurement systems – to build transformational relationships between businesses and the people they serve. About Srijan Srijan is a global engineering firm that builds transformative digital paths to better futures for Fortune 500 enterprises to nonprofits all over the world. Srijan brings advanced engineering capabilities and agile practices to some of the biggest names across FMCG, Aviation, Telecom, Technology, and others. We help businesses embrace the digital future with cloud, data, API and platform centric technologies and adapt to changing business models and market demands. Srijan leads in Drupal with 350+ Drupal engineers, 80+ Acquia certifications. Srijan is also a Drupal Enterprise Partner & Diamond Certified Skillls and Requrement : Requirement : - Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals Solve complex data problems to deliver insights that helps business to achieve their goals Create data products for analytics and data scientist team members to improve their productivity Advise, consult, mentor and coach other data and analytic professionals on data standards and practices Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering in order to improve our productivity as a team Develop and deliver communication and education plans on analytic data engineering capabilities, standards, and processes Partner with tribe members and solutions architects to develop technical architectures for strategic projects and initiatives. Learn about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics Skills : - ▪Bachelor’s degree required; Computer Science, MIS, or Engineering preferred ▪5+ years of experience working in data engineering or architecture role ▪Expertise in SQL and data analysis and experience with at least one programming language (Python or Scala preferred) ▪Experience developing and maintaining data warehouses in big data solutions ▪Experience with developing solutions on cloud computing services and infrastructure in the data and analytics space (preferred) ▪Database development experience using Hadoop or Big Query and experience with a variety of relational, NoSQL, SAP BW and cloud database technologies ▪Worked with BI tools such as Tableau, Power BI, Looker, Shiny ▪Conceptual knowledge of data and analytics, such as dimensional modeling, ETL, reporting tools, data governance, data warehousing, structured and unstructured data. ▪Exposure to machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics Responsibilities: Requirement Gathering & Analysis: Responsible for participating in business requirements gathering exercise and translating business requirements into functional and technical specifications. Participate and provide inputs during requirements feasibility analysis and provide alternate solutions based on application architecture. Responsible for functional requirements interpretation and guiding the team on design and development process. Technology Review: Responsible for end-to-end analysis of the application portfolio and provide inputs for transformation opportunities for a given line of business. Testing: Responsible for creating the test plan and associated functional test cases. Perform functional testing as required for a given release. Project Support: Guide the delivery team during impact analysis of incidents by providing inputs on upstream and downstream dependencies. Provide inputs for prioritizing incidents and problems. Participate and provide inputs during change impact analysis and prioritization process. Assist the delivery team in complying with regulatory and compliance requirements. Participate in release acceptance exercise and provide inputs for business signoff. People Management: Drive the SME development program to assess and develop domain experts. Create a career road map for Application SME to become domain experts and track the progress periodically. Business Development: Work with pre-sales and practice on business development and existing growth opportunities in terms of discovery, solution options, evaluation, estimation, training and creation of collaterals Customer Relationship Management: Contribute to continuous service improvement plans (CSI). Knowledge Management: Contribute and participate proactively in knowledge sharing sessions. Audits Participate in security and compliance audits.  What you will get: Competitive Salaries with flexi benefits  Group Mediclaim Insurance and Personal Accidental Policy 30+ Paid Leaves in a year  Learning and Development of quarterly budgets for certification    Apply to this job Company Description Transforming businesses, driving success: SmarTek21 SmarTek21 is an IT services company founded in 2006 with a vision to empower organizations to excel in a data-driven world. Our team of technology and business experts understood that data had become a strategic asset that could drive business strategy and improve customer engagement. We started off by providing consulting and development services in Microsoft technologies, but as the world evolved, so did we. Today, we offer a wide range of services that include Agile Dev/Ops, Data Engineering & Analytics, Testing Automation & Support, and Managed Application and Infrastructure Services. These services are designed to help organizations transform into digital enterprises that can thrive in a data-driven world. We specialize in integrating technologies from various disciplines into holistic solutions, making digital transformations seamless for our clients Job Description SmarTek21 is looking for a hands-on architect to map customer business problems centered around data to reusable end-to-end technology solutions. You will engage over the entire project lifecycle from pre-sales to delivery oversight and will work with both the product organization and the services organization. You will also work closely with the business development team as their point-person and subject matter expert for all things Big Data.  Lastly, you will present to executive audiences, both external and internal.   Qualifications • Strong hands-on experience as a Big Data Architect with a solid design and development background in Java, Scala, or Python. • Expertise in Hadoop and other industry Big Data and Distributed Data Processing frameworks. • Expertise in designing, building, and scaling data platforms big data solutions on premises and on the cloud (AWS, Azure, GCP). • Solid understanding of enterprise strategies for data security and data governance. • Experience in practice development, architecture, and consulting or product development. • Experience delivering data analytics projects and architecture guidelines. • Experience in engaging with enterprise architects. Non-technical Skills: • Excellent oral and written communication and presentation skills. • Ability to handle ambiguous situations and take trade-off decisions. • Strong problem solving and analytical skills to break down complex problems into smaller components. • Ability and willingness to perform in a team environment. Requirements: • Understand prospect/customer/partner technology landscape. • Devise, document, and present solution approaches (based on current offerings, and as appropriate, reference architecture) that balance risk, organizational maturity and appetite for modernization, budget, and technical innovation. • Ensure requirements, constraints, assumptions, and tradeoff decisions are traceable, and wherever possible, solutions scale across multiple customers/partners. • Drive agreement among internal and external stakeholders on proposed technology solutions based on customer priorities, requirements, and constraints. • Collaborate with the engineering team to create proof-of-concepts (POCs). • Collaborate with the engineering team to convert POCs into pilots and then into full-blown implementations following design, build, and deployment best practices. • Demonstrate business value of proposed solutions or current products to prospects and customers. Salary Range: $200,000-$215,000 (may be subject to change outside of WA State) Additional Information What Is in It for You: Paid Time off – start with 15 days accrued paid time off (PTO) a year. PTO days increase with years of service. Paid Holidays - 8 paid holiday a year in addition to your PTO. Health Insurance for FT employees – we pay 100 % premium of medical, dental and vision. Health Insurance for FT employee’s family – we pay 50% of premium for medical, dental and vision for dependents. 401(k) – we administer 401(K) retirement contribution for FT employees. Life Insurance/Short Term and Long-Term Disability – at no cost to you Opportunities for internal promotions/career advancement Family friendly work hours (closed on weekends and paid holidays) SmarTek21 is an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity and/or expression, status as a veteran, and basis of disability or any other federal, State, or local protected class. Excella is a leading provider of Agile software development and data and analytics solutions to clients in the federal, commercial and non-profit sectors. We believe that great work leads to great things –- our experts measure success by the positive impact we make on our clients, community, and colleagues. We are growing fast and need passionate, innovative people who love working with technology and are ready to make an impact. Here's what you can expect from us: Workplace sites look different for everyone – whether it’s your home or the office, we believe in a flexible work/life balance that supports you regardless of your location. We offer a home office allowance that can be used for home office furniture/equipment, a daily pass for a coworking space, etc. Our commute reimbursement plan has you covered for whether you bike, Metro, or drive to work. We offer top of industry medical, dental, and vision benefits with multiple options to choose from such as an employer-contributed health savings account, infertility coverage, and orthodontia so you can select the plan that works best for you. Regardless of what stage of life you’re in, Excella wants to support you. We provide 8 weeks of Parental Leave, discounted pet insurance, and a Care.com membership with 3 back-up emergency child or elder care days annually – all available to you on your first day. Starting day one, every employee is bonus eligible and receives 15 days of paid vacation, 6 federal holidays, and 4 floating holidays. Diversity and inclusion matter. Excella created and continues to support employee led-affinity groups and the Inclusion Diversity Equity Ambassador (IDEA) team, a cross-functional employee-led initiative to continually foster innovation and increase inclusion within Excella. We have a "bring your own device" workplace and will share the cost of a new computer of your choice -- Mac or PC. It's up to you. We'll invest in your career by providing 3 days of paid professional development every year, including travel and registration fees to attend classes and conferences. We encourage mindfulness and overall well-being through employee wellness events, a HeadSpace membership, as well as access to TalkSpace and mental health coverage through our medical plans. Overview The Data Visualization Developer is responsible for creating reports and dashboards using popular tools to support self-service analytics environments for our clients.   This is not a Data Science role and does not require the use of advanced statistical techniques to analyze data. Responsibilities Interacts directly with client stakeholders (business or technical) to understand client stakeholder needs. Uses SQL queries to explore and understand data sources. Creates prototypes based upon stakeholder requirements in order to confirm the report or dashboard design meets the business need. Creates simple to complex reports and dashboards using visual analytics and business intelligence tools like Tableau and PowerBI Uses SQL or other language to connect directly to data source for data quality checks and to ensure the numbers being represented in reports are accurate compared to source data. Ensures the final product follows data visualization and design best practices, is automated where feasible, and is easily transitioned into the client's environment for ongoing maintenance. Creates and delivers end-user training and documentation on BI deliverables. Qualifications Technical: 3+ years developing reports and dashboards using Power BI. 3+ years writing simple to medium complexity SQL queries. Understanding of relational databases structures (tables and relationships) in order to source effectively from these for reports and dashboards. Key Capabilities: Analytical thinker and problem solver who can listen to a non-data person share a problem, and identify and package data to help them solve that issue Ability to write medium-complexity SQL queries Packages large, complex datasets into intuitive, easy to use dashboards, reports, and decks that help decisions makers answer questions Detail oriented, with a clear understanding of how to quality check reports and data pulls, due to the high visibility of the work Skilled in managing work intake/requirements sessions, including mapping detailed documentation of requirements and tracking progress in shared collaboration tools (JIRA) Written communication is paramount – needs to write clear, concise summaries of complex information and understand how to structure written communication for senior business stakeholders/executives Takes a user-centered approach to developing data visualization products, like dashboards. Enthusiastic about learning about and using new features within tools like Tableau and PowerBI to ensure dashboards leverage the most up to date functionality Strong understanding of data visualization best practices, including chart selection, visual encodings, preattentive attributes, and Gestalt principles, and experience using those principles in the development of executive dashboards. Seeks and sees the larger business context of their work, and identifies opportunities to add value in complex and changing environments Optional, but industry or subject matter expertise (e.g., finance, employment, hospitality, digital analytics). Excella is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. What if you could join a rapidly growing company and play a critical role in bringing new medicines to patients through looking at and treating disease in a revolutionary way? What this position is all about: Are you a highly motivated and organized computational biologist who is enthusiastic about exploring how emerging data technologies will enhance our understanding of cellular behaviors that drive disease phenotypes? Are you motivated to enable a computational biology team to realize as much value as possible from our data and to enable cross-functional communication with other technology teams? As Senior Manager in Computational Biology, you will be responsible for optimizing our data strategy efforts, productionizing our processes, and bringing creative thinking to the integration of novel data modalities into the overall discovery process at Cellarity. You will get the opportunity to work in an innovative computational team, driven to deliver high-impact results. You will be in an early group of pioneers developing and applying the world's first AI platform that models disease based on complex cellular behaviors. You will begin your career at Cellarity as part of a large team of world-class computational biologists and machine learning scientists (https://cellarity.com/the-team), biologists (co-developing hypotheses), chemists, clinicians, and technologists (co-developing proprietary data assets). If you think you can contribute to the capabilities that we are building and are keen on applying our platform to advance our exploratory drug programs and learning from some of the best scientists, while getting to work with proprietary and relevant data sets, then we are looking for you. What you would be responsible for: Work with the New Data Types team to prototype and develop capabilities for integration of novel data technologies into Cellarity’s computational biology platform Act as a liaison between Computational Sciences, Technology, and Data & Software Engineering to ensure clarity in data flow, pipeline maintenance, optimization of processes Contribute to the development of novel approaches to analyze complex data types such as single-cell RNA-seq, single-cell ATAC-seq, single-cell genotyping, Perturb-seq Apply rigorous statistical techniques to improve our understanding of single-cell data at multi-omics levels Be an active member of the Computational Sciences team engaging in discussions on study designs that benefit programs, developing and maintaining SOPs for integration of varied data modalities into program ideation, and providing guidance and mentorship to the team on best practices for data analyses Present your results in an interdisciplinary team of biologists, chemists, clinicians, technologists, and other machine learning colleagues in meetings covering cross-functional project teams, functional teams, to whole company and management meetings What experiences will you need: Ph.D. or equivalent experience in biology, computational biology, mathematics, statistics, computer science, or related scientific field Two or more years of experience (post academic training) working in an industry setting Extensive experience in analyzing and deriving hypothesis from single-cell data, across multiple modalities Demonstrated scientific understanding of molecular and systems biology, diverse molecular data types, and analysis tools Excellent programming and scripting skills, preferably in Python Fast learner, analytical thinker, creative, "hands-on", strong communication skills. Able to work both independently and as part of a team What sets you apart: Experience with generating, analyzing, and deriving hypotheses from other single-cell omics data types or large-scale clinical datasets. Experience driving an impactful and relevant project within industry. Background in statistics or machine learning. Experience with clinical or biological data. What it is like to work at Cellarity  At Cellarity, we  Push Boundaries: We create a legacy with breakthrough science in service of patients. Inject Energy: We build strengths from different perspectives and tell it like it is. Own it: We transcend our job descriptions and relentlessly follow through on our commitments. Go all out: We work quickly and with conviction. Company Summary:  Cellarity’s mission is to fundamentally redesign the way drugs are created for the sake of bringing new hope to patients.  By shifting the focus from a single target to the underlying cellular dysfunction, we unravel the complexity of disease biology and create medicines that were not possible before. The company has developed unique capabilities that link biology and chemistry with high dimensional -omics data from which we design medicines against the cellular signature of disease. The Cellarity platform allows us to uncover new biology in diseases even in the absence of known causal targets. The company has drug discovery programs underway in several disease areas, including metabolic disease, hematology, and immunology.  Cellarity recently completed a Series C financing and has raised a total of $274M from all funding rounds to date, with contributions from world-renowned investors alongside Flagship Pioneering who created the company.  Cellarity’s goal is to grow into a fully integrated next generation Biotech company driving a new age in drug creation.  Cellarity is committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Recruitment & Staffing Agencies: Cellarity does not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to Cellarity or its employees is prohibited unless contacted directly by Cellarity’s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of Cellarity, and Cellarity will not owe any referral or other fees with respect thereto.   PowerBI Developer NTT DATA is a team of more than 139,000 diverse professionals, operating in more than 50 countries throughout the world. The sectors where we have activities include: telecommunications, finance, industry, utilities, energy, public administration and health. Our mission? Offer technological solutions, business, strategy, development and maintenance of applications, while being a benchmark in consulting. All thanks to the collaboration between teams, the human quality of our people and the fact that we do not conform to what is established, we always seek innovation that brings us closer to the future. Our essence has led us to the forefront of technology, breaking paradigms and providing solutions that truly respond to the needs of each client. Our talent has led us to be one of the top 6 technology companies in the world. Because #Greattech, needs #GreatPeople, like you NTT DATA is looking for high-achieving team players that are quickly adaptable to new challenges and entrepreneurial ventures. We are looking for a PowerBI Developer to work in Orange, CT with our global client. This position would be hybrid 4 days a week onsite.  Responsibilities: Gather data from Altiris, SCCM, CMDB. ServiceNow, SAP, Excel, and other data sources Utilize PowerBI platform to transform the data and produce reports   Perform data model design and implementation Integrate reporting components from multiple data sources Requirements: 3+ years of experience working directly with Power BI Experience gathering data from data sources such as: Altiris, SCCM, CMDB. ServiceNow, SAP, Excel Experience developing reports and dashboards Experience in optimizing dashboards with focus on usability and performance   Why NTT DATA?    Empowerment and rewards are the cornerstone of our career development model. We are a young, fast-growing company, with a highly innovative and entrepreneurial spirit, because of this professional experience and growth will be unmatched. Our talent and positive attitude allows us to transform our goals into achievements, and projects into realities. NTT DATA is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. NTT DATA is an Equal Opportunity Employer Male/Female/Disabled/Veteran and a VEVRAA Federal Contractor. #LI-JW1 Sword is a leader in data insights, digital transformation, and technology services with a substantial reputation in software development, complex business IT projects, and mission critical operations. With over 2,500 technology, digital and software specialists working globally we unlock solutions for the most critical business technology challenges. In Houston, we provide expert data and information management advisory, project, support and consulting services to the energy industry, helping our customers reduce costs and increased efficiency through effective data management. This Environmental and Sustainability Data Manager role provides the opportunity from someone with the deep data management and analysis experience to shape the direction and structure of this important emerging business area. We are looking for someone who is passionate about the power of data to inform critical business decisions. Role Objectives: Support all aspects of data management for ongoing operations and technical evaluations, as part of a E&S data team, Building data models for the increasing range of data feed that will be informing the E&S agenda. Build models that are robust and appropriate for this emerging business area, Establishing and implementing data governance practices around the existing and future data elements. Able to develop appropriate and useable standards and documentation consistent with the clients existing systems, Ability to analyse the data to identify the key items and attributes that need to be defined in the data model. Also able to use analysis to establish appropriate data quality checks, Good stewardship of the data to provide confidence in the quality and accuracy of the data used for compliance reporting and critical decision making, Work with a dispersed team to define the forward direction in this important new area and help shape a sustainable data environment, Act as an interface with the data engineers to understand their needs and ensure that the data model is consistent with their needs and the digital ecosystem, Network with both data end users and those providing data streams to align the needs and system constraints in building the data models. Requirements Required skills: Experience building and managing sustainable data models (any complex industry), Ability to analyse technical data, understand its quality and trouble shoot reliability issues, Track record of establishing and implementing data governance, Strong demonstrated digital skills including, SQL, Python, PowerBI and Power Automate, Understanding and use of different database structures, Able to work with ambiguity and demonstrated ability to create new solutions, Work collaboratively, and able to communicate effectively with other disciplines. Desirable skills: Experience working with Environmental and Sustainability data, Familiar working with Kanban and Agile processes to manage multiple tasks, Knowledge of Microsoft Azure stack, A degree or diploma like a BSc Degree or equivalent in the Information Technology field or a STEM subject. Benefits Sword offers career paths in rapidly evolving technology spaces including Data & AI, Modern Managed Services, Information Management, Digital Services, Content Services, and Modern Workplace Transformation. This role offers a highly competitive, success-driven, open-ended commission scheme where we reward those that over deliver. Our team culture is based on building inclusive teams, investing in training and development, the quality of our interactions with our customers and our position as an employer of choice in the areas in which we operate. All Sword Group colleagues are supported and encouraged to develop their career with Sword through our personal training and development plan alongside a competitive salary, pension, private healthcare, and employee assistance programme. Company Description Proekspert bridges the gap between the digital and the physical. We build world-changing solutions by combining data science and product development expertise with a design thinking approach. Always more than just a software company, we have worked on clever machines and industrial automation, smart screws, production lines, complex device integrations, banking backbones, and management automatics: in short, advancing the new industrial revolution. Our code makes elevators move, heating systems run. Our software helps to grow useful bacteria, makes business decisions. It can analyze satellite images and is used to provide self-service to millions of people. Job Description Our Business Intelligence team helps local and international companies to transform data into actionable and relevant insights. This enables our clients to make informed strategic decisions and to improve their operational efficiency & business productivity. Are you as passionate about data and BI as we are? Then this BI Analyst role is for you! What you will do: Work with Proekspert customers to determine business requirements and priorities Identify user needs together with users and the customer Analyse the data sources necessary for the data model and make suggestions to the customer regarding the improvement of data quality Prepare initial tasks for a data developers to perform database structures and data transfers Design and document dashboards, alerts and reports Educate and train customers to use data as an analytical tool Apply good practices of agile development process Qualifications We’re looking for a team member who: Has at least 2 years of experience as BI Analyst or similar role Has experience of using analytical tool/s like Microsoft Power BI, Tableau, etc. Has strong SQL skills Is familiar with creating data models Has an analytical mindset and great communication skills Has an in-depth understanding of the business environment and an interest in going beyond the obvious Has the ability to present data in the form of user history (storytelling) Has skills to set priorities, systematically plan and coordinate activities Possesses skills in critical thinking, attention to detail Is motivated, self-directed, and proactive Has very good written and spoken English Nice-to-haves: Very good written and spoken Estonian Previous experience with Python, R scripting language Familiarity with any cloud systems (AWS, Azure, Google app engine) Education in economics-, statistics- or mathematics Additional Information Proekspert values individual freedom, decision-making and proactiveness. In our self-organizing and supportive work environment, teamwork is of the utmost importance.  What we offer: Interesting, steady work. Our projects have a positive impact on people and the world.  We value the well-being of our people and their families.  Inspiring community and teams, who support and mentor you.  An exciting benefit package, including a personal growth budget and profit-sharing.  A motivational program and competitive salary. Unternehmensbeschreibung Wir bei rheindata beraten unsere Kunden in den Bereichen Big Data, Business Intelligence und Data Science. Wir sind ein buntes Team aus den unterschiedlichsten Fachbereichen wie z.B. Mathematik, VWL, Informatik oder Physik. Uns ist wichtig, dass wir uns weiterbilden können und offen sind, unser Wissen zu teilen. Bei uns gibt es wenig Bürokratie, stattdessen kurze und flache Entscheidungswege und großes Mitspracherecht. Wenn du also Lust hast, uns kennenzulernen… los geht´s! Stellenbeschreibung Als BI Berater ETL/ELT (m/w/d) arbeitest du in unterschiedlichen BI Projekten bei unseren Kunden und entwickelst kreative und innovative BI Lösungen, entwickelst du ETL/ELT Strecken und zudem orchestrierst und parallelisierst du Ladestrecken, erstellst du SQL-basierte Datenbank-Abfragen, arbeitest du mit strukturierten und unstrukturierten Daten und bist du offen für neue Technologien und gibst dein Wissen auch gerne weiter. Qualifikationen Das bringst du mit: Einige Jahre praktische Erfahrung im BI Bereich, ein abgeschlossenes Studium in einem MINT (Mathematik, Informatik, Wirtschaftsinformatik, -mathematik, Physik o.ä.)- oder wirtschaftswissenschaftlichen (BWL, VWL, o.ä.) Fach, Kommunikationsstärke, Deutschkenntnisse auf muttersprachlichem Niveau (C2), Englisch fließend in Wort und Schrift. Zudem verfügst du über Kenntnisse z.B. in: SSIS, Talend oder Informatica SQL Erfahrung in Cloud-Plattformen wie Azure, AWS oder GCP Zusätzliche Informationen Das bieten wir dir: 6 Wochen Urlaub im Jahr und in jedem fünften Jahr sogar 10 Wochen eine deinen Bedürfnissen entsprechende Einarbeitungsphase mit Begleitung deines Mentors, die Möglichkeit zu individuell gestaltbaren Sabbaticals, die Teilnahme an unserem Mitarbeiter-Beteiligungsprogramm, eine kostenlose M-Mitgliedschaft bei Urban Sports Club und vergünstigte Konditionen bei L- und XL-Tarifen neben einem attraktiven Vergütungspaket erhältst du natürlich ein Notebook und ein Smartphone sowie weitere Zusatzleistungen wie z.B. Jobticket, JobRad oder betriebliche Altersvorsorge je nach Projektgegebenheiten, die Möglichkeit im Homeoffice zu arbeiten – wobei du in unserem Büro im belgischen Viertel natürlich auch immer willkommen bist. Company Description Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region. Job Description Overall 4 - 6 years with minimum 3 years relevant experience Ability to Propose and Design large, scaled-out, real-time, high performing Data Lake / Data Warehouse systems Experience in data management, data governance, master data management and meta data management. Experience in building modern data platforms and automation of data pipelines. Liaise with customers and manage customers expectations Should be flexible enough to connect and work whenever required  Roles & Responsibilities Hands on experience with Azure Data Lake, Azure Data Factory, SQL Data Warehouse Azure Blob, Azure Storage Explorer Experience in Data warehouse/analytical systems using Azure Synapse. Proficient in creating Azure Data Factory pipelines for ETL processing; copy activity, custom Azure development etc.  Knowledge of Azure Data Catalog, Event Grid, Service Bus, SQL, Purview and Synapse Good technical knowledge in Microsoft SQL Server BI Suite (ETL, Reporting, Analytics, Dashboards) using SSIS, SSAS, SSRS, Power BI Design and develop batch and real-time streaming of data loads to data warehouse systems Qualifications Qualifications B.E/B.Tech/MCA Additional Information Added advantage - Certifications in  Azure Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. United by our core values and our purpose of helping people thrive in the brave pursuit of next, our 20,000+ people in 53 offices around the world combine experience across technology, data sciences, consulting and customer obsession to accelerate our clients’ businesses through designing the products and services their customers truly value Job Description As Senior Associate L2 in Data Engineering, you will translate client requirements into technical design, and implement components for data engineering solutions. Utilize a deep understanding of data integration and big data design principles in creating custom solutions or implementing package solutions. You will independently drive design discussions to ensure the necessary health of the overall solution. The role requires a hands-on technologist who has strong programming background like Java / Scala / Python and should have experience in Data Ingestion, Integration and data Wrangling, Computation, Analytics pipelines, and exposure to Hadoop ecosystem components. You are also required to have hands-on knowledge of at least one of the AWS, GCP, and Azure cloud platforms.  Role & Responsibilities: Your role is focused on the Design, Development and delivery of solutions involving: Data Integration, Processing & Governance Data Storage and ComputationFrameworks,PerformanceOptimizations Analytics & Visualizations Infrastructure & Cloud Computing Data Management Platforms Implement scalable architectural models for data processing and storage Build functionality for data ingestion from multiple heterogeneous sources in batch & real-time mode Build functionality for data analytics, search and aggregation Qualifications Overall 5+ years of IT experience with 3+ years in Data related technologies Minimum 2.5 years of experience in Big Data technologies and working exposure in at least one cloud platform on related data services (AWS / Azure / GCP) Hands-on experience with the Hadoop stack – HDFS, scoop, kafka, Pulsar, NiFi, Spark, Spark Streaming, Flink, Storm, hive, oozie, airflow and other components required in building end to end data pipeline. Strong experience in at least of the programming language Java, Scala, Python. Java preferable Hands-on working knowledge of NoSQL and MPP data platforms like Hbase, MongoDb, Cassandra, AWS Redshift, Azure SQLDW, GCP BigQuery etc  Well-versed and working knowledge with data platform related services on at least 1 cloud platform, IAM and data security   Competency 1. Good knowledge of traditional ETL tools (Informatica, Talend, etc) and database technologies (Oracle, MySQL, SQL Server, Postgres) with hands on experience 2. Knowledge on data governance processes (security, lineage, catalog) and tools like Collibra, Alation etc 3. Knowledge on distributed messaging frameworks like ActiveMQ / RabbiMQ / Solace, search & indexing and Micro services architectures 4. Performance tuning and optimization of data pipelines Job Title: Senior Associate L2 – Data Engineering 5. CI/CD – Infra provisioning on cloud, auto build & deployment pipelines, code quality 6. Cloud data specialty and other related Big data technology certifications Personal Attributes: Strong written and verbal communication skills Articulaion skills Good team player Self-starter who requires minimal oversight Ability to prioritize and manage multiple tasks Process orientation and the ability to define and set up processe Additional Information Gender Neutral Policy 18 paid holidays throughout the year for NCR/BLR (22 For Mumbai) Generous parental leave and new parent transition program Flexible work arrangements Employee Assistance Programs to help you in wellness and well being As a Big Data Consultant, you will report to the Consulting Manager, Data, Analytics & Machine Learning. You will work with clients to understand their current environment, technical challenges, and future state needs. You will design and propose solutions, helping clients understand how the project will accomplish their goals. You will lead a team of Big Data Engineers to implement projects and build cutting-edge solutions. This position is 100% remote, with up to 50% travel required (post-COVID). Responsibilities Facilitate design sessions with clients and Mission team to create the strategy, architecture, and implementation plan for data engineering projects Design end-to-end modern data platforms for analytics and AI use cases for multiple clients simultaneously Communicate the proposed solution to clients so they understand the benefits, translating the technical elements into business language Develop strategic roadmaps and project plans based on customer goals Work with Big Data Engineers and Architects to break down complex development plans into LOE estimates, design documents and project plans Oversee the implementation customer roadmaps in coordination with Big Data Engineers; ensure project tasks are completed on time, high quality, and progress toward the project goals Design data ingestion, data storage, data modeling, data virtualization, self-service data preparation and analytics pipelines Develop customer solutions for data privacy and security Create workload orchestration using common tools like Jenkins, Airflow and MLFlow Be the technical liaison between customers and engineering teams; communicate complex technical concepts in easy-to-understand non-technical language Work with Project Managers to set customer expectations, drive alignment, and coordinate timelines Support pre-sales engineers in proposal design and positioning, including helping define an approach to solving a prospect’s technical challenges and helping the business development team estimate and plan projects Mentor Big Data Engineers and more junior consultants Support Data Science & Engineering process improvement initiatives Support Data Science & Engineering recruiting efforts by participating on interview panels Requirements 5+ years experience designing and implementing creative data solutions leveraging the latest in Big Data frameworks, especially from AWS 5+ years experience architecting solutions for optimal extraction, transformation and loading of data from a wide variety of traditional and non-traditional sources such as structured, unstructured, and semi-structured data using SQL, NoSQL and data pipelines for real-time, streaming, batch and on-demand workloads 3+ years experience with analytics/data management strategy formulation, architectural blueprinting, and business case development  SQL, Database, Data Modeling, Data Warehousing and Development skills Experience with AWS services like S3, Redshift, Athena, EMR, Glue, and Quicksight Experience with Dashboarding and Reporting Tools used in the Industry (Tableau, Qlik, etc.) Experience  leading teams, training, and mentoring more junior team members  Experience with implementation of data security, encryption, PII/PSI legislation, identity and access management across sources and environments AWS Data Analytics  Specialty Certification (required within 6 months of hire) AWS Solution Architect - Professional Certification (required within 6 months of hire) Additional AWS Specialty Certification within the Data Analytics, Development or Machine learning space (required within 1 year of hire) Perks & Benefits Medical, dental, and vision insurance for employees and their dependents with options for 100% company paid premiums 401(k) plan with company matching Profit sharing bonuses based on performance Flexible Spending Accounts (Health and Dependent Care) Life insurance paid by Mission Paid time off (FlexPTO, parental leave, volunteering time off) Inclusive work environment with several Employee Resource Groups Fully distributed team with flexible work hours Home office expense benefit Cell phone stipend Flex stipend for use on cell phone, home internet, wellness, snacks, etc. It’s up to you! Participation in Mission’s Cash Incentive Unit Award program An internal department dedicated to helping team members on their career path Commitment to Diversity and Inclusion We are committed to diversity and inclusion. We value every individual’s unique story, experience, and perspective. We aim to amplify the voices of our team members and our community to create a safe, empathetic, and inclusive environment where everyone can contribute to one’s authentic self. Mission Cloud makes every effort to ensure that all employees are compensated fairly regardless of gender, ethnicity, race, or past salary history. We understand that fair compensation practices establish that diversity, fair hiring processes, and fair pay are part of who we are as a company and maintain positive employee morale. We use market data to define salary ranges for each role and regularly review compensation adjustments as needed based on salary range updates. Mission Cloud is an Equal Opportunity Employer and participant in the U.S. Federal E-Verify program. Mission will consider qualified applicants with criminal histories in a manner consistent with The Los Angeles Fair Chance Initiative for Hiring Ordinance. About Mission Cloud Mission Cloud is an Amazon Web Services (AWS) Premier Consulting Partner and MSP. Clients depend on us to expertly and securely architect, migrate, manage, and optimize their cloud environments.Mission Cloud’s team of AWS Certified Solutions Architects and DevOps Engineers are ready to help you harness the full power of the AWS cloud to transform your business and operations. So Energy was created in 2015 because we knew energy suppliers could be better. Since then, we’re grown rapidly but sustainably, with 300,000+ customers and over 300 So Energists. But, we’re not done. We’re on the road to a million customers by the end of 2026 and, thanks to our recent merger with ESB Energy, we’re well on the way. We’re tech first, we’re customer-centric and we’re passionate about sustainability. We want to do the best we can by our customers and by each other, so we’ve created a workplace that is encouraging, supportive and offers the opportunity for growth. As a company, we live by six core values that guide everything we do. Clear Honest Ambitious Inquisitive Caring Sustainable  We are looking for a Business Intelligence Data Analyst who will be responsible for supporting the business in our data driven focus on growth and efficiency. Within this role, you will be identifying reporting and data opportunities, analysing trends, and presenting back insights with potential solutions to solve some of the key business challenges. Our solutions are primarily built on the Google Cloud stack, of which Looker is our main BI reporting tool. This will require you to be adept to working on Looker with other BI tools being an added advantage. Requirements As a BI Data Analyst you will need to be a detailed orientated individual who has a passion for analysing data This will require you to learn and fully understand our data landscape both from a source system and reporting perspective You will work closely with our Data Engineering team to build reporting friendly structures A key attention to detail will be required in the reviewing and validating of data prior to it being shared with the business You should have experience in end user engagement on requirements elicitation and the ability to identify stakeholder problems that can be solved through data Proven and extensive hands-on experience in building dashboards using Google Looker which are insightful and builds a data storyline which makes sense to your end users You should be comfortable with communicating insights to senior management and across the organisation. - Provide technical support to other teams within the organisation as required You should have a strong SQL background with a deep understanding of how to use SQL and interrogate data in the context of business objectives Be a team player, contributing towards the upliftment of our overall BI capability and supporting junior team members produce higher quality outputs  What you will be doing Gather and document requirements in a way that allows us to design well suited dashboards and reports Translate requirements to technical solutions Analyse data to identify trends and patterns Interrogate and curate the quality, consistency and completeness of data to ensure that the quality of insights are complete and relevant Script data transformation and business rules in SQL and Python Research new data sources which will add value into the reporting that you will be delivering Define metrics that are suited to business monitoring Support the business in ad-hoc data analysis and data supply covering auditing, marketing campaigns and customer segmentation Design reporting tables which facilitate the delivery of dashboards and insights Build dashboards and reports in Google Looker Dashboard design should follow intuitive data flow and presentation for easier end-user consumption and decision making Model data within Looker (LookML) which conforms to standards and principles that keeps the quality and integrity of the Looker backend intact Input and guide on new standards to improve our delivery of dashboards and the quality of our outputs Perform data reconciliation tasks to ensure that new reporting outputs are aligned or of better accuracy than existing reports Write quality technical documentation of SQL coding as well as dashboards delivered Contribute as part of an agile team with sprint planning sessions and daily standups Communicate status, blockers, and progress clearly Benefits Competitive salary Hybrid remote working Life Assurance 4x Base Salary Bonus Up to 10% of Base Salary 25 days holiday, plus bank holidays, and an extra day holiday for your birthday Perkbox Ongoing support and development as well as a generous learning and development budget Free daily breakfast Great reward and recognition Exposure to all parts of a growing business Pension matching as part of auto-enrolment pension scheme  So Energy care about helping the energy industry become a much more diverse and inclusive environment and we work hard to lead by example. We are committed to Equal Employment Opportunity and building an inclusive environment for all. If you are interested in finding out more please apply making sure to complete all the questions to the best of your ability and attached an up to date version of your CV.  Good luck! Descripción de la empresa Devoteam Data Driven Somos más de 8.500 personas distribuidos en 18 países de EMEA y Oriente Medio  y de ellos más de 850 compañeros estamos en España (y en aumento!!). Contamos con un Centro de Excelencia de Datos a nivel internacional, donde podemos replantear los modelos operativos y reinventar las relaciones con partners y clientes. Devoteam Data Driven es nuestra unidad transversal de proyectos relacionados con datos. Trabajamos con nuestros Partners Globales de Microsoft PowerBI, AWS y nuestros Partners Locales del mundo del Dato reconocidos internacionalmente tanto en la parte de Integración y Gobierno (Enterprise Platinum Partner de Informática, Collibra, Databricks, Alteryx, Snowflake) como en la parte de explotación (Tableau, Qlik, Microstrategy). Devoteam Data Driven te da ahora la oportunidad de participar en todo el Ciclo de Vida de los datos, desde la extracción a la visualización usando las tecnologías referentes del mercado actual. Si te consideras una persona amante de los datos y te gusta ofrecer experiencias personalizadas a organizaciones, con calidad en lo que haces, te interesa ayudar a diseñar soluciones eficaces y consideras que tienes una mente abierta para reimaginar el futuro de  grandes empresas…¡Tu sitio es Devoteam Data Driven! Para más información,  accede a la web de la unidad: https://es.devoteam.com/playground/data-driven-intelligence/ Y si te atrae lo que ves inscríbete ya en nuestras Ofertas Activas de Devoteam Data Driven en Infojobs (https://devoteamingenieria.ofertas-trabajo.infojobs.net/ofertas) o busca tu perfil en todas nuestras vacantes en Devoteam Career (https://es.devoteamcareers.com/envia-tu-solicitud/?query=servicenow#). ¡No dejes pasar el momento y sube de nivel! ¡¡Te estamos esperando!! Descripción del empleo Estamos en búsqueda de un perfil Big Data Engineer con AWS para que se incorpore a nuestro equipo de Data y que formará parte del equipo que configura la estrategia, la arquitectura y la infraestructura de datos del cliente. Tus funciones principales serían: Desarrollar pipelines en batch y tiempo real con Spark, dbt, Spark Structured Streaming y Kafka. Desarrollar y gestionar el Data Lake, el procesamiento de datos y las plataformas de datos end to end: Diseñar y gestionar soluciones de arquitectura cloud. Desarrollar integraciones de datos escalables y confiables para alimentar los modelos de Data Science. Administrar y orquestar mecanismos adecuados de monitorización. Diseñar pipelines CI / CD. Participar en la automatización de tests, calidad del código y despliegue automático de aplicaciones. Estar conectado con los últimos avances en Big Data y colaborarás en el I+D que aportarán nuevos casos de uso y mejoras. Requisitos Al menos 3 años de experiencia desarrollando en Python, Scala, o cualquier otro lenguaje orientado a objetos. Experiencia en el desarrollo de ELT escalable, procesos de integración de datos con Spark, Spark Structured Streaming o cualquier otra tecnología de procesamiento de datos. Interesado/a en buenas prácticas: tests, automatizaciones, construyas pipelines en CI, etc. Experiencia en la construcción y el mantenimiento de cargas de datos de alto volumen complejas y orquestando dependencias (por ejemplo, Airflow). Experiencia con servicios de AWS (por ejemplo, S3, Lambda, DynamoDB, API Gateway, Glue, Athena, ECR/ECS), y Databricks es muy deseable. Persona comprometida, proactiva, que se preocupe por la calidad de sus entregables, y una mentalidad hands-on. La posición es presencial en Barcelona, la empresa proporciona transporte público desde Barcelona y el Vallès para llegar a las oficinas del cliente. Company Description Discover the Unexpected  Experian is the world’s leading global information services company. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index. We’re passionate about unlocking the power of data in order to transform lives and create opportunities for consumers, businesses and society. For more than 125 years, we’ve helped businesses grow, consumers and small businesses gain access to financial services, and economies and communities flourish – and we’re not done. Our 18k amazing employees in 40+ countries believe the possibilities for you, and the world, are growing. We’re investing in the future, through new technologies, talented people and innovation so we can help create a better tomorrow. To do this we employ the greatest and brightest minds that share our purpose and want to make a difference. Experian Asia Pacific's culture, people and environments are key differentiators. We focus on what truly matters; diversity and inclusion, work/life balance, flexible working, development, equity, engagement, collaboration, wellness, reward & recognition, volunteering... the list goes on. We’re committed to fostering a strong sense of belonging and a place where you can bring your true self to work. Our uniqueness is that we truly value yours. We’re an award winning organisation due to our strong people first focus. This includes Top Employer™ and Great Place To Work™ accreditations. Learn more at www.experianplc.com Job Description Job description You will be working within a team of highly motivated and talented software engineering specialists, who develop and maintain reporting services for our corporate business communities.  Our primary systems and activities include development, integration, processing, and reporting applications using wide range of Oracle technologies that are located within Experian data centres and cloud-based platforms. We are looking for experienced personnel who are keen to engage in development, analytical and support roles and who understand database management systems, data warehousing principles and have confidence in working with structural and procedural data query languages. You will be working closely with our core integration and business intelligence team and internal business partners, using established development methodologies, secure practices, change and incident management procedures.  Essential requirements Bachelor’s degree in information technology, computer science or closely related field Hands-on development expertise with ELT technologies, reporting, data modelling techniques with solid knowledge of data warehousing concepts Must have development and implementation experience with Oracle Data Integrator integrated with Hyperion and business intelligence applications Experience working with the Hyperion Planning and Essbase applications Experience working with OBIEE/OAS in the distributed architecture Must have experience in working on high-Availability and load-balanced BI Infrastructure environments. Ability to design and troubleshoot Oracle database queries and logic involved with business intelligence applications. Ability to provide Application Production Support as well as design & develop. Good understanding of diverse source systems and relational databases in BI space Experience handling the windows and Unix batch scripting. Experience working with Autonomous Data warehouse (ADW) and oracle cloud infrastructure (OCI) will be added advantage Analyse ELT processes and ability to identify areas for performance improvements and automation Independent, knowledgeable, and self–motivated Qualifications Useful requirements Minimum of 5-8 years of experience within the information technology industry An understanding of security principles Agile development techniques Shell scripting and Linux operating systems experience Experience in writing SQL and PL/SQL Certified Oracle practitioner Strong analytical and problem-solving skills Ability to interact with cross-functional teams Knowledge of windows and Linux operating systems Ability to work in a fast-paced environment  Additional Information Experian Careers - Creating a better tomorrow together Find out what its like to work for Experian by clicking here 1099 or Corp to Corp 12 month plus Remote may require 1-2 trips onsite expenses paid  We are looking for a passionate certified Data Analyst or BI. The successful candidate will turn data into information, information into insight and insight into business decisions. Data analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design. Data analysts will develop analysis and reporting capabilities. They will also monitor performance and quality control plans to identify improvements.We are looking for a Business Intelligence (BI) Developer to create and manage BI and analytics solutions that turn data into knowledge. In this role, you should have a background in data and business analysis. You should be analytical and an excellent communicator. If you also have a business acumen and problem-solving aptitude, we’d like to meet you. Ultimately, you will enhance our business intelligence system to help us make better decisions. Requirements Minimum Technical Qualifications: a) Minimum of five (5) years of experience as a data analyst or in other quantitative analysis or related disciplines, such as researcher, data engineer or BI analyst. b) Possession of a bachelor’s degree. Additional qualifying experience may be substituted for the required education on a year-for-year basis. Desirable Technical Qualifications: a) Four (4) years of Senior Data Analyst experience analyzing Structured Query Language (SQL) Server database structures, data, and implementations to identify any potential security, performance, or support concerns. b) Four (4) years of Senior Data Analyst experience recommending changes to improve security, performance, availability, and ease of access to PDR system data. c) Four (4) years of Senior Data Analyst experience creating secure databases that comply with State Information Security protection requirements, at the database level. d) Four (4) years of Senior Data Analyst experience modifying legacy databases to meet security requirements, and improve performance, availability, and data access. e) Four (4) years of Senior Data Analyst experience converting/migrating legacy data into new database structure and participate in verifying application-database functionality. f) Four (4) years of Senior Data Analyst experience participating in configuration, migration, troubleshooting and remediation activities. Company Description Ocorian is a global leader in corporate and fiduciary services, fund administration and capital markets. Wherever our clients hold financial interests, or however they are structured, we provide compliant, tailored solutions that are individual to their needs. We manage over 17,000 structures for 8000+ clients with a global footprint operating from 18 locations. Our scale offers all our people great opportunities to develop their knowledge and skills and to progress their careers. Job Description Purpose of the job To assist in the development of business intelligence and management information solutions for Ocorian taking information from the financial, HR, corporate administration systems, and Cloud-based solutions to create a reporting base for the business, the single source of truth Delivery of key dashboards and reporting requirements from the BI/MI solutions with appropriate robust security models Assist with data cleansing and data loading exercises, which may extend to jurisdictional and regulatory filing requirements Documentation of solutions, handover to BAU Teams, and supporting solutions Prior experience of creating/supporting ETL, data warehouses and Tabular data models. Ocorian utilises Microsoft SQL Server technologies, including SSIS, SSAS, SSRS and Power BI and the successful candidate should have delivered projects using aspects of this technology stack in recent times The individual will be expected to work across all levels of the Business to liaise with key stakeholders to ensure the design, development and documentation meets the requirements of the Business. The role will work extensively with IT functions and the role may be matrix-managed when required with tasks assigned by the BAU BI Team  Main responsibilities Design and implement data warehouse solutions and Tabular data models Develop dashboards and reporting to meet business reporting needs Deliver approved projects within timeframe Provide regular updates to management Make recommendations for potential improvement or changes Promote the use of core systems for data capture aligned to standards and initiatives Qualifications  TECHNICAL SKILLS SQL Server 2016 onwards SQL Server BI stack – SSAS / SSIS / SSRS Microsoft Power BI Experience of data cleansing tools and methodologies BUSINESS SKILLS Demonstrated ability to apply IT in solving business problems Good written, oral, and interpersonal communication skills Ability to present ideas in business-friendly and user-friendly language Highly self-motivated, proactive and attentive to detail Ability to effectively prioritise and execute tasks in a high-pressure environment Extensive experience working in a team-oriented, collaborative multi-jurisdictional environment Experience of working in project teams with mixed skillsets and levels of technical knowledge Energy and enthusiasm to support the future growth and success of the business Additional Information All staff are expected to embody our core values that underpin everything that we do and that reflect the skills and behaviours we all need to be successful.  These are: We are AMBITIOUS - We think and act globally, seizing every opportunity to support our clients and staff - wherever in the world they may be. We are AGILE - Our independence from any financial institution gives us the flexibility and freedom to keep things simple, efficient and effective. We are COLLABORATIVE - We take the time to understand our clients' needs so that we can deliver personalised solutions every time. Company Description Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive. When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement. Join Visa: A Network Working for Everyone. Job Description The Marketing, Sales, Services Technology Systems (MSST) Team manage the Customer Relationship Manager (CRM) systems, Business process management (BPM) applications and custom applications for Sales, Services, Marketing and Product teams. The Analytics team within this team integrate data from multiple applications like CRM, Contact Center applications, Appian and build executive and operational reports as well as enable self-service reporting and insights from to empower Business to monitor and track KPIs and make data driven decisions.  The Sr. Data Engineer (ETL/Power BI/SQL) within the Analytics Delivery team will be responsible for solution design, development and implementation of Data integration and Analytics solutions on data platforms (SQL server) and Hadoop. This position requires designing database schemas for reporting, perform data engineering activities using ETL tools like Pentaho and/or scripts to ingest data from multiple applications on the cloud and on premise, build Power BI data sets and enable self- service reporting on Power BI and Hadoop. This position requires close collaboration with Global Sales Business partners and Product owners to understand Business goals and requirements and implement Data Analytics solutions following agile methodologies. This position requires collaboration with multiple global IT teams including application teams, database teams, Infrastructure and Platform teams and respond to changing Business priorities with agility. This position provides Production support for applications, data analysis and requires investigation and resolution of issues. Responsibilities: Participate in Technology project delivery activities such as gathering Business requirements, conceptual technology approach, design, development, enhance and build scalable solutions and support systems in production in a DevOps model. Work as a member of Sales domain scrum teams and provide solutions for complex reporting requirements. Work as a Subject matter expert on data from Sales and Marketing domain. Architect solutions and build data management systems – on premise or on cloud. Understand application systems, architect solution, develop the source to target mapping documents and ETL code to load data from Cloud applications (MS Dynamics) other CRM applications to databases on premise. Develop workflows using ETL tools like Pentaho. Develop database components on premise databases (SQL Server) and/or Hadoop for reporting. Develop Power BI data models and dashboards. Support QA, UAT and performance testing phases of development cycle and implement DevOps principles from development to deployment to production Partner with IT groups such as Engineering, Product, Cybersecurity, and Infrastructure on project delivery activities and security findings remediation. Own Operational support for multiple applications Perform POC and build prototypes based on business and technology requirements. This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs. Qualifications Basic Qualifications: • 2 or more years of work experience with a Bachelor’s Degree or an Advanced Degree in Computer Science/ Engineering, Information Science or a related discipline with strong technical experiences (e.g. Masters, MBA, JD, MD, or PhD). Preferred Qualifications: • Minimum of 2-3 years’ experience with Master’s degree or 4-5 years' experience with Bachelor’s degree in Computer Science/ Engineering, Information Science or a related discipline • Experience of at least four years in building data pipelines and utilizing data engineering techniques like ELT or ETL for building and scaling reporting and Analytical solutions • Strong expertise in Data analysis, writing SQL scripts and hands on experience working on Relational data bases like SQl Server required • Experience building Power BI data models and dashboards required • Extensive experience with ingesting and transforming data using ETL tools like Pentaho, Informatica is required • Experience using FetchXML, DAX functions, implementing Power BI security features required • Experience using MS Dynamics Sales and Services modules nice to have • Experience in provisioning databases and managing application servers (on premise or on cloud) nice to have • Experience with ensuring data quality for reporting and implementing data observability metrics highly desirable • Experience using Hadoop (Hive, Presto, Spark) highly desirable • Experience in Python, PowerShell, job scheduling (Control M) and version control (bitbuket, GitHub), implementing CI/CD for Reporting components nice to have • Experience with embedding dashboards in MS Dynamics, Power apps, Power Automate nice to have • Experience working in Agile methodology owning end to end product solutions • Experience with cloud infrastructure like Azure data lake, Synapse, Snowflake on Azure nice to have • Good Presentation skills and communication skills presenting ideas and insights to Business is highly desired • Experience on Sales and Marketing domain nice to have • Demonstrated analytical rigor, strong attention to detail, team oriented, collaborative, agile and flexible style Additional Information Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law. With a passion to deliver high-end cinematic games, Supermassive Games is carving a unique and exciting path in the games industry. Want to join us on the journey? We’re looking for an experienced BI Analyst/Developer to join our central Management Information Systems (MIS) team. This role will give you the opportunity to work with various groups across the business including publishing, game development, management, finance, and live service, with a view to providing them key performance information on both an ad hoc and regular basis. This is a new and growing team in the company and the knowledge and experience you bring will be instrumental in shaping how we develop and move forward. Role responsibilities: Building reports/dashboards from various onsite/cloud/application data sources for purposes such as game telemetry, project tracking, finance & HR, using appropriate tools. Providing commentary and investigation/analysis of data to highlight meaningful trends and information. Gather requirements and respond to requests from customers for information on an ad hoc basis, or by including new requests into existing reports. Work with team members & customers across the company to identify, learn and understand their data points, key metrics, and other requirements thoroughly. Coordinate with and work alongside other MIS team members to prioritise and manage report delivery. Help build a new game telemetry reporting service within MIS. Requirements Skills and experience: Understanding of metrics and data relevant to video games player telemetry e.g., player activities, retention, cross-product tracking, design metrics, purchases etc. Building secure, live, network accessible dashboards with filtering/slicing capability and good use of visual formats to illustrate and highlight information. Experience using tools such as Azure Data Explorer/SQL DB/Synapse and Power BI. Experience querying large complex data sets from both onsite and cloud sources. Familiarity with SQL, NoSQL, JSON, columnar data e.g. Parquet, and query performance optimisation. Basic understanding of GDPR compliance, particularly relating to PIl  Desirable: Knowledge of data analysis, statistics, and statistical modelling methods relating to financial data and/or live service operations Experience administering and querying data from PlayFab. Knowledge and use of REST API, advanced Excel, VBA, C#, Python, Power Query/Pivot, MS Dynamics, Jet Reports, Jira, SharePoint etc. Experience dealing with cloud data tools and services in Azure and AWS Qualification in computer science, statistics, mathematics, or related discipline. Benefits Why join us? We make big games with small teams - you will play a full and active role Challenging and rewarding projects as standard 25 days annual leave Private health insurance Pension Life assurance x6 time annual salary Quarterly profit related bonus scheme Social events - including large summer party Constantly improving tools and workflow so you can focus on creativity Fast decision-making allows good ideas to flourish We celebrate and nurture talent Our supportive, inclusive and friendly team culture is something we are proud of Work-life balance is something we respect and protect Ultimately, you’ll work on the cutting edge - making innovative and immersive games Company Description We’re the world’s leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business. Job Description OVERVIEW: Make the team that changes the way the world experiences sport. Sportradar is the leading global provider of sports betting and sports entertainment products and services. Since 2001, we have occupied a unique position at the intersection of the sports, media and betting industries; providing sports federations, news media, consumer platforms and sports betting operators with a range of solutions to help grow their business.  Managed Trading Services (MTS) is a holistic solution that enables Wagering Operators to future-proof their business by offering services such as risk management and advanced marketing tools. The Operational Account Management Team, (which sits within MTS) performs an important role by acting as the main point of contact between our growing client base and Sportradar. Subsequently, we’re looking for a dedicated, Business Intelligence Analyst for our OAM department who will support our unit by developing interactive analytical applications, scheduled customer reports and ad hoc customer report requests. The Business Intelligence Analyst will also recommend and implement improvements into our reporting processes that will allow us to automate specific requests coming from our client base.  THE CHALLENGE: Deliver state-of-the-art data analytics and reporting solutions leveraging our data. Development of data visualizations and reports using statistical packages for analyzing datasets (Excel, PowerBI) Periodic reporting: automatic setup and distribution of reports Present ideas and solutions to business users and software developers in a clear and understandable way. Propose new, innovative ways of using data to improve our products and services Participate in Data modelling for reporting and analytics. Co-create and deliver an ambitious business intelligence roadmap in close coordination with various business and technical stakeholders in the Sportradar  YOUR PROFILE: Demonstrated technical expertise in the following areas: business intelligence tools, design & development of data analytics solutions and reports, querying databases. Prior experience working on projects related to data management and/or business intelligence. The successful candidate will be practiced in hands-on development of software or analytics solutions. Knowledge of VBA beneficial. Comfortable presenting to Senior OAM Management with good verbal and written communication skills Experience working with Amazon Redshift, Amazon Athena and/or Microsoft SQL Server are a benefit as is knowledge of Qlik View/Qlik Sense, Qlik NPrinting, NB: Must have previous experience working in the sports betting industry.  Sportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences.  Additional Information Sportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences  Company Description Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region. Job Description Mandatory RequirementOverall 8+  years of experience in IT Industry.Min 3+ year experience working on Data Engineering using Databricks, Redshift, Glue, EMR. Atleast 4 Project experience in Building and maintaining ETL / ELT pipelines for large data sets , complex data and feature engineering processes Must Have skills : AWS Glue, Databricks (DB), AWS Redshift(SQL DW), AWS Athena, AWS EMR, AWS Kinesis, AWS S3, AWS RDS(SQL DB), SQLExperience with NoSQL databases such as DynamoDB, Cassandra, MongoDB. Experience in Real-Time Data Processing using AWS Kinesis, AWS IoT, Apache Kafka ,Structured Streaming and Stream analytics. Experience with SparkCore, Spark Streaming, PySpark, Hive, Impala, SparkSQL, DynamoDB, Kafka, AWS Glue, S3, Kinesis. Sound Knowledge on AWS DevOps and CI/CD tools  like Jira, Confluence, Bamboo, Bitbucket.Hands on experience in RDBMS  like MSSQL,Oracle,Mysql ,Teradata  Qualifications Qualifications - BE, MS, M.Tech or MCA  Additional Information Experience / Knowledge on  Containerizations - Docker , KubernetesExperience with Data Visualization tools Using Quicksight / Tableau  ....Designing Data modelling and Datawarehosuing solutions using tools like erwin etc Experience in designing / Architecting  Datalakes,Delta lakehouse. Sound Knowledge in programming skills such as Python, R. Mentor team members both onshore and offshore to ensure timely and high quality deliverable Good problem solving skills and communication skills. AWS Certified Solutions ArchitectAWS Certified Big Data - Specialty Certification Unternehmensbeschreibung Bei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch. Die Robert Bosch GmbH freut sich auf Deine Bewerbung! Stellenbeschreibung Im Geschäftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen – von hocheffizienten Antrieben über das erste serienreife ABS fürs Pedelec bis hin zu smarten Connectivity-Lösungen. Für eine nachhaltige Mobilität, die Spaß macht. Du bist Expert:in für den Bereich Data Engineering bei Bosch eBike Systems und stellst die relevanten Daten den Nutzern unserer Cloud-basierten Datenplattform zur Verfügung. Du programmierst gerne und beherrschst Python und SQL. Zu Deinem Repertoire zählen außerdem ausgeprägte Kenntnisse über die performante Verarbeitung und Speicherung großer Datenmengen sowohl in Data Lakes als auch in Data Warehouse Systemen. Im Rahmen Deiner Tätigkeit führst Du Code-Reviews durch und definierst Best Practices und Leitplanken für die Entwicklung von Data Pipelines.  Wir unterstützen Dich, damit Du Deine Kreativität in dem Bereich entfalten kannst und bieten Design Reviews mit anderen erfahrenen Kolleg:innen und Interessengruppen an. Du baust Deine Data Pipelines robust und mit einem hohen Fokus auf Observability, um eine einfache Fehleranalyse zu ermöglichen. Zudem übernimmst Du Verantwortung für deine entwickelten Daten Pipelines auch während des Betriebs und entwickelst diese kontinuierlich weiter, um eine optimale Qualität und Zuverlässigkeit sicherzustellen. Du hast Spaß daran, dein Wissen weiterzugeben und agierst als Mentor:in für Junior Kolleg:innen im Team. Es macht Dir Spaß mit dem Daten-Team, den Fachbereichen, der IT und den Kolleg:innen im fachlichen Diskurs die beste Lösung zu identifizieren. Qualifikationen Ausbildung: abgeschlossenes Hochschulstudium (Master/Diplom/Promotion) der Wirtschaftsinformatik oder eines vergleichbaren Studienganges Persönlichkeit und Arbeitsweise: kommunikativ, selbstreflektiert, getting-things-done-Mindset, stetig lernbereit, Interesse für Innovationen im Arbeitsgebiet, eigenverantwortlich, lösungs- und kundenorientiert, pragmatisch und problembewusst Erfahrungen und Know-how: 5 Jahre Berufserfahrung als Data Engineer sowie Erfahrung im Aufbau von zuverlässigen Data Pipelines; Erfahrung in der agilen Softwareentwicklung (SCRUM, Kanban) und Erfahrung in der Datenmodellierung sowie in unterschiedlichen Ansätzen für Daten Architekturen; Erfahrung im Arbeiten in multinationalen Teams Know-How: Breites Wissen über unterschiedliche Technologien im Bereich Big Data Engineering (z.B. Databricks /Spark, Snowflake, Apache Airflow, dbt, Kafka) sowie fundierte Kenntnisse in relevanten Programmiersprachen (Python, SQL, Scala) und CI/CD (Gitlab CI/CD, Jenkins); Außerdem Kenntnisse der Daten-Analyse, des Daten-Managements und der Softwareentwicklung Begeisterung: Spaß daran, Wissen an andere zu vermitteln Sprachen: sehr gute Deutsch- und Englischkenntnisse in Wort und Schrift Zusätzliche Informationen In diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente.  Bewirb Dich jetzt in nur 3 Minuten! Du möchtest Remote oder in Teilzeit tätig sein - wir bieten tolle Möglichkeiten des mobilen Arbeitens sowie unterschiedliche Teilzeitmodelle. Sprich uns gerne dazu an. Du hast Fragen zum Bewerbungsprozess? Nelly Ehrmann (Personalabteilung) +49 711 811 27525 Du hast fachliche Fragen zum Job? Daniel Grimm (Fachabteilung) +49 7121 35 18668 Interessierst Du Dich für diese oder weitere Stellen? Dann bewerbe Dich auf die Virtual JobFair@BOSCH und verschaffe Dir einen Überblick über die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de/events/                                         We are growing rapidly, and looking for a talented Site Reliability engineer to join our team of engineers, designers, and data scientists to work on the development and maintenance of the Faculty Platform. The Role You will be working with truly cutting-edge technology which underpins a new generation of machine learning products produced at Faculty. The tooling you develop will make possible the delivery of high-impact AI applications which are robust, highly available and trusted by our customers.  At Faculty, we’re passionate about productionising machine learning. We believe that both DevOps and MLOps have a huge part to play in realising the promise of AI. We continue to advocate for the development and adoption of MLOps with our partners and the wider community. As an SRE in the Faculty Platform team, you will be central in developing the tools that enable best practices for deploying complex machine learning systems  Who we are Faculty is an applied AI company that helps organisations who have the scale, data, and foresight to adopt AI into their business. We’re helping make AI real across society by providing a unique combination of strategy, software and skills to our customers: everything needed to successfully create value from AI. Founder-led and with over 80 PhDs, we’re a team of specialists with experience across healthcare, finance, government, retail, engineering, construction and a host of other sectors. We believe that AI should be trustworthy, impactful and beneficial across society. Those principles have shaped our work with more than 230 organisations across the public and private sectors as we help them use AI to act faster, make better decisions and understand more deeply. Faculty Platform is core to how we deliver our work. It provides the core algorithms we use to deliver AI solutions, an AI Safety layer to ensure our applications are explainable and fair, components common to robust, performant AI systems, such as data monitoring, workflow management, autoscaling, authentication and authorization, as well as a development and deployment environment for AI applications.  What you will do Co-own our production infrastructure with the rest of the platform team. Design, develop and deploy software that improves the stability, scalability, availability, and security of our solutions. Improve the quality of deployment, monitoring, and security automation tooling to improve reliability and velocity. Resolve issues with our production systems and build solutions to prevent them from reoccurring. Develop tools to assist the product teams with continuous integration and deployment. Support the engineering teams with system design, developing software platforms and frameworks, and security reviews. Run postmortems of production issues. In terms of technology, you will deploy Docker containers on Kubernetes in AWS and GCP, and use CloudFormation and Terraform to automate the deployment of Faculty Platform. You will create continuous integration and deployment on GitLab. You will use Python to automate manual tasks. You will also contribute to the Faculty Platform application layer, which is written in Scala. Requirements Who you are The ideal candidate has a demonstrated passion for technology and building robust and resilient solutions. They can explain complex ideas simply and clearly, and have a focus on getting things done. They possess strong technical skills in computer science and software development, and enjoy keeping up with cutting-edge technologies. You should be a systems expert that can also code with a passion for technology and solving the toughest problems. You should be comfortable jumping in at the deep end and learning new skills on a bleeding edge platform. Experience of containerisation and designing complex applications. Experience building infrastructure as code (for example using Terraform, Ansible, Chef, Puppet, Kops, or AWS CloudFormation). An understanding of common web application architectures. Experience deploying and configuring machines in a cloud environment. Understanding of application deployment strategies and continuous integration. Familiarity with network protocols such as TCP/IP, HTTP and TLS. Understanding of security best practices. Comfortable in a small, high-growth startup environment. Knowledge of Python and *nix systems Knowledge of Scala or other JVM languages is a plus. Post-COVID, we expect most team members will come to the office one or two days a week. We value skills over certificates; speak to us if you think you would be great for the role, but do not have the conventional qualifications. Benefits What we can offer you The Faculty team is diverse and distinctive, and we all come from different personal, professional and organisational backgrounds. We all have one thing in common: we are driven by a deep intellectual curiosity that powers us forward each day. This curiosity pushes us to seek truth and understanding in everything we do, to execute work in a nimble and pragmatic manner, to foster talent in one another and always to challenge assumptions. Faculty is the professional challenge of a lifetime. You’ll be surrounded by an impressive group of brilliant minds working to advance our goal of making artificial intelligence real. Our consultants, product developers, business development specialists, operations professionals and more all bring something unique to Faculty, and you’ll learn something new from everyone you meet. You’ll also have the opportunity to make your mark on a high-growth start-up now poised to expand internationally. Fostering talent is one of our core values, it’s built into our culture and what we offer. Faculty was founded by people who are passionate about continuous learning, and adding value to our people. Some of our benefits….. Genuinely flexible working: We believe people have needs, responsibilities and interests that require something different to a strict working day. We trust people to organise and take accountability for their own work and do our best to support their lives outside Faculty. We provide you with all you need to work from home, including a laptop, keyboard, chair…even Sony headphones! Equity, we want you to benefit from Faculty’s growth and success. Unlimited holidays: We encourage each other to use this time to take a break, work on personal projects, or to spend time with their friends and family. Fantastic private health, optical and dental cover, for you & your family - including 24/7 unlimited virtual private GP appointments and covering pre-existing medical conditions. Access to mental health coaching with Sanctus Breakfast & Lunch daily, and more fruit, drinks and snacks than you could ever eat (for office-based employees). We work hard and make sure we enjoy what we do. So we have frequent socials and informal get-togethers to help make sure you enjoy your time with us. You’ll make friends and professional connections that will last a lifetime. #LI-Hybrid Company Description Wolt is a technology company that makes it incredibly easy to discover and get the best restaurants, grocery stores and other local shops delivered to your home or office. Wolt is not just a delivery app – we’re a technology company building a commerce platform to seamlessly connect our millions of customers with thousands of merchant and courier partners, in real-time across 23 countries and 250+ cities. Our apps (iOS and Android) have the industry’s highest ratings, largely thanks to our customer-first-mindset, which shows in how we build products and run operations. In June 2022 we officially joined forces with DoorDash. Combined, we have a presence in 27 countries, 23 of which operate with the Wolt brand and app. Wolt and DoorDash continue largely independently, with Wolt’s name, brand, product, technology and team. Working in Product Development at Wolt At Wolt, we’re about getting things done. You’ll probably enjoy it here if you like taking ownership, developing yourself and being around friendly, humble and ambitious people.  The behind the scenes of Wolt is run by an awesome bunch of over 400+ planners, builders, designers and data crunchers. We call ourselves Product+, as we’re the very core of Wolt’s products, tools and platforms. To build our products, we work in over 40  cross-functional, independent and autonomous teams. Teams are made up of a mix of talented individuals: engineers, designers, data scientists, analysts, and product leads. Each team takes ownership for solving customer problems in the best possible way. Our Commitment to Diversity, Equity & Inclusion We want to have all sorts of people in our team – people like you and me, and people different from you and me. To be able to work with diverse teammates – when it comes to gender, age, ethnicity, life background, sexual orientation, political views, religion, or any other personal trait – we consciously aim to offer equal opportunity for everyone to work with us. This is because we believe diverse teams make the most thought-through decisions and build things in the most inclusive way. Join us today to build Wolt together! #LI-ZF1 Job Description About the program  The program will last for 4-6 months — you can decide the duration within this frame. The start date of the program is set for June 2023 (we can be flexible here). The internship is paid (3300€/month) and you’ll be assigned to our Finance domain where your existing skills will find their best match in terms of mentorship and tech. We are preferring candidates who are able to continue full-time after the internship period, so this is truly a chance for a career path - today we have numerous members in different product teams who originally started as interns! Analytics at Wolt is a business-critical area that covers three different teams — data science, product data analytics, and business intelligence. The complexity of online delivery, differences between the economics and dynamics of the cities we operate in and vast amounts of data make our work truly interesting! About the team As a BI developer intern, you’ll join our awesome BI Platform team of seven people. Our team is focused on building a performant and reliable BI platform, maintaining and developing best practices for data developers and users as well as ensuring everyone working with data is empowered to do that independently and efficiently. In addition, we work on various data and reporting projects of key importance to Wolt. During the internship, your role will be to work on Financial projects together with a couple of teammates, who would also serve as your onboarding buddies. Your responsibilities • Working on all sorts of data affecting our profitability, ranging from various revenue sources to multiple types of costs related to our business operations. Familiarity with financial data and profit and loss (PnL) statement structure is a plus, but not required, as we will walk you through the basics during the onboarding.  • Cooperation with other BI developers, analysts and data engineers at Wolt, as well as more direct project related stakeholders within the finance & planning domain. • Participating in periodical earnings reporting by producing main business KPIs such as retention and gross order volume that are shared with numerous stakeholders, requiring strong attention to detail from the applicant. • Working on financial metrics and datasets, which involves maintaining and building data pipelines with Airflow and exposing the data in our data warehouse (Snowflake) and providing data in an understandable, ready-to-use format in Looker (our BI tool). Qualifications We use SQL for data collection and processing, and Python for managing this data flow within our data warehouse. Most of the work during the internship relies on the former, thus SQL knowledge is also tested in the application phase. We also hope that you are familiar with the basics of Python or a similar language. Studies in a relevant field (programming, mathematics or finance) might be helpful in excelling in this role, but are not a hard requirement, as we are firm believers in the growth potential of our next teammate. This also means that we want to provide long-term career paths, and thus are prioritizing candidates who are able to continue with us full-time after the internship. We want to welcome people from diverse backgrounds, with an open mindset and curiosity. We hope you are a person who does not refrain from asking questions and proposing improvements, nor a person who is scared of diving deep into financial data. 💙 Ideally, you’re already located in Helsinki or close by to have the possibility to visit the office at least once a week, to work as close as possible with your mentor and team members that are located in Helsinki. We are unfortunately unable to offer relocation or visa support for internships, so you should be eligible for work in Finland for the duration of the program. If you’re offered to stay with us on a permanent basis after the internship, we’ll take care of your work visa if that’s needed. Additional Information 👀 The process is easy: 1 - Read through the assignment instructions carefully. When your solution is ready, put it as a zip file to Google Drive, Dropbox, OneDrive (or similar). Remember to check permissions! If we cannot access the file, we cannot review your solution. Please don’t store your solution in a public GitHub repository during the application period. 2 - Click “Apply now”, fill in your details, and attach your solution. If you have a CV, want to tell us more about yourself and your interests in a cover letter, or have some interesting projects that you’d like to share with us, feel free to include those as well. 3 - Send your application! Please note that the assignment is a mandatory part of the process. Applications without attached solutions won’t be accepted. The deadline is the 22nd of February (end of the day). If you have any questions you can turn to our Talent Acquisition Partner, Zhanna at zhanna.filintseva@wolt.com. Please note that we do not accept applications via email or LinkedIn messages. Company Description Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region. Job Description Mandatory RequirementOverall 8+  years of experience in IT Industry.Min 3+ year experience working on Data Engineering using Databricks, Redshift, Glue, EMR. Atleast 4 Project experience in Building and maintaining ETL / ELT pipelines for large data sets , complex data and feature engineering processes Must Have skills : AWS Glue, Databricks (DB), AWS Redshift(SQL DW), AWS Athena, AWS EMR, AWS Kinesis, AWS S3,  AWS RDS(SQL DB), SQLExperience with NoSQL databases such as DynamoDB, Cassandra, MongoDB. Experience in Real-Time Data Processing using AWS Kinesis, AWS IoT, Apache Kafka ,Structured Streaming and Stream analytics. Experience with SparkCore, Spark Streaming, PySpark, Hive, Impala, SparkSQL, DynamoDB, Kafka, AWS Glue, S3, Kinesis. Sound Knowledge on AWS DevOps and CI/CD tools  like Jira, Confluence, Bamboo, Bitbucket. Hands on experience in RDBMS  like MSSQL,Oracle,Mysql ,Teradata  Qualifications Qualifications - BE, MS, M.Tech or MCA  Additional Information Additional Information Good to have: •    Industry recognized Blockchain certification / course •    Prior experience and knowledge of Hyperledger fabric 2.x and production scale implementation •    Experience with microservices, NoSQL, Version control tools, building CI/CD pipelines •    Experience with any of the cloud platforms - AWS/GCP/Azure •    Domain expertise in supply chain, mobility, industry 4.0 would be a bonus. Additional information - Experience / Knowledge on  Containerizations - Docker , Kubernetes Certifications :  BigData , Azure and Azure architect certification About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to know our team: Partner Development is a team of creative entrepreneurs that develop solutions for Agoda’s accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. In this role you'll get to This role is designed to mainly growth opportunity identification among mid to long tail hotels, experiment execution and data tracking within Partner Development team for the global teams. You will get to work directly with the regional team to design and put in place global experimentation and initiatives to drive tangible impact in each market. Key activities involved include but not limit to: Apply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations Own end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development Build dashboards, identify new and track key metrics to closely monitor team’s performance and identify quick and long term opportunities for improvements Work closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified Support global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization What you'll need to succeed  Bachelor’s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline 4-8 years experience working in a business analysis, data analysis, reporting or business strategy role Excellent problem-solving skills including the ability to analyze and resolve complex problems using data Team player with strong interpersonal, relationship-building, and stakeholder management skills Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala) Data visualization tool experience such as with Tableau or your weapon of choice. Ability to work under pressure in a fast-paced and rapidly changing environment Excellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner  Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Company Description Bosch Global Software Technologies Private Limited is a 100% owned subsidiary of Robert Bosch GmbH, one of the world's leading global supplier of technology and services, offering end-to-end Engineering, IT and Business Solutions. With over 22,700 associates, it’s the largest software development center of Bosch, outside Germany, indicating that it is the Technology Powerhouse of Bosch in India with a global footprint and presence in the US, Europe and the Asia Pacific region. Job Description Overall 8+  years of experience in IT Industry. Min 3+ year experience working on Data Engineering using Databricks,Synapse, ADF. Atleast 4 Project experience in Building and maintaining ETL / ELT pipelines for large data sets , complex data and feature engineering processes Must Have skills : Azure Data factory (ADF), Azure Databricks (ADB), Azure Synapse Analytics (SQL DW), Azure Analysis Services (AAS), Azure Data Lake Storage (ADLS), Azure SQL Database (SQL DB), SQL Experience with NoSQL databases such as cosmosdb, Cassandra, CosmosDB, MongoDB.Experience in Real-Time Data Processing using Eventhub,IoT Hub,Apache Kafka ,Structured Streaming and Stream analytics. Experience with SparkCore, Spark Streaming, PySpark, Hive, Impala, SparkSQL, CosmosDB, Kafka, Azure Data Factory (ADF), Blob, ADLS, EventHub. Sound Knowledge on Azure DevOps and CI/CD tools  like Jira, Confluence, Bamboo, Bitbucket. Hands on experience in RDBMS  like MSSQL,Oracle,Mysql ,Teradata  Qualifications Qualifications - BE, MS, M.Tech or MCA  Additional Information Additional Information Good to have: •    Industry recognized Blockchain certification / course •    Prior experience and knowledge of Hyperledger fabric 2.x and production scale implementation •    Experience with microservices, NoSQL, Version control tools, building CI/CD pipelines •    Experience with any of the cloud platforms - AWS/GCP/Azure •    Domain expertise in supply chain, mobility, industry 4.0 would be a bonus. Additional information - Experience / Knowledge on  Containerizations - Docker , Kubernetes Certifications :  BigData , Azure and Azure architect certification Company Description Wolt is a technology company that makes it incredibly easy to discover and get the best restaurants, grocery stores and other local shops delivered to your home or office. Wolt is not just a delivery app – we’re a technology company building a commerce platform to seamlessly connect our millions of customers with thousands of merchant and courier partners, in real-time across 23 countries and 250+ cities. Our apps (iOS and Android) have the industry’s highest ratings, largely thanks to our customer-first-mindset, which shows in how we build products and run operations. In June 2022 we officially joined forces with DoorDash. Combined, we have a presence in 27 countries, 23 of which operate with the Wolt brand and app. Wolt and DoorDash continue largely independently, with Wolt’s name, brand, product, technology and team. Working in Product Development at Wolt At Wolt, we’re about getting things done. You’ll probably enjoy it here if you like taking ownership, developing yourself and being around friendly, humble and ambitious people.  The behind the scenes of Wolt is run by an awesome bunch of over 400+ planners, builders, designers and data crunchers. We call ourselves Product+, as we’re the very core of Wolt’s products, tools and platforms. To build our products, we work in over 40  cross-functional, independent and autonomous teams. Teams are made up of a mix of talented individuals: engineers, designers, data scientists, analysts, and product leads. Each team takes ownership for solving customer problems in the best possible way. Our Commitment to Diversity, Equity & Inclusion We want to have all sorts of people in our team – people like you and me, and people different from you and me. To be able to work with diverse teammates – when it comes to gender, age, ethnicity, life background, sexual orientation, political views, religion, or any other personal trait – we consciously aim to offer equal opportunity for everyone to work with us. This is because we believe diverse teams make the most thought-through decisions and build things in the most inclusive way. Join us today to build Wolt together! #LI-ZF1 Job Description About the program  The program will last for 4-6 months — you can decide the duration within this frame. The start date of the program is set for June 2023 (we can be flexible here). The internship is paid (3300€/month) and you’ll be assigned to our Merchant group where your existing skills will find their best match in terms of mentorship and tech. We are preferring candidates who are able to continue full-time after the internship period, so this is truly a chance for a career path - today we have numerous members in different product teams who originally started as interns! Analytics at Wolt is a business-critical area that covers three different teams — data science, product data analytics, and business intelligence. The complexity of online delivery, differences between the economics and dynamics of the cities we operate in and vast amounts of data make our work truly interesting! About the team As a BI developer intern, you’ll join our awesome analytics team of BI developers and Data analysts. You’ll be exposed to various business metrics related to merchants from a B2B point of view and build reporting infrastructure that can help these businesses grow on Wolt. During the internship, your role will be to work on one of the Merchant group's projects together with a couple of teammates, who will also serve as your onboarding buddies. The Merchant team is responsible for all data needs related to the Merchant domain and helps various product teams in setting up the right metrics and enabling data-driven decision-making. You will be embedded in the Merchant product team along with your teammates. This means you will work as close as possible where the decisions are made, and hence get to participate in decision-making yourself. Your responsibilities • Working on all sorts of Merchant related data, which involves maintaining and building data pipelines with Airflow and exposing the data in our data warehouse (Snowflake) and providing data in an understandable, ready-to-use format in Looker (our BI tool). • Implementing business metrics and KPIs to create visibility on business or product performance. • Exposing new data points from Snowflake to Looker in an easy-to-use format for further analysis and dashboard development. • Cooperation with other BI developers, analysts and data engineers at Wolt, as well as more direct project-related stakeholders within the Merchant domain. • You would have a chance to contribute to a variety of projects, such as: Building data pipelines for our Merchant Insights tool, where we provide valuable information for our Merchants about their performance Helping our product teams to collect vast amounts of app analytics data and turn that into insights about the new product features. Creating pipelines for possible 3rd party integrations and developing ways to connect that data to our data Qualifications We use SQL for data collection and processing, and Python for managing this data flow within our data warehouse. Most of the work during the internship relies on the former, thus SQL knowledge is also tested in the application phase. We also hope that you are familiar with the basics of Python or a similar language. Studies in a relevant field (programming, mathematics or finance) might be helpful in excelling in this role, but are not a hard requirement, as we are firm believers in the growth potential of our next teammate. This also means that we want to provide long-term career paths, and thus are prioritizing candidates who are able to continue with us full-time after the internship. We want to welcome people from diverse backgrounds, with an open mindset and curiosity. We hope you are a person who does not refrain from asking questions and proposing improvements, nor a person who is scared of diving deep into the Merchant datasets. 💙 Ideally, you’re already located in Helsinki or close by to have the possibility to visit the office at least once a week, to work as close as possible with your mentor and team members that are located in Helsinki. We are unfortunately unable to offer relocation or visa support for internships, so you should be eligible for work in Finland for the duration of the program. If you’re offered to stay with us on a permanent basis after the internship, we’ll take care of your work visa if that’s needed. Additional Information 👀 The process is easy: 1 - Read through the assignment instructions carefully. When your solution is ready, put it as a zip file to Google Drive, Dropbox, OneDrive (or similar). Remember to check permissions! If we cannot access the file, we cannot review your solution. Please don’t store your solution in a public GitHub repository during the application period. 2 - Click “Apply now”, fill in your details, and attach your solution. If you have a CV, want to tell us more about yourself and your interests in a cover letter, or have some interesting projects that you’d like to share with us, feel free to include those as well. 3 - Send your application! Please note that the assignment is a mandatory part of the process. Applications without attached solutions won’t be accepted. The deadline is the 22nd of February (end of the day). If you have any questions you can turn to our Talent Acquisition Partner, Zhanna at zhanna.filintseva@wolt.com. Please note that we do not accept applications via email or LinkedIn messages. Company Description Our brand Deutsche Telekom IT Solutions Slovakia entered the life of Košice region in 2006 under the name of T-Systems Slovakia and ever since has been inextricably linked with the region when became one of the founding members of Košice IT Valley. We have managed to grow from scratch to the second largest employer in the eastern part of the country with more than 3900 employees. Our goal is to proactively find new ways to improve and continuously transform into the type of company providing innovative information and communication technology services. Job Description Purpose Design new solution (standard and non-standard) to fulfill customer requirements. Execute testing and analyzes to identify flaws of the configuration. Create migration concepts and plans describing all necessary steps to deliver successful migration of new solution. Execute and support migrations/implementation of designed solution to deliver new functionality to the customer. Test, validate and document new releases in order to identify flaws and provide migration plan from old to new version of the release. General description Maintenance, improvement, cleaning, and manipulation of data in the business’s operational and analytics tools Leads innovation through exploration, benchmarking, making recommendations, and implementing big data technologies Explore and implement new technologies within area of Cloud based Big Data solutions, like  Databricks, Data Warehouse, Confluent, Spark, HD Insight, etc.. Enabling and running data migrations across different technologies and platforms Build stable, scalable, and repeatable data-driven products Perform, coordinate and improve most complex activities (3rd level environment) needed to provide IT services and the supporting infrastructure in order to fulfill relevant KPI’s Key accountabilities Design, develop, test, implement and support big data cloud based application in order to deliver  quality standard cloud product portfolio Build and develop concepts, processes and methods for automation, optimization and standardization to satisfy  efficiency and automation requirements Analyze complex data elements and systems, data flow, dependencies, and relationships in order to contribute to conceptual physical and logical data models Testing and validation in order to support the accuracy of data transformations and data verification used in machine learning models Managing the life cycle of multiple database tools by enabling smooth upgrades and/or installation and support of new capabilities Contribute to the development of the capacity planning function to properly identify needed hardware, software, database configuration / architecture to support application / business needs Designs, builds, verifies, implements and maintains the structure of databases to support business needs including integration of vendor database solutions into data environment Data munging, manipulation, cleansing and blending from multiple data sources and exposure to various data types and storage paradigms Working with data to solve business problems and will build and maintain the infrastructure to answer questions with data Provide project deliverables in order to fulfil the project scope Provide overall solutions and principles in planning, developing and implementing new cloud products to satisfy  business requirements Mentor developers to spread knowledge level in the team and develop their skills May provide consulting services to project teams on areas of expertise Researches development in assigned technology, determines business requirements, proposes changes and develop implementation plans Qualifications Special technical skills Experience with programming languages (Python,R, Scala_ Experience with Cloud PaaS solution with BigData area (Azure, or AWS) OR Experience with application engineering & Linux OS, Knowledge of data processing methods (Hadoop, Kafka, Spark) Overview of distributed file systems, SQL and NoSQL Databases Knowledge about Data streaming, Data warehousing Background about cloud products in range of data processing Capability of communicating effectively with business and data science leaders on project status, timeline and technical results Education University degree  Experience 3-5  years’ experience in the area of responsibility , valid certification in given technology Languages English C1, German B2 - advantage Others Strong presentation skills, Project leadership skills Valid certification in given technology Additional Information Benefits We believe in balance between work and personal life. An attractive and extensive work-life balance portfolio guarantees lasting motivation for employees and thus a better quality of life, promotes physical and mental well-being and contributes to a positive work environment. All this with the aim of providing more freedom in reconciling work, career growth, private life and individual lifestyle. Therefore we offer to our employees over 25 different benefits to improve their personal and professional life in these areas: Financial benefits Benefits with focus on learning and development Benefits with focus on health and sport Benefits with focus on family and work – life balance Other benefits For more information about our benefits click to Benefits Salary Final salary is negotiable. We are offering base salary depending on seniority level and previous experience of candidate. In addition to base salary we provide variable part and other financial benefits. Base salary will not be lower than 1900 € /brutto. Additional information * Please be informed that our remote working possibility is only available within Slovakia due to European taxation regulation. About Alltrna Flagship Pioneering has conceived of and created companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune’s “Change the World” list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies. Alltrna is the world’s first tRNA platform company to decipher tRNA biology and pioneer tRNA therapeutics to treat thousands of diseases. Alltrna unlocks tRNA biology to correct disease. The company's platform incorporates AI/ML tools to learn the tRNA language and deliver diverse programmable molecules with broad therapeutic potential. Alltrna has an unprecedented opportunity to advance a single tRNA medicine to unify treatment across a wide range of diseases with the same underlying genetic mutation. Alltrna was founded in 2018 by Flagship Pioneering. For more info, visit www.alltrna.com. About The Role  Come join a creative and collaborative team of scientists at Alltrna dedicated to leveraging emerging insights in RNA biology to develop a novel class of human therapeutics. In this role you will apply computational biology methods to turn diverse data streams into scientific insights, which will have a major impact on Alltrna’s tRNA platform. You will develop computational analyses for Next-Generation Sequencing, proteomics, and high-throughput screening data, and will partner with teams throughout Alltrna to visualize and interpret study results. You will contribute to Alltrna’s computational biology strategy, working in partnership with our Machine Learning, Informatics, Computational Chemistry, and leadership team to address computational technology and infrastructure needs. You will also work closely with other wet- and dry-lab scientists to develop, evaluate, and benchmark performance of new molecular and computational methods. Through these collaborations you will help generate hypotheses and design experiments that drive forward our understanding of tRNA medicines. Core Responsibilities  Contribute to Alltrna’s computational strategy in collaboration with colleagues in Machine Learning, Informatics, Computational Chemistry, and the leadership team Develop computational pipelines to analyze NGS data generated using both established and proprietary library preparation methods, whole-cell and targeted proteomics data, and high-throughput screening data Perform exploratory analyses on internal and public data to develop new hypotheses for subsequent wet-lab testing Formulate and evaluate hypotheses that advance our understanding of tRNA medicines through collaboration with other wet- and dry-lab scientists Contribute to improving the software infrastructure underlying analysis pipelines, visualizations, and data apps Develop and implement criteria for evaluating experiment integrity and ensuring pipeline and data robustness Collaborate with our informatics team to automate analysis pipelines and deploy data apps that promote broader-team access to data and analyses Create effective data visualizations and communicate study results to cross-functional teams Qualifications and Skills Ph.D. in computational biology, bioinformatics, or a related field and an additional 5+ years of relevant experience, including 3+ years working with NGS data in an academic or industry setting Expert in Python, common data science packages and bioinformatic toolkits Experience with computational pipeline development and maintenance (snakemake, nextflow, etc) Strong data visualization skills and experience developing data apps (Streamlit/Dash/Flask) Experience with computational notebooks (i.e., Jupyter), version control (i.e., Git), code documentation, coding standards, and unit tests Excellent communication skills and the ability to clearly explain computational analyses and their implications to team members of diverse backgrounds and drive decision-making The preferred candidate will ideally also possess the following skills: Experience working with proteomics, pooled screening, high-throughput screening, and/or single-cell sequencing data Experience working in a cloud computing environment (AWS/GCP) What We’ll Offer You Comprehensive, competitive healthcare and dental coverage through Blue Cross Blue Shield, vision coverage through VSP, family leave, paid time off, 401k retirement plan, disability and life insurance, and fully covered parking/commuter benefits. A dynamic early-stage work environment and highly interdisciplinary, talented, and collaborative team. Participation in an unprecedented opportunity to advance a single tRNA medicine to restore disrupted protein production, regardless of target, for thousands of diseases with the same underlying genetic mutation. Professional growth opportunities through mentoring, training, immersion in cross-functional projects, and opportunities to learn and try new things. Daily on-site snacks, cold brew coffee, and Bevi, as well as weekly catered lunches. Our Core Values Fast-acting/efficient. Moves quickly and proactively with a strong work ethic to produce high-quality results while fostering a positive work environment. Focuses on key priorities. Demonstrates tenacity and willingness to go the distance to get something done. Integrity. Does not cut corners ethically. Earns trust and maintains confidences. Does what is right not just what is politically expedient. Speaks plainly and truthfully. Follows-through on commitments. Expects a high level of personal performance and team performance. Critical thinking. Learns quickly. Demonstrates ability to proficiently understand new information and independently achieve meaningful outcomes. Able to structure and process qualitative/quantitative data and draw insightful conclusions. Creativity & Innovation. Scientifically curious and bold. Generates new and creative approaches to problem solving. Positive ‘can-do’ attitude. Views the toughest challenges as the greatest opportunities for personal growth and company innovation. Able to challenge dogma. Teamwork. Fully engaged in facilitating personal and team success. Reaches out to peers and cooperates with the team to establish an overall collaborative work environment. Often solicits and responds well to constructive feedback. Possesses good written and oral communication skills with the ability to clearly and concisely convey ideas and opinions. Flexibility/adaptability. Adjusts quickly to changing strategic and tactical priorities. Comfortable with ambiguity. Self-starter mentality. Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto. What We’ll Offer You Comprehensive, competitive healthcare and dental coverage through Blue Cross Blue Shield, vision coverage through VSP, family leave, paid time off, 401k retirement plan, disability and life insurance, and fully covered parking/commuter benefits. A dynamic early-stage work environment and highly interdisciplinary, talented, and collaborative team. Participation in an unprecedented opportunity to advance a single tRNA medicine to restore disrupted protein production, regardless of target, for thousands of diseases with the same underlying genetic mutation. Professional growth opportunities through mentoring, training, immersion in cross-functional projects, and opportunities to learn and try new things. Daily on-site snacks, cold brew coffee, and Bevi, as well as weekly catered lunches. Our Core Values Fast-acting/efficient. Moves quickly and proactively with a strong work ethic to produce high-quality results while fostering a positive work environment. Focuses on key priorities. Demonstrates tenacity and willingness to go the distance to get something done. Integrity. Does not cut corners ethically. Earns trust and maintains confidences. Does what is right not just what is politically expedient. Speaks plainly and truthfully. Follows-through on commitments. Expects a high level of personal performance and team performance. Critical thinking. Learns quickly. Demonstrates ability to proficiently understand new information and independently achieve meaningful outcomes. Able to structure and process qualitative/quantitative data and draw insightful conclusions. Creativity & Innovation. Scientifically curious and bold. Generates new and creative approaches to problem solving. Positive ‘can-do’ attitude. Views the toughest challenges as the greatest opportunities for personal growth and company innovation. Able to challenge dogma. Teamwork. Fully engaged in facilitating personal and team success. Reaches out to peers and cooperates with the team to establish an overall collaborative work environment. Often solicits and responds well to constructive feedback. Possesses good written and oral communication skills with the ability to clearly and concisely convey ideas and opinions. Flexibility/adaptability. Adjusts quickly to changing strategic and tactical priorities. Comfortable with ambiguity. Self-starter mentality.     Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.   Recruitment & Staffing Agencies: Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates. The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team. Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto. Company Description Octopus  Octopus is a group of innovative, entrepreneurial businesses investing in the people, ideas and industries that will help to change the world. We are experts in financial services and energy, and we’re also a certified B Corp, meaning we care as much about the impact of our investments as the returns they generate. Today we manage more than £12.6* billion on behalf of retail and institutional investors. Our energy supply business is one of the fastest growing companies in the UK, reaching 3.1 million customers in just five years, and is the only supplier to be recommended by Which? four years in a row.  Octopus Energy, Octopus Giving, Octopus Moneycoach, Octopus Investments, Octopus Renewables, Octopus Real Estate, Octopus Ventures, Octopus Wealth and Seccl Technology are all part of Octopus Group. Visit octopusgroup.com.  *Funds Under Management data includes undrawn commitments, funds under advisory mandates, funds monitored and the Octopus Cash service as of 31st December 2021  Job Description We are looking for a Senior Power BI Developer to join the Data Insights team within Octopus Investments.  This is an opportunity to join a growing team in an exciting period of transformation where you will be at the forefront of shaping how the business uses data & insight.  You will be the ‘go-to PowerBI person’ in the team, spearheading the development and rollout of PowerBI across the business. Core responsibilities will include: Providing end-to-end delivery of enterprise-level Power BI solutions for OI. Gathering, clarifying, and developing requirements with stakeholders. Leading the architectural design, governance, and adoption of Power BI. Using a working knowledge of modern data warehousing frameworks to work closely with the Data Engineering team to define data solutions. Building and delivering Power BI training. Ownership of the Power BI development roadmap. Creating and maintaining complete and accurate solution design documents. Qualifications Essential experience & characteristics: Experience developing end-to-end Power BI reporting and analytics solutions Excellent knowledge SQL, DAX, and Power Query (M) Strong understanding of data modelling concepts Proficiency in data visualisation and report design Experience working in or alongside data engineering teams to deliver data solutions Experience of designing and delivering Power BI training. Great people skills - this role will involve working with lots of internal stakeholders both technical and non-technical. Desire to learn new technologies and continuously develop new skills and expertise. Nice to have: Working knowledge of DBT. Experience of coaching more junior team members. Experience working for a similar, fast paced Financial Services company. Additional Information Our Values  At Octopus we don't just focus on what we do but also how we do it. Everyone shares our values of being straightforward, helpful and bold. And while these are the principles that guide us as an organisation.  What we offer 💰  A competitive salary, bonus, pension and share incentive plan ✈️ Take what you need holiday 🏡 Flexible working  ⚓ Anchor (our wellness hub) which includes Headspace, one to one coaching through Sanctus, Parent Cloud, Digital GP, Shout & more 👪 Enhanced family leave policies ❤️ Life insurance, critical illness cover and income protection 🏥 Private medical insurance for you and your family 🚗 Electric vehicle leasing 🌍 The option to work overseas up to a month per year About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to Know our Team:  Partner Development is a team of creative entrepreneurs that develop solutions for Agoda’s accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. In this role you'll get to As a Data Analyst in the PD Analytics team, you will be using data and modeling techniques to identify opportunities and build models and tools to improve efficiency and effectiveness for Agoda's supply team.  Key activities involved include but not limit to: Apply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations Own end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development Build dashboards, identify new and track key metrics to closely monitor team’s performance and identify quick and long term opportunities for improvements Work closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified Support global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization What you'll need to succeed  Bachelor’s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline 3-6 years experience working in a business analysis, data analysis, reporting or business strategy role Excellent problem-solving skills including the ability to analyze and resolve complex problems using data Team player with strong interpersonal, relationship-building, and stakeholder management skills Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala) Data visualization tool experience such as with Tableau or your weapon of choice. Ability to work under pressure in a fast-paced and rapidly changing environment Excellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner  Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to Know our Team:  The Supply, Operations, Analytics and Programs (SOAP) team is a team of creative entrepreneurs that develop solutions for Agoda’s non-accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek.  Utilizing our strong brand and resources, we build new channels to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.  The Opportunity:   The role sits within the Supply Analytics team under SOAP team of Partner Services, where new business ideas, and partnership types are incubated and scaled. We are looking for a Senior BI Analyst whose main focus areas are providing visibility and insights for people-related issues through Business Intelligence tools like Tableau and SQL, managing data warehouses, building ETL processes, and helping build other tools to optimize the business. This role will be involved in strategic projects and work closely with commercial owners and business stakeholders, using data to identify and translate business needs and opportunities into actionable initiatives. In this Role, you’ll get to: Translate internal briefs into analytical projects (to include refining the initial brief and asking the ‘right questions’, working through potential hypotheses and storyboarding the output) Use and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders. Proactively identify opportunities for growth within supply and the wider business. Drive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply. Identify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence. Automate manual operational processes and present back on time savings gained through modernization of business operations What you’ll Need to Succeed: 4+ years of experience in analytics/data science/insights/strategy. Bachelor’s degree ideally in a business or quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance). 3+ years of experience with BI & analytics tools (SQL, Tableau, Metabase or similar technologies) 2+ years of solid project management Good stakeholder management experience. Comfortable presenting to senior leadership and C-suite. Strong experience in finding data insights and provide business recommendation to the business A hacker’s mindset – the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping. Excellent communicator with superior written, verbal, presentation and interpersonal communication skills. Data driven in both decision making and performance measurement. Extreme comfort in ambiguous, fast-paced environment. Ability to multi-task, prioritize and coordinate resources. It’s Great if you Have:   Travel industry / e-commerce / tech / consulting experience. Experience in conducting A/B testing experimentation (a plus) A good understanding of statistical modelling knowledge or any machine learning technique knowledge is a plus (regression, logistic regression, random forest, etc.)   #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluisdata representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner  Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Overview: The Agoda Content department is currently looking for a curious and questioning self-starter and proactive analyst, who will help drive decision making with insights from content, marketing and partner performance data. You will get the opportunity to own analytical projects to direct our department’s focus, and prioritize our actions. By joining Agoda, you will become part of a truly international team, with leading experts of different backgrounds coming from 50+ countries around the world. This is a genuine opportunity to gain valuable experience in a challenging and cutting-edge tech environment. The ideal candidate would have a passion for high-converting content, great user-experience, data and analysis tools and methods. This position reports to the Associate Director of Content Operations, in Bangkok, Thailand.   Main responsibilities: Understand Content goals and KPIs and be able to align reports and insights based on them. Identify and investigate trends, anomalies and opportunities to improve Agoda’s Content strategy. Identify content opportunities that drive customer value, bookings and conversion Help build business cases around the opportunity and get buy-in from stakeholders Ensure appropriate data/tools/dashboards to measure execution and enable deeper analysis Track execution and report up in regular updates Work with product, data/BI team and IT to create data resources and build appropriate reporting Work with Content team leads to understand their business needs and identify opportunities in terms of team actions prioritization and focus. Use multiple data sources to report Content projects insights and impact; support Content tests and experiments. Encourage and train the Content team in best practice use of Agoda data, analysis techniques and interpretation. Coordinate with other Cross Functional departments like Analytics, Partner Services, and Product Owners Use Web-Analytics for Research and Analysis Requirements: Bachelor degree or higher 2+ years of relevant experience Experience / knowledge in statistics, SQL, Python/R, Tableau and advanced Excel – required Ability to demonstrate data manipulation using data warehouse and create meaningful insight and visualization Experience / knowledge in Vertica and / or Impala – advantage Experience in generating data and / or preparing experiments for product development – advantage Professional characteristics: Attentive to detail and committed to data integrity Keen and curious nature; able and willing to share your opinion Organized; able to manage multiple, competing priorities and deliver results under tight deadlines Able to communicate effectively; fluent in English – both spoken and written #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner  Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to Know our Team:  Partner Development is a team of creative entrepreneurs that develop solutions for Agoda’s accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. In this role you'll get to As a Data Analyst in the PD Analytics team, you will be using data and modeling techniques to identify opportunities and build models and tools to improve efficiency and effectiveness for Agoda's supply team.  Key activities involved include but not limit to: Apply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations Own end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development Build dashboards, identify new and track key metrics to closely monitor team’s performance and identify quick and long term opportunities for improvements Work closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified Support global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization What you'll need to succeed  Bachelor’s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline 3-6 years experience working in a business analysis, data analysis, reporting or business strategy role Excellent problem-solving skills including the ability to analyze and resolve complex problems using data Team player with strong interpersonal, relationship-building, and stakeholder management skills Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala) Data visualization tool experience such as with Tableau or your weapon of choice. Ability to work under pressure in a fast-paced and rapidly changing environment Excellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Company Description Vericast is a premier marketing solutions company that accelerates profitable revenue growth for the thousands of businesses it serves directly by influencing consumer purchasing and transaction behavior at scale while engaging with over 120 million households daily.  We are recognized as leading providers of incentives, advertising, marketing services, transaction solutions, customer data and cross-channel campaign management, and intelligent media delivery that create millions of customer touch points annually for their clients.  For more information, visit http://www.vericast.com or follow Vericast on LinkedIn. Job Description Valassis Digital (a division of Vericast) is seeking a Principal Software Engineer to develop services, tools, bots, and workflows for our big data processing infrastructure. The Big Data Platform Team owns and operates the world-class big data processing infrastructure that over a dozen engineering teams use to power their 24/7 technical marketing products. We own and operate a large hadoop+spark processing cloud on which we store 6PB of data, and run 30 thousand jobs every day. We write a fabric of java microservices and bots to manage all those jobs, extend hadoop's functionality, and help us operate and optimize our investment. We write custom data streaming services that ingest and curate 100TB of data each day that drives the entire advertising data ecosystem. We also participate in all our users' groundbreaking workflow projects so that we can constantly stay abreast of our developer's tooling needs. What you're like: This position is perfect for a far-sighted engineer who always wants to be the first to apply cutting-edge technologies to solve complex business and engineering problems. You want to have a leading voice on our team and across our organization. You will work throughout the software lifecycle including customer interaction and product planning, requirements analysis, architecture, directing our team of developers, development, testing and operations. If you are energized by the thought of developing new system stacks and tools for big data processing and analytics we want to talk to you. If you have worked on big data engineering, cloud migration, or infrastructure tooling projects, we want to talk to you. If you have ever worked on a collection of data workflows or a service mesh and thought 'I could make this better', we want to talk to you! What you'll do: Work with our users, architects, and product leaders to architect and plan our data platforms Design, develop, and maintain the software and systems that make up the data platform that runs our entire business Partner with the Data Engineering and Data Science teams who use our platform to diagnose, predict and address scaling problems Work on new products initiatives to provide design support and establish best practices Contribute to our team’s growing set of development platforms, tools, processes, and products Qualifications Experience working on big data systems and technologies with emphasis on the Hadoop platform General knowledge of design patterns & UML with a few years of taking a lead on architectural design and development Proficiency in Java, Scala, or Python programming; exposure to microservices and Spark dataframe programming. Proficiency in networking, Thrift, Spring Framework and/or Spring Boot for microservices is a plus.  Understand RDMS and proficiency in DML, SQL & PL/SQL a plus Hands on experience with Spark; exposure to Kafka and YARN or similar technologies Experience with migration of infrastructure from on-prem to cloud or vice versa is a big advantage Curiosity to learn and apply new technologies and a background full of diverse design challenges Excellent problem-solving abilities Excellent verbal, graphical, and written communication skills Experience with agile development methodologies  Your qualifications: BS/MS in Computer Science or other technical discipline (with significant computer coursework) 10+ recent years of professional software development experience using java, scala, or python 3+ recent years working with the hadoop+spark big data platform or similar Additional Information Salary:  180,000-200,000 with 10% bonus opportunity The ultimate compensation offered for the position will depend upon several factors such as skill level, cost of living, experience, and responsibilities. Vericast offers a generous total rewards benefits package that includes medical, dental and vision coverage, 401K and flexible PTO. A wide variety of additional benefits like life insurance, employee assistance and pet insurance are also available, not to mention smart and friendly coworkers! At Vericast, we don’t just accept differences - we celebrate them, we support them, and we thrive on them for the benefit of our employees, our clients, and our community. As an Equal Opportunity employer, Vericast considers applicants for all positions without regard to race, color, creed, religion, national origin or ancestry, sex, sexual orientation, gender identity, age, disability, genetic information, veteran status, or any other classifications protected by law. Applicants who have disabilities may request that accommodations be made in order to complete the selection process by contacting our Talent Acquisition team at talentacquisition@vericast.com. EEO is the law. To review your rights under Equal Employment Opportunity please visit: www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf. #LI-TE1 #LI-Remote Company Description Through Columbia University's Pre-College Programs, high schoolers from around the globe prepare for the college experience through exploratory coursework and community activities over seven weeks in the summer. This highly selective program is open to academically exceptional high school students, entering grades 9–12 and freshman year of college. Job Description Columbia University’s Pre-College Programs for High School Students is seeking qualified candidates to develop and teach on-campus (i.e., in person) during Summer ’23.  Please Note: Course(s) and course availability is subject to change.   Three week courses (Sessions 1 & 2): Big Data, Machine Learning, and their Real World Applications Course descriptions and schedule information can be found via the links above.  On Campus Dates: All classes meet during the day Monday-Friday Session 1: June 26th - July 14th Session 2: July 18th - August 4th Responsibilities: Develop course content, syllabus, lesson plans, and assigned work Lead and attend all in-person class sessions Establish and maintain a dynamic in-class environment tailored for our high school population Evaluate student work and write a holistic evaluation of each participant after the course ends Monitor and address student concerns and inquiries (you will have around 20-24 students) Attend and complete all required online trainings Qualifications Graduate degree or equivalent professional or academic background Expertise in the pertinent subject matter Aptitude for teaching Additional Information Hiring Salary Ranges:  Sessions 1 & 2 on-campus: $6,150-$7,850 Please specify which session(s) you would be interested in teaching.  Course descriptions and schedule information are available via the links above. Please submit a resume inclusive of teaching experience as well as formal teaching evaluations (if available) Applicants must have U.S. work authorization and will need to be in the U.S. while teaching Applicants may not hold a concurrent appointment with Columbia for the duration of their appointment Once hired, applicants are required to submit to a third party background check and complete Protection of Minors training in addition to other training(s) mandated by the University  All Columbia University faculty and staff must follow the COVID-19 vaccination protocol. Learn more about the vaccination requirements here: https://covid19.columbia.edu/ All your information will be kept confidential according to EEO guidelines. Columbia University is an Equal Opportunity/Affirmative Action employer.   About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Overview: The Agoda Content department is currently looking for a curious and questioning self-starter and proactive analyst, who will help drive decision making with insights from content, marketing and partner performance data. You will get the opportunity to own analytical projects to direct our department’s focus, and prioritize our actions. By joining Agoda, you will become part of a truly international team, with leading experts of different backgrounds coming from 50+ countries around the world. This is a genuine opportunity to gain valuable experience in a challenging and cutting-edge tech environment. The ideal candidate would have a passion for high-converting content, great user-experience, data and analysis tools and methods. This position reports to the Associate Director of Content Operations, in Bangkok, Thailand.   Main responsibilities: Understand Content goals and KPIs and be able to align reports and insights based on them. Identify and investigate trends, anomalies and opportunities to improve Agoda’s Content strategy. Identify content opportunities that drive customer value, bookings and conversion Help build business cases around the opportunity and get buy-in from stakeholders Ensure appropriate data/tools/dashboards to measure execution and enable deeper analysis Track execution and report up in regular updates Work with product, data/BI team and IT to create data resources and build appropriate reporting Work with Content team leads to understand their business needs and identify opportunities in terms of team actions prioritization and focus. Use multiple data sources to report Content projects insights and impact; support Content tests and experiments. Encourage and train the Content team in best practice use of Agoda data, analysis techniques and interpretation. Coordinate with other Cross Functional departments like Analytics, Partner Services, and Product Owners Use Web-Analytics for Research and Analysis Requirements: Bachelor degree or higher 2+ years of relevant experience Experience / knowledge in statistics, SQL, Python/R, Tableau and advanced Excel – required Ability to demonstrate data manipulation using data warehouse and create meaningful insight and visualization Experience / knowledge in Vertica and / or Impala – advantage Experience in generating data and / or preparing experiments for product development – advantage Professional characteristics: Attentive to detail and committed to data integrity Keen and curious nature; able and willing to share your opinion Organized; able to manage multiple, competing priorities and deliver results under tight deadlines Able to communicate effectively; fluent in English – both spoken and written #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Company Description In India, Bosch is a leading supplier of technology and services in the areas of Mobility Solutions, Industrial Technology, Consumer Goods, and Energy and Building Technology. Additionally, Bosch has in India the largest development center outside Germany, for end to end engineering and technology solutions. The Bosch Group operates in India through twelve companies.  Bosch set-up its manufacturing operation in 1951, which has grown over the years to include 18 manufacturing sites, and seven development and application centers. Bosch Group in India employs over 31,000 associates and generated consolidated revenue of about ₨. 21,450 crores* (2.66 billion euros) in 2018 of which ₨. 15,824 crores* (1.96 billion euros) from third party. The Group in India has close to 18,000 research and development associates. Job Description Shape the future: As data scientist you will translate business needs into technical solutions and help to develop advanced models for the analysis of large-scale data. Act customer-oriented: You support the local and global controller community with the implementation of an AI based forecasting tool. Live Cooperation: You become part of our Controlling team in Bangalore and work in an interdisciplinary project across the time-zones. Take responsibility: You will be responsible to further develop and implement predictive analytics solutions for our internal customers. Qualifications Education: Successfully completed degree (min. Bachelors) in the field of data science, computer science or in the commercial field, with focus on data science or computer science. Experience: Ideally 2+ years with predictive analytics or machine learning algorithms. Time series knowledge is a plus. Additional Information Personality: Keen to learn new technologies and share knowledge, a team player with strong analytical and problem solving skills, eager to take on responsibility. Working style: Independent, structured and solution-oriented. Know-How: MS Excel, Phyton, KNIME, MS PowerBI Enthusiasm: Interested in controlling in connection with IT tools as well as fun and understanding of numbers and complex interrelationships Languages: fluent in English (written and spoken) Description de l'entreprise La mission de CS GROUP : être à la pointe des technologies pour garantir la sécurité de tous dans un monde en pleine mutation. L’expertise reconnue du groupe lui permet d’intervenir là où les enjeux sont les plus critiques : aéronautique, défense, énergie, spatial. Et, aussi, là où les réponses sont à inventer ou à réinventer : lutte anti-drones, cybersécurité… Notre esprit Tech et pragmatique, ainsi que notre agilité d’ETI nous permettent d’allier proximité, engagement et innovation, pour diffuser notre culture à tous les niveaux : dans la relation client, dans le mode de management interne, dans notre engagement social et environnemental… Et bien sûr, dans le développement de votre carrière, notre ambition est de faire de vous un collaborateur accompli : formations, revue de carrière, mobilité, programme ambassadeur… Nous sommes engagés à vos côtés, au service de votre épanouissement professionnel ! Description du poste Nous recrutons un.e Architecte Plateforme Big Data pour rejoindre notre Business Unit INDUSTRIE au sein de la Business Line Digitalisation Processus & Applications Métier. Elle accompagne nos clients dans leurs problématiques associées à la transformation digitale. Nos offres se déclinent autour de la digitalisation des processus industriels et du SI Métiers. Votre mission : Dans un contexte technologique et motivant, où la curiosité technique est nécessaire, vous serez intégré à l’équipe en charge des plateformes Big Data. Votre mission sera de configurer des serveurs, plateformes et services pour les solutions Big Data à destination de différents groupes utilisateurs ou équipes de développement dans un contexte Agile et DevOps. Vous réaliserez différentes activités parmi celles dont l’équipe est en charge : - Comprendre les besoins et identifier les différentes briques qui vont y répondre ; - Participer à la réalisation de POC, à la configurations des plateformes et aux déploiements ; - Administrer les plateformes, gérer et planifier les activités d’opérations et de monitoring ; - Assurer le support techniques aux équipes des projets hébergés ; - Assurer la veille technologique et participer à la démarche d’amélioration continue ; - Faire le suivi technique des activités et le reporting au responsable de service. Environnement technique : - Linux (Redhat), Windows Server - IaC : Ansible, CDK, Terraform - Monitoring : Prometheus, Nagios, Ambari, Splunk, Grafana - Sécurité : AD / Kerberos… - IAM : SSO solutions, Keycloak - Conteneurisation :  Kubernetes, Docker, Helm - Langages : Python, Bash, Spark, Java - Stockage : S3, Private object storage, DFS, NFS. Qualifications Qui êtes-vous ?  De formation ingénieur informatique ou équivalent universitaire (Bac+5), vous avez au moins 3 ans d’expérience. La maîtrise des environnements Big Data, plateformes et outils, notamment Hadoop (HDP), Kubernetes (Rancher), Spark, Elasticsearch et AWS, est nécessaire à l’exercice de votre fonction. Vous avez des compétences dans les domaines de la sécurité et de la gestion des identités et accès (IAM). Un niveau d’anglais courant est requis. Vous êtes organisé.e et vous savez faire preuve de capacité d’analyse ? Vous êtes curieux.se et rigoureux.se, et avez le sens du service client ? Alors vous êtes la pépite que nous recherchons ! A compétences égales, ce poste est ouvert aux personnes en situation de handicap. Informations supplémentaires Qui sommes-nous ? La Business Unit INDUSTRIE contribue aux développements de programmes dans les domaines de la simulation, la transformation digitale et le développement de systèmes critiques. Elle est un acteur référent sur l’Intelligence de la donnée (Data Engineering & Data Science), la digitalisation des processus (PLM), la simulation numérique, le développement de logiciels embarqués & certifiés ainsi que la sécurisation des systèmes (cybersécurité). Pourquoi choisir CS GROUP ? Pour notre filière Expert qui valorise vos compétences techniques, notre engagement dans l’innovation avec un budget R&D de 30 millions d’euros/an, nos engagements sociétaux et environnementaux : index d’égalité professionnelle à 86/100, partenaire de l’association Elles bougent, membre de la planète Tech Care etc. Et bien sûr : la possibilité de télétravailler, un programme de cooptation, la complémentaire santé, les RTT, le CE. N’attendez plus, partagez votre CV et additionnons nos talents ! La suite des événements : Si votre profil est un match, vous aurez un entretien technique avec un de nos Responsables opérationnels. Puis, vous rencontrerez Emeline lors d’un entretien RH.    #CSGROUP #hiring #LI-Hybrid #LI-EQ1 #DevOps Definitive Logic has a unique opportunity for a Business Intelligence (BI) Solution Developer to join our tightly knit team supporting the implementation and deployment of a Cloud software solution. We are an award-winning company that cares about its customers and its employees, and we are a recognized consulting leader in Corporate Performance Management services.  We offer great benefits, a casual work environment, volunteer hours to help the community, and training.  If you want to work with a great team that provides growth and training opportunities, we want to talk with you.  We are only looking for people who want to join our team as regular, full-time employees.  We want to continue building our corporate knowledge and invest in making our employees the best in the business. Roles and Responsibilities include but not limited the following: Apply standard industry practices and methodologies to develop, deploy, and maintain BI interfaces, those include query tools, data visualization and interactive dashboards, ad hoc reporting, and data warehousing tools Background development data solutions and can operate in a fast paced, highly collaborative environment Assist in the development of dashboards and other data visualizations Assist in all conversion, design, and training activities throughout program planning and execution Required Qualifications Bachelor's degree or higher in Computer Science, Engineering, Information Systems, Mathematics, Business, Accounting or related degree Experience consulting or delivering solutions to federal clients Minimum of 8 years of work experience in a technical field with at least 2 years of hands-on experience with BI platforms to include Tableau, Microsoft Power BI, Qlik, etc The ability to obtain a DoD Secret Security Clearance Desired Qualifications General knowledge of federal financial management processes and requirements SQL experience with Oracle databases or SQL Server, or other industry standard DB platforms Tableau development experience Experience working with Redshift, AWS or other Cloud Platforms Active DoD Secret Clearance About Definitive Logic Definitive Logic (DL) is a management and technology consulting firm known for delivering outcomes and ROI for agencies’ most complex business challenges.  DL delivers performance-based and outcome-driven technology consulting solutions that directly support the strategic intent of our Defense, Homeland Security, Emergency Management, Federal Civilian and Commercial clients. We’re the preferred technology integration partner for Federal agencies to apply the best of data science, app dev, DevSecOps, cyber and cloud solutions to improve decision support, empower front-line employees and enhance back-office operations. We serve as trusted advisors providing objective, fact-based, vendor & technology-neutral consulting services.  Definitive Logic is ultimately a team of problem solvers — thought leaders, domain experts, coders, data enthusiasts, and technophiles.  Our exciting projects and learning and sharing culture have consistently resulted in validation as a Great Place to Work: 2023 Washington Post Top Workplaces (8-time winner) | 2023 Virginia Best Places to Work (10 years running, #1 midsize in 2019).  Definitive Logic is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action Employer, making decisions without regard to race, color, religion, creed, sex, sexual orientation, gender identity, marital status, national origin, age, veteran status, disability, or any other protected class. If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable, or limited in your ability, to use or access our Careers page: https://www.definitivelogic.com/careers/open-opportunities/ as a result of your disability. You can request a reasonable accommodation by sending an e-mail to Recruiting@DefinitiveLogic.com or via phone: 703-955-4186. In order to quickly respond to your request, please use the words "Accommodation Request" as your e-mail subject line. DL BenefitsHealthDentalVisionLife/AD&D: Company paid STD/LTD:Company paidSupplemental Plans: TriCare Supplement, Pet Insurance through Nationwide, Legal Resources and hospital/accidental indemnity plans and Wellness initiatives. Compensation Benefits:Competitive Base SalaryAnnual performance based bonus401(k) & Roth option: You are fully (100%) vested on day 1 and DL matches up to 5%Spot Bonuses Referral Bonuses Additional Benefits:Flexible Time Off (FTO): Under our FTO plan, there is no cap in the amount of leave you choose to take, with proper coordination and prior approval.Volunteer Hours: DL allocates up to 8 hours for you to use every year to volunteer for a 501c3 organization of your choice and DL will donate to that charity based on how many hours you volunteer.Cell Phone Reimbursement: $80/monthLocation Specific Metro/Parking Tuition Reimbursement Training & Certifications Company Description We’re over 2,700 strong across the globe. We’re scientists, strategists, creatives, and innovators. We value individual brilliance and build a strong foundation for Teamwork across all our business. We love the challenge of our industry. We’re changing lives and redefining success every step of the way. You are dynamic. You are curious. You are more than your job. For you, excellence isn’t just a word; it’s the measure for all you do. You’re passionate. Driven. Dedicated. You can’t stand mediocrity. And you might be the team member we're looking for.  Job Description PSI CRO is looking for a hands-on, experienced Database Architect & ETL Developer who is a visionary, self-directed and comfortable supporting the various data & analytics needs of multiple teams, systems, and products. In this role, the Database Architect/ETL Developer will be responsible for requirements, analyzing, designing, coding & testing various databases & ETL processes required by the Data Platform team to build world class data lakes, databases, and data repositories utilizing both Microsoft SQL Servers as well as cutting-edge Azure cloud data technologies. Requirements: Demonstrated ability to have successfully completed multiple, complex technical projects and create high-level design and architecture of the solution, including class, sequence, and deployment infrastructure diagrams. Develop and maintain documentation of the data architecture, data flow and data models of the data warehouse appropriate for various audiences. Ensure new features and subject areas are modelled to integrate with existing structures and provide a consistent view. Provide input on Azure technologies and industry best practices in the field of data warehouse architecture and modelling. Take ownership or assistance of technical solutions from design and architecture perspective for projects from conceptual phase through architecture, feasibility, design, and implementation Maintain, monitor, upgrade and secure the SQL Server/Azure platform in partnership with established vendor. Develop ETL (extract, transform and load) processes to populate Data Marts and Warehouses Develop systems integrations across between traditional databases and modern Cloud APIs. Follow established Software Development Lifecycle (SDLC) activities and AGILE including Analysis, Design, Development, UAT, Pilot, Testing & lessons learned. Design, model and develop across both Relational Databases and Data Warehouse and Synapse Troubleshoot data integrations/data feeds between systems. Qualifications 5+ Years’ Experience in SQL Server Database Management 5+ Years’ Experience in SQL Server Database Development and SQL scripting (T-SQL) Must have experience with at least one end to end implementation of Azure cloud data warehouse Expertise in Azure – data modelling, ELT using Azure ADF pipelines, implementing complex stored Procedures and standard DWH and ETL concepts. Expertise in Azure advanced concepts like setting up resource monitors, RBAC controls, virtual warehouse sizing, query performance tuning, Zero copy clone, time travel and understand how to use these features. Expertise in deploying Azure features such as data sharing, events, and lake-house patterns Hands-on experience with Azure utilities, PySpark, ADF, Synapse, Big Data model techniques using Python or similar. 3+ years of hands-on experience with on prem and Azure Data warehouse, ETL, BI projects, Azure Synapse. Additional Information If you feel it is time to make your skills and knowledge visible within a growing company with true focus on its people, then PSI is the right choice for you. Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. As digital pioneers with 20,000 people and 53 offices around the globe, our experience spanning technology, data sciences, consulting and customer obsession – combined with our culture of curiosity and relentlessness – enables us to accelerate our clients’ businesses through designing the products and services their customers truly value. Publicis Sapient is the digital business transformation hub of Publicis Groupe. For more information, visit publicissapient.com. Job Description Publicis Sapient is looking for Senior Manager  (in-office 2-3 days per week) to join our team of bright thinkers and doers. You will team up with top-notch technologists to enable real business outcomes for our enterprise clients by translating their needs into transformative solutions that provide valuable insight. Working with the latest data technologies in the industry, you will be instrumental in helping the world’s most established brands evolve for a more digital future. Your Impact:  Work closely with our clients providing evaluation and recommendations of design patterns and solutions for data platforms with a focus on batch, near-real time, structured and unstructured data  Define SLAs, SLIs, and SLOs with inputs from clients, product owners, and engineers to deliver data-driven interactive experiences  Provide expertise, proof-of-concept, prototype, and reference implementations of architectural solutions for Azure Data Platform Provide technical inputs to agile processes, such as epic, story, and task definition to resolve issues and remove barriers throughout the lifecycle of client engagements Creation and maintenance of infrastructure-as-code and CI/CD for Azure environment using tools such as Terraform and Ansible Mentor, support and manage team members Qualifications Your Skills And Experience:  Demonstrable experience in enterprise level data platforms involving implementation of end-to-end data pipelines  Hands-on experience with at Azure   Experience with column-oriented database technologies (e.g., Synapse), NoSQL database technologies (e.g., DynamoDB, Cosmos DB, etc.) and traditional database systems (e.g., SQL Server, Oracle, MySQL) Experience in architecting data pipelines and solutions for both streaming and batch integrations using tools/frameworks like Azure Data Factory, Azure functions and Stream analytics  Metadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, and Azure Purview Test plan creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks Data modeling, querying, and optimization for relational, NoSQL, timeseries, graph databases, data warehouses and data lakes Data processing programming using SQL, Python, and similar tools Logical programming in Python, Spark, PySpark, Java, Javascript, and/or Scala Cloud-native data platform design with a focus on streaming and event-driven architectures Participate in integrated validation and analysis sessions of components and subsystems on production servers Data ingest, validation, and enrichment pipeline design and implementation SDLC optimization across workstreams within a solution  Bachelor’s degree in Computer Science, Engineering, or related field Set Yourself Apart With:  Certifications in Azure  Experience working with code repositories and continuous integration Understanding of development and project methodologies Additional Information Pay Range:$108,000 -$210,000 Benefits of Working Here: Flexible vacation policy; time is not limited, allocated, or accrued 16 paid holidays throughout the year Generous parental leave and new parent transition program Tuition reimbursement  Corporate gift matching program  As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at hiring@publicissapient.com or you may call us at +1-617-621-0200. At Databricks we work on some of the most complex distributed processing and machine learning problems in the world and our customers challenge us daily with interesting new big data and AI use cases. As Director, Resident Solutions Architects at Databricks, you will provide strategic leadership for delivering professional services engagements to high-value Databricks customers, helping shape the future big data and machine learning landscape for leading Fortune 500 organisations. You will report directly to the regional Vice President of Field Engineering. In the Director, Resident Solutions Architects role, you will will lead a team of exceptional Resident Solution Architects, responsible for core aspects of building and managing the Resident Solutions Architect team. Through your oversight and mentorship, this team will guide our largest customers, implementing pipelines spanning data engineering through model building and deployment, plus other technical tasks to help customers get value out of their data with Databricks. Your responsibilities will include hiring and developing the team, and providing oversight of customer projects to ensure they are managed and delivered to target and exacting standards.   The impact you will have: You will achieve regional team targets for billable utilisation and hiring You will partner with account executives, customer success and field engineering leaders while guiding Resident Solutions Architects to achieve success with professional services projects with customers Help resolve customer concerns on strategic accounts and professional services engagements Analyze operational processes, escalation procedures and perform training needs assessments for identifying opportunities for services delivery improvements and contribution to customers. Manage a team of Resident Solution Architects and act in a supportive manager capacity, including handling escalations, mentoring team members, building a career path for the assigned team members. What we look for: Great at hiring qualified candidates and mentoring / growing leaders Have experience in hiring, mentoring and growing Team Leads, Managers & Senior Managers Have experience scaling field and/or technical teams from scratch to 50+ - ideally at hyper-growth speed Great at instituting processes for technical field members to drive efficiency and effectiveness Have experience in building and operationalising a technical specialist Leadership experience experience managing consultant/delivery teams or solution architects Significant prior individual contributor experience, as a hands-on technical solutions architect that will allow you to act in a supportive manager capacity with technical architects that report to you Experience driving software platform adoption in Fortune 500 organisations in markets such as: Finance, Media, Retail, Telco, Energy, and Healthcare Implement a project schedule with experience with customer engagement Experience with Databricks products, Spark ecosystem, and direct competitors Up to 30% of travel (depending on Covid regulations) Benefits Private hospital plan and extras coverage Life, disability and income protection coverage Superannuation Equity awards Paid parental leave Gym reimbursement Annual personal development fund Work headphones reimbursement Business travel insurance Mental wellness resources About Databricks Databricks is the lakehouse company. More than 7,000 organizations worldwide — including Comcast, Condé Nast, H&M and over 50% of the Fortune 500 — rely on the Databricks Lakehouse Platform to unify their data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world’s toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook. Our Commitment to Diversity and Inclusion At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.   Compliance If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone. Job Description This is a new role for a BI Developer to develop Business Intelligence Solutions for internal customers. Solutions developed are used to aid process and drive business decisions in all departments.  Interacting with key stakeholders at all levels of business the role has a strong customer focus. The successful candidate is expected to work collaboratively with their internal customers to provide solutions that are accurate, have integrity and are of value to the business.  Please note that while the role will come under our hybrid working policy it will require the successful candidate to come into the office two days per week at our head office in Salford Quays. What does the job involve? The key responsibilities of the role are as follows: Identifying and refining data and reporting requirements from key stakeholders. Develop reporting. Visualising and reporting data findings creatively in a variety of formats. Thinking strategically about uses of data and how data use interacts with data design. Performing data studies and data discovery around new data sources or new uses for existing data sources. Data extraction from multiple sources for reporting purposes. Core Competencies and skills:  Microsoft BI Stack - SSRS, SSIS SQL Server 2014-2019 Visual Studio Data Warehouse knowledge Comfortable commenting code and documenting solutions Comfortable with source controlling developments (Git/Bucket) Able to adhere to coding and development standards Good knowledge of IT products and systems Good analytical and problem-solving skills Good communication skills and comfortable working with both technical and non-technical teams Able to prioritise work effectively and multitask MS Office including Word, Excel, Outlook, and PowerPoint Customer focused Flexible approach to work - team player Adaptable to changing environment. Embraces continuous self-learning Desirable competencies and skills: Knowledge and experience of creating Data Marts Power BI – DAX, Power Query Python Power Shell Performance Tuning JIRA / Confluence. Analysis of large data sets AJ Bell is one of the fastest-growing investment platform businesses in the UK offering an award-winning range of solutions that caters for everyone, from professional financial advisers, to DIY investors with little to no experience. We have over 449,000 customers using our award-winning platform propositions to manage assets totalling more than £71.5 billion. Our customers trust us with their investments, and by continuously striving to make investing easier, we aim to help even more people take control of their financial futures. Having listed on the Main Market of the London Stock Exchange in December 2018, AJ Bell is now a FTSE 250 company. Headquartered in Manchester with offices in central London and Bristol, we now have over 1100 employees and have been named one of the Sunday Times ‘100 Best Companies to Work For’ for five consecutive years. There are opportunities for growth and professional development for employees wanting to progress within their career including induction training and our study support scheme which is part of our benefits package. There is an active programme of social events throughout the year, which are open to all employees. In return we will provide all the training and support you need in order to develop within your role. What we offer: Competitive starting salary Generous holiday allowance of 25 days, increasing up to 30 days with service, plus bank holidays Holiday buy/sell scheme Hybrid working policy Casual dress code Discretionary bi-annual bonus Contributory pension scheme Buy as you earn share scheme Free shares scheme Paid study support for qualifications Enhanced maternity/paternity scheme from day one Bike loan Season ticket loan portal Discounted PMI and Dental On-site gym and personal trainer led classes Paid volunteering opportunities Free social events and more AJ Bell is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and all employees are empowered to bring their whole self to work. We do not discriminate on the basis of race, sex, gender identity, sexual orientation, age, pregnancy, religion, physical and mental disability, marital status and any other characteristics protected by the Equality Act 2010. All decisions to hire are based on qualifications, merit and business need. Leading the future in luxury electric and mobilityAt Lucid, we set out to introduce the most captivating, luxury electric vehicles that elevate the human experience and transcend the perceived limitations of space, performance, and intelligence. Vehicles that are intuitive, liberating, and designed for the future of mobility. We plan to lead in this new era of luxury electric by returning to the fundamentals of great design – where every decision we make is in service of the individual and environment. Because when you are no longer bound by convention, you are free to define your own experience. Come work alongside some of the most accomplished minds in the industry. Beyond providing competitive salaries, we’re providing a community for innovators who want to make an immediate and significant impact. If you are driven to create a better, more sustainable future, then this is the right place for you. You will play one of the leading roles in the implementation of core enterprise systems for Lucid, including cross-functional business processes, coordination of core business data, and delivery of business enabling solutions.  You will bridge the technical and functional worlds while engaging with broad functional teams, including Supply Chain, Purchasing, Logistics, Manufacturing, Finance, HR, and Engineering. To be successful in this role, you will need to establish strong partnerships and have a hands-on approach to managing data and business processes from the ground up. As a result, you will gain a comprehensive understanding of the EV manufacturing processes and enterprise management systems. Other things you should know about this position are: •You will be part of the evolution of a game changing electric vehicle manufacturer.•You will be a peer with some of the brightest people with working experience in the greatest companies of our time: Tesla, BMW, Ford, Apple, Amazon, and more.•You will be prepared for a career in cutting edge business fields like cloud ERP, data science, design for manufacturing, and strategic sourcing.  Responsibilities: Working with the business to analyze requirements, design and configure SAP system. Write functional specification, work with technical team to guide, test and deploy system solutions Troubleshooting production issues and provide SAP system support as and when needed Participate in ongoing technology evaluations and keep up with technology trends and industry standards. Suggest system improvements based on technology, best practices, or changing requirements. Provide regular management updates on advantages and potential opportunities for new technologies and automation. Train/Mentor junior staff members as appropriate.   Minimum Qualifications: Bachelor's degree in Computer Science, Information Systems or equivalent 10+ years previous experience working across a range of SAP implementations, support, and system upgrade projects. Deep and broad SAP SD experience in a global capacity Deep understanding of different business processes, including logistics, warehouse, procurement, manufacturing, finance with a focus on OTC Proficient in end-to-end process design/development and integration with cross-functional areas with SAP Experience in OTC integration with Salesforce and other eCommerce systems Ability to prioritize, document, organize & follow up.  Preferred Qualifications: Experience working in a dynamic and fast pace environment Experience in automotive industry is a plus Experience in SAP VMS (Vehicle Management System) Industry solution is a plus Strong oral and written communication skills Ability to work well and collaborate with other teams of various skills Analytical skills coupled with technical creativity and vision Customer service oriented with strong interpersonal and leadership skills Time management and prioritizing skills Self-motivator able to take tasks or projects and run with them Lucid maintains your privacy according to its Candidate Privacy Notice. If you are a California resident, please refer to our California Candidate Privacy Notice. At Lucid, we don’t just welcome diversity - we celebrate it! Lucid Motors is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, national or ethnic origin, age, religion, disability, sexual orientation, gender, gender identity and expression, marital status, and any other characteristic protected under applicable State or Federal laws and regulations. Notice regarding COVID-19 protocols  At Lucid, we prioritize the health and wellbeing of our employees, families, and friends above all else. In response to the novel Coronavirus all new Lucid employees, whose job will be based in the United States may or may not be required to provide original documentation confirming status as having received the prescribed inoculation (doses). Vaccination requirements are dependent upon location and position, please refer to the job description for more details. Individuals in positions requiring vaccinations may seek a medical and/or religious exemption from this requirement and may be granted such an accommodation after submitting a formal request to and the subsequent review and approval thereof by our dedicated Covid-19 Response team. To all recruitment agencies: Lucid Motors does not accept agency resumes. Please do not forward resumes to our careers alias or other Lucid Motors employees. Lucid Motors is not responsible for any fees related to unsolicited resumes. About the Role You will be responsible for designing and developing tests and associated software tools to ensure the best possible customer experience.  You will identify, generate, and evaluate data and metrics for testing our computational biology pipelines. You will work closely with software engineers and scientists to identify requirements and develop test plans and test cases for new and existing products.   You will identify possible edge cases outside normal usage and develop tests to ensure support of a broader range of data. You will work with software support to help resolve customer issues.  You will develop new tools to automate tests, support development, and contribute to existing automation. What You Will Be Doing Lead a small team of test engineers testing 10x pipelines. Plan design, develop, and automate test plans against software releases. Work with software engineers and computational biologists to develop tests, define test metrics and troubleshoot/resolve issues. Report test issues and results in a consistent and timely manner. Support troubleshooting of customer issues. Test installations over a range of operating systems. Minimum Requirements   BS/MS in computer science, bioinformatics, computational biology, or equivalent. Experience with Python, Bash, Linux, and Git. 4 years experience in bioinformatics or software testing Preferred Qualifications Experience leading small to medium-sized projects. Experience in designing and developing validation, verification, and regression tests. Experience in bioinformatics applications and DNA sequencing. Experience with continuous integration systems (Jenkins, Travis). Experience with image processing tools (e.g. OpenCV) and algorithms. Experience in JavaScript. Experience with issue tracking systems (Jira). Experience in Go, Rust, and/or R is a plus. Experience with Amazon Web Services and/or VMWare is a plus. #LI-RT1  Below is the base pay range for this full time position.  The actual base pay will depend on several factors unique to each candidate, including one’s skills, qualifications, and experience.  At 10x, base pay is also just one component of the Company’s total compensation package.  This role is also eligible for 10x’s equity grants, its comprehensive health and retirement benefit programs, and its annual bonus program or sales incentive program.  Your 10x recruiter can share more about the Company’s total compensation package during the hiring process. Pay Range$163,800—$200,200 USD About 10x Genomics At 10x Genomics, accelerating our understanding of biology is more than a mission for us. It is a commitment. This is the century of biology, and the breakthroughs we make now have the potential to change the world.  We enable scientists to advance their research, allowing them to address scientific questions they did not even know they could ask. Our tools have enabled fundamental discoveries across biology including cancer, immunology, and neuroscience.  Our teams are empowered and encouraged to follow their passions, pursue new ideas, and perform at their best in an inclusive and dynamic environment. We know that behind every scientific breakthrough, there is a deep infrastructure of talented people driving the life sciences industry and making it possible for scientists and clinicians to make new strides. We are dedicated to finding the very best person for every aspect of our work because the innovations and discoveries that we enable together will lead to better technologies, better treatments, and a better future. Find out how you can make a 10x difference.  Individuals seeking employment at 10x Genomics are considered without regards to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, gender identity, or sexual orientation, or any other characteristic protected by applicable law. 10x does not accept unsolicited applicants submitted by third-party recruiters or agencies. Any resume or application submitted to 10x without a vendor agreement in place will be considered unsolicited and property of 10x, and 10x will not pay a placement fee.     Company Description ¿Apasionad@ de lo digital, los datos, el IoT o la IA y con ganas de ayudar a un equipo dinámico y ambicioso a escala humana?   Llevamos más de 20 años asesorando a empresas y administraciones y acompañándolas en la puesta en marcha de sus proyectos de transformación en Francia y en el extranjero.     Para ello, nos apoyamos tanto en el apalancamiento tecnológico como en la fuerza de nuestro ADN basado en la inteligencia colectiva, la agilidad y el espíritu emprendedor.     Presentes en los cinco continentes y con más de 5.000 empleados, nuestro objetivo es superar los 1.000 millones de euros de ingresos en 2024. La innovación está en el centro de nuestro desarrollo y participamos en áreas vinculadas a los cambios tecnológicos de los grandes grupos, como Big Data, IoT, Blockchain e Inteligencia Artificial.    Nuestros valores: Inteligencia colectiva   Agilidad   Emprendimiento / Intrapreneurship   Promoción de la diversidad Compromiso (empleados, socios, escuelas, asociaciones...)    Respeto del ser humano y calidad de vida en el trabajo    Apertura de espíritu e inclusión Job Description ¿Cuál será tu rol? Diseño y desarrollo de soluciones de acceso al mercado basadas en la integración de productos nuevos y existentes con aplicaciones y servicios de terceros. Definición de buenas prácticas de desarrollo, pruebas automáticas y despliegue. Trabajar activamente en la optimización y eficiencia de los procesos de desarrollo de software. Implementación de alertas y métricas oportunas para medir las soluciones. Además de desarrollar, deberás colaborar en el diseño técnico de las soluciones para cumplir con el marco de arquitectura de referencia en microservicios. Garantizar que el software tenga la calidad necesaria tanto en el mantenimiento como en el nuevo software que se desarrolle. Implementar controles de calidad del software. Garantizar que el software cumple con las mejores prácticas de seguridad definidas. Qualifications ¿Qué nos gustaría encontrar? Experiencia con tecnologías como: Java UX Shell Script Rest / JSON SQL Oracle GitHub y GitLab Jenkins (CloudBees) Python Hadoop Impala, Hive, Spark y/o Scala Kafka NoSQL. Experiencia y conocimiento de frameworks y tecnologías como: Spring Boot APIs Testing Big Data OpenShift Docker Hub y Kubernetes Sonar Kiuwan Fortify Idiomas: Inglés y Español Additional Information ¿Qué te ofrecemos? Contrato laboral indefinido y a jornada completa Pack Smart Office para que puedas trabajar cómodamente desde casa  Formación y desarrollo profesional  Beneficios y ventajas como seguro médico privado, seguro de vida, almuerzo y tarjetas de transporte como parte del paquete de remuneración flexible  Posibilidad de formar parte de un equipo multicultural y trabajar en proyectos internacionales  Puesto híbrido ubicado en Málaga Posibilidad de gestionar permisos de trabajo Si has leído hasta aquí y tienes ganas de sumarte a este reto, no dudes en aplicar... estaremos encantados de conocerte!!! About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to Know our Team:  The Supply Analytics team is a team of creative entrepreneurs that develop solutions for Agoda’s non-accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek.  Utilizing our strong brand and resources, we build new channels to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business.  The Opportunity:   The role sits within the Supply Analytics team under Central Supply Team, where new business ideas, and partnership types are incubated and scaled. We are looking for a Senior BI Analyst whose main focus areas are providing visibility and insights for people-related issues through Business Intelligence tools like Tableau and SQL, managing data warehouses, building ETL processes, and helping build other tools to optimize the business. This role will be involved in strategic projects and work closely with commercial owners and business stakeholders, using data to identify and translate business needs and opportunities into actionable initiatives. In this Role, you’ll get to: Translate internal briefs into analytical projects (to include refining the initial brief and asking the ‘right questions’, working through potential hypotheses and storyboarding the output) Use and analyze data from multiple large-scale data warehouses and present statistically strong analysis to a wide range of business stakeholders. Proactively identify opportunities for growth within supply and the wider business. Drive new analytical initiatives and projects aimed at improving organizational efficiency and shaping Agoda supply. Identify, support, and lead projects aimed at scaling up the way the Supply organization leverages on data, insights, and intelligence. Automate manual operational processes and present back on time savings gained through modernization of business operations What you’ll Need to Succeed: 4+ years of experience in analytics/data science/insights/strategy. Bachelor’s degree ideally in a business or quantitative subject (e.g. computer science, mathematics, engineering, science, economics or finance). 3+ years of experience with BI & analytics tools (SQL, Tableau, Metabase, Data Studio, or similar technologies) 2+ years of solid project management Good stakeholder management experience. Comfortable presenting to senior leadership and C-suite. Strong experience in finding data insights and provide business recommendation to the business A hacker’s mindset – the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping. Excellent communicator with superior written, verbal, presentation and interpersonal communication skills. Data driven in both decision making and performance measurement. Extreme comfort in ambiguous, fast-paced environment. Ability to multi-task, prioritize and coordinate resources. It’s Great if you Have:   Travel industry / e-commerce / tech / consulting experience. Experience in conducting A/B testing experimentation (a plus) A good understanding of statistical modelling knowledge or any machine learning technique knowledge is a plus (regression, logistic regression, random forest, etc.)   #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Company Description At Bosch, we shape the future by inventing high-quality technologies and services that spark enthusiasm and enrich people’s lives. Our promise to our associates is rock-solid: we grow together, we enjoy our work, and we inspire each other.  The Bosch Center of Competence Big Data and AI is searching for new highly motivated colleagues in our international DevOps team. As DevOps Engineer for our new Big Data platform on Microsoft Azure public cloud, you will play a crucial role for further developing and enhancing our platform services, thus creating significant benefit for Bosch business. Your focus will be on Infrastructure as Code (IaC) and automation of deployment and maintenance processes. Our team is looking forward to your application!  Job Description Tasks: As DevOps Engineer for Cloud Data Platform services you act as a IT infrastructurespecialist. You drive industrialization of the cloud based Bosch divisions platforms through further automation of deployment, configuration, upgrade, and maintenance processes. Part of your work also entails developing new datalake platform features supportinginfrastructure automation, monitoring, and platform security. In your responsibility lies the development of Infrastructure as Code scripts and small applications for automation (deployment, configuration) purposes. Your tasks also include testing and evaluating new product features in close alignment with project stakeholders, internal customers, and vendors. You contribute actively with the setup of reusable infrastructure as code modules across our different cloud platform teams. Qualifications Profile: At least 3 years of hands-on experience as a Software or DevOps engineer in cloud based Big Data and Analytics frameworks (e.g. Azure Data Lake, Apache Spark, Databricks) Advanced experience with the Microsoft Azure ecosystem and common cloud concepts like infrastructure as code, e.g. Terraform Good knowledge in version control tools (e.g. git) and in CI/CD Pipeline tools (e.g. Azure,DevOps) Good knowledge of at least one scripting language (Bash, PowerShell or Python) Ideally knowledge of Cloud security Ability to move easily between conceptual and implementation level Willingness to learn, understand and adapt to new technologies Analytical thinking skills, initiative, ability to succeed in a complex environment Willingness to work in a larger team including customers and enjoy working in an international team You are communicative, flexible, goal-oriented University degree in Computer Science, Information Technology, Engineering or related fields Very good command of English - both written and spoken Additional Information Benefits: We would like to offer you number of amenities for you and your loved ones.  Work #LikeABosch: • Contract of employment  and a competitive salary (together with annual bonus) • Flexible working hours with home office after the pandemic as well • Referral Bonus Program • Copyright costs for IT employees • Canteen in the office with co-financed lunches  Grow #LikeABosch: • Complex environment of working, professional support and possibility to share knowledge and best practices • On-going development opportunities in a multinational environment • Broad access to professional trainings, conferences and webinars • Language courses  Live #LikeABosch: • Private medical care and life insurance • Multisport card and sports teams • Number of benefits for families (for instance summer camps for kids) • Non working days on the 24th and 31st of December • Discounts for Bosch products Are you inspired by invention? Is problem solving through teamwork in your DNA? Do you like the idea of seeing how your work impacts the bigger picture? Answer yes to any of these and you’ll fit right in here at Amazon Robotics. We are a smart team of doers who work passionately to apply cutting edge advances in robotics and software to solve real-world challenges that will transform our customers’ experiences. We invent new improvements every day. We are Amazon Robotics and we will give you the tools and support you need to invent with us in ways that are rewarding, fulfilling, and fun.  Amazon Robotics empowers a smarter, faster, more consistent customer experience through automation. Amazon Robotics automates fulfillment center operations using various methods of robotic technology including autonomous mobile robots, sophisticated control software, language perception, power management, computer vision, depth sensing, machine learning, object recognition, and semantic understanding of commands. Amazon Robotics has a dedicated focus on research and development to continuously explore new opportunities to extend its product lines into new areas.  Amazon Robotics internship/co-op opportunities will be based out of the Greater Boston Area in our state-of-the-art facility in Westborough, MA. Both campuses provide a unique opportunity to have direct access to robotics testing labs and manufacturing facilities.  Amazon Robotics (AR) is looking for a motivated Business Intelligence Engineer Co-op with a passion for delivering insightful and influential solutions to challenging and ambiguous problems. A practiced analyst, who uses data engineering, statistics, data visualization, and data science to influence decision making in cross-functional teams. We are seeking an individual who can think holistically through compound problems to understand how systems work together to define and execute projects which drive improvements to robotic architecture or design.  Key job responsibilities You will work cross-functionally with product development teams and leaders throughout the organization to deliver projects aimed at characterizing and improving the performance of new robotic automation technology in Amazon's network of warehouses. In this role, you will use a combination of unified and disparate data sources to uncover insights delivered through decision-driving analytics white-papers and automated data visualizations to influence the development and deployment of cutting edge robotic technology. You will collaborate with Data Scientists, Data Engineers, and development teams to define and deliver world class analytics tools and insights to shape the robotic technology landscape.  About the team The Robotic Manipulation Organization develops technology that tackles some of Amazon's most challenging material handling problems at scale. We are a highly collaborative group, designing and delivering robotic manipulation solutions that integrate cutting edge perception and motion planning algorithms with state of the art hardware. Thinking big and delighting our customers motivates this group of passionate technologists. Basic Qualifications  Currently enrolled in a Bachelor’s/Master's (or higher) in analytically rigorous field such as Data Science, Statistics, Computer Science, Industrial Engineering, Econometrics or other equivalent discipline with a graduation date after May/June 2024 Must be eligible and available for a full-time (40h / week) internship between July 10 to December 15, 2023 Proficient understanding of data modelling, descriptive statistics, and SQL Excellent written and verbal communication skills and the ability to succinctly summarize key findings Working knowledge of Python or R for exploratory data analysis and modeling  Preferred Qualifications Knows how to ingest, process, persist, and analyze data with a strong technical insight to address customer challenges Ability to work successfully in an ambiguous environment, to meet tight deadlines and prioritize workload even when faced with conflicting priorities   Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Company Description Experian is the world’s leading global information services company. During life’s big moments — from buying a home or a car to sending a child to college to growing a business by connecting with new customers — we empower consumers and our clients to manage their data with confidence. We help individuals to take financial control and access financial services, businesses to make smarter decisions and thrive, lenders to lend more responsibly, and organizations to prevent identity fraud and crime. We have 17,800 people operating across 44 countries, and every day we’re investing in new technologies, talented people and innovation to help all our clients maximize every opportunity. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index. Learn more at www.experianplc.com or visit our global content hub at our global news blog for the latest news and insights from the Group Experian is the world’s leading global information services company. During life’s big moments — from buying a home or a car to sending a child to college to growing a business by connecting with new customers — we empower consumers and our clients to manage their data with confidence. We help individuals to take financial control and access financial services, businesses to make smarter decisions and thrive, lenders to lend more responsibly, and organizations to prevent identity fraud and crime. We have 17,800 people operating across 44 countries, and every day we’re investing in new technologies, talented people and innovation to help all our clients maximize every opportunity. We are listed on the London Stock Exchange (EXPN) and are a constituent of the FTSE 100 Index. Learn more at www.experianplc.com or visit our global content hub at our global news blog for the latest news and insights from the Group Job Description As a key aide to both the IT Infrastructure and Development teams, we are looking for an individual, who can lead a team of Big Data Platform Engineers supporting data management platforms globally. This is an exciting opportunity to come and work in a company that develops many solutions involving data platforms at their core. The candidate will be responsible for managing data platform environments and engineers to maintain, optimize, develop, and integrate working solutions for our big data, relational and No SQL data management technologies. To support the product development process in line with the product roadmap for product maintenance and enhancement such that the quality of software deliverables maintains excellent customer relationships and increases the customer base.   The ideal candidate will have a strong track record of leadership and influence. This individual will be driving the data platforms support for the company’s web, online, and batch systems which are critical for delivering business results. Candidate must have demonstrated not only an ability to lead and motivate a team of direct reports, but also can drive change across a broader organization. Candidate will be responsible for team mentoring, training, forecasting and goal setting for the staff.    An overall experience of big data platforms, databases is required. Candidate should have a mastery of a wide range of Big Data, database architectures for 24/7 transactional and batch systems. An ideal candidate would also have prior experience in administering cloud data management systems preferably, but an added plus would be experience in embracing cloud native principles (12-factor concepts etc.) such as AWS EMR platforms. A major plus is experience in data warehouse designing, master data management, unstructured data and metadata management.    If you have the skills and “can do” attitude, we would love to talk to you!   What you’ll be doing   Responsible for implementation and ongoing administration of Data Platforms in hybrid environments On-premises/Co-Lo/Cloud  Hands-on Technical leader working with your team, including participating in on call rotation with your team  Provide technical leadership to build high-quality performant big data platform solutions that scale well conforming to internal and industry enterprise standards  Manage engineering teams and drive new initiatives in a fast-paced environment, embrace cloud native principles (12-factor concepts, and similar), automation, CI/CD, including a coding skillset.    Bring a DevOps mindset to enable big data and batch/real-time analytical solutions that leverage emerging technologies  Ensure team members follow software development life cycle “SDLC” (branch/release strategies, peer review and merge practices, CI and CD pipelines) practices so that solutions meet specified requirements (e.g., business requirements, company enterprise standards, quality, availability and performance expectations)  Manage coding practices such as SQL, Python, Scala etc. across data management platforms  Manage internal and external dependencies, collaborate with stakeholders and product managers, operations, customer research teams to deliver business objectivities  Maintain and improve existing codebases and contribute technically to the overall engineering processes followed in Connected Technologies  Review, design and vet architecture, system design to solve complex distributed system problems with scale and security  Collaborate with Senior Management, Product Managers, Tech Leads etc. and help build backlogs for product  Identify and encourage adoption of new technologies, tools, processes for the organization as needed  Unblock Engineers and ensure project milestones are met  Recruit top talent and scale team/s, conduct performance reviews for software engineers  Establish and monitor objectives for all employees by providing regular feedback, coaching, training and development that fosters both personal and organizational growth  Develop a team-oriented, supportive culture with a strong focus on creating a working environment that fosters creativity and open communication, as well as one that demands discipline and results  Build a first-class Engineering team that will scale as the company and business grows, identifying and filling any organizational gaps  Continually strengthen and simplify the engineering ecosystem  Qualifications Typically requires a bachelor's degree (in Computer Science or related field) or equivalent.  5+ years of proven experience in data management platform engineering, including leading high-performance teams  10+ years of experience with software backend systems, architectures, infrastructure, especially cross-platform, cloud native Hadoop systems.  Strong Data management platforms design and development experience for very large enterprises  Expert Level in designing and implementing large scale data platform systems catering to consumer products with Hadoop distribution both hybrid and cloud native platforms  Expert level in managing coding practices such as SQL, Python, Scala etc. across data management platforms  Expert level in AWS systems such as ECS, EMR, RDS etc. leveraging terraform for data platform automation.  Proven experience designing and scaling relational databases  Expert level in non-relational databases such as HBase, Redis, DynamoDB etc.  Expert level working in a data-driven culture to improve the efficiency of continuous deliver, scalability, stability, and security of software  Expert level in agile framework (Scrum, Kanban etc.), facilitation, and consensus-building skills to mediate priority conflicts in an effective and collaborative manner  Continuously build and test code using tools like Jenkins  Expert level in building highly scalable distributed data platforms and processes in Cloud environment IaaS/PaaS.  Expert level in recruiting and managing technical teams, including performance management  Expert level in working with Engineering teams, product management, and Architecture teams to define product strategy  Demonstrated success influencing senior level stakeholders on strategic direction based on recommendations backed by in-depth analysis  Bring a strong perspective that inspires change and motivates engineers to develop simple solutions to hard problems  Ability to adapt to multi-lingual and multicultural environment, additional language skills are a bonus.  Experience working with geographically distributed teams  High energy, confidence, and ambition--someone who can consistently perform at the highest level   Additional Information Experian Careers - Creating a better tomorrow together Find out what its like to work for Experian by clicking here Company Description SSENSE (pronounced [es-uhns]) is a global technology platform operating at the intersection of culture, community, and commerce. Headquartered in Montreal, it features a mix of established and emerging luxury brands across womenswear, menswear, kidswear, and Everything Else. SSENSE has garnered critical acclaim as both an e-commerce engine and a producer of cultural content, generating an average of 100 million monthly page views. Approximately 80% of its audience is between the ages of 18 to 40. It is privately held and has achieved high double digit annual growth and profitability since its inception. Job Description Reporting to the Senior Director of Global Operational Excellence & Continuous Improvement, the Manager of Data Visibility, Governance, and Product is responsible for leading the design, development, and successful implementation of current and future data visualisation, reporting standards, and workflow data products for Operations. They will oversee a team of analysts that translate business requirements into technical reporting requirements across all end-to-end processes, define the metrics, and then build the data products and corresponding dashboards that will be a cornerstone of all Operational roles and training programs at SSENSE. The incumbent will ensure data visualisation, metric, and KPI standards are clearly defined ahead of our global network expansion plans over the coming 1-3 years. RESPONSIBILITIES Data visibility, governance, and product design (75%) Develop and lead the Operations Visualization & Data Governance transformation plan that will standardise and operationalize all data points related to physical and systemic movement of products within the SSENSE Network, spanning operational process paths to C-suite executive-level reporting Translate and develop standard metrics for reporting, and collaborate with the Product and Engineering, and Data Platform team to determine the right mechanism for delivering the reports and insights to maximize how they are used and actioned by Operational teams Develop, and implement reporting solutions with AWS tools like Athena, Tableau, and operational reporting capabilities available through operational systems Work closely with all Operational teams and executive leadership to ensure clear and consistent metric definitions, comprehensive capture and up-to-date documentation of operational reporting and analytical reporting requirements  Oversee all data, metric, and dashboard development by the direct team; define the internal development process and stakeholder engagement model, establishing quality measures for product delivery; achieve and maintain best-in-class benchmarks for adoption rates Develop prioritised roadmap for scaling visibility, maturity, automation, and real-time capability for all operational process paths in tandem with process maturity assessment; design agile approach for near-term output and ongoing, ad hoc request management Implement design principles and templates for data visualisation and governance across Operations that guides all dashboard development in current and future state Collaborate with the Product and Data Platform teams to define and demarcate data accessibility and tools for analysis vs. standardised user interface for operational process and reporting Partner with Business Process Owners and Operations leadership to implement standard metrics based on industry best practices to integrate with company-wide metric reporting  Implement continuous improvement processes for refining / streamlining data or visualisation standards, as well as change management practices for deployment; inclusive of scalable approach to deprecating and removing legacy reports and dashboards Pilot workflow tools that support predictive analytics and algorithmic recommendations Oversee successful migration of reporting, visualisation, and workflow tools with existing system or product changes (e.g., WMS); partner with Product teams to define requirements of new systems or product implementation (e.g., YMS, LMS); ensuring successful integration with data governance and reporting standards Partner directly with the Data Platform team and the Product and Engineering teams to develop a design of the future for these collaterals and corresponding data architecture People leadership and development (25%) Work with Senior Leadership to gauge and monitor team engagement and implement solutions to create a transparent, collaborative and productive work environment  Collaborate with Senior Leadership to establish the department short term objectives for the department and ensure the team's are engaged towards achieving them  Hold weekly one-on-ones, conduct performance reviews, analyze individual KPIs and assess promotion readiness to help each contributor evolve in their roles Provide mentorship and development opportunities to team members, catalyzing growth through coaching and team building Qualifications REQUIREMENTS Bachelors Degree in Computer Science, Information Systems, Mathematics, Statistics, Data Science, Software Engineering, or another relevant field  A minimum of 5 years of professional, hands-on data management/Operations and analytics experience, with at least 3 years of formal management experience leading highly developed data management and analytical professionals, ideally in fast-paced Fulfillment industry, Distribution, Logistics or Production/Manufacturing environment Extensive experience with data manipulation and data visualisation tools, such as Tableau for reporting and dashboarding is essential Extensive experience with data manipulation using SQL or other means to extract and transform data is a must Analytical mindset and experience working with business and technical teams to define key metrics, KPIs, definitions, and governance standards, along with the process to manage and maintain them over time is a must Experience with Operational SAAS systems and their reporting capabilities (pros and cons) is a plus Experience leading teams in information design principles and data visualisation methods, best practices, and software packages and APIs such as Tableau or equivalent analytics tools Strong written and verbal communication skills in English and French SKILLS Strong organisational and time management skills  Advanced data analysis skills, and an expert in using supporting tools Strong collaboration and prioritisation skills Ability to identify, prioritise and articulate high impactful initiatives The ability to translate operational issues into workable data solutions Creative out-of-the-box thinking with excellent problem-solving abilities Team player with solid leadership and interpersonal skills Strong communication skills, with an ability to influence cross-functional teams Additional Information WORLD CLASS TECHNOLOGY  Technology is at the core of everything we do at SSENSE. Driven by an engineering mindset and a problem-solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the SSENSE offering.  WORLD CLASS TEAM The SSENSE tech team is responsible for an international headless commerce platform. Working in an agile environment, our squads are made up of experienced innovators in Product Management, QA, Design, DevOps, Software Development, Machine Learning, Data Engineering, and Security. Headquartered in Montreal, our technology organization has been growing at a rate of 2X year-over-year and is doubling once again in 2021 as we expand across Canada, US, and Europe.   WORLD CLASS PLATFORM  The SSENSE platform runs on Amazon Web Services making use of serverless microservices across web, mobile and app. Our event-source architecture already achieves over 10,000 requests / second and growing at an unmatched pace, currently unseen across the industry.  Our data-driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in Machine Learning techniques. Our automated continuous improvement DevOps model (making use of both blue / green and canary deployments) results in an average of 50 production releases every day.   Read more about us on our SSENSE Tech Blog. About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to know our team: Partner Development is a team of creative entrepreneurs that develop solutions for Agoda’s accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. In this role you'll get to This role is designed to mainly growth opportunity identification among mid to long tail hotels, experiment execution and data tracking within Partner Development team for the global teams. You will get to work directly with the regional team to design and put in place global experimentation and initiatives to drive tangible impact in each market. Key activities involved include but not limit to: Apply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations Own end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development Build dashboards, identify new and track key metrics to closely monitor team’s performance and identify quick and long term opportunities for improvements Work closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified Support global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization What you'll need to succeed  Bachelor’s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline 4-8 years experience working in a business analysis, data analysis, reporting or business strategy role Excellent problem-solving skills including the ability to analyze and resolve complex problems using data Team player with strong interpersonal, relationship-building, and stakeholder management skills Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala) Data visualization tool experience such as with Tableau or your weapon of choice. Ability to work under pressure in a fast-paced and rapidly changing environment Excellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Company Description REF25129J At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking for a Senior Big Data Software Engineer to join our ciValue Technology team in Israel. The ciValue division of NIQ is a leading provider of AI-powered customer analytics, personalization, and brand collaboration platform. Serving dozens of retailers and brands across the world using cutting-edge big-data, real-time analytics, and data-science automation. Our solution is disrupting existing data & media monetization model by enabling retailers to remain in control of their revenue. Job Description We believe that building a great product and teams starts with amazing, diverse-minded, and bright people who make an impact, generate creative & innovative ideas and take on new perspectives.   The Big Data Software Engineer is responsible for building new data solutions for our rapidly expanding customer base and working with the top data ingestion technologies in an open, collaborative, and innovative environment.  Responsibilities Be responsible for Data flow stages from definition to architecture, including Data acquisition, Data set acceptance criteria, and Data Science integration.  Architecture designing and customizing technological solutions for large-scale data processing.  Develop and deploy real-time and batch data processing infrastructures and pipelines.  Take responsibility to explore technologies to scale up the Data ecosystem to handle rapid Big Data growth.  Work closely with Data Science team to embed ML / AI algorithms into the product. Work with cloud, DevOps, application, and client teams to make sure your solution is solving significant business problems in a robust, scalable manner.  Use cutting-edge technologies: Python, Airflow, Java, Kubernetes, Spark, Scala, Kafka. Qualifications 4+ years of backend engineering work experience in production environments (Data environments, Big Data processing, Database techniques).  Experience in Big Data – Spark / Kafka / Flink.  Proven experience with Python and Java/Scala. Experience in the design and development of scalable Big Data solutions. Experience working with SQL & NO-SQL Databases – PostgreSQL, DataLake, Columnar DB. Experience in Kubernetes, containers & Helm is a plus. Ability to learn new technologies and work in a dynamic fast-paced environment. Result-driven, pragmatic, and innovative.  Experience with Cloud technology is an advantage. Excellent English communication skills spoken and written.  Bachelor's or Master’s degree in Computer Science, Computer Engineering or related field. Full-time position in our office in Yokneam (Hybrid)  #LI-SG Additional Information About NIQ NIQ, the world’s leading consumer intelligence company, reveals new pathways to growth for retailers and consumer goods manufacturers. With operations in more than 100 countries, NIQ delivers the most complete and clear understanding of consumer buying behavior through an advanced business intelligence platform with integrated predictive analytics. NIQ delivers the Full View.  NIQ was founded in 1923 and is an Advent International portfolio company. For more information, visit NIQ.com   Want to keep up with our latest updates? Follow us on: LinkedIn | Instagram | Twitter | Facebook Our commitment to Diversity, Equity, and Inclusion NIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion/ NIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process. Company Description Publicis Media harnesses the power of modern media through global agency brands Performics, Spark Foundry, Starcom and Zenith. A key business solution of Publicis Groupe ([Euronext Paris FR0000130577, CAC 40], Publicis Media’s digital-first, data-driven global practices deliver client value and drive growth in a platform-powered world. It is present in more than sixty countries with over 23,000 employees worldwide. Job Description We are seeking a driven individual with a proven track record of scalable and innovative business intelligence solutions. He/she shines when serving as a consultant to the business and is genuinely interested in understanding the objectives of complex and evolving projects. In this role, you will champion and advocate the use of Alteryx and Tableau to create an environment of self-service analytics. The candidate must be a self-starter with a sense of urgency and a commitment to quality and professionalism.  Responsibilities: Analyze business needs and partner with stakeholders to provide a strategic solution Work independently on end to end solutions, from data analysis to ETL design and development through to the final visual dashboard Collaborate across the organization to build solutions that achieve business objectives Guide stakeholders with operational decisions that impact data structures and connectivity Bring best practices in data architecture and data visualization to the table Build tools in a generic fashion for reuse across other solutions Develop technical documentation for each solution Manage projects in an agile environment Qualifications Minimum Bachelor’s Degree in Computer Sciences, Information Technology, or its equivalent 3+ years’ experience with Tableau 1+ years’ experience with AWS core+ services (EC2, S3, Lambda, Redshift, Glue) 1+ years’ experience with Python 3+ years’ experience with data visualization Comfortable with data warehousing concepts, preparing data, and configuring automated workflows Excellent communication and presentation skills as well as an analytical mindset Experience with complex logic Strong data analysis skills Experience connecting and merging disparate datasets Strong organizational skills & attention to detail Possess a desire to work for a fast-paced, results-based company Experience managing multiple projects simultaneously  Required Skills: Experience with media and ad tech platforms (Ad Servers, Media Planning and Buying systems, DSP’s, Programmatic, etc) SQL Adobe Site Catalyst Google Analytics Basic knowledge of ETL, data modeling, data warehouse, extracting and manipulating large record of data Additional Information Compensation Range: $106,500 - $167,500 annually. This is the pay range the Company believes it will pay for this position at the time of this posting. Consistent with applicable law, compensation will be determined based on the skills, qualifications, and experience of the applicant along with the requirements of the position, and the Company reserves the right to modify this pay range at any time. For this role, the Company will offer medical coverage, dental, vision, disability, 401k, and paid time off. All your information will be kept confidential according to EEO guidelines. Company Description Bosch Global Software Technologies Private Limited (BGSW) is a 100% owned subsidiary of Robert Bosch GmbH. We are one of the world’s leading global suppliers of technology and services, offering end-to-end Engineering, IT, and Business Solutions. With a global footprint and presence in US, Europe, Japan, China, and the Asia Pacific region, we are at the forefront of designing, developing, and executing IoT ecosystems through our all-encompassing capability within the 3 aspects of IoT – Sensors, Software, and Services. We have always focused on improving the quality of the life of people, providing newer revenue-generating opportunities, and improving operational efficiencies for enterprises through an array of solutions. With our unique ability to offer end-to-end solutions that connect Sensors, Software, and Services, we enable businesses to move from the traditional to digital or improve businesses by introducing a digital element in their products and processes. Job Description ·        Passionate about data and how it can make a difference? ·        Interested in learning how to create a strategy and execute the same? ·        Want to be part of a vibrant global Power BI community with some of the most passionate people? ·        Committed to making a difference with a role with vast opportunities to grow and excel? If your answer to all above questions is “Yes”, then the role is for you! We are looking for passionate and dynamic associate who want to be part of this exciting journey. What you’ll do? You will work as part of our global DevOps teams to provide data solutions for our internal customers across the globe. In collaboration with our product owners and business experts you will create and improve Power BI Reports and meaningful Premium Data Sets. You will be able to explore the full world of our business data platform to generate insights and derive actions. You will be responsible to drive continuous improvement engagements and be part of a problem-solving culture Take responsibility: You will work with our internal customers and international team of developers to design and implement Power BI Reports and Power BI Premium Datasets. Help shape the future: As an employee of the global cross-functional Business Intelligence team (xBI), you will work on the future steering of Bosch. Use freedom and creativity: We live agile values so that you can contribute your ideas and experiences for the benefit of the team and the company. Think entrepreneurially: As part of the leading in-house provider for data and analytics-based solutions within Bosch, you will experience the start-up spirit with us and make your contribution through entrepreneurial thinking and acting. Live Cooperation: You will work in an interdisciplinary and international team supported by internal and external service providers as well as in direct exchange with our internal customers. Personality: Team player, committed, responsible and flexible Qualifications Education: Graduate / Postgraduate in Engineering (preferably Computer Science) / MBA / MCA   Experience: 5+ years of experience working as a Power BI developer (rare exceptions for highly skilled developers). Professional experience in the field of BI and Data Warehouse. Working knowledge of Microsoft BI and Azure stack. Prolific experience with data analytics and data warehousing environments. Experience in translating business requirements into set of analytical tasks. Way of working: Agile, analytical, proactive, result, solution-oriented and high code/solution quality. Additional Information Know-How: ·        Collection and analysis of complex requirements and creation of solution concepts ·        Ability to tackle complex problems independently or by collaborating with other team members ·        Conception and implementation of data analysis, data strategies and visualizations ·        Working knowledge on how to extract data from SQL, transform data through SQL backend, Power Query, DAX. ·        Familiarity with BI concepts such as ETL design, analytics, and reporting ·        Excellent troubleshooting and analytical skills ·        Experience in DAX queries, Power BI, Building Analysis Services tabular models (SSAS) ·        Solid understanding of data warehousing concepts including the common schema architectures, dimensions, facts, aggregate facts, and data marts. Data Vault knowledge and Azure certificates will be beneficial. ·        Certification in Power BI will be an added advantage ·        Good understanding of Agile and leveraging Agile to deliver consistent business results Enthusiasm: Passion for data, data solutions and its integration, developing interdisciplinary approaches and products for customers and presenting complex issues in a simple manner Languages: Fluent in English, written and spoken to collaborate with developers and communicate with customers. We currently have a vacancy for an Enterprise Architect (Big Data) fluent in English, to offer his/her services as an expert who will be based in Brussels. The work will be carried out either in the company’s premises or on site at customer premises. In the context of the first assignment, the successful candidate will be integrated in the team of the company that will closely cooperate with a major client’s IT team on site. Your tasks Support designing and follow up deployment of new data processing workflows, especially the Analytics Data Models and Data processing/ Data flows; Analyse, clarify, and document priorities for each set of requirements to ensure they are implemented within applicable constraints (timing, contractual, technology, infrastructure); Ensure that the design of the system will fulfil the business requirements and non-functional requirements (volume, scalability, stability, confidentiality, security, integrity, availability, usability). Requirements University degree in IT combined with minimum 13 years of IT professional experience; Minimum 5 years of professional experience as Enterprise Architect working in Analytics or Big Data project responsible for data/functional/IT architecture and at least 4 years of specialised experience in data architecture, experience in design of large-scale IT systems and high availability; Strong experience in business process analysis, business needs analysis, Use cases, , users stories and producing functional specifications; Good knowledge of interoperability technology (e.g. APIs, web services, message oriented middleware, service oriented bus); Good knowledge of service implementation patterns (synchronous, asynchronous, request/response), distributed system design and messaging layer; Capability for modelling components, data modelling, data processing models, service interfaces, service data and reference models; Capacity to review and assess the quality, integrity and completeness of the various IT and Business specification documentation such as IT Architecture documents, conceptual and logical data models, use case specification, user interface specification, Web service specification, business specification (BPMs); Excellent command of the English language. Benefits If you are seeking a career in an exciting and dynamic company, where you will offer your services as part of a team of a major European Institution, operating in an international, multilingual and multicultural environment where you can expect real chances to make a difference, please send us your detailed CV in English, quoting reference: (14886/03/23). We offer a competitive remuneration (either on contract basis or remuneration with full benefits package), based on qualifications and experience. All applications will be treated as confidential. EUROPEAN DYNAMICS (www.eurodyn.com)is a leading Software, Information and Communication Technologies company, operating internationally (Athens, Brussels, Luxembourg, Copenhagen, Stockholm, London, Nicosia, Hong-Kong, Valetta, etc). The company employs over 600 engineers, IT experts and consultants (around 3% PhD, 36% MSc and 53% BSc or equivalent). We design and develop software applications using state-of-the-art technology. The group generates annual revenues in the range of EURO 40 million, with an EBITDA in the range of 20%. The value of our contract portfolio exceeds EURO 250 million. EUROPEAN DYNAMICS is a renowned supplier of IT services to government institutions, multinational corporations, public administrations and multinational companies, research and academic institutes. As part of our dedication to the diversity of our workforce, we are committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, disability, sexual orientation, gender identity, or religion. EUROPEAN DYNAMICS (ED) adheres to the General Data Protection Regulation principles by applying its Privacy Policy as published in www.eurodyn.com/privacy. By submitting an application to this position and by sharing your personal data with ED, you acknowledge and accept its Policy and authorise ED to process your personal data for the purposes of the company's recruitment opportunities, in line to the Policy. Furthermore, when providing your data, it is up to you to explicitly consent that your data can be assessed for future job openings, for as long as you do not withdraw such consent. If you do not consent, we will not be able to consider the data you provide to us for future job openings. Company Description SSENSE (pronounced [es-uhns]) is a global technology platform operating at the intersection of culture, community, and commerce. Headquartered in Montreal, it features a mix of established and emerging luxury brands across womenswear, menswear, kidswear, and Everything Else. SSENSE has garnered critical acclaim as both an e-commerce engine and a producer of cultural content, generating an average of 100 million monthly page views. Approximately 80% of its audience is between the ages of 18 to 40. It is privately held and has achieved high double digit annual growth and profitability since its inception. Job Description Reporting to the Senior Director of Global Operational Excellence & Continuous Improvement, the Manager of Data Visibility, Governance, and Product is responsible for leading the design, development, and successful implementation of current and future data visualisation, reporting standards, and workflow data products for Operations. They will oversee a team of analysts that translate business requirements into technical reporting requirements across all end-to-end processes, define the metrics, and then build the data products and corresponding dashboards that will be a cornerstone of all Operational roles and training programs at SSENSE. The incumbent will ensure data visualisation, metric, and KPI standards are clearly defined ahead of our global network expansion plans over the coming 1-3 years. RESPONSIBILITIES Data visibility, governance, and product design (75%) Develop and lead the Operations Visualization & Data Governance transformation plan that will standardise and operationalize all data points related to physical and systemic movement of products within the SSENSE Network, spanning operational process paths to C-suite executive-level reporting Translate and develop standard metrics for reporting, and collaborate with the Product and Engineering, and Data Platform team to determine the right mechanism for delivering the reports and insights to maximize how they are used and actioned by Operational teams Develop, and implement reporting solutions with AWS tools like Athena, Tableau, and operational reporting capabilities available through operational systems Work closely with all Operational teams and executive leadership to ensure clear and consistent metric definitions, comprehensive capture and up-to-date documentation of operational reporting and analytical reporting requirements  Oversee all data, metric, and dashboard development by the direct team; define the internal development process and stakeholder engagement model, establishing quality measures for product delivery; achieve and maintain best-in-class benchmarks for adoption rates Develop prioritised roadmap for scaling visibility, maturity, automation, and real-time capability for all operational process paths in tandem with process maturity assessment; design agile approach for near-term output and ongoing, ad hoc request management Implement design principles and templates for data visualisation and governance across Operations that guides all dashboard development in current and future state Collaborate with the Product and Data Platform teams to define and demarcate data accessibility and tools for analysis vs. standardised user interface for operational process and reporting Partner with Business Process Owners and Operations leadership to implement standard metrics based on industry best practices to integrate with company-wide metric reporting  Implement continuous improvement processes for refining / streamlining data or visualisation standards, as well as change management practices for deployment; inclusive of scalable approach to deprecating and removing legacy reports and dashboards Pilot workflow tools that support predictive analytics and algorithmic recommendations Oversee successful migration of reporting, visualisation, and workflow tools with existing system or product changes (e.g., WMS); partner with Product teams to define requirements of new systems or product implementation (e.g., YMS, LMS); ensuring successful integration with data governance and reporting standards Partner directly with the Data Platform team and the Product and Engineering teams to develop a design of the future for these collaterals and corresponding data architecture People leadership and development (25%) Work with Senior Leadership to gauge and monitor team engagement and implement solutions to create a transparent, collaborative and productive work environment  Collaborate with Senior Leadership to establish the department short term objectives for the department and ensure the team's are engaged towards achieving them  Hold weekly one-on-ones, conduct performance reviews, analyze individual KPIs and assess promotion readiness to help each contributor evolve in their roles Provide mentorship and development opportunities to team members, catalyzing growth through coaching and team building Qualifications REQUIREMENTS Bachelors Degree in Computer Science, Information Systems, Mathematics, Statistics, Data Science, Software Engineering, or another relevant field  A minimum of 5 years of professional, hands-on data management/Operations and analytics experience, with at least 3 years of formal management experience leading highly developed data management and analytical professionals, ideally in fast-paced Fulfillment industry, Distribution, Logistics or Production/Manufacturing environment Extensive experience with data manipulation and data visualisation tools, such as Tableau for reporting and dashboarding is essential Extensive experience with data manipulation using SQL or other means to extract and transform data is a must Analytical mindset and experience working with business and technical teams to define key metrics, KPIs, definitions, and governance standards, along with the process to manage and maintain them over time is a must Experience with Operational SAAS systems and their reporting capabilities (pros and cons) is a plus Experience leading teams in information design principles and data visualisation methods, best practices, and software packages and APIs such as Tableau or equivalent analytics tools Strong written and verbal communication skills in English and French SKILLS Strong organisational and time management skills  Advanced data analysis skills, and an expert in using supporting tools Strong collaboration and prioritisation skills Ability to identify, prioritise and articulate high impactful initiatives The ability to translate operational issues into workable data solutions Creative out-of-the-box thinking with excellent problem-solving abilities Team player with solid leadership and interpersonal skills Strong communication skills, with an ability to influence cross-functional teams Additional Information WORLD CLASS TECHNOLOGY  Technology is at the core of everything we do at SSENSE. Driven by an engineering mindset and a problem-solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the SSENSE offering.  WORLD CLASS TEAM The SSENSE tech team is responsible for an international headless commerce platform. Working in an agile environment, our squads are made up of experienced innovators in Product Management, QA, Design, DevOps, Software Development, Machine Learning, Data Engineering, and Security. Headquartered in Montreal, our technology organization has been growing at a rate of 2X year-over-year and is doubling once again in 2021 as we expand across Canada, US, and Europe.   WORLD CLASS PLATFORM  The SSENSE platform runs on Amazon Web Services making use of serverless microservices across web, mobile and app. Our event-source architecture already achieves over 10,000 requests / second and growing at an unmatched pace, currently unseen across the industry.  Our data-driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in Machine Learning techniques. Our automated continuous improvement DevOps model (making use of both blue / green and canary deployments) results in an average of 50 production releases every day.   Read more about us on our SSENSE Tech Blog. Who is DigitalOnUs by Tech Mahindra? At Tech Mahindra, we have a culture of driving positive change, celebrating each moment, and empowering all to Rise drives us to dream, do, and become more. By living our culture, both as individuals and as a team, we establish and advance our presence as a brand that is global, innovative, and caring. Our culture also leads the way for us to be and become a Company with a Purpose. We try to achieve this by making responsibility personal and adopting sustainability as a way of life at Tech Mahindra. Our service offerings are aligned to the changing world of our customers. Our portfolio of services range from designing strategy to delivering impact. We are Software Engineers, Technical Architects, Cloud and DevOps specialists. But the most important, we are dreamers, creators and challengers. Each day, we strive to make great come alive. Our technology partners are Hashicorp, Google Cloud, AWS, Oracle, SFDC, BMC, HPE, Pega, VMware, Cisco, IBM, SAP, Dell EMC, Microsoft and Service Now. At Tech Mahindra, we are more than 140,000 employees with presence in more than 90 countries. Our DigitALL philosophy focuses on transforming clients' businesses across Products, Services, Business Models and Reimagined Business Processes, leading to new Revenue Opportunities, Enhanced Customer Experience, Operational Efficiency, Reduced Risk, and a better Society. We are always looking for the brightest candidates to come and we offer a work environment with everything you need to be your best. Does Ambition, Success, Fun, Friends & Learning define your idea of a career? Join us and be part of our family! We're looking for a passionate, product-focused Sr Data Analyst/ Power BI  who has hacked systems in creative ways, and who are curious about new languages, technologies, and trends. We believe that working hard is a byproduct of loving what you do and not something that can be assured on a timesheet.   Location: Mexico - Remote Quailifications we are looking for: Minimum 5+ years of experience working directly with Powe BI. Perform data model design and implementation Data experience (data architecture, data modeling, data engineering) 3+ years of experience with writing and debugging SQL queries. Have proven experience in visual analytics best practices, development processes, and knowledge of typical BI & analytics too. (Power BI, Qlik Sense, Tableau, etc.) Ability to integrate reporting components from multiple data sources Effective analytical, conceptual, and problem-solving skills. Ability to work concurrently across multiple technologies (e.g. Power BI, Qlik Sense, Tableau) depending upon specific needs of the client Ability to manage multiple parallel assignments and meets specified milestones Experience in optimizing dashboards with focus on usability, performance, flexibility and standardization Experience in end-to-end implementation of BI projects for developing a portfolio of scorecards, KPIs, reports & dashboards. What you can expect from us At DigitalOnUs by TechMahindra, what distinguishes us from other teams is the comfortable environment which engenders trust within teams and with our customers. Trust and openness leads to quality, innovation, commitment to deliverables, efficiency and cost-effectiveness for all our customers. Work with some truly remarkable IT engineers, architects, specialists and more. We’re growing at a phenomenal pace and we’d like some company. Hear your voice, nurture your talent and help you strengthen your foot print! Benefits above the law Mentorship, and opportunities to grow and learn   ID:2301 If you apply for this opportunity we will get you resume and its contain personal data whose treatment has been authorized by its owner for Digital OnUs, S. de RL de CV (the "Company”). If you are not the owner of this information or have no relation whatsoever with the subjects treated in it, you are requested in the most attentive way not to make copies of it and / or its attached files and delete it immediately, under the risk of being considered as responsible for the unauthorized treatment of personal data in accordance with the Federal Law on Protection of Personal Data Held by Private Parties, its Regulations, and other applicable regulations. If you are the owner of personal data in possession of the Company and wish to obtain further information regarding the processing of your personal data or the exercise of your ARCO rights, please consult our integral privacy notice on the website https://www.digitalonus.com/privacy-policy/ Company Description The Bosch Group is a leading global supplier of technology and services. It employs roughly 394,500 associates worldwide (as of December 31, 2020). According to preliminary figures, the company generated sales of 71.6 billion euros in 2020. Its operations are divided into four business sectors: Mobility Solutions, Industrial Technology, Consumer Goods, and Energy and Building Technology. The Bosch Group comprises Robert Bosch GmbH and its roughly 440 subsidiaries and regional companies in some 60 countries. If its sales and service partners are included, then Bosch is represented in roughly 126 locations. This worldwide development, manufacturing, and sales network is the foundation for further growth. RBVH - Robert Bosch Engineering and Business Solutions Vietnam Company Limited is 100% owned subsidiary of Robert Bosch GmbH.  RBVH has started its operations from 19th October, 2010 at E-Town2 in HCMC. This engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide IT (SAP Consulting, JAVA Development….) and Business Services (Finance and accounting, Economics, Purchasing, Logistics, Translations Japanese-English-Japanese, Information Security ) solutions to the Bosch group of companies globally.  Job Description Designing and coding Hadoop applications to analyze data collections. Creating data processing frameworks. Extracting data and isolating data clusters. Testing scripts and analyzing results. Troubleshooting application bugs. Maintaining the data security. Producing Hadoop development documentation. Qualifications Bachelor degree in IT/ Computer Science or relevant background Have at least 1 year of experience in the relevant technologies Experience in the Hadoop ecosystem and its components: HDFS, Yarn, MapReduce, Apache Spark (Python/Scala), Apache Sqoop, Apache Impala, Apache Avro, Apache Flume, Apache Kafka Preferred: having certificate CCA175 – Spark and Hadoop Developer Designed and developed ETL process Experienced in Unix with Scripting experience is preferred Should have strong knowledge on concepts of data warehousing models, data ingestion patterns, data quality and data governance Experience on the Hadoop systems with good understanding and knowledge of Hadoop cluster Good at English communication skills Additional Information           Committed 13-month bonus          Collaboratively yearly performance bonus          Meal & Parking allowances          Premium insurance (PVI) for employee and 2 family members          Overseas training programs and working onsite opportunity          Good benefits of Trade Union activities, team building and company trip.          Opportunity to work in global projects of fast developing company and being a part of innovation team contributing initiative ideas to the hi-tech world.          Engage in our diverse training programs which surely help strengthen both your personal and professional skills Company Description The Bosch Group is a leading global supplier of technology and services. In 2013, its roughly 281,000 associates generated sales of 46.4 billion Euros. Since the beginning of 2013, its operations have been divided into four business sectors: Automotive Technology, Industrial Technology, Consumer Goods, and Energy and Building Technology.  The Bosch Group comprises Robert Bosch GmbH and its roughly 360 subsidiaries and regional companies in some 50 countries. If its sales and service partners are included, then Bosch is represented in roughly 150 countries. This worldwide development, manufacturing, and sales network is the foundation for further growth RBVH - Robert Bosch Engineering and Business Solutions Vietnam Company Limited is 100% owned subsidiary of Robert Bosch GmbH.  RBVH has started its operations from 19th October, 2010 at e-Town2 in HCMC. This engineering development center will be engaged in developing embedded systems and software, mechanical design and simulation, and will provide IT (SAP Consulting, JAVA Development….) and Business Services (Finance and accounting, Economics, Purchasing, Logistics, Translations Japanese-English-Japanese, Information Security ) solutions to the Bosch group of companies globally.  Job Description Create data model based on data source Generate different kinds of PowerBI report Requirement verification Task estimation Unit Testing Qualifications Bachelor degree in IT/ Computer Science or relevant background Have at least 2 years of experience in Power BI development Hands-on experience in SQL Query in SQL server Hands-on experience in SQL Server Integration Services (SSIS) Hands-on experience in SQL Server Reporting Services (SSRS) Good at unit testing and integration test strategies Willing to support team members/others on DB-related tasks Good English communication skills Must be able to multi-task and deal with changing priorities Additional Information Why BOSCH? Because we don't just follow trends, we create them. Because together we turn ideas into reality, working every day to make the world of tomorrow a better place. Do you have high standards when it comes to your job? So do we. At Bosch, you will discover more than just work. Benefits and Career Opportunities Working in one of the Best Places to Work in Vietnam Join a dynamic and fast growing global company (English-speaking environment) 13th-month salary bonus + attractive performance bonus (you'll love it!) + annual performance appraisal 100% monthly basic salary and mandatory social insurances in 2-month probation Onsite opportunities: short-term and long-term assignments 15++ days of annual leave + 1 day of birthday leave Premium health insurance for employee and 02 family members Flexible working time Lunch and parking allowance Various training on hot-trend technologies/ foreign language (English/Chinese/Japanese) and soft-skills Fitness & sport activities: football, badminton, yoga, Aerobic Free in-house entertainment facilities and snack Join in various team building, company trip, year-end party, tech talks and a lot of charity events Company Description Bosch Global Software Technologies Private Limited (BGSW) is a 100% owned subsidiary of Robert Bosch GmbH. We are one of the world’s leading global suppliers of technology and services, offering end-to-end Engineering, IT, and Business Solutions. With a global footprint and presence in US, Europe, Japan, China, and the Asia Pacific region, we are at the forefront of designing, developing, and executing IoT ecosystems through our all-encompassing capability within the 3 aspects of IoT – Sensors, Software, and Services. We have always focused on improving the quality of the life of people, providing newer revenue-generating opportunities, and improving operational efficiencies for enterprises through an array of solutions. With our unique ability to offer end-to-end solutions that connect Sensors, Software, and Services, we enable businesses to move from the traditional to digital or improve businesses by introducing a digital element in their products and processes. Job Description ·        Passionate about data and how it can make a difference? ·        Interested in learning how to create a strategy and execute the same? ·        Want to be part of a vibrant global Power BI community with some of the most passionate people? ·        Committed to making a difference with a role with vast opportunities to grow and excel? If your answer to all above questions is “Yes”, then the role is for you! We are looking for passionate and dynamic associate who want to be part of this exciting journey. What you’ll do? You will work as part of our global DevOps teams to provide data solutions for our internal customers across the globe. In collaboration with our product owners and business experts you will create and improve Power BI Reports and meaningful Premium Data Sets. You will be able to explore the full world of our business data platform to generate insights and derive actions. You will be responsible to drive continuous improvement engagements and be part of a problem-solving culture Take responsibility: You will work with our internal customers and international team of developers to design and implement Power BI Reports and Power BI Premium Datasets. Help shape the future: As an employee of the global cross-functional Business Intelligence team (xBI), you will work on the future steering of Bosch. Use freedom and creativity: We live agile values so that you can contribute your ideas and experiences for the benefit of the team and the company. Think entrepreneurially: As part of the leading in-house provider for data and analytics-based solutions within Bosch, you will experience the start-up spirit with us and make your contribution through entrepreneurial thinking and acting. Live Cooperation: You will work in an interdisciplinary and international team supported by internal and external service providers as well as in direct exchange with our internal customers. Personality: Team player, committed, responsible and flexible Qualifications Education: Graduate / Postgraduate in Engineering (preferably Computer Science) / MBA / MCA   Experience: 5+ years of experience working as a Power BI developer (rare exceptions for highly skilled developers). Professional experience in the field of BI and Data Warehouse. Working knowledge of Microsoft BI and Azure stack. Prolific experience with data analytics and data warehousing environments. Experience in translating business requirements into set of analytical tasks. Way of working: Agile, analytical, proactive, result, solution-oriented and high code/solution quality. Additional Information Know-How: ·        Collection and analysis of complex requirements and creation of solution concepts ·        Ability to tackle complex problems independently or by collaborating with other team members ·        Conception and implementation of data analysis, data strategies and visualizations ·        Working knowledge on how to extract data from SQL, transform data through SQL backend, Power Query, DAX. ·        Familiarity with BI concepts such as ETL design, analytics, and reporting ·        Excellent troubleshooting and analytical skills ·        Experience in DAX queries, Power BI, Building Analysis Services tabular models (SSAS) ·        Solid understanding of data warehousing concepts including the common schema architectures, dimensions, facts, aggregate facts, and data marts. Data Vault knowledge and Azure certificates will be beneficial. ·        Certification in Power BI will be an added advantage ·        Good understanding of Agile and leveraging Agile to deliver consistent business results Enthusiasm: Passion for data, data solutions and its integration, developing interdisciplinary approaches and products for customers and presenting complex issues in a simple manner Languages: Fluent in English, written and spoken to collaborate with developers and communicate with customers. GRAIL is a healthcare company whose mission is to detect cancer early, when it can be cured. GRAIL is focused on alleviating the global burden of cancer by developing pioneering technology to detect and identify multiple deadly cancer types early. The company is using the power of next-generation sequencing, population-scale clinical studies, and state-of-the-art computer science and data science to enhance the scientific understanding of cancer biology, and to develop its multi-cancer early detection blood test. GRAIL is headquartered in Menlo Park, CA with locations in Washington, D.C., North Carolina, and the United Kingdom. GRAIL, LLC is a wholly-owned subsidiary of Illumina, Inc. (NASDAQ:ILMN). For more information, please visit www.grail.com. The Data Engineering group, within the Software - Technology organization, is looking to hire a Bioinformatics Data Engineer (BXDE) to partner with computational, engineering and clinical study teams in developing data solutions for the GRAIL product pipeline.  The BXDE will partner with scientists and statisticians to support efficient and accurate capture and transfer of sample information and analysis results through GRAIL’s analysis systems. As such, the BXDE will become proficient in GRAIL’s analysis system architecture, including primarily GRAIL’s LIMS for laboratory data; Electronic Data Capture (EDC) for clinical study data; the Bioinformatics Pipeline for sequence analysis and cancer classification data; and TidyData, the system that aggregates, packages, and serves datasets created from LIMS, EDC, and Pipeline outputs.  The BXDE will also collaborate with software engineers and scientists to develop and produce analysis-ready datasets for clinical research and product development. The BXDE will develop code and procedures to support dataset generation, perform QC, and troubleshoot issues that arise during dataset generation. The BXDE will also collect requirements, develop prototypes, and collaborate on production implementations of new reporting-related features as needed. The BXDE will learn analysis requirements by reading laboratory protocols, Statistical Analysis Plans, and other analysis planning documents and meeting with scientists, biostatisticians, and other stakeholders.  Additionally the BXDE may have opportunities to collaborate on statistical analyses and creation of analysis reports and interactive data visualizations.    RESPONSIBILITIES Support successful scientific analyses by ensuring scientists can focus on analyses and not have to learn all of the nuances of GRAIL’s analysis systems Ensure that at the end of sample and data processing, TidyData can generate a complete and accurate analysis-ready dataset Develop and support processes for analysis dataset creation, QC, and release Develop standards and procedures to improve efficiency of new dataset implementation Collect user requirements and develop custom reporting features as well as prototypes for future production reporting features Define dataset QC procedures, report templates, and automated reports for streamlined execution of QC procedures Maintain data integrity and quality throughout the data lifecycle, including ensuring clinical study-related blinding where appropriate. PREFERRED BACKGROUND BS or MS in a scientific field (life science, computer science, engineering, mathematics, statistics, bioinformatics, etc.). Experience with R or Python programming is required Experience with basic concepts of molecular biology is required Experience with cross-functional collaboration while ensuring data quality and commitment to analysis reproducibility is required Excellent interpersonal communication (written and verbal) and organizational skills is required Excellent team player with a demonstrated track record of success in a cross-functional team environment. Consistent commitment to delivering on team goals with a sense of shared urgency is required Experience in the field of molecular diagnostics is a plus Experience with CDISC data models is a plus Experience with Amazon Web Services is a plus Experience with data visualization and analytics tools is a plus The estimated, full-time, annual base pay scale for this position is $111,000 - $150,000.  Actual base pay will consider skills, experience, and location.  Based on the role, colleagues may be eligible to participate in an annual bonus plan tied to company and individual performance, or an incentive plan. We also offer a long-term incentive plan to align company and colleague success over time. In addition, GRAIL offers a progressive benefit package, including flexible time-off, a 401k with a company match, and alongside our medical, dental, vision plans, carefully selected mindfulness offerings. GRAIL is an Equal Employment Office and Affirmative Action Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability or any other legally protected status. We will reasonably accommodate all individuals with disabilities so that they can participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation. Following extensive monitoring, consideration of business implications, and advice from internal and external experts, GRAIL US has made the decision to require that all U.S. employees be “Fully Vaccinated” with the COVID-19 vaccine. “Fully Vaccinated” is defined as two weeks after both doses of a two-dose vaccine (e.g. Pfizer or Moderna) or two weeks since a single-dose vaccine (e.g. Johnson & Johnson) has been administered. Absent a qualifying exemption, all GRAIL US employees are to comply with this requirement, including providing documentation of such vaccination status, as a condition of employment. Anyone unable to be vaccinated, either because of a sincerely held religious belief or a medical condition or disability that prevents them from being vaccinated, can request a reasonable accommodation for consideration by GRAIL. Company Description Publicis Sapient, the digital business transformation hub of Publicis Groupe, helps clients drive growth and efficiency and evolve the ways they work, in a world where consumer behavior and technology are catalyzing social and commercial changes at an unprecedented pace. With 17,000 people and over 100 offices around the globe, our expertise spanning technology, data sciences, consulting and creative, combined with our culture of innovation, enables us to deliver on complex transformation initiatives that accelerate our clients’ businesses through creating the products and services their customers expect. Job Description As a  Manager with our Data Engineering group, you will be responsible for consulting clients on data solutions. You will architect, design, estimate, developing and deploy cutting edge software products and services that leverage large scale data ingestion, processing, storage and querying, in-stream & batch analytics for Cloud and on-prem environments.  Your role will be focused on delivering high quality solutions while driving design discussions across Data Engineering topics (ingestion, consumption, storage, computation, data models, performance, DevOps, Test automation & Security) to enables enterprise scale digital transformation of many of the biggest companies in the world.  As a hands-on technologist you will be excited to join super talented and supportive community of Data Engineers who are passionate about building the best possible solutions for our clients and endorse a culture of life-long learning and collaboration. Qualifications  Extensive experience with Data related technologies, to include knowledge of Big Data Architecture Patterns and Cloud services (AWS / Azure / GCP) Experience delivering end to end Big Data solutions on premise and/or on Cloud Knowledge of the pros and cons of various database technologies like Relational, NoSQL, MPP, Columnar databases Expertise in the Hadoop eco-system with one or more distribution-like Cloudera and cloud specific distributions Proficiency in Java and Scala programming languages (Python a plus) Expertise in one or more NoSQL database (Mongo DB, Cassandra, HBase, DynamoDB, Big Table etc.) Experience of one or more big data ingestion tools (Sqoop, Flume, NiFI etc.), distributed messaging and ingestion frameworks (Kafka, Pulsar, Pub/Sub etc.) Expertise with at least one distributed data processing framework e.g. Spark (Core, Streaming, SQL), Storm, Flink etc. Knowledge of flexible, scalable data models addressing a wide variety of consumption patterns including random-access, sequential access including necessary optimisations like bucketing, aggregating, sharding Knowledge of performance tuning, optimization and scaling solutions from a storage/processing standpoint Experience building DevOps pipelines for data solutions, including automated testing You’ll Also Likely Have Some Of The Following Knowledge of containerization, orchestration and Kubernetes engine An understanding of how to setup Big data cluster security (Authorization/ Authentication, Security for data at rest, data in transit) A basic understanding of how to manage and setup Monitoring and alerting for Big data clusters Experience of orchestration tools – Oozie , Airflow , Ctr-M or similar Experience of MPP style query engines like Impala, Presto, Athena etc. Knowledge of multi-dimensional modeling like start schema, snowflakes, normalized and de-normalized models Exposure to data governance, catalog, lineage and associated tools would be an added advantage A certification in one or more cloud platforms or big data technologies Any active participation in the Data Engineering thought community (e.g. blogs, key note sessions, POV/POC, hackathon) Additional Information There is a superb package of benefits waiting for you at Publicis Sapient. We cover all the basics generously, with 25 days paid annual leave, life assurance, dental insurance, income protection, private healthcare for you AND your family (pre-existing conditions included), and a pension. The learning opportunities here are endless. Most importantly, of course, there’s the chance to be part of a game-changing organisation that celebrates creative thinking and empowerment. The creature comforts are super: free barista coffee bar (the best in town), gym-fee reimbursement and working in the most exciting, colourful and diverse local area you could imagine. Flexibility and mobility are needed for this role. You might need to spend time on-site with our clients to deliver our world-class services. Are you inspired by invention? Is problem solving through teamwork in your DNA? Do you like the idea of seeing how your work impacts the bigger picture? Answer yes to any of these and you’ll fit right in here at Amazon Robotics. We are a smart team of doers who work passionately to apply cutting edge advances in robotics and software to solve real-world challenges that will transform our customers’ experiences. We invent new improvements every day. We are Amazon Robotics and we will give you the tools and support you need to invent with us in ways that are rewarding, fulfilling, and fun.  Amazon Robotics empowers a smarter, faster, more consistent customer experience through automation. Amazon Robotics automates fulfillment center operations using various methods of robotic technology including autonomous mobile robots, sophisticated control software, language perception, power management, computer vision, depth sensing, machine learning, object recognition, and semantic understanding of commands. Amazon Robotics has a dedicated focus on research and development to continuously explore new opportunities to extend its product lines into new areas.  Amazon Robotics internship/co-op opportunities will be based out of the Greater Boston Area in North Reading, MA. Campuses provide a unique opportunity to have direct access to robotics testing labs and manufacturing facilities.  Key job responsibilities Amazon Robotics Storage Technologies is looking for a Business Intelligence Engineer intern/co-op to analyze robotic systems, improve program dashboards, and to create data pipelines through AWS. A successful Co-op candidate will use data and technology to seek improvements or find disruptions in current storage field operations. In addition, a successful team member seeks opportunities to deep dive issues and influence future decisions. Candidates should have experience in business analytics, data science, data visualization, data engineering, and communicating analyses effectively. Amazon Robotics’ culture encourages innovation and expects co-ops to take a high level of ownership in all tasks.  Key Responsibilities for the Co-op: Analyze historical data to gauge relative performance metric changes, highlighting causation. Analyze data related to NPI storage solutions to evaluate expected vs actual system performance and entitlement Work with partner teams to onboard data from other Amazon data providers Write queries to pull data and act as a thought partner through the design phase of NPI solutions Support existing dashboards making edits to the underlying SQL, metric definitions, and customer facing visualizations Evaluate and observe data practices in your own work and throughout the team, always insisting on the highest standards  About the team The Robotic Storage Technology Analytics team (RST-A) is comprised of data scientists and Business Intelligence Engineers who support data exploration and analysis to support Amazon Robotics (AR) fulfillment buildings and new product development. We conduct relevant, insightful analysis and communicate the results through white papers, dashboards, and presentations. Our methods include design of experiments, statistical modeling, financial analysis, data pipelining, exploratory data analysis, metric generation, and data visualization. Basic Qualifications  Currently enrolled in Bachelor's or higher in an analytically rigorous field (Mathematics, Data Science, Statistics, Computer Science, Industrial Engineering, Econometrics) or other equivalent discipline with a graduation date after May/June 2024 Must be eligible and available for a full-time (40h / week) 6-month co-op between July to December 2023 Experience building dashboards in Tableau or other relevant data visualization tool (Looker, PowerBI, Grafana, etc.) Write high-quality and optimized SQL queries to retrieve datasets Basic understanding of Python or R for exploratory data analysis and modeling Ability to communicate analytic results effectively across stakeholder groups  Preferred Qualifications Pursuing a Master’s or higher in an analytically rigorous field (Mathematics, Data Science, Statistics, Computer Science, Industrial Engineering, Econometrics) or other equivalent discipline Understanding of statistics, specifically random variable distributions and A/B tests Familiarity with AWS tools and products for data engineering and data science such as S3, Glue, Sagemaker, and Athena   Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Company Description   Job Description Widełki wynagrodzenia przewidziane przy tym stanowisku to (umowa o pracę): mid: 12 300 - 17 600 PLN brutto senior: 16 100 - 23 200 PLN brutto Model pracy hybrydowej według ustaleń lidera i zespołu.  Ofertę kierujemy do osób, które: Bardzo dobrze znają SQL Posiadają doświadczenie z co najmniej jednym typem baz danych: Oracle, PostgreSQL, MySQL, BigQuery Biegle posługują się Google Sheets (Google Suite), MS Excel Posiadają doświadczenie z narzędziami raportowymi takimi jak: Google Data Studio, Tableau, Power BI, Cognos Potrafią sprawnie zarządzać czasem i pracować w zespole Oczekują pracy, która ma głębszy sens (nie tylko “management zlecił”) i realny wpływ na decyzyjność kadry zarządzającej Potrafią szukać efektywnych rozwiązań do wymagań stawianych przez użytkowników Chcą się ciągle rozwijać i aktualizować swoją wiedzę Dodatkowym atutem będzie: Podstawowa umiejętność programowania w języku Python Podstawowa znajomość Google Apps Script Wiedza oraz doświadczenie w modelowaniu, tworzeniu i utrzymaniu procesów ETL Znajomość zagadnień związanych Airflow, Google Composer, Dataproc, Spark Doświadczenie w pracy w środowisku GCP Dlaczego miał(a)byś z nami pracować? Zapewnisz dane niezbędne do rozwoju systemów wspomagających działalność zespołów finansów oraz kadry zarządzającej Będziesz odpowiadać za prezentację wybranych danych oraz automatyzację procesów raportowych w obszarze Technologii oraz Finansów  Będziesz wspierać automatyzację istotnych procesów biznesowych i back officowych Zajmiesz się tworzeniem i wsparciem utrzymania procesów ETL oraz przygotowaniem agregatów danych  Odpowiesz za rozwój procesów raportowych w oparciu o wymagania biznesowe przy użyciu Google Data Studio Będziesz mieć realny wpływ na kluczowe KPI Allegro Zaangażujesz się w zróżnicowane projekty z obszaru styku Finansów i Technologii, Otrzymasz możliwość rozwoju w obszarze BI i AI&ML oraz umiejętności związanych z programowaniem w języku Python Ze swojej strony oferujemy: Model pracy hybrydowej, który ustalisz z liderem i zespołem. Mamy świetnie zlokalizowane biura ( z w pełni wyposażonymi kuchniami i parkingami dla rowerów) i znakomite narzędzia pracy (podnoszone biurka, interaktywne sale konferencyjne) Bonus roczny do 10% wynagrodzenia rocznego liczony z kwoty brutto (zależny od Twojej oceny rocznej oraz wyników firmy) Bogaty pakiet świadczeń pozapłacowych w systemie kafeteryjnym – Ty decydujesz z czego korzystasz (do wyboru mamy m.in. pakiety medyczne, sportowe, lunchowe, ubezpieczenia, bony na zakupy) Zajęcia angielskiego opłacane przez nas i skoncentrowane na specyfice Twojej pracy Hackathony, turystykę zespołową, budżet szkoleniowy oraz wewnętrzna platforma MindUp (m.in. szkolenia z zakresu organizacji pracy, sposobu komunikacji, motywacji do pracy oraz różnych technologii i zagadnień merytorycznych) Wyślij nam swoje CV i sprawdź dlaczego #dobrzetubyć Company Description SSENSE (pronounced [es-uhns]) is a global technology platform operating at the intersection of culture, community, and commerce. Headquartered in Montreal, it features a mix of established and emerging luxury brands across womenswear, menswear, kidswear, and Everything Else. SSENSE has garnered critical acclaim as both an e-commerce engine and a producer of cultural content, generating an average of 100 million monthly page views. Approximately 80% of its audience is between the ages of 18 to 40. It is privately held and has achieved high double digit annual growth and profitability since its inception. Job Description Reporting to the Senior Director of Global Operational Excellence & Continuous Improvement, the Manager of Data Visibility, Governance, and Product is responsible for leading the design, development, and successful implementation of current and future data visualisation, reporting standards, and workflow data products for Operations. They will oversee a team of analysts that translate business requirements into technical reporting requirements across all end-to-end processes, define the metrics, and then build the data products and corresponding dashboards that will be a cornerstone of all Operational roles and training programs at SSENSE. The incumbent will ensure data visualisation, metric, and KPI standards are clearly defined ahead of our global network expansion plans over the coming 1-3 years. RESPONSIBILITIES Data visibility, governance, and product design (75%) Develop and lead the Operations Visualization & Data Governance transformation plan that will standardise and operationalize all data points related to physical and systemic movement of products within the SSENSE Network, spanning operational process paths to C-suite executive-level reporting Translate and develop standard metrics for reporting, and collaborate with the Product and Engineering, and Data Platform team to determine the right mechanism for delivering the reports and insights to maximize how they are used and actioned by Operational teams Develop, and implement reporting solutions with AWS tools like Athena, Tableau, and operational reporting capabilities available through operational systems Work closely with all Operational teams and executive leadership to ensure clear and consistent metric definitions, comprehensive capture and up-to-date documentation of operational reporting and analytical reporting requirements  Oversee all data, metric, and dashboard development by the direct team; define the internal development process and stakeholder engagement model, establishing quality measures for product delivery; achieve and maintain best-in-class benchmarks for adoption rates Develop prioritised roadmap for scaling visibility, maturity, automation, and real-time capability for all operational process paths in tandem with process maturity assessment; design agile approach for near-term output and ongoing, ad hoc request management Implement design principles and templates for data visualisation and governance across Operations that guides all dashboard development in current and future state Collaborate with the Product and Data Platform teams to define and demarcate data accessibility and tools for analysis vs. standardised user interface for operational process and reporting Partner with Business Process Owners and Operations leadership to implement standard metrics based on industry best practices to integrate with company-wide metric reporting  Implement continuous improvement processes for refining / streamlining data or visualisation standards, as well as change management practices for deployment; inclusive of scalable approach to deprecating and removing legacy reports and dashboards Pilot workflow tools that support predictive analytics and algorithmic recommendations Oversee successful migration of reporting, visualisation, and workflow tools with existing system or product changes (e.g., WMS); partner with Product teams to define requirements of new systems or product implementation (e.g., YMS, LMS); ensuring successful integration with data governance and reporting standards Partner directly with the Data Platform team and the Product and Engineering teams to develop a design of the future for these collaterals and corresponding data architecture People leadership and development (25%) Work with Senior Leadership to gauge and monitor team engagement and implement solutions to create a transparent, collaborative and productive work environment  Collaborate with Senior Leadership to establish the department short term objectives for the department and ensure the team's are engaged towards achieving them  Hold weekly one-on-ones, conduct performance reviews, analyze individual KPIs and assess promotion readiness to help each contributor evolve in their roles Provide mentorship and development opportunities to team members, catalyzing growth through coaching and team building Qualifications REQUIREMENTS Bachelors Degree in Computer Science, Information Systems, Mathematics, Statistics, Data Science, Software Engineering, or another relevant field  A minimum of 5 years of professional, hands-on data management/Operations and analytics experience, with at least 3 years of formal management experience leading highly developed data management and analytical professionals, ideally in fast-paced Fulfillment industry, Distribution, Logistics or Production/Manufacturing environment Extensive experience with data manipulation and data visualisation tools, such as Tableau for reporting and dashboarding is essential Extensive experience with data manipulation using SQL or other means to extract and transform data is a must Analytical mindset and experience working with business and technical teams to define key metrics, KPIs, definitions, and governance standards, along with the process to manage and maintain them over time is a must Experience with Operational SAAS systems and their reporting capabilities (pros and cons) is a plus Experience leading teams in information design principles and data visualisation methods, best practices, and software packages and APIs such as Tableau or equivalent analytics tools Strong written and verbal communication skills in English and French SKILLS Strong organisational and time management skills  Advanced data analysis skills, and an expert in using supporting tools Strong collaboration and prioritisation skills Ability to identify, prioritise and articulate high impactful initiatives The ability to translate operational issues into workable data solutions Creative out-of-the-box thinking with excellent problem-solving abilities Team player with solid leadership and interpersonal skills Strong communication skills, with an ability to influence cross-functional teams Additional Information WORLD CLASS TECHNOLOGY  Technology is at the core of everything we do at SSENSE. Driven by an engineering mindset and a problem-solving attitude, we blend fashion with technology to deliver an unparalleled experience to our customers as we build seamless, custom solutions to deliver the SSENSE offering.  WORLD CLASS TEAM The SSENSE tech team is responsible for an international headless commerce platform. Working in an agile environment, our squads are made up of experienced innovators in Product Management, QA, Design, DevOps, Software Development, Machine Learning, Data Engineering, and Security. Headquartered in Montreal, our technology organization has been growing at a rate of 2X year-over-year and is doubling once again in 2021 as we expand across Canada, US, and Europe.   WORLD CLASS PLATFORM  The SSENSE platform runs on Amazon Web Services making use of serverless microservices across web, mobile and app. Our event-source architecture already achieves over 10,000 requests / second and growing at an unmatched pace, currently unseen across the industry.  Our data-driven culture of innovation empowers every product team across the tech organization to explore building, testing and learning with the latest in Machine Learning techniques. Our automated continuous improvement DevOps model (making use of both blue / green and canary deployments) results in an average of 50 production releases every day.   Read more about us on our SSENSE Tech Blog. Binance is the global blockchain company behind the world’s largest digital asset exchange by trading volume and users, serving a greater mission to accelerate cryptocurrency adoption and increase the freedom of money. Are you looking to be a part of the most influential company in the blockchain industry and contribute to the crypto-currency revolution that is changing the world? About Binance Accelerator Programme Binance Accelerator Programme is a concise 3 - 6 months programme designed to have an immersive experience in the rapidly expanding Web3 space.  You will be given the opportunity to experience life at Binance and understand what goes on behind the scenes of the worlds’ leading blockchain ecosystem. Alongside your job, there will also be a focus on networking and development, which will expand your professional network and build transferable skills to propel you forward in your career.  Who may applyCurrent students, fresh graduates, and candidates who are mid-career switchers. Data driven based business is the core in helping  to use cloud native platform to serve tens of millions of crypto-currency users. Engineers and Data Scientists across the company use the data platform to do interesting and impactful analysis for continuous innovations. As a data scientist, you will have the opportunity to leverage rich data (PB-level scalability) and state-of-art machine learning infrastructure to develop data products which are used by our tens of millions of crypto-currency users. You will collaborate with a strong team of engineers, data analysts, business operation and product/marketing managers to define and build solutions, features, algorithms and products based off our rich data and cutting-edge machine learning technology. Responsibilities: Facilitate data collection that will allow the identification of crypto address owners Work closely with the Data Science team, who will guide your data collection strategy Requirements: Experience in making transactions on the blockchain Broad understanding of blockchain technology and existing ecosystem Experience in investigation of blockchain cyber crimes is plus Knowledge of DeFi ecosystem (DEX, Lending Platform, etc) is plus Title: Data Engineer II / BI Analyst (Growth and Acquisition) Reporting to: Lead Data Engineer Location: United States / Remote, requires U.S. work authorization Term: Permanent Full Time Compensation: $90,000 Deadline: Applications reviewed on a rolling basis, target start mid April About WorkMoney WorkMoney is a nonprofit organization dedicated to lowering costs and raising incomes for all Americans to make American life more affordable and American families more economically secure. We provide products, services, perks, benefits, tips, and tools to help members improve their financial lives. We are a trusted source of information about financial matters, economic policy, and public debates about the economy. In 2023, we will be increasing our presence and investment across a broader range of paid, owned, earned and shared channels which will enable us to advance our core vision that everyone in America can afford to live a good life. You can find out more about WorkMoney at workmoney.org and Facebook. Why are we looking for a Data Engineer / BI Analyst? In our first two years of operation, we built things fast and relied on a web of vendors, platforms, staff, and consultants to do so. As the organization grows and the work becomes more complex, we’ve invested in growing our Data Science & Analytics team to increase internal capacity to manage our data environment and build the foundations for making smart data-informed decisions across platforms. With significant investments being made in our web presence and growth programs this year, we’re ready to add another member to our team to take one of our largest programs to the next level. Requirements What are we looking for? WorkMoney is looking for a Data Engineer to build and monitor pipelines to various social media platforms and internal data systems, while also analyzing existing processes and investigating problem areas. Successful candidates will have experience with owning and building APIs, investigating and diagnosing data inaccuracies, and managing external relationships with relevant vendors. We also need someone who can analyze the data and create reporting dashboards to showcase performance and other program metrics. This role will be a combination of engineering and analytics as we build out the program and analyze incoming data to show progress. A unique role for a solutions oriented engineer who wants to flex their technical and cross-functional communication skills. Responsibilities Build, test, and monitor APIs to various social media platforms (including but not limited to Google, Facebook, Snapchat, etc.) Troubleshoot data issues with various internal and external partners, such as missing data and repairing broken pipelines Create and maintain documentation and training materials Maintain reporting dashboards to communicate insights across the organization Respond to requests for data and reporting in a timely manner Must Haves Practical experience designing and controlling APIs for consistency, simplicity, and extensibility Proficiency with SQL Proficiency with AWS and Redshift integrations Ability to analyze and communicate data in clear visualizations and dashboards, such as creating infrastructure and schema diagrams Self-motivated problem solver with a knack for sniffing out data inaccuracies Scope out new tools and recommend improvements to current systems and processes Big picture thinker with excellent communication skills Nice to Haves Experience working with and managing external consultants or vendors Knowledge of other data programming languages Experience working at high-growth companies and interest in building systems that can scale with increased traffic and larger datasets Benefits We’re proud to offer generous benefits like competitive pay, expansive paid time off options, and employer contributions to retirement and student loan repayment. The salary for this role is $90,000 annually and as part of our commitment to pay transparency and equity in our organization, the salary for this position is not negotiable. WorkMoney covers the premiums for healthcare, dental, and vision plans so you don’t have to, offers a 6% 401K employer match, four weeks paid vacation, generous paid family and medical leave, and annual allowances for remote work and professional development. Why join our team? Our workplace is dynamic and we aren’t afraid to pivot when things don’t work. We’re mission driven, hard working, and scrappy AF. We have a good time working on hard things, and embrace the line ‘feedback is a gift’. We jump in to help each other, and make time to reflect when things go well and not so well. The truth of the matter is: we’re doing cool stuff with really cool people and having a great time doing it. WorkMoney is an equal opportunity employer. WorkMoney prohibits unlawful discrimination against any employee or applicant for employment based on age, color, disability, gender, marital status, national origin, religion, sexual orientation, expression, gender identity, veteran’s status, or any other basis prohibited by law. We see diversity of all kinds as a necessary precondition to doing our work well and strive to build a team that reflects the diverse composition of America itself. We strongly encourage applicants from historically under-represented communities to apply. To Apply Follow the link to the application page, complete the required fields, and submit a resume. Applications will be reviewed on a rolling basis. **Please do not reach out directly to any team members. If you’d like additional information or to check the status of your application, email careers@workmoney.org.** Unternehmensbeschreibung Möchtest du deine Ideen in nutzbringende und sinnvolle Technologien verwandeln? Ob im Bereich Mobility Solutions, Consumer Goods, Industrial Technology oder Energy and Building Technology – mit uns verbesserst du die Lebensqualität der Menschen auf der ganzen Welt. Willkommen bei Bosch. Die Robert Bosch GmbH freut sich auf deine Bewerbung! Stellenbeschreibung Du bist verantwortlich für die Data Analytics und Visualisierung von Produkt- und Fertigungsdaten. Du erweiterst bereits existierende Business Intelligence (BI) Lösungen. Du koordinierst und begleitest die Roll-Outs dieser Lösungen und stimmst dich mit den AnwenderInnen, Leitung von Arbeitsgruppen ab. Du überprüfst die Funktionalität und unterstützt die ProduktmanagerInnen in der Anwendung durch zum Beispiel Trainings und Schulungen. Qualifikationen Ausbildung: überdurchschnittlich abgeschlossenes Hochschulstudium (Bachelor) im Bereich Informatik, Ingenieurwissenschaften, Naturwissenschaften, Wirtschaftsingeniurwesen und konkrete Absicht im Anschluss ein Masterstudium aufzunehmen Arbeitsweise: Teamfähig, durchsetzungsvermögen, systematisch, proaktiv, kreativ Erfahrungen und Know-how: Technisches Verständnis, erste Programmiererfahrung in Big Data Technologien wie Python, BI-Tools und Statistik und C#, Spotfire, SQL/Impala, Tableau, KNIME. Begeisterung: Interesse an IT-affiner Tätigkeit im Produktionsumfeld Sprachen: gute Deutsch- und Englischkenntnisse Zusätzliche Informationen Das Bosch PreMaster Programm ist ein zweistufiges Qualifizierungsprogramm für engagierte Bachelor-Absolventinnen und Absolventen, die das Ziel haben, ein Masterstudium zu absolvieren. Nach dem Bachelor bietet die erste Phase bis zu 12 Monaten praktische Erfahrung, um die fachlichen und unternehmerischen Zusammenhänge kennenzulernen. Die zweite Phase umfasst das Masterstudium und beinhaltet weitere Events und Seminare sowie persönliche Betreuung durch einen Mentor auf dem Weg zum erfolgreichen Abschluss. Beginn: ab September 2022 / nach Absprache Du hast Fragen zum Bewerbungsprozess? Michelle Kurz (Personalabteilung) +49(7121)35-33122 Du hast fachliche Fragen zum Job? Alexander Gölz (Fachabteilung) +49 (7121) 35-2741 Unternehmensbeschreibung Do you want beneficial technologies being shaped by your ideas? Whether in the areas of mobility solutions, consumer goods, industrial technology or energy and building technology – with us, you will have the chance to improve quality of life all across the globe. Welcome to Bosch.                        The Bosch Engineering GmbH is looking forward to your application! Stellenbeschreibung Affinity for new programming languages and analysis of big data in the vehicle SW development. Among your tasks are: Creation of queries and metrics Creation of dashboards  You support us with advice and assistance in the creation and revision of Splunk dashboards.  You take part in implementation activities for upcoming automation endeavors as part of our team.  After an initial set up and Splunk training remote working is possible. Start: September 2022  Time: 6 months Qualifikationen Personality: You work in a self-sufficient, thorough and target oriented manner. You have a knack for programming and dealing with large data sets supported by good communication skills and a friendly demeanor.  Way of working: You are thorough, detail oriented and excel at working in a team.  Know-How: Knowledge in dealing with data base systems and the use of applications for data analysis and visualization (SQL/Azure/Grafana/Tableau or similar). Ideally experience with SPLUNK and proficiency in the use of the SPLUNK-SPL. Basic proficiency in Python.  Enthusiasm: You are initiative and have strong interests in new technologies.  Language: English or German proficiency on a professional level.   Education: Enrolled student (f/m/div.) in a study program with a Computer Science or IT related background, e.g. Computer Science, Mathematics with focus on machine learning/optimization, Computer Engineering or Engineering Informatics.  Prerequisite for the internship is the matriculation at a university. Please enclose with your application a current certificate of enrollment, study and examination regulations and, if applicable, a valid work and residence permit for Germany. Zusätzliche Informationen Need support during your application? Daniela Schneider (Human Resources) +49(7062)911-9555 Need further information about the job? Sebastian Pollak (Functional Department) +49 173 6199307 Here at Mindera, we are continuously developing a fantastic team, and would love it for you to join us. As a Business Intelligence Engineer you will be responsible for building, maintaining, scaling, and integrating big data based platforms. Notwithstanding, you will also be engaged with the Data Science team in setting up and automating the Data Science models/algorithms for production use. This is a fantastic opportunity for someone who is passionate about Data and is excited to use different tools to provide data insight for further analysis and drive business decisions. National and international expected travelling time varies according to project/client and organizational needs: 0%-15% estimated. Requirements You are good at: Have expert knowledge in SQL Designing and building data models, either using Kimball Dimensional Modelling or Data Vault. Familiar with troubleshooting and debugging implementations to quickly and efficiently measure data integrity; analysing implementations for problems and proactively managing issues Working in a multi-disciplinary team Working with GitHub (Preferably experience) working with DBT Cloud (Preferably experience ) Using Fivetran (It would be a bonus) Benefits The Things We Really Care About: Health Insurance, because health comes first Flexible working hours Open holidays, take the time you need for yourself Profit distribution for everyone Mindera Annual Trip, Sports, and sharing groups to connect and have fun! Training & conferences, create your own training plan Child Care vouchers Other Good Things: Choose Laptop & Peripherals that best suit your needs Hotspot with unlimited usage (PT), for work or Netflix ;) We have amazing offices in Porto, Aveiro, and Coimbra if you want to physically connect with minders. Remote is also an option. At the offices, we have a wide range of snacks to keep you fed and healthy Partnerships with local businesses  Most of all You get to work with a bunch of great people, where the whole team owns the project together in a politics-free environment. Our culture reflects our lean and self-organization attitude. We encourage our colleagues to take risks, make decisions, work in a collaborative way and talk to everyone to enhance communication. Freedom and Responsibility go hand in hand, and we value commitment, feedback, and empathy.  About Mindera At Mindera we use technology to build products we are proud of, with people we love. Software Engineering Applications, including Web and Mobile, are at the core of what we do at Mindera. We partner with our clients, to understand their products and deliver high-performance, resilient and scalable software systems that create an impact in their users and businesses across the world. You get to work with a bunch of great people, where the whole team owns the project together. Our culture reflects our lean and self management attitude. We encourage our colleagues to take risks, make decisions, work in a collaborative way and talk to everyone to enhance communication. We are proud of our work and we love to learn all and everything while navigating through an Agile, Lean and collaborative environment. Check out our Blog and our Handbook! Our offices are located: Porto, Portugal | Aveiro, Portugal | Coimbra, Portugal | Leicester, UK | San Diego, USA | San Francisco, USA | Chennai, India | Bengaluru, India | Cluj-Napoca, Romania | Blumenau, Brazil Company Description Ocorian is a global leader in corporate and fiduciary services, fund administration and capital markets. Wherever our clients hold financial interests, or however they are structured, we provide compliant, tailored solutions that are individual to their needs. We manage over 17,000 structures for 8000+ clients with a global footprint operating from 18 locations. Our scale offers all our people great opportunities to develop their knowledge and skills and to progress their careers. Job Description Purpose of the job To assist in the development of business intelligence and management information solutions for Ocorian taking information from the financial, HR, corporate administration systems, and Cloud-based solutions to create a reporting base for the business, the single source of truth Delivery of key dashboards and reporting requirements from the BI/MI solutions with appropriate robust security models Assist with data cleansing and data loading exercises, which may extend to jurisdictional and regulatory filing requirements Documentation of solutions, handover to BAU Teams, and supporting solutions Prior experience of creating/supporting ETL, data warehouses and Tabular data models. Ocorian utilises Microsoft SQL Server technologies, including SSIS, SSAS, SSRS and Power BI and the successful candidate should have delivered projects using aspects of this technology stack in recent times The individual will be expected to work across all levels of the Business to liaise with key stakeholders to ensure the design, development and documentation meets the requirements of the Business. The role will work extensively with IT functions and the role may be matrix-managed when required with tasks assigned by the BAU BI Team Main Rresponsibilities Design and implement data warehouse solutions and Tabular data models Develop dashboards and reporting to meet business reporting needs Deliver approved projects within timeframe Provide regular updates to management Make recommendations for potential improvement or changes Promote the use of core systems for data capture aligned to standards and initiatives Qualifications Technical Skills SQL Server 2016 onwards SQL Server BI stack – SSAS / SSIS / SSRS Microsoft Power BI Experience of data cleansing tools and methodologies Businesss Skills Demonstrated ability to apply IT in solving business problems Good written, oral, and interpersonal communication skills Ability to present ideas in business-friendly and user-friendly language Highly self-motivated, proactive and attentive to detail Ability to effectively prioritise and execute tasks in a high-pressure environment Extensive experience working in a team-oriented, collaborative multi-jurisdictional environment Experience of working in project teams with mixed skillsets and levels of technical knowledge Energy and enthusiasm to support the future growth and success of the business Additional Information All staff are expected to embody our core values that underpin everything that we do and that reflect the skills and behaviours we all need to be successful.  These are: We are AMBITIOUS - We think and act globally, seizing every opportunity to support our clients and staff - wherever in the world they may be. We are AGILE - Our independence from any financial institution gives us the flexibility and freedom to keep things simple, efficient and effective. We are COLLABORATIVE - We take the time to understand our clients' needs so that we can deliver personalised solutions every time. We're Cruise, a self-driving service designed for the cities we love. We’re building the world’s most advanced, self-driving vehicles to safely connect people to the places, things, and experiences they care about. We believe self-driving vehicles will help save lives, reshape cities, give back time in transit, and restore freedom of movement for many. Cruisers have the opportunity to grow and develop while learning from leaders at the forefront of their fields. With a culture of internal mobility, there's an opportunity to thrive in a variety of disciplines. This is a place for dreamers and doers to succeed. If you are looking to play a part in making a positive impact in the world by advancing the revolutionary work of self-driving cars, join us. Cruise is looking for a Fleet Reliability and Engineering Data Analyst for the Commercial Operations team to support us in our scaling efforts. This role will involve analyzing data to cultivate a deeper understanding of our AVs in the field and working with various teams across the organization to accelerate scalable improvements within our growing fleet. If you want to play a critical role in an autonomous future, let's chat! What you’ll be doing: Design and develop models, analyses, and dashboards using large data sets to report on and improve overall fleet reliability. Generate data-driven insights and build out business cases to drive improvements within the fleet. Partner with Data Science and Data Engineering in developing new data resources for the team. Help identify and drive continuous improvement opportunities. What you must have: Bachelor's degree or proven experience Proficiency in Google Sheets/Excel, SQL, and data visualization tools ( (e.g. Tableau, PowerBI, Looker, Plotly, Data Studio) Ability to extract concrete insights from data Strong work ethic and excitement to collaborate with cross functional teams Bonus points! A degree in Statistics, Economics, Mathematics, Computer Science or similar field Comfort independently learning new data tables and writing/validating queries of your own design. Experience or interest in AV or transportation space. The salary range for this position is $91,900 - 135,000. Compensation will vary depending on location, job-related knowledge, skills, and experience. You may also be offered a bonus, restricted stock units, and benefits. These ranges are subject to change. Why Cruise? Our benefits are here to support the whole you: Medical / dental / vision, AD+D and life insurance Subsidized mental health benefits One Medical membership Flexible Spending Account  Monthly wellness stipend 401(k) match  Paid time off: vacation, sick, public health emergency, jury duty, bereavement and company holidays.  Paid parental, family care and medical leave Family care benefits: fertility benefits, Dependent Care Flexible Spending Account (subsidized by Cruise). Non-remote employees: Pre-tax Commuter Benefit Plan, healthy meals and snacks  CruiseFlex - a working policy for US-Based Cruisers that lets you and your manager find what working style is best for you, whether it’s primarily in-person, primarily at home or a combination of home and in-office time. We’re Integrated Through our partnerships with General Motors and Honda, we are the only self-driving company with fully integrated manufacturing at scale. We’re Funded GM, Honda, Microsoft, T. Rowe Price & Walmart have invested billions in Cruise. Their backing for our technology demonstrates their confidence in our progress, team, and vision and makes us one of the leading autonomous vehicle organizations in the industry. Our deep resources greatly accelerate our operating speed. We’re Independent We have our own governance, board of directors, equity, and investors. Our independence allows us to not just work on the edge of technology, but also define it. We’re Vested You won’t just own your work here, you’ll have the potential to own equity in Cruise, too. We are competing in a market that is projected to grow exponentially, which gives our company valuation room to grow. Recurring Liquidity Opportunity (RLO) - a unique equity program where employees, both current and former, have the option to sell any amount of their vested equity on a recurring basis, currently quarterly. We’re Safety Conscious We integrate #staysafe, our top priority at Cruise, into our everyday work. Through our Safety Management System, every Cruiser is asked to do their part by reporting any potential issues or hazards they observe and making continuous improvements. You’ll be able to contribute to safety at Cruise, no matter your job function or title. Cruise LLC is an equal opportunity employer. We strive to create a supportive and inclusive workplace where contributions are valued and celebrated, and our employees thrive by being themselves and are inspired to do the best work of their lives.  We seek applicants of all backgrounds and identities, across race, color, ethnicity, national origin or ancestry, citizenship, religion, sex, sexual orientation, gender identity or expression, veteran status, marital status, pregnancy or parental status, or disability. Applicants will not be discriminated against based on these or other protected categories or social identities. Cruise will consider for employment qualified applicants with arrest and conviction records, in accordance with applicable laws. Cruise is committed to the full inclusion of all applicants. If reasonable accommodation is needed to participate in the job application or interview process please let our recruiting team know or email HR@getcruise.com. We proactively work to design hiring processes that promote equity and inclusion while mitigating bias. To help us track the effectiveness and inclusivity of our recruiting efforts, please consider answering the following demographic questions. Answering these questions is entirely voluntary. Your answers to these questions will not be shared with the hiring decision makers and will not impact the hiring decision in any way. Instead, Cruise will use this information not only to comply with any government reporting obligations but also to track our progress toward meeting our diversity, equity, inclusion, and belonging objectives. Note to Recruitment Agencies: Cruise does not accept unsolicited agency resumes. Furthermore, Cruise does not pay placement fees for candidates submitted by any agency other than its approved partners. Job Description NielsenIQ’s technology teams are working on our new Connected platform, a unified, global, open data ecosystem powered by Microsoft Azure. Our clients around the world rely on NielsenIQ’s data and insights to innovate and grow. As an Engineer, you’ll be part of a team of smart, highly skilled technologists who are passionate about learning, data mining and prototyping cutting-edge technologies. Right now, our platform is based in Python, R, Elastic search, Kafka, NiFi, Mongo, Postgres and Snowflake. As an Engineer, you will collaborate with other Engineers, Development teams, Product Owners & Scrum Masters to realize critical business goals. Our team is co-located and agile, with central technology hubs in Europe, Canada, and India. Responsibilities : Write complex algorithms to get an optimal solution for real time problems  Qualitative analysis and data mining to extract data, discover hidden patterns, and develop predictive models based on findings Use distributed computing to validate and process large volumes of data to deliver insights Evaluate technologies we can leverage, including open-source frameworks, libraries, and tools Interface with product and other engineering teams on a regular cadence Qualifications 3+ years of applicable data engineering experience, including Python& RESTful APIs Strong fundamentals in data mining & data processing methodologies Strong knowledge of data structures, algorithms and designing for performance, scalability and  availability Sound understanding of Big Data & RDBMS technologies, such as SQL, Hive, Spark, Databricks, Snowflake or Postgresql Orchestration and messaging frameworks: Airflow, Messaging Frameworks (Kafka) Experience in Azure or any cloud computing Good experience working in containerization framework, Docker is a plus. Experience in agile software development practices and DevOps is a plus Knowledge of and Experience with Kubernetes is a plus Excellent English communication skills, with the ability to effectively interface across cross-functional technology teams and the business Minimum B.S. degree in Computer Science, Computer Engineering or related field Additional Information Enjoy a flexible and rewarding work environment with peer-to-peer recognition platforms.  Recharge and revitalize with help of wellness plans made for you and your family.  Plan your future with financial wellness tools.  Stay relevant and upskill yourself with career development opportunities.  About NIQ NIQ, the world’s leading consumer intelligence company, reveals new pathways to growth for retailers and consumer goods manufacturers. With operations in more than 100 countries, NIQ delivers the most complete and clear understanding of consumer buying behavior through an advanced business intelligence platform with integrated predictive analytics. NIQ delivers the Full View.  NIQ was founded in 1923 and is an Advent International portfolio company. For more information, visit NIQ.com   Want to keep up with our latest updates? Follow us on: LinkedIn | Instagram | Twitter | Facebook Our commitment to Diversity, Equity, and Inclusion NIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion/ NIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process. Join an innovative company developing a cutting-edge AI platform and knowledge graph that promises to transform how life science organizations work together. By harnessing the power of generative technology, this platform has the potential to unlock unprecedented insights and accelerate scientific discovery. With a focus on collaboration, this company is poised to impact life sciences and beyond significantly. This operating system allows every scientist and biotech company to work together in the same sandbox, quickly building upon each other's creations. The company is looking to revolutionize the way data is utilized in its field with its advanced knowledge graph and generative AI platform. By eliminating the limitations of data interoperability, they can seamlessly combine various data types and sources into a cohesive, comprehensive narrative. This breakthrough technology opens up new opportunities for scientific discovery and collaboration. Key Details to Catch your Eye Team members are encouraged to be self-starters and work purposefully. You’ll be the first Data Engineer on the team, but you’ll still be working closely with other team members. Agile software development process in a fast-paced environment. Requirements Your Skills 3+ years as a Data Engineer or related fields (Semi Sr/Sr). Strong knowledge of Python and Pandas. Proficient understanding of Apache Airflow. Familiar with NoSQL databases like Redis and MongoDB and graph databases like Neo4j. Bachelor’s degree or equivalent. English Proficiency. How You’ll Stand Out Knowledge of various file formats, including JSON and XML. Understanding of Spark. Experience with data lineage frameworks like OpenLineage. The Screening Process Verification by the BEON team. Coding challenge. Technical Interview with the CTO and Head fo Data. Cultural interview. Total expected timeframe: 5-7 days. About BEON.tech BEON.tech connects the brightest Latin American talent with the most innovative and disruptive U.S. companies. You’ll get access to a custom-vetted pool of full-time, long-term, remote software jobs with compensation comparable to U.S.-based positions. To join BEON.tech is to be in a devs-first company, which means you are the priority when it comes to decision-making, client selection, and growth planning. Develop your career at the pace you deserve. Benefits USD compensation comparable to U.S.-based positions. A US$ 1,500 welcome package to get you started with the right gear. Health insurance. Internet service. Trip to Headquarters in Buenos Aires. Flexible payments in crypto, wire transfer, Wise, PayPal, or Payoneer. English conversation club & workshops. Rewards Program: Win prizes every month by participating in weekly challenges. The annual winner will earn a trip for two to NYC! Psychotherapy sessions. Unlimited reskilling in Udemy, Educación IT & O’Reilly. Job Description About You We are looking for a Big Data Engineer to work with large data volumes read from scattered information sources in an organization's technology infrastructure. You bring to Applaudo the following competencies: 2+ years of experience with Scala Spark 3+ years of data delivery, ETL (extract, transform and load) and data warehouse design, analysis, and programming experience. Experiencie with Google Cloud Plattform. Experience with an excellent grasp of relational and dimensional data modeling Strong mathematical, statistical, and analytics skills 1+ year of Agile experience English is required, as you will work directly with US-based clients. You will be accountable for the following responsibilities: Extracting data from different data sources and transferring it into a data warehouse environment. Designing, maintaining, and implementing transactional and analytical data storage structures. Design, build and maintain data pipelines, consuming for multiple sources, and servicing multiple tenants Experience in one or more of the following DBMS: PostgreSQL, MySQL, Google Cloud Datastore, Cosmos Experience in one or more of the following programming languages: Scala, PL/SQL, Java Experience in one or more of the following cloud environment tools: GCP Elaborate informative, expressive, and meaningful reports that support business decision-making processes through the information provided. Reporting and subsequently translating the emanating results into good technical and consistent data designs. Qualifications Technical Skills: 2+ years of experience with Scala Spark Experience with cloud environment tools Additional Information Here at Applaudo Studios values as trust, communication, respect, excellence and team work are our keys to success. We know we are working with the best and thus treat each other with respect and admiration without asking. Submit your application today, and don't miss this opportunity to join the Best Digital team in the Region! We truly appreciate all the hard and outstanding work our team makes every day at Applaudo Studios, and that's why the perks that we offer, are deeply thought and designed as a way to thank them for their commitment and excellence. Some of our perks and benefits: Work from home Flexible schedule Celebrations Special discounts Entertainment area Flexible work spaces Great work environment Private medical insurance *Benefits may vary according to your location and/or availability. Request further information when applying. Company Description We help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable. Job Description Analyze business requirements and develop the necessary analytical solutions such as worksheets and liveboards. Incorporate Azure DevOps in daily development cycles and deployments. Troubleshoot production incidents as identified by QA. Contribute to excellent user experience from a customer perspective. Qualifications Minimum of a bachelor’s degree or equivalent in Computer Science, Information Systems, Engineering, or Mathematics Minimum of 2 years of experience in development using business intelligence tools such as ThoughtSpot, Spotfire, Power BI, or other browser-based BI applications. Minimum of 2 years of experience working in an Agile software development environment. Knowledgeable of data modeling techniques such as Kimball data modeling and data warehouses. Proficiency with database technologies MySQL (Aurora), MSSQL, Oracle, S3, Redshift, Snowflake or equivalent. Technical Knowledge in Python / Java / C++ and/or C#. Proficiency with version control systems (GIT). A deep desire to drive efficiency through process and methodology improvements. Motivated by working in a collaborative environment with individuals from multiple departments. Excellent verbal and written communication skills. Excellent technical, problem-solving, and troubleshooting instincts. General work office/remote work conditions. Ability to work extended hours as needed to meet deadlines. Occasional after hours support for deployments. Additional Information iiX, a Verisk business and member of the Verisk Insurance Underwriting group, is a nationwide provider of insurance underwriting and employment reports. Our systems make it quick and easy for our over 20,000 customers to get real-time reports through one of several platforms. iiX provides high-tech, innovative products and services combined with excellent customer service. To learn more about iiX please visit us at: www.iix.com. We are proud to be a part of the Verisk family of companies!  At the heart of what we do is help clients manage risk. Verisk (Nasdaq: VRSK) provides data and insights to our customers in insurance, energy and the financial services markets so they can make faster and more informed decisions.    Our global team uses AI, machine learning, automation, and other emerging technologies to collect and analyze billions of records. We provide advanced decision-support to prevent credit, lending, and cyber risks. In addition, we monitor and advise companies on complex global matters such as climate change, catastrophes, and geopolitical issues.   But why we do our work is what sets us apart. It stems from a commitment to making the world better, safer and stronger.   It’s the reason Verisk is part of the UN Global Compact sustainability initiative. It’s why we made a commitment to balancing 100 percent of our carbon emissions. It’s the aim of our “returnship” program for experienced professionals rejoining the workforce after time away. And, it’s what drives our annual Innovation Day, where we identify our next first-to-market innovations to solve our customers’ problems.    At its core, Verisk uses data to minimize risk and maximize value. But far bigger, is why we do what we do.  At Verisk you can build an exciting career with meaningful work; create positive and lasting impact on business; and find the support, coaching, and training you need to advance your career. We have received the Great Place to Work® Certification for the 7th consecutive year. We’ve been recognized by Forbes as a World’s Best Employer and a Best Employer for Women, testaments to our culture of engagement and the value we place on an inclusive and diverse workforce.  Verisk’s Statement on Racial Equity and Diversity supports our commitment to these values and affecting positive and lasting change in the communities where we live and work. Verisk Analytics is an equal opportunity employer. All members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability. http://www.verisk.com/careers.html Unsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume. Consumer Privacy Notice Amazon Web Services is the market leader and technology forerunner in the Cloud business. As a member of the AWS Support team you will be at the forefront of this transformational technology, assisting a global list of companies and developers that are taking advantage of a growing set of services and features to run their mission-critical applications. As a Cloud Support Engineer, you will act as the ‘Cloud Ambassador’ across all the cloud products, arming our customers with required tools & tactics to get the most out of their Product and Support investment.  Would you like to use the latest cloud computing technologies? Do you have an interest in helping customers understand application architectures and integration approaches? Are you familiar with best practices for applications, servers and networks? Do you want to be part of a customer facing technology team helping to ensure the success of Amazon Web Services (AWS) as a leading technology organization?  If you fit the description, you might be the person we are looking for! We are a group of smart people, passionate about cloud computing, and believe that world class support is critical to customer success   Key job responsibilities • First and foremost this is a customer support role – in The Cloud. • On a typical day, a Support Engineer will be primarily responsible for solving customer’s cases through a variety of customer contact channels which include telephone, email, and web/live chat. You will apply advanced troubleshooting techniques to provide tailored solutions for our customers and drive customer interactions by thoughtfully working with customers to dive deep into the root cause of an issue. • Apart from working on a broad spectrum of technical issues, an AWS Support Engineer may also coach/mentor new hires, develop & present training, partner with development teams on complex issues or contact deflection initiatives, participate in new hiring, write tools/script to help the team, or work with leadership on process improvement and strategic initiatives. • Career development: We promote advancement opportunities across the organization to help you meet your career goals. • Training: We have training programs to help you develop the skills required to be successful in your role. We hire smart people who are keen to build a career with AWS, so we are more interested in the areas that you do know instead of those you haven’t been exposed to yet. • Support engineers interested in travel have presented training or participated in focused summits across our sites or at specific AWS events. • AWS Support Engineering has 24/7/365 operation model and work schedule will be required to include nights, weekends and holidays.   A day in the life Every day will bring new and exciting challenges on the job while you: • Learn and use groundbreaking technologies • Apply advanced troubleshooting techniques to provide unique solutions to our customers' individual needs • Interact with leading technologists around the world • Work directly with Amazon Web Services teams to help reproduce and resolve customer issues • Leverage your extensive customer support experience to provide feedback to internal AWS teams on how to improve our services • Drive customer communication during critical events • Drive projects that improve support-related processes and our customers’ technical support experience • Write tutorials, how-to videos, and other technical articles for the customer community • Work on critical, highly complex customer problems that may span multiple AWS services   About the team INCLUSIVE TEAM CULTURE  Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have ten employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 16 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.  WORK/LIFE BALANCE  Our team puts a high value on work-life balance. It isn’t about how many hours you spend at home or at work; it’s about the flow you establish that brings energy to both parts of your life. We believe striking the right balance between your personal and professional life is critical to life-long happiness and fulfillment. We offer flexibility in working hours and encourage you to find your own balance between your work and personal lives.  MENTORSHIP/CAREER GROWTH  Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future. Basic Qualifications  Strong Linux/Unix system administrator skills Intermediate programming/scripting skills. Ideally in Java or Python, but will consider experience in other Object Oriented and Functional languages Understanding of networking principles and ability to troubleshoot (DNS, TCP/IP, HTTP) Foundational knowledge of databases and Structured Query Language (SQL) Understanding of Virtualization and/or cloud computing Good understanding of security best practices Exceptional customer focus / Customer service experience Good understanding of distributed computing environments and methodologies Candidates must have excellent oral and written communication skills in Korean and basic writing/reading skills in English Flexibility to work weekend shifts  Preferred Qualifications Experience in Apache Hadoop, Apache Spark, Apache Hive, and Presto or ETL skills with working Experience in DynamoDB or NoSQL technologies like MongoDB or Cassandra In depth experience in the Hadoop Ecosystem including Apache Spark and Presto Experience in NoSQL Experience in data Data Lake architecture and administration Experience managing full application stacks from the OS up through custom applications Prior work experience with AWS - any or all of EC2, VPC, S3, RDS, EMR, Glue, SageMaker Excellent knowledge of Hadoop architecture, administration and support   What if I’m not an expert in all the preferred qualifications listed on the job description? That’s okay. That’s our preferred list, not a required listed. We hire smart people who can dive deep so we’re more interested in the areas that you do know instead of those you haven’t been exposed to yet. Speak to an AWS recruiter and we will be happy to provide you with more information about this role or guide you to the best possible match for your profile and your career interests.  아마존은 구성원의 다양성과 포용적 기업정책 및 조직문화를 만들어 가고 있습니다. 아마존은 공정한 기회를 제공하며, 인종, 국적, 성별, 성별정체성, 성적지향, 나이, 보훈, 장애여부 등 업무수행와 관련없는 다양성을 차별하지 않습니다. #aws-kr-premiumsupport-ap #AWSKOREA The AWS Partner Organization is looking for a talented Business Intelligence Engineer (BIE) to help drive the strategy for AWS Programs, an important driver of AWS revenue worldwide. AWS is the world’s leading cloud provider with the most comprehensive and broadly adopted portfolio of cloud services and a vibrant, innovative community of customers and partners. Millions of customers—including the fastest-growing startups, largest enterprises, and leading government agencies—are using AWS to lower costs, become more agile, and innovate faster.  AWS customers transform and reinvent their businesses through the cloud and the AWS Partner Network (APN) is helping to dramatically accelerate that innovation. There are tens of thousands of APN Partners across the globe. More than 90% of Fortune 100 companies and the majority of Fortune 500 companies utilize APN Partner solutions and services.  This is excellent opportunity for a BIE interested in joining AWS. Given the scope and breadth of the Programs business for AWS, you will have the opportunity to learn about all the AWS services, global revenue drivers and leading AWS end customers. This position also provides exposure to AWS senior leadership. BI is core to the Program strategy and this position will play a central role in supporting leadership doc reviews with AWS S-team members.  Key job responsibilities  As a BIE of the global Programs analytics, you will own the reporting and insights for this large growth business, influencing the global vision and strategic direction. This is an exciting opportunity for a Business Intelligence Engineer who wants to develop innovative ways of interacting with and interpreting business metrics, and shape the future of a growth AWS business. Your work will encompass the end-to-end development of self-service reporting, analytical investigations and automation solutions. You will use your excellent communication and technical skills to translate a variety of business problems into analytical solutions, collaborating with and challenging business owners (Program leaders, Partner Development leaders, Finance and Marketing) to make better decisions on behalf of AWS and our customers.  About the team  Our team puts a high value on work-life balance. Striking a healthy balance between your personal and professional life is crucial to your happiness and success here, which is why we aren’t focused on how many hours you spend at work or online. Instead, we encourage you to have a more productive and well-balanced life—both in and outside of work.  Mentorship & Career Growth  Our team is dedicated to supporting new members. We have a broad mix of experience levels and tenures, and we’re building an environment that celebrates knowledge sharing and mentorship. We care about your career growth and strive to assign projects based on what will help each team member develop into a better-rounded professional and enable them to take on more complex tasks in the future.  Inclusive and Diverse Culture  Here at AWS, we embrace our differences. We are committed to furthering our culture of inclusion. We have twelve employee-led affinity groups, reaching 40,000 employees in over 190 chapters globally. We have innovative benefit offerings, and we host annual and ongoing learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences. Amazon’s culture of inclusion is reinforced within our 14 Leadership Principles, which remind team members to seek diverse perspectives, learn and be curious, and earn trust.  Tenured AWS employees welcome to apply Basic Qualifications  3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience Experience with data visualization using Tableau, Quicksight, or similar tools Experience with data modeling, warehousing and building ETL pipelines Experience writing complex SQL queries  Preferred Qualifications Bachelors Degree   Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us. Company Description Finc3 is a group of high-end online marketing companies with over 150 employees that work in the areas of   E-Commerce and marketplace management (Finc3 Commerce)   B2B performance marketing (BizMut) Analytics- and CRM-consulting (Finc3 Marketing Services)  We pride ourselves in offering a fast-paced place to learn, a competitive salary, high-end tools to use and challenging problems to solve.  Finc3 Commerce – one of our companies with specialists in e-commerce, marketplace and Amazon management – is currently looking for a motivated BI Developer (f/m/d) to help us scale or software as a service reporting solution whilst working towards bridging the gap between business processes and business intelligence for our clients.   The position can either be part-time (min. 80%) or full-time and is located in Hamburg.  Job Description What we want you to achieve  You help us in scaling our software as a service reporting solution  You translate business needs to technical specifications  You optimize Power BI data models of our products & custom client solutions  You develop and execute database queries and conduct performance analyses  You identify & implement data transformations along the data pipeline  You work closely with our software developers and product managers on our SaaS solution  You collaborate with our business analysts on custom client projects  Your focus will be on Business Intelligence projects, but you will also gain a broad understanding of our business and understand the industry  Qualifications What we want you to contribute  You have successfully completed studies in the field of computer science, informatics or number driven studies  You have 4+ years of experience with business intelligence tools. At least wo of those with Microsoft Power BI / Power Query    You have previously worked as a BI Developer or comparable position – preferably with a DBA responsibility  You are an expert in SQL  Knowledge of Python is a benefit but no must  You are a self-motivated person, eager to learn and to expand your own know-how daily  You are highly analytical, show self-initiative and can prioritize tasks independently  You possess excellent written and verbal communication skills in English  Additional Information What we offer  A highly dynamic company that belongs to the leading agencies in Europe, especially for Amazon consulting and marketing  Interesting insights in several companies from traditional German and international brands to online pure players   Gaining a lot of responsibility for your own projects and great development opportunities   Encouragement of your individual career development based on the Gallup StrengthsFinder and an unlimited learning budget   A positive client relationship – we do not only work at eye level internally, but also with all our clients  A zero bullshit attitude: we know what we are doing and strive to be thought leaders in our services   Diversity and inclusion are fostered in our company values and build our foundation for sustainable business success   A very positive and truly international working culture with more than 30 nationalities   Benefit from many company events, afterworks, getaways and internal support – we enjoy working together and it shows!   A competitive salary and a modern workplace right in the center of Hamburg  Flexible working hours and the possibility for remote work  Enjoy our yearly sunshine office abroad   Bike leasing  An attractive pension plan  HVV-ProfiTicket     Lunch allowance  And much more...  Find out what our colleagues appreciate the most about working at Finc3 at our kununu page.  You think this might be a good fit?  We are looking forward to your application with CV, short explanation of your motivation, preferred starting date, and salary expectations via our Finc3 career website.  Company Description Welcome to SMG Swiss Marketplace Group AG We are a pioneering network of online marketplaces and a leading European digital company that simplifies people's lives with forward-looking products. Job Description As the new Business Intelligence Developer, you will be part of the Group Data Team (GDT). You will work together with data engineers, data architects, data product owners and diverse business domain stakeholders to make group-wide data more accessible, well-governed and understood. As a contributor to the GDT, you will be responsible for delivering data products for our internal customers. To be effective in this position, you must be comfortable working with various business domains, a bottom-up management approach and be able to get up to speed with new technologies quickly.  Role Ratio: 60% Backend - data extraction, loading and transformation (ELT) 40% Frontend - data visualization (charts and dashboard building)  Your Responsibilities: Make use of the cloud infrastructure created by data engineers to extract, load and transform (ELT) data from different sources/domains into the Group Business Intelligence platform Develop reusable data assets (marts, reports, metrics, metadata) that reflect the business's needs and follow data protection guidelines Apply data warehousing best practices to the data assets and monitor them to guarantee data completeness, uniqueness, consistency, validity, accuracy and timeliness Follow naming standards guidelines and perform technical data documentation in order to have data assets metadata flowing into the group data catalogue and downstream tools Version code, deploy using continuous integration and continuous delivery tools, review code and test changes assuring data quality and business requirements satisfaction. Implement business-defined metrics and key performance indicators as a single source of truth Work closely with the BI Team Lead, Data Product Owner and Stakeholders to understand their needs/requirements in order to design data visualizations that bring value, business insights capabilities and help the teams measure the impact of their work Develop charts and dashboards using a cloud data visualization tool incorporating usability best practices and following SMG branding guidelines when designing it Collaborate with the remote teams making transparent your activities' progress and keeping Kanban board updated to keep track of tasks and documentation for future support on troubleshooting Participate and collaborate with the data engineering, data product enablement and business intelligence teams in different workshops to define objectives and key results (OKRs) that are achievable in order to promote innovation and learning Qualifications  You have a Bachelor’s or Master’s Degree in Information Technology, Data Analytics, Management Information Systems, Computer Science, Artificial Intelligence, Data Science or a related technical/data field You have at least 2 years of professional experience working with Structured Query Language (SQL ansi) You have at least 2 years of professional experience working with one data warehousing architecture (E.g. Star schema, Snowflake schema, One Big Table, Data Vault, Data Lake, etc) You have at least 1 year of professional experience working with business intelligence or/and analytics engineering or/and data engineering or/and data analysis You have experience with at least one modern cloud data warehousing tool. E.g. BigQuery (preferably), Azure, Redshift, Snowflake, etc.  You have experience with at least one data visualization tool. E.g. Looker (preferably), Tableau, Power BI, etc. You have experience with at least one code versioning tool. E.g. git (preferably), svn, etc. You have experience with at least one code repository platform. E.g. Github (preferably), Bitbucket, etc. You have strong interpersonal and collaboration skills, organization and attention to detail You have the ability to take initiative and engage in discussions related to requirements and data products Good verbal and written communication skills in English. German is a plus.   Nice to have experience with: Online marketplaces and/or digital businesses Google Cloud Platform data warehousing and business intelligence tools (BigQuery sql syntax, Looker as a LookML developer) Data Build Tool (dbt core) as a data transformation tool The git protocol and Github for code versioning and repository platforms Agile methodologies (E.g. Kanban, Scrum, Lean, etc) Continuous integration and continuous delivery (CI/CD) Atlan data catalogue tool Data mesh decentralized data architecture Python Notion Jira  Additional Information Benefits you'll love and why you should join us Your new team and the people you work with will consist of an international and diverse group of fantastic people. We live a hybrid working model without fixed office days. You are welcome to work in our modern and spacious office in Zurich, or from your home base in Switzerland.  In addition, SMG offers you: 6 weeks of holidays (with the possibility to buy up to 10 additional days) 40-hour week (flexitime) We take work-life balance seriously 4 months' notice after the probationary period SBB Half-Fare Card You travel 1st class by train between SMG sites in Switzerland 18 weeks maternity and 6 weeks paternity leave (also in case of adoption) Professional accident and supplementary insurance (100% covered by SMG) No fixed office days (teams organize themself regarding onsite presence) Independent counselling centre for personal and psychological problems Gender-neutral fair pay with clearly defined career profiles Choose your hardware (Mac or Windows + 2 monitors for home) Choose your mobile phone (iPhone, Samsung or Pixel) Free Gym Facilities (Flamatt office only)  Apply Now! We are looking forward to getting to know you!   SMG Swiss Marketplace Group Ltd. is a pioneering network of online marketplaces and an innovative European digital company that simplifies people’s lives with groundbreaking products.  SMG Swiss Marketplace Group Ltd. provides customers with the best tools to meet their life decision needs. The portfolio includes Real Estate (ImmoScout24, Homegate, Immostreet.ch, home.ch, Acheter-Louer.ch), Automotive (AutoScout24, MotoScout24, CAR FOR YOU), General Marketplaces (anibis.ch, tutti.ch, Ricardo) and Finance & Insurance (FinanceScout24). The company is owned by TX Group AG (31%), Ringier AG (29.5%), La Mobilière (29.5%), and General Atlantic (10%). Company Description We’re the world’s leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business. Job Description Job Description Are you passionate about Data Visualization?  Sportradar is seeking a curious and motivated BI Developer to join the fast paced and dynamic Trading Services Unit Operations team.  You will be responsible for the design, creation, and implementation of the reporting layer for our global Trading Services Operations. You will implement creative approaches to solving complex problems with ambiguous paths to resolution. In addition to building new features, you will constantly be improving and adding to existing reporting interfaces.  The role is a key member of the team that will help develop the vision and architecture for our Trading Services Data Infrastructure. The Trading Services Unit Operations team drives innovation and operational excellence through the projects they support across the Unit.  You will report directly to the Head of Trading Services Unit Operations and collaborate with management of our Trading Operations and Core BI/Data teams to surface the answers to key operational and business questions.  What You Will Do - Consolidate data from various sources via ETL processes - Qlik Sense Dashboard Development - Pro-actively Identify opportunities for new projects, using existing tools in new ways, using existing data differently, and generally demonstrating the value of data - Reining-in and centralizing reporting interfaces that have been developed in silo. - Driving best practices and technical excellence - Engaging with Trading BI/Data projects throughout their lifespan; from conception, development, launch, and beyond - Being the main liaison with the Core BI/Data Team for Trading Services - Lead the translation of business requirements into technical tasks. - Creating and maintaining technical documentation for BI Tools - Participate in Departmental knowledge transfer Programmes in order that they can transfer their knowledge to others in the Unit who will benefit - Proactively plan educational learning sessions in order to ensure that technical knowledge is developed so that appropriate new technology and techniques can be suggested in order to effectively meet business needs Basic Qualifications - Experience of working in BI Developer roles in support of BI and Analytics - Deep Understanding of SQL - Strong Data Visualization skills - Ability to present to senior stakeholders - Excellent communication skills Preferred Qualifications - Strong experience using Data Visualization tools (e.g., Qlik Sense) - Track record of having earned the trust of leadership by challenging norms and improving efficiency. - Ability to dive deep into data, existing processes, people, and technology to identify risks and opportunities. - Demonstrated ability to meet deadlines while working on multiple complex projects. - Demonstrated ability to work in global environments and with people/teams from different cultural backgrounds. - Experience working with AWS (Amazon Web Services) (e.g Redshift and Athena) About Sportradar Sportradar is a leading global provider of sports betting and sports entertainment products and services. Established in 2001, the company is well-positioned at the intersection of the sports, media and betting industries, providing sports federations, news media, consumer platforms and sports betting operators with a range of solutions to help grow their business. Sportradar employs more than 2,300 full time employees across 19 countries around the world. It is our commitment to excellent service, quality and reliability that makes us the trusted partner of more than 1,600 customers in over 120 countries and an official partner of the NBA, NHL, MLB, NASCAR, FIFA and UEFA. We cover more than 750,000 events annually across 83 sports. With deep industry relationships, Sportradar is not just redefining the sports fan experience; it also safeguards the sports themselves through its Integrity Services division and advocacy for an integrity-driven environment for all involved. Additional Information Sportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences  Company Description Experian unlocks the power of data to create opportunities for consumers, businesses and society. We gather, analyze and process data in ways others can’t. We help individuals take financial control and access financial services, businesses make smarter decision and thrive, lenders lend more responsibly, and organizations prevent identity fraud and crime. For more than 125 years, we’ve helped consumers and clients prosper, and economies and communities flourish – and we’re not done. Our 17,800 people in 45 countries believe the possibilities for you, and our world, are growing. We’re investing in new technologies, talented people and innovation so we can help create a better tomorrow. Job Description Experian India is looking for a Data Analyst to join Credit Bureau development team. The candidate would possess a strong analytical mind, be a technical and creative thinker, have a strong aptitude for problem solving, and have zero tolerance for inefficiencies in software development & deliveries. The ideal candidate will have excellent written, oral and interpersonal communication skills, along with the fervent desire to continuously learn about different products and technologies.                                                                                                                                                    You will be working on Big Data application. You will be a member of a team collaborating and working together towards common goals. The team is responsible for the design, development and support of the application. What you’ll be doing Utilize your software engineering skills including Java, Spark, Python, Scala to Analyze disparate, complex systems and collaboratively design new products and services Integrate new data sources and tools Implement scalable and reliable distributed data replication strategies Ability to mentor and provide direction in architecture and design to onsite/offshore developers Collaborate with other teams to design and develop and deploy data tools that support both operations and product use cases Perform analysis of large data sets using components from the Hadoop ecosystem Own product features from the development, testing through to production deployment Evaluate big data technologies and prototype solutions to improve our data processing architecture • Automate everythin Qualifications What you’ll need to bring to the party BS degree in computer science, computer engineering or equivalent 5 – 6 years of experience delivering enterprise software solutions • Proficient in Spark, Scala, Python, AWS Cloud technologies 3+ years of experience across multiple Hadoop / Spark technologies such as Hadoop, MapReduce, HDFS, HBase, Hive, Flume, Sqoop, Kafka, Scala Flair for data, schema, data model, how to bring efficiency in big data related life cycle Must be able to quickly understand technical and business requirements and can translate them into technical implementations Experience with Agile Development methodologies Experience with data ingestion and transformation Solid understanding of secure application development methodologies Experienced in developing microservices using spring framework is a plus Experience in with Airflow and Python will be preferred Understanding of automated QA needs related to Big data Strong object-oriented design and analysis skills Excellent written and verbal communication skills Additional Information Why us We’re a high-performance and driven team but we don’t forget to celebrate success We offer strong career and international opportunities for high performers We invest heavily in our products and our people We offer training and support from experienced subject matter experts and managers plus dedicated learning & development time Experian Careers - Creating a better tomorrow together Find out what its like to work for Experian by clicking here Unternehmensbeschreibung Bei Bosch gestalten wir Zukunft mit hochwertigen Technologien und Dienstleistungen, die Begeisterung wecken und das Leben der Menschen verbessern. Unser Versprechen an unsere Mitarbeiterinnen und Mitarbeiter steht dabei felsenfest: Wir wachsen gemeinsam, haben Freude an unserer Arbeit und inspirieren uns gegenseitig. Willkommen bei Bosch. Die Robert Bosch GmbH freut sich auf Deine Bewerbung! Stellenbeschreibung Im Geschäftsbereich eBike Systems entwickeln wir innovative Produkte und Services, die das eBiken noch faszinierender machen – von hocheffizienten Antrieben über das erste serienreife ABS fürs Pedelec bis hin zu smarten Connectivity-Lösungen. Für eine nachhaltige Mobilität, die Spaß macht. Als Data Analyst und Scientist bist Du der Experte, der aus Big Data Smart Data für den Bosch eBike Service macht und dabei sowohl eigene komplexe Projekte als auch Teilprojekte verantwortet. Deine Ergebnisse stellen eine wertvolle Zuarbeit für andere Projekte und Services dar. Du analysierst die uns vorliegenden Datenmengen mit dem Ziel, unsere Prozesse sowie unsere Angebote an den Fachhandel und Endkunden zu verbessern, damit wir unseren Wettbewerbsvorsprung ausbauen. Du bist intrinsisch motiviert, aus unstrukturierten Daten unterschiedlicher Quellen und Systemen Muster zu erkennen. Durch die Verbindung von weiteren und der Erschließung neuer Datenquellen definierst Du Anwendungsfälle für den Bosch eBike Service. Gemeinsam mit den verschiedenen agilen Teams setzt Du diese Anwendungsfälle um und begeisterst unsere Kunden. Das Technology Scouting und Benchmarking bzgl. neuer Analysemethoden führst Du selbständig aktiv durch und leitest daraus mögliche Anwendungen für Bosch eBike Systems ab. Du stellst die Anforderungen zur Etablierung neuer Datenpipelines und die Realisierung sicher. Dabei agierst Du sowohl bereichsübergreifend als auch international und mit Zentralstellen von Bosch. Basierend auf Deinen Analysen führst Du datengetriebene Entscheidungen auf Leitungs- und Bereichsvorstandsebene herbei. Ein Berichtswesen u. a. mittels einprägsamer Visualisierungen gehört zu Deinem Methodenbaukasten. Zudem sind advanced und predictive Analytics oder KI für Dich keine kryptischen Kürzel. Du befähigst die eBike Kollegen in der Nutzung und Wiederverwendung Deiner Analysen und bereitgestellter Dashboards. Qualifikationen Ausbildung: abgeschlossenes Hochschulstudium (Master/Diplom/Promotion) der Informatik, der Wirtschaftsinformatik oder eines vergleichbaren Studienganges; idealerweise Master in Data Analytics Erfahrungen und Know-how: mehrjährige Berufserfahrung im IT-Bereich wie Software-, Datenbankentwicklung, Big Data und Analytics-Technologien sowohl on-Premise als auch in der Cloud; Erfahrung mit Machine Learning und von künstlicher Intelligenz getriebenen Anwendungen; KPI-Wissen im Web und App Kontext; Grundkenntnisse des Datenschutzes und den gesetzlichen Regularien im Umgang mit Data und Customer Analytics von Vorteil; Erfahrung in der abteilungs- und geschäftsbereichsübergreifenden Koordination in einem internationalen Umfeld Persönlichkeit und Arbeitsweise: Deine Arbeitsweise zeichnet sich durch Selbstständigkeit und Struktur aus; Du bist zielgerichtet, kommunikationsstark und überzeugend; Du arbeitest gerne im Team; Dein Handeln ist von unternehmerischem Denken getrieben Sprachen: verhandlungssicheres Deutsch und Englisch in Wort und Schrift Zusätzliche Informationen In diesem Team sind wir per Du. Werde ein Teil davon und erlebe mit uns einzigartige Bosch-Momente. Wir bieten tolle Möglichkeiten des remoten Arbeitens sowie unterschiedliche Teilzeitmodelle bis hin zum Jobsharing. Sprich uns gerne dazu an.  Vielfalt und Inklusion sind für uns keine Trends, sondern fest verankert in unserer Unternehmenskultur. Daher freuen wir uns über alle Bewerbungen: unabhängig von Geschlecht, Alter, Behinderung, Religion, ethnischer Herkunft oder sexueller Identität.  Du hast Fragen zum Bewerbungsprozess? Nina Sier (Personalabteilung) +49 711 811 27525 Du hast fachliche Fragen zum Job? Patrick Millen (Fachabteilung) +49 7121 35 39465 Interessierst Du Dich für diese oder weitere Stellen? Dann bewerbe auf die Virtual JobFair@BOSCH und verschaffe Dir einen Überblick über die abwechslungsreichen Aufgaben und spannenden Projekte bei BOSCH. Termine findest Du hier: www.bosch.de/events/                                         Are you looking to be in a workplace where colleagues inspire one another? Are you interested in competitive and impactful benefits? Do you prefer flexible work arrangements?  We are seeking a talented and experienced Product Owner to join our team of experts focused on designing and building microservices that leverage Big Data and Artificial Intelligence (AI) to identify and act on personal information in the RelativityOne platform. This successful candidate will lead the development and execution of the product roadmap to ensure the commercial success of both Text IQ for Data Breach and Text IQ for Personal Information offerings.  Responsibilities: Develop and execute on the product roadmap that supports the Text IQ for Data Breach and Text IQ for Personal Information offerings.  Collaborate with cross-functional teams (including engineering, operations, marketing, sales, and customer success) to ensure successful product delivery and customer adoption.  Identify market trends, customer needs, and competitive insights to inform product strategy and roadmap.  Create user stories and prioritize the product backlog to align with the overall product vision and goals.  Work closely with the engineering team to deliver high-quality product features and functionality, and ensure timely product delivery.  Define and measure product success metrics, and use data to continuously improve product performance and user satisfaction.  Communicate product strategy, roadmap, and progress to internal and external stakeholders.  Collaborate with the go-to-market teams to develop effective product positioning, messaging, and launch plans.  Collect, analyze, and summarize data from disparate sources to drive conclusions and recommendations.  Work independently and effectively in a results-oriented, efficient environment.  Deliver products and ensure customer success through strong project management and team leadership.  Communicate effectively with stakeholders at all levels, including senior leadership.  Manage and prioritize multiple tasks and projects simultaneously.  Your skills: BS or BA degree; 7+ years of work experience, with at least 5 in product management.  Strong problem-solving skills, including ability to dissect complicated technical problems, simplify experiences, and innovate on behalf of our customers.  Strong technical acumen and working knowledge of software architectures and AI/ML.  Strong business knowledge to help build go-to-market machinery for existing and new products.  Solid understanding of software development lifecycle and agile methodologies.  Ability to collaborate with and lead teams of all levels and disciplines within an organization, from engineers to senior leadership.  A history of developing and owning product roadmaps to drive business outcomes.  Experience collecting, analyzing, and summarizing data from disparate sources to drive conclusions and recommendations.  Entrepreneurial spirit and ability to work independently and effectively in a results-oriented, efficient environment.  Strong track record of delivering products and ensuring customer success.  Organized, with the ability to communicate effectively with stakeholders.  Excellent written and verbal communication skills.  Experience working with international teams is a plus.  Relativity is a diverse workplace with different skills and life experiences—and we love and celebrate those differences. We believe that employees are happiest when they're empowered to be their full, authentic selves, regardless how you identify. Benefit Highlights:Comprehensive health, dental, and vision plansParental leave for primary and secondary caregivers Flexible work arrangementsTwo, week-long company breaks per yearUnlimited time offLong-term incentive programTraining investment program All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin, disability or protected veteran status, or any other legally protected basis, in accordance with applicable law. We are expanding our development teams and although we don’t care much about titles, we call this role Data Engineer with Power BI experience and the key is having experience and knowledges in Cloud, and a constant desire to keep learning. Our vision is to build multidisciplinary teams which directly manage projects in an AGILE way to find and implement the best solutions 😊  What will you do? You will participate developing projects from scratch with the collaboration of the team. You will participate in the design of architectures and decisions making in a constructive environment and with co-creation dynamics. You will be a key player in the development of good practices, clean and reusable code. You will develop ETLs with Spark (Python/Scala). You will develop projects in the cloud (Azure/AWS). Analyzing, querying, and transforming data using DAX. You will build scalable pipelines with different technologies: Airflow, data factory… Requirements What are we looking for? More than 3 years in Software/data engineering experience. Solid experience in Python or Scala and Spark processing large volumes of data. Solid Cloud experience (Azure or AWS). Experience with Power BI (visualization, modeling, DAX) Experience working with tabular models. Experience in creating data pipelines (CI/CD). Knowledge of SQL and NoSQL databases. Experience with Databricks, Data Factory, Synapse, Apache Airflow, etc. High level of English and German. A team player. Benefits What do we offer? Salary determined by the market and your experience 🤑 Flexible schedule 35 Hours / Week 😎 (no salary reduction) Fully remote work (optional) 🌍 Individual budget for training and free Microsoft certifications 📚 Monthly bonus for electricity and Internet expenses at home 💻 Plain Camp (annual team-building event) 🎪 Birthday day off 🌴🥳 ➕ The pleasure of always working with the latest technological tools!  With all this information you already know a lot about us. Will you let us know you better? The selection process? Simple, just 3 steps: a call and 2 interviews with the team 🤘 And you may wonder… Who is Plain Concepts? Plain Concepts is made up of 400 people who are passionate about technology, driven by the change towards finding the best solutions for our customers and projects. Throughout the years, the company has grown thanks to the great technical potential we have and relying on our craziest and most innovative ideas. We currently have over 14 offices in 6 different countries. Our main goal is to keep growing as a team, developing the best and most advanced projects in the market. We truly believe in the importance of bringing together people from different backgrounds and countries to build the best team, with a diverse and inclusive culture. What do we do at Plain Concepts? We are characterized for having a 100% technical DNA. We develop customized projects from scratch, technical consultancy, training, and our own product: Sidra Data Platform 💜 We don’t do bodyshopping or outsourcing Our teams are multidisciplinary, and the organizational structure is flat and horizontal We are very committed to AGILE values Living is sharing: We help, support, and encourage each other to expand our knowledge internally and also towards the community (with conferences, events, talks…) We always look for creativity and innovation, even when the idea might seem crazy to others Transparency is key to any relationship We make our clients’ ideas and solutions a reality with a high degree of technical excellence, for more information you can visit our website:  ➡ https://www.plainconcepts.com/case-studies/  At Plain Concepts, we certainly seek to provide equal opportunities. We want diverse applicants regardless of race, colour, gender, religion, national origin, citizenship, disability, age, sexual orientation, or any other characteristic protected by law. Company Description Talan est un cabinet de conseil en innovation et transformation par la technologie. Depuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en œuvre leurs projets de transformation et d’innovation en France et à l'international. Présent sur cinq continents, le groupe prévoit de réaliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant·e·s et vise à dépasser la barre du milliard d’€ de CA à horizon 2024. Le Groupe met l'innovation au cœur de son développement et intervient dans les domaines liés aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle. Présent dans les événements incontournables du secteur, comme Viva Technology, Talan prend régulièrement la parole sur les enjeux de ces technologies révolutionnaires aux côtés d'acteurs majeurs du secteur et de parlementaires (Syntec Numérique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny…). Talan est une entreprise responsable, attachée à la diversité. Des aménagements de poste peuvent être organisés pour tenir compte des personnes en situation de handicap. Retrouvez nos engagements RSE ici et nos actions en faveur de la diversité ici Job Description Au cœur de la stratégie Data du groupe, Talan recherche un(e) Architect(e) Data capable d’accompagner les projets, les avant-ventes, avec une approche de bout en bout, sur toute la chaîne de valeur de la donnée.  Qui sommes-nous ?  Le pôle Data Intelligence est composé de +200 experts (AMOA Data, Agile Data, Data Gov, Data Streaming, Data Engineer, Data Analyst…), vous intervenez sur des projets de modern data platform et d’innovation pour accompagner les entreprises vers une organisation Data Driven.  Nos réalisations tournent autour de thématiques telles que :  Move to cloud : passer du on-premise vers une modern data platform, …  Real time : streaming, change data capture…  Modélisation DWH : DataVault et Dimensionnelle,  Data Warehouse as Service: Snowflake, BigQuery, Redshift, Azure Synapse…  Data Virtualisation : accélérer l’accès aux données,  Nous intervenons autant dans des DSI que dans des direction métiers, dans des modes forfaitaires ou en régie.  Venez intégrer notre communauté d'experts Data chez Talan !  Talan renforce sa communauté au sein du pôle Data pour intervenir sur les différents projets de nos clients grands comptes.  Nous sommes à la recherche d’un Architect Data capable d’accompagner le démarrage des projets sur la mise en place d’une plateforme modern data, définition des solutions à mettre en place, dimensionnement, sécurisation, participer aux avants ventes : rédaction, soutenance…  Les responsabilités d’un Architect Data comprennent des activités d’expertise, de mentoring - coaching, d’avant-vente et de sécurisation de projet au forfait. Vous devrez faire preuve d’un état d’esprit à la fois innovant, méthodique, orienté solution (et non problème !), et communiquant.  Votre but ultime sera de garantir l’excellence d’une équipe de spécialistes, pièce maitresse de la réalisation de projets à forts enjeux pour nos clients.  VOTRE ROLE SUR NOS PROJETS: En mission : analyse des exigences techniques, définition des normes et bonnes pratiques, rédaction de document d’architecture, aide à la mise en place des solutions, sécurisation des accès, définition des rôles et accès  Coacher techniquement les équipes  Avant-vente : participation aux réponses à appel d’offre au forfait  Communication : écriture d’article, animation d’évènement  Veille : sur les solutions Data, méthodologie de datawarehousing, ...  VOTRE ROLE CHEZ TALAN : Benchmark de solutions et conseil auprès de nos clients sur les solutions technologiques à adopter, en lien avec leurs besoins  Réalisation de POC (Proof Of Concept)  Participation à des projets internes et partage de connaissances au sein de nos équipes  Partage de connaissances et formations interne  Ensemble réalisons de nouveaux projets Talantueux!!  Qualifications VOTRE PROFIL: Connaissance des systèmes de fédérations d’identités, et des mécanismes d’authentification  Maitrise des techniques de Data management, de DataViz  Méthodologie de conception et de modélisation d’entrepôt / lac de données  Design d’architecture technique et applicative  Bonnes connaissances des technologies Data en générale (stockage, ingestion et transformation de données, data visualisation, data sharing, API Management, cloud provider…)   Force de proposition  Qualité rédactionnelle, vulgarisation  Autonomie, organisation, sens du partage  Excellente communication  Orientation métier  Alors n'attendez plus ! Postulez vite ! Additional Information AVANTAGES : Top 5 du Palmarès Great Place to Work  Management de proximité par des experts  Organisation sous forme de communautés  Un parcours excellence Agile DevOps  Financement de plusieurs certifications officielles à l’année grâce à nos partenaires éditeurs  Un accès à la plateforme CampusTalan avec plus de 1000 formations disponibles dès votre arrivée  Une mobilité interne facilitée  Un engagement auprès des travailleurs en situation de handicap  Des événements et afterworks réguliers  Siège parisien situé à Charles-De-Gaulle Etoile  Tickets restaurants digitalisés  Mutuelle d’entreprise prise en charge à 100%  Prime vacances  Prime de participation  Primes de cooptation  Actionnariat  1% logement  Partenaire de l'organisme Mobility dans le cadre de l'accompagnement à la mobilité et à la recherche de logement  RTT  At Jamf, people are at the core of everything we do. We do what’s right for our customers, our employees, our communities and our world. We take pride in simplifying technology for tens of thousands of customers around the globe and helping organizations succeed with Apple.   Jamf operates as a choice-based office model. Choose to work in the office, connect 100% remote from your home, or find the blend that works best for you.  SUMMARY At Jamf, we empower people to be their best selves and do their best work. The business Intelligence group at Jamf manages and delivers insights about company data so businesses can make informed decisions. Through the core disciplines of data management and data analytics the team delivers data visualizations and analytics while managing the data infrastructure to support our growing systems at Jamf. The Business Intelligence Data Architect II is an integral member of data management, responsible for ensuring we have the right data architecture to deliver on our vision to democratize data to users and consumers across major business lines. By development of a Business Intelligence and Analytics framework to put accurate and current data to the people who need to make business decisions. The Business Intelligence Data Architect II will collaborate closely with stakeholders, Enterprise Architecture, Data Analysts, Data Engineers, end-users and other members across the company in the design, orchestration, and management of our corporate data within our ecosystem - ensuring our data is secured, governed, and consumed by major business lines at Jamf resulting in a data-driven culture. RESPONSIBILITIES Provide feasible, efficient, and performant data solutions and implementations for our business. Collaborating cross-functionally to define and prioritize requirements for data needed from internal and external sources to support analytics and decision making. Work with engineering and analyst teams to capture and delivered required data to the Enterprise Data Platform while meeting multi-dimensional standards for data quality. Develop key performance measures for data integration, quality, and operations. Build a framework of principles to ensure data integrity across the business (including but not limited to ERP, CRM, BI, Data warehouse, external interfaces etc.) Manage and help build a robust and scalable Data Integration pipeline of the ETL/ELT process Understand and document data flow throughout critical business systems Work with stakeholder groups on definition of a Unified Data Model that serves as the foundation for the single source of truth for all product, customer and reference data used for BI & analytics. Use the best-fit data warehousing methodologies and modeling techniques Assists with cloud Infrastructure design best practices, templates, and processes. Help achieve and maintain compliance with regulatory, legal and company standards. Participate an active contributor to how Jamf evolves Data Governance practices and influence the adoption of data standards. Ensure that the BI Data Architecture strategy and roadmap is aligned to the business and technology strategies. Contribute to, participate in, and deliver architectures through architecture reviews. Advocate of data security principles and ensure appropriate security practices are incorporated into solutions/capabilities. Mentor/coach team members in data architecture, engineering and dimensional modelling. SKILLS AND EXPERIENCE Minimum 3 years of Data Architecture experience including but not limited to: Experience in architecting and implementing Business Intelligence and Data warehouse platforms, Master data management and data integration (Required) Experience in business intelligence and analytics architecture framework: ability to collect, integrate, and store the data so it is accessible and actionable (Required) Minimum 5 years of experience in Logical and Physical data modelling. (Required) Demonstrated experience using Agile/Scrum frameworks and software development workflows (Required) Ability to lead technical initiatives, communicate with leadership and guide projects (Required) Experience communicating project direction and status with stakeholders (Required) Comfortable with resolving conflicting viewpoints and achieving agreement (Required) Experience coaching teams on modelling Experience integrating data governance functions into the data delivery process Strong understanding of cloud platforms, databases, and data capabilities to source, integrate, manage, and leverage data Ability to understand existing and new technologies and lead their adoption across the enterprise EDUCATION & CERTIFICATIONS 4 Year/ Bachelor’s degree in Science, Technology, Engineering, Mathematics, or related field (Required) A combination of relevant experience and education may be considered    At Jamf, people are at the core of everything we do. We do what’s right for our customers, our employees, our communities and our world. We take pride in simplifying technology for tens of thousands of customers around the globe and helping organizations succeed with Apple. Jamf operates as a choice-based office model. Choose to work in the office, connect 100% remote from your home, or find the blend that works best for you.  What is a Jamf? You go above and beyond for others, are willing to help, and support the team around you. You value and learn from different perspectives. You are curious and resourceful, a problem-solver, self-driven and constantly improving. You are excited by not knowing what may lie ahead. You are willing to take risks, try new things, even fail just to do it better next time. You’re not a jerk. You are someone who cares about doing the right thing.  What does Jamf do? Jamf extends the legendary Apple experience people enjoy in their personal lives to the workplace. We believe the experience of using a device at work or school should feel the same, and be as secure as, using a personal device. With Jamf, IT and security teams are able to confidently manage and protect Mac, iPad, iPhone and Apple TV devices, easing the burden of updating, deploying and securing the data used by their end-users. Jamf’s purpose is to simplify work by helping organizations manage and secure an Apple experience that end-users love and organizations trust.   We are free-thinkers, can-doers and problem crushers with a passion for helping customers empower their workforce to focus on their jobs, not the hassles of managing technology – freeing nurses to care, teachers to teach and businesses to thrive. We have over 2,500 employees worldwide who are encouraged to bring their whole selves to work each and every day.   Get social with us and follow the conversation at #OneJamf   #LI-REMOTE Company Description It all started with an idea at Block in 2013. Initially built to take the pain out of peer-to-peer payments, Cash App has gone from a simple product with a single purpose to a dynamic app, bringing a better way to send, spend, invest, borrow and save to our millions of monthly active users. With a mission to redefine the world's relationship with money by making it more relatable, available and accessible, at Cash App you'll have the opportunity to make a real-world impact with your career. Today, Cash App has thousands of employees around the world with a culture geared toward creativity, collaboration and impact. We’ve been a distributed team since day one, and continue to value working across time zones and continents both remotely and in our Cash App offices. Our offices are great, but many of our roles can be done remotely from the countries where Block operates. We tailor our experience to champion our employees’ creativity and productivity wherever they are.  Job Description The BI Team at Cash App enables our teams to make impactful business decisions. Our BI Engineers handle everything from data architecture and modeling to data pipeline tooling and dashboarding. As a Senior BI Engineer at Cash App, you will report to the BI Manager and work with Analysts, Data Scientists, Software Engineers and Product Managers to lay the foundation for analyzing our large, unique dataset. We are an extremely data-driven team - from understanding our customers, managing and operating our business, to informing product development. You will build, curate, document, and manage key datasets and ETLs to increase the impact of the entire team.  You will: Create brand new and optimize existing data models for the most widely used Cash App events, entities, and processes Standardize business and product metric definitions in curated and optimized datasets Build pipelines out of our data warehouse Teach (and encourage) others to self-serve while building tools that make it simpler and faster for them to do so Promote data, analytics, and data model design best practices Create dashboards that help our teams understand the performance of the business and help them make decisions Qualifications You have: Background/knowledge in Computer Science, Applied Math, Engineering, Stats, Physics, or a something comparable 5+ years of industry experience building complex, scalable ETLs for a variety of different business and product use cases An interest in advancing Cash App's vision of building products for economic empowerment - this should be something that legitimately excites you Technologies we use and teach: SQL (MySQL, Snowflake, BigQuery, etc.) Airflow, Looker and Tableau Python and Java Additional Information Block takes a market-based approach to pay, and pay may vary depending on your location. U.S. locations are categorized into one of four zones based on a cost of labor index for that geographic area. The successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, work location, and market conditions. These ranges may be modified in the future.  Zone A: USD $152,100 - USD $185,900 Zone B: USD $144,500 - USD $176,700 Zone C: USD $136,900 - USD $167,300 Zone D: USD $129,300 - USD $158,100 To find a location’s zone designation, please refer to this resource. If a location of interest is not listed, please speak with a recruiter for additional information.  Benefits include the following: Healthcare coverage Retirement Plans including company match  Employee Stock Purchase Program Wellness programs, including access to mental health, 1:1 financial planners, and a monthly wellness allowance  Paid parental and caregiving leave Paid time off Learning and Development resources Paid Life insurance, AD&D. and disability benefits  Perks such as WFH reimbursements and free access to caregiving, legal, and discounted resources  This role is also eligible to participate in Block's equity plan subject to the terms of the applicable plans and policies, and may be eligible for a sign-on bonus. Sales roles may be eligible to participate in a commission plan subject to the terms of the applicable plans and policies. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans. We’re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, veteran status, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.  We believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible. Want to learn more about what we’re doing to build a workplace that is fair and square? Check out our I+D page.  Additionally, we consider qualified applicants with criminal histories for employment on our team, assessing candidates in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. Block, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution. Company Summary: Tessera Therapeutics is pioneering Gene Writing™— a new biotechnology designed to offer scientists and clinicians the ability to write small and large therapeutic messages into the genome, thereby curing diseases at their source. Gene Writing holds the potential to become a new category in genetic medicine, building upon recent breakthroughs in gene therapy and gene editing while eliminating important limitations in their reach, utilization, and efficacy. Tessera Therapeutics was founded by Flagship Pioneering, a life sciences innovation enterprise that conceives, resources, and develops first-in-category companies to transform human health and sustainability.   Position Summary: Tessera is seeking a talented and motivated Computational Biologist to join our expanding Data Sciences team.  You will tackle challenging bioinformatics and computational biology problems to advance our understanding of Gene Writing and help accelerate programs to the clinic.  You will contribute scientific, technical, and leadership expertise to a multidisciplinary team, emphasizing conceptualization, experimentation, data analysis, presentation, and strategic planning.    Key Responsibilities: Work collaboratively with our platform and Biology teams to enable scientific discovery and progression through data analysis, data visualization, and data integration. Build and implement data analysis pipelines and storage solutions for various forms of sequencing primarily related to genotoxicity analysis, including Amplicon sequencing, long-read sequencing, One-seq, and chimeric read analysis. Design computational methods to combine and analyze off-target events, characterize mutations, and disentangle experiment-related features toward new biological hypotheses, providing project support to gene therapy project teams. Analyze human variations and how these variations may alter the genotoxic potential of our elements, onboarding relevant methods and datasets. Identify and acquire relevant public and third-party ‘omics data and perform integrative data analyses to generate insights that address strategic biological questions critical to Tessera’s core mission. Design and development of pipelines in a cloud environment with a standard software life cycle approach, releasing full documentation, and validation of the methods with statistical benchmarking. Operationalize data analysis aspects of relevant molecular assays to maximize the design, build, test cycle for platform and pipeline candidates. Structure and store data to enable data reuse, data mining, and machine learning, supporting data standardization and high-level data integration. Create compelling data visualizations and result presentations for internal and external dissemination.    Basic Qualifications: Ph.D./M.S. in Computational Biology, Bioinformatics, or related quantitative discipline. 8+ years of industry experience in discovery research. Proficient with experimental design, data processing, statistical analysis, and bioinformatics analysis/reporting of next-generation sequencing data. Experience analyzing gene therapy, gene editing, in vitro/vivo assay, genetics, genomics and cell biology data. Proficient interaction with experimental biologists to provide feedback on raw sequencing data quality. Strong grounding in biology or medicine. Strong data visualization skills and experience. Fluency in one or more programming languages with bioinformatics applications (R, Python). Track record of success working in a fast-paced, cross-functional, and rapidly growing organization. Outstanding written and verbal communication skills, ability to work with colleagues from diverse scientific backgrounds and cultures.   Preferred Qualifications: Experience with recent advances in gene therapy and development of gene editing platforms as therapeutics. Familiarity with short and long-read next-generation sequencing platforms (Illumina, PacBio, Nanopore). Proficiency in handling large-scale sequencing data in a cloud environment (AWS preferred). Proficiency in statistics and machine learning. Experience in virology or mobile genetic elements.   More About Flagship Pioneering Flagship Pioneering has conceived of and created companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune’s “Change the World” list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies. Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.   Recruitment & Staffing Agencies:  Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates.  The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team.   Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.    Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto “Building Success Together®,” Nisum has grown to over 1,800 professionals across the United States, Chile,Colombia, India, Pakistan and Canada. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today’s world, with immersive and seamless experiences across digital and physical channels. What You'll Do Deep problem-solving skills to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement   Competent in design/implementation for reliability, availability, scalability, and performance  Designing and developing dashboards using Splunk What You Know Overall 5-8 years of experience working with Big Data using Spark/Scala Should be well-versed in Core Java, and Java frameworks Has mentored junior software developers on design patterns, development best practices, and DevOps trade-offs Experienced with all ancillary technologies necessary for Internet applications: HTTP, TCP/IP, POP/SMTP, etc. High-scalability projects involving cloud-based infrastructure design and implementation Working knowledge of object-oriented design and development skills Successful track record of developing quality software products and shipping production-ready software Good understanding of Web Services protocols such as REST, SOAP, and API design for extensibility and portability Experience debugging distributed systems with high data loads Deep knowledge of distributed data model Should have excellent communication and presentation skills Should have experience in AWS: Lambda, EC2. Knowledge of AWS EMR or Cloudera is a great plus. Good problem-solving and troubleshooting abilities Ability to multitask in a fast-changing environment Should be involved in working in an onsite/offshore model Should have performed on all the stages of SDLC from Design to System Testing, implementation, and post-implementation Education BS degree in computer science, computer engineering or equivalent Benefits In addition to competitive salaries and benefits packages, Nisum India offers its employees some unique and fun extras: Continuous Learning - Year-round training sessions are offered as part of skill enhancement certifications sponsored by the company on an as need basis. We support our team to excel in their field. Parental Medical Insurance - Nisum believes our team is the heart of our business and we want to make sure to take care of the heart of theirs. We offer opt-in parental medical insurance in addition to our medical benefits. Activities -From the Nisum Premier League's cricket tournaments to hosted Hack-a-thon, Nisum employees can participate in a variety of team building activities such as skits, dances performance in addition to festival celebrations. Free Meals - Free snacks and dinner is provided on a daily basis, in addition to subsidized lunch. Nisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace. Nisum is a leading global digital commerce firm headquartered in California, with services spanning digital strategy and transformation, insights and analytics, blockchain, business agility, and custom software development. Founded in 2000 with the customer-centric motto “Building Success Together®,” Nisum has grown to over 1,800 professionals across the United States, Chile,Colombia, India, Pakistan and Canada. A preferred advisor to leading Fortune 500 brands, Nisum enables clients to achieve direct business growth by building the advanced technology they need to reach end customers in today’s world, with immersive and seamless experiences across digital and physical channels. What You'll Do Deep problem-solving skills to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement   Competent in design/implementation for reliability, availability, scalability, and performance  Designing and developing dashboards using Splunk What You Know Overall 5-8 years of experience working with Big Data using Spark/Scala Should be well-versed in Core Java, and Java frameworks Has mentored junior software developers on design patterns, development best practices, and DevOps trade-offs Experienced with all ancillary technologies necessary for Internet applications: HTTP, TCP/IP, POP/SMTP, etc. High-scalability projects involving cloud-based infrastructure design and implementation Working knowledge of object-oriented design and development skills Successful track record of developing quality software products and shipping production-ready software Good understanding of Web Services protocols such as REST, SOAP, and API design for extensibility and portability Experience debugging distributed systems with high data loads Deep knowledge of distributed data model Should have excellent communication and presentation skills Should have experience in AWS: Lambda, EC2. Knowledge of AWS EMR or Cloudera is a great plus. Good problem-solving and troubleshooting abilities Ability to multitask in a fast-changing environment Should be involved in working in an onsite/offshore model Should have performed on all the stages of SDLC from Design to System Testing, implementation, and post-implementation Education BS degree in computer science, computer engineering or equivalent Benefits In addition to competitive salaries and benefits packages, Nisum India offers its employees some unique and fun extras: Continuous Learning - Year-round training sessions are offered as part of skill enhancement certifications sponsored by the company on an as need basis. We support our team to excel in their field. Parental Medical Insurance - Nisum believes our team is the heart of our business and we want to make sure to take care of the heart of theirs. We offer opt-in parental medical insurance in addition to our medical benefits. Activities -From the Nisum Premier League's cricket tournaments to hosted Hack-a-thon, Nisum employees can participate in a variety of team building activities such as skits, dances performance in addition to festival celebrations. Free Meals - Free snacks and dinner is provided on a daily basis, in addition to subsidized lunch. Nisum is an Equal Opportunity Employer and we are proud of our ongoing efforts to foster diversity and inclusion in the workplace. Company Description We’re a seven-time “Best Company to Work For,” where intelligent, talented people come together to do outstanding work—and have a lot of fun while they’re at it. Because we’re a full-service consulting firm with a diverse client base, you can count on a steady stream of opportunities to work with cutting-edge technologies on projects that make a real difference. Logic20/20's Global Delivery Model creates a connected experience for Logicians across geographies. You'll have access to projects in different locations, the technology to support Connected Teams, and in-person and online culture events in our Connected Hub cities. Job Description Bring your skillset to an exciting and meaningful initiative where we are leveraging data science, artificial intelligence, and machine learning to mitigate wildfires. By proactively identifying and addressing issues with power lines and related equipment, we’re increasing safety, saving lives, and protecting the environment. This is a highly visible, highly impactful project with implications for millions of customers. As a Big Data Engineer, you’ll join our Data Management team to design and develop scalable data processing infrastructure. Applying an Agile approach, you’ll work closely with our team of analysts, technical product owners, and data scientists to provide the structure for a highly anticipated solution. You’ll leverage your balance of technical skills and business acumen to help the client better understand their core needs and technical capabilities. Your efforts will result in greater protection for the community and our environment, long-term. Hear more about these efforts as Jeff Lovington shares his experience working in Data Science and Machine Learning for the Energy & Utilities sector. About the team The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go. “We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Director, Advanced Analytics About you You are collaborative, working with partners to understand business needs and pain points You are determined and able to manage obstacles while maintaining a positive outlook You are patient and savvy in explaining technical benefits and deficits to non-technical audiences You have a passion for learning new data tools and best practices You have built large-scale machine learning pipelines, quickly developing and iterating solutions Qualifications Must have 3+ years of implementation experience using PySpark 5+ years of data engineering experience Strong understanding of high-performance ETL development with Python Experience with Big Data Technologies (Hadoop, Spark, MongoDB) Experience designing and developing cloud ELT and date pipeline with various technologies such as Python, Spark, PySpark, SparkSQL, Airflow, Talend, Matillion, DBT, and/or Fivetran Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule Preferred Experience with Palantir’s Foundry and LiDAR Ideal, but not required An undergraduate degree in technology or business Agile, Scrum, and/or SAFe experience and certifications Experience building data and computational systems that support machine learning Knowledge of AWS services Experience with modern software delivery practices, including source control, testing, and continuous delivery Experience with streaming data in Spark Additional Information All your information will be kept confidential according to EEO guidelines. Compensation range: $130,000 - $162,500 annually About Logic20/20  To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic   Core Values  At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity & Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.  Logic20/20 Benefits Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).  You will have  Career Development – A built-in program from day 1, providing a mentor and individually-directed training opportunities, plus access to leaders across the company  PTO, Paid Holidays, & Voluntary Leave – Worry-free time off to recharge and pursue your personal goals  Community & Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities  Recognition – From peer recognition, swag, and the chance to win a once-in-a-lifetime type of award, we make your Logic20/20 journey stand out  Referral Programs & Bonuses – Employee, project, and sales referral programs with paid incentives   Equal Opportunity Statement  We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.  To learn more about our DE&I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion   Privacy Policy  During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.  Company Description Publicis Sapient is a digital transformation partner helping established organizations get to their future, digitally-enabled state, both in the way they work and the way they serve their customers. We help unlock value through a start-up mindset and modern methods, fusing strategy, consulting and customer experience with agile engineering and problem-solving creativity. As digital pioneers with 20,000 people and 53 offices around the globe, our experience spanning technology, data sciences, consulting and customer obsession – combined with our culture of curiosity and relentlessness – enables us to accelerate our clients’ businesses through designing the products and services their customers truly value. Publicis Sapient is the digital business transformation hub of Publicis Groupe. For more information, visit publicissapient.com. Job Description Publicis Sapient is looking for Senior Manager  (in-office 2-3 days per week) to join our team of bright thinkers and doers. You will team up with top-notch technologists to enable real business outcomes for our enterprise clients by translating their needs into transformative solutions that provide valuable insight. Working with the latest data technologies in the industry, you will be instrumental in helping the world’s most established brands evolve for a more digital future. Your Impact:  Work closely with our clients providing evaluation and recommendations of design patterns and solutions for data platforms with a focus on batch, near-real time, structured and unstructured data  Define SLAs, SLIs, and SLOs with inputs from clients, product owners, and engineers to deliver data-driven interactive experiences  Provide expertise, proof-of-concept, prototype, and reference implementations of architectural solutions for Azure Data Platform Provide technical inputs to agile processes, such as epic, story, and task definition to resolve issues and remove barriers throughout the lifecycle of client engagements Creation and maintenance of infrastructure-as-code and CI/CD for Azure environment using tools such as Terraform and Ansible Mentor, support and manage team members Qualifications Your Skills And Experience:  Demonstrable experience in enterprise level data platforms involving implementation of end-to-end data pipelines  Hands-on experience with at Azure   Experience with column-oriented database technologies (e.g., Synapse), NoSQL database technologies (e.g., DynamoDB, Cosmos DB, etc.) and traditional database systems (e.g., SQL Server, Oracle, MySQL) Experience in architecting data pipelines and solutions for both streaming and batch integrations using tools/frameworks like Azure Data Factory, Azure functions and Stream analytics  Metadata definition and management via data catalogs, service catalogs, and stewardship tools such as OpenMetadata, and Azure Purview Test plan creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks Data modeling, querying, and optimization for relational, NoSQL, timeseries, graph databases, data warehouses and data lakes Data processing programming using SQL, Python, and similar tools Logical programming in Python, Spark, PySpark, Java, Javascript, and/or Scala Cloud-native data platform design with a focus on streaming and event-driven architectures Participate in integrated validation and analysis sessions of components and subsystems on production servers Data ingest, validation, and enrichment pipeline design and implementation SDLC optimization across workstreams within a solution  Bachelor’s degree in Computer Science, Engineering, or related field Set Yourself Apart With:  Certifications in Azure  Experience working with code repositories and continuous integration Understanding of development and project methodologies Additional Information Pay Range:$108,000 -$210,000 Benefits of Working Here: Flexible vacation policy; time is not limited, allocated, or accrued 16 paid holidays throughout the year Generous parental leave and new parent transition program Tuition reimbursement  Corporate gift matching program  As part of our dedication to an inclusive and diverse workforce, Publicis Sapient is committed to Equal Employment Opportunity without regard for race, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at hiring@publicissapient.com or you may call us at +1-617-621-0200. Every day, tens of millions of people come to Roblox to explore, create, play, learn, and connect with friends in 3D immersive digital experiences– all created by our global community of developers and creators.  At Roblox, we’re building the tools and platform that empower our community to bring any experience that they can imagine to life. Our vision is to reimagine the way people come together, from anywhere in the world, and on any device. We’re on a mission to connect a billion people with optimism and civility, and looking for amazing talent to help us get there.  A career at Roblox means you’ll be working to shape the future of human interaction, solving unique technical challenges at scale, and helping to create safer, more civil shared experiences for everyone. Work with the most passionate and team-oriented people you'll ever meet. As a Big Data Software Engineer, you will be a key participant in helping our Data Infrastructure team shape the future of Roblox. You will report into the Engineering Manager of our Data Infrastructure Team. If you know what it takes to develop large-scale infrastructure to Analyze user behavior from 200 million monthly users , you'll fit right into our accomplished and ever-expanding engineering team. You Will: Have primary responsibility in building the massive horizontally scalable streaming and ingestion services that feed not only our Data Lake, Data Warehouse but also business critical applications. Own design, implementation, testing, and support of next-generation features related to scalability, reliability, robustness, usability, security, and performance of Roblox Core Data Pipeline. Work with our software stack such as: Kafka , Spark or Flink - the engines upon which we are building our next-generation streaming pipelines for Roblox scale. Be a part of a collaborative team: The Data Infrastructure Team and the Analytics Team are combined at Roblox to ensure that data processing and analytics are guided by the user needs -- ie. query patterns and product requirements. Design Structures: For compact encoding of data for in-memory storage to enable in-stream computation-message fidelity from source to target: preserving message ordering guarantees across all nodes in the cluster. Work with our stakeholders to push innovation across Roblox. You Have: 8+ years of experience with different real-time data streaming technologies tools such as Kafka, Spark, Beam, Samza or Flink. Experience in Java and/or Go at scale. For roles that are based at our headquarters in San Mateo, CA: The starting base pay for this position is as shown below. The actual base pay is dependent upon a variety of job-related factors such as professional background, training, work experience, location, business needs and market demand. Therefore, in some circumstances, the actual salary could fall outside of this expected range. This pay range is subject to change and may be modified in the future.  All full-time employees are also eligible for equity compensation and for benefits.Annual Salary Range$283,780—$331,640 USD You’ll Love:  Industry-leading compensation package Excellent medical, dental, and vision coverage A rewarding 401k program Flexible vacation policy Roflex - Flexible and supportive work policy  Roblox Admin badge for your avatar At Roblox HQ:  Free catered lunches five times a week and several fully stocked kitchens with unlimited snacks Onsite fitness center and fitness program credit Annual CalTrain Go Pass Roblox provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Company Description Vericast is a premier marketing solutions company that accelerates profitable revenue growth for the thousands of businesses it serves directly by influencing consumer purchasing and transaction behavior at scale while engaging with over 120 million households daily.  We are recognized as leading providers of incentives, advertising, marketing services, transaction solutions, customer data and cross-channel campaign management, and intelligent media delivery that create millions of customer touch points annually for their clients.  For more information, visit http://www.vericast.com or follow Vericast on LinkedIn. Job Description Valassis Digital (a division of Vericast) is seeking a Principal Software Engineer to develop services, tools, bots, and workflows for our big data processing infrastructure. The Big Data Platform Team owns and operates the world-class big data processing infrastructure that over a dozen engineering teams use to power their 24/7 technical marketing products. We own and operate a large hadoop+spark processing cloud on which we store 6PB of data, and run 30 thousand jobs every day. We write a fabric of java microservices and bots to manage all those jobs, extend hadoop's functionality, and help us operate and optimize our investment. We write custom data streaming services that ingest and curate 100TB of data each day that drives the entire advertising data ecosystem. We also participate in all our users' groundbreaking workflow projects so that we can constantly stay abreast of our developer's tooling needs. What you're like: This position is perfect for a far-sighted engineer who always wants to be the first to apply cutting-edge technologies to solve complex business and engineering problems. You want to have a leading voice on our team and across our organization. You will work throughout the software lifecycle including customer interaction and product planning, requirements analysis, architecture, directing our team of developers, development, testing and operations. If you are energized by the thought of developing new system stacks and tools for big data processing and analytics we want to talk to you. If you have worked on big data engineering, cloud migration, or infrastructure tooling projects, we want to talk to you. If you have ever worked on a collection of data workflows or a service mesh and thought 'I could make this better', we want to talk to you! What you'll do: Work with our users, architects, and product leaders to architect and plan our data platforms Design, develop, and maintain the software and systems that make up the data platform that runs our entire business Partner with the Data Engineering and Data Science teams who use our platform to diagnose, predict and address scaling problems Work on new products initiatives to provide design support and establish best practices Contribute to our team’s growing set of development platforms, tools, processes, and products Qualifications Experience working on big data systems and technologies with emphasis on the Hadoop platform General knowledge of design patterns & UML with a few years of taking a lead on architectural design and development Proficiency in Java, Scala, or Python programming; exposure to microservices and Spark dataframe programming. Proficiency in networking, Thrift, Spring Framework and/or Spring Boot for microservices is a plus.  Understand RDMS and proficiency in DML, SQL & PL/SQL a plus Hands on experience with Spark; exposure to Kafka and YARN or similar technologies Experience with migration of infrastructure from on-prem to cloud or vice versa is a big advantage Curiosity to learn and apply new technologies and a background full of diverse design challenges Excellent problem-solving abilities Excellent verbal, graphical, and written communication skills Experience with agile development methodologies  Your qualifications: BS/MS in Computer Science or other technical discipline (with significant computer coursework) 10+ recent years of professional software development experience using java, scala, or python 3+ recent years working with the hadoop+spark big data platform or similar Additional Information Salary:  180,000-200,000 with 10% bonus opportunity The ultimate compensation offered for the position will depend upon several factors such as skill level, cost of living, experience, and responsibilities. Vericast offers a generous total rewards benefits package that includes medical, dental and vision coverage, 401K and flexible PTO. A wide variety of additional benefits like life insurance, employee assistance and pet insurance are also available, not to mention smart and friendly coworkers! At Vericast, we don’t just accept differences - we celebrate them, we support them, and we thrive on them for the benefit of our employees, our clients, and our community. As an Equal Opportunity employer, Vericast considers applicants for all positions without regard to race, color, creed, religion, national origin or ancestry, sex, sexual orientation, gender identity, age, disability, genetic information, veteran status, or any other classifications protected by law. Applicants who have disabilities may request that accommodations be made in order to complete the selection process by contacting our Talent Acquisition team at talentacquisition@vericast.com. EEO is the law. To review your rights under Equal Employment Opportunity please visit: www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf. #LI-TE1 #LI-Remote Company Description We’re the world’s leading sports technology company, at the intersection between sports, media, and betting. More than 1,700 sports federations, media outlets, betting operators, and consumer platforms across 120 countries rely on our know-how and technology to boost their business. Job Description OVERVIEW: Make the team that changes the way the world experiences sport. Sportradar is the leading global provider of sports betting and sports entertainment products and services. Since 2001, we have occupied a unique position at the intersection of the sports, media and betting industries; providing sports federations, news media, consumer platforms and sports betting operators with a range of solutions to help grow their business.  Managed Trading Services (MTS) is a holistic solution that enables Wagering Operators to future-proof their business by offering services such as risk management and advanced marketing tools. The Operational Account Management Team, (which sits within MTS) performs an important role by acting as the main point of contact between our growing client base and Sportradar. Subsequently, we’re looking for a dedicated, Business Intelligence Analyst for our OAM department who will support our unit by developing interactive analytical applications, scheduled customer reports and ad hoc customer report requests. The Business Intelligence Analyst will also recommend and implement improvements into our reporting processes that will allow us to automate specific requests coming from our client base.  THE CHALLENGE: Deliver state-of-the-art data analytics and reporting solutions leveraging our data. Development of data visualizations and reports using statistical packages for analyzing datasets (Excel, PowerBI) Periodic reporting: automatic setup and distribution of reports Present ideas and solutions to business users and software developers in a clear and understandable way. Propose new, innovative ways of using data to improve our products and services Participate in Data modelling for reporting and analytics. Co-create and deliver an ambitious business intelligence roadmap in close coordination with various business and technical stakeholders in the Sportradar  YOUR PROFILE: Demonstrated technical expertise in the following areas: business intelligence tools, design & development of data analytics solutions and reports, querying databases. Prior experience working on projects related to data management and/or business intelligence. The successful candidate will be practiced in hands-on development of software or analytics solutions. Knowledge of VBA beneficial. Comfortable presenting to Senior OAM Management with good verbal and written communication skills Experience working with Amazon Redshift, Amazon Athena and/or Microsoft SQL Server are a benefit as is knowledge of Qlik View/Qlik Sense, Qlik NPrinting, NB: Must have previous experience working in the sports betting industry.  Sportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences.  Additional Information Sportradar is an Equal Opportunity Employer. We are committed to encourage diversity within our teams. All qualified applicants will receive consideration without regard to among other things, your background, status, or personal preferences  Company Description At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can’t wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.  With more than 7,400+ customers, we serve approximately 80% of the Fortune 500, and we're proud to be one of FORTUNE's 100 Best Companies to Work For® and World's Most Admired Companies® 2022. Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow. Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates. Job Description You will be part of the ServiceNow Cloud Services Big Data Team.  The Big Data team is building the next-generation platform that collects, stores and provides real-time access to large amounts of data. You will be driving the design and implementation of ServiceNow in-house real-time data visualization and analytics platform to support the growth of ServiceNow.  What you get to do in this role: Bring your innovation and experience in designing and developing the next generation data analytics platform using cutting-edge technologies.  Lead a global engineering team to drive end to end product design and implementation.  Standardize processes for complete development cycle including design, implementation, unit testing, code review, testing automation etc.  Research and adopt the right technologies to improve the scalability and productivity of the engineering group.  Work closely with key stakeholders and product owners to drive technical design for requirements of various use cases.  Coordinate with cross-function teams (DevOps, network, QA, etc.) to ensure a smooth cycle from development to deployment. Qualifications To be successful in this role you have: Hands-on experience architecting enterprise data analytics products with high scalability and performance. 6+ years of software development experience along with strong troubleshooting and debugging skills. Expert level skills with JavaScript, NodeJS, Webpack, ReactJS or other modern UI frameworks, Java and REST API developments. Background with data analytics, data visualization, BI tools and Hadoop ecosystem. Ability to produce high-quality software that is unit tested, code reviewed, and checked in regularly for continuous integration. Solid background in complicated SQL & data analytics. Zeal for learning and adopting new ideas and patterns. Strong Computer Science fundamentals,  data structures, algorithms, and software design. Additional Information ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law. At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office. If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance. For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government. Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.  From Fortune. © 2022 Fortune Media IP Limited All rights reserved. Used under license. Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow. Company at a GlanceOpenX is focused on unleashing the full economic potential of digital media companies. We do this by making digital advertising markets and technologies that are designed to deliver optimal value to publishers and advertisers on every ad served across all screens. At OpenX, we have built a team that is uniquely experienced in designing and operating high-scale ad marketplaces, and we are constantly on the lookout for thoughtful, creative executors who are as fascinated as we are about finding new ways to apply a blend of market design, technical innovation, operational excellence, and empathetic partner service to the frontiers of digital advertising. We are operating at a scale:100% Cloud-based (GCP) platformsOver 250 billion Ad requests every dayOver 120,000 CPU dailyOver 140 TB RAM dailyOver 50 PB of data per weekOver 1200 production deployments a month Who we are looking forOpenX is looking for a talented and highly motivated  Software Engineer  to help us innovate and improve our products. You will work in all aspects of agile application development, including both front-end and back-end systems. You will collaborate to design products that customers love and set OpenX apart. If you're:- Open-minded - happy to give & receive feedback, not afraid to fail and move on- Proactive - always want to find a satisfying solution- Self-organized and self-motivated We want to talk to you.  The OpportunityYou will work in all aspects of agile application development, including our enterprise platform that interfaces with a multitude of services that are dependent on to deliver billions of requests per day. Your opinions will be important in all phases of product development, starting from requirements to validation and deployment.Working on the enterprise platform, you will be working with multiple distributed teams to architect, create, and deliver new features and functionality in order to deliver the best possible advertising experience in the market. Scalability, performance, and rock-solid reliability are all factors to consider with every line you code. The Team and Project:You will be part of the core data development team. Our exchange handles billions of ad requests daily connecting thousands of publishers with demand partners. Each request produces data events that have to be processed to extract business value from them. Daily our applications produce more than 1PB of data.Please note: all interview stages are run remotely  What we offer Working with the newest technologies such as Cloud Computing (GCP) Experienced Team (50% of the company are senior developers!) Challenges at work that are difficult to find anywhere else! Solving important problems in a scale Joining a company that is growing and scaling Flexible working hours & hybrid work option (we would like you to come to the office once every two weeks) Key responsibilites Design large-scale data processing systems Work with Product to drive the requirements, and own the project end-to-end Analyze and improve efficiency, scalability, and stability of applications Think long-term and be unsatisfied with band-aids Identify unnecessary complexity and remove it Required Qualifications Ideally 5+ years of experience in Java development for large-scale Hadoop environments including performance tuning and monitoring Expertise using an appropriate mix of applications in the big data ecosystem (Kafka, Spark, Hadoop MapReduce, Hive, YARN, Zookeeper, HBase, and other NoSql products) Experience with databases system design, RDBMs, and/or NoSQL Cloud experience with Google Cloud Platform or AWS, k8s, and Docker Fluently speak algorithms, data structures, and platforms (Linux) Communicative Polish and English Desired qualifications/characteristics: Be comfortable using the right tools and languages for the job, even brand-new ones Have the ability to develop scalable, modular applications SCRUM / Agile environment experience Experience working in digital media, marketing technology, or advertising technology is a big plus Good written & oral communication skills Good sense of humor Team player Self-starter with the ability to independently identify and act on areas of improvement Our benefits Annual performance bonus Tax-deductible system due to copyright protection  Private health care for you and your family (covered by OpenX) Private life and travel insurance (Covid insurance included) MultiKafeteria program  Training: access to the LinkedIn Learning platform, Tech workshops, English lessons Holiday Allowance Pension scheme (PPK from PZU) Additional paid day off  Free parking lot  Access to peer to peer recognition platform Monthly work-from-home allowance and one-time payment when you join us to help you set up your home office We celebrate team members' important personal milestones (vouchers, gifts) OpenX VALUESOur five company values form a solid bedrock serving to define us as a group and guide the company. Our values remind us that how we do things often matters as much as what we do. WE ARE ONEWe are one team. There are no exceptions. We are a group of strong and diverse individuals unified by a shared mission. We embrace challenges and win together as a team. We respect and care about our colleagues and cultivate an inclusive culture WE ARE CUSTOMER CENTRICWe innovate on behalf of our customers. We understand, respect, and listen carefully to our customers. We build great products to solve our customers’ problems. We manage our customers’ expectations clearly and honestly. We are a trusted partner to all of our customers - we act with integrity at all times. We care. OPENX IS OURSWe innovate on behalf of our customers. We understand, respect, and listen carefully to our customers. We build great products to solve our customers’ problems. We manage our customers’ expectations clearly and honestly. We are a trusted partner to all of our customers - we act with integrity at all times. We care. WE ARE AN OPEN BOOKWe understand and respect what each of us does. We are eager to teach and share what we know with others, both internally and externally. We are eager to learn from others and we ask questions internally and externally.  WE EVOLVE FASTWe take responsible risks and own and learn from our mistakes. We recognize and repeat success. We actively seek out and provide constructive feedback. We adapt quickly and embrace change. We tackle growth and learning with real urgency. We are endlessly curious. OpenX is committed to equal employment opportunities. It is a fundamental principle at OpenX not to discriminate against employees or applicants for employment on any legally-recognized basis including, but not limited to: age, race, creed, color, religion, national origin, sexual orientation, sex, disability, predisposing genetic characteristics, genetic information, military or veteran status, marital status, gender identity/transgender status, pregnancy, childbirth or related medical condition, and other protected characteristic as established by law. OpenX Applicant Privacy PolicyApplicants can review our Applicant Privacy Policy at any time by visiting the following link: https://www.openx.com/privacy-center/applicant-privacy-policy/. Effective Date: March 1, 2022 About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Get to Know our Team:  Partner Development is a team of creative entrepreneurs that develop solutions for Agoda’s accommodation partners and promote Agoda’s top and bottom line growth. We design tailored business and product solutions with our partners and help them generate measurable value. Members of our team are empowered and supported to grow their market(s) or accounts. We develop win-win relationships and leverage Agoda’s unique accommodations portfolio and tech solutions to bring our partners the advantages they seek. Utilizing our strong brand and resources, we roll out new product to increase the visibility of Agoda, introduce more travelers to our great products and service and deliver significant revenues to the overall business. In this role you'll get to As a Data Analyst in the PD Analytics team, you will be using data and modeling techniques to identify opportunities and build models and tools to improve efficiency and effectiveness for Agoda's supply team.  Key activities involved include but not limit to: Apply your expertise in quantitative analysis, data mining, and the presentation of data to identify opportunities for business improvements and support your recommendations Own end-to-end project or roll out new experiments to validate in-market impact of an initiative within Partner Development Build dashboards, identify new and track key metrics to closely monitor team’s performance and identify quick and long term opportunities for improvements Work closely with cross-functional teams of analysts, regional team leads, product managers and business owners to drive changes based on opportunities identified Support global Partner Development related initiatives, including experimentation infrastructure-building and methodology standardization What you'll need to succeed  Bachelor’s degree in science, computer science, statistics, economics, mathematics, or similar quantitative discipline 3-6 years experience working in a business analysis, data analysis, reporting or business strategy role Excellent problem-solving skills including the ability to analyze and resolve complex problems using data Team player with strong interpersonal, relationship-building, and stakeholder management skills Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala) Data visualization tool experience such as with Tableau or your weapon of choice. Ability to work under pressure in a fast-paced and rapidly changing environment Excellent communication skills (both verbal and written in English), with proven ability to convey complex messages clearly and with conviction #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Company Summary: Tessera Therapeutics is pioneering Gene Writing™— a new biotechnology designed to offer scientists and clinicians the ability to write small and large therapeutic messages into the genome, thereby curing diseases at their source. Gene Writing holds the potential to become a new category in genetic medicine, building upon recent breakthroughs in gene therapy and gene editing while eliminating important limitations in their reach, utilization, and efficacy. Tessera Therapeutics was founded by Flagship Pioneering, a life sciences innovation enterprise that conceives, resources, and develops first-in-category companies to transform human health and sustainability.   Position Summary: Tessera is seeking a talented and motivated Computational Biologist to join our expanding Data Sciences team.  You will tackle challenging bioinformatics and computational biology problems to advance our understanding of Gene Writing and help accelerate programs to the clinic.  You will contribute scientific, technical, and leadership expertise to a multidisciplinary team, emphasizing conceptualization, experimentation, data analysis, presentation, and strategic planning.    Key Responsibilities: Work collaboratively with our platform and Biology teams to enable scientific discovery and progression through data analysis, data visualization, and data integration. Build and implement data analysis pipelines and storage solutions for various forms of sequencing primarily related to genotoxicity analysis, including Amplicon sequencing, long-read sequencing, One-seq, and chimeric read analysis. Design computational methods to combine and analyze off-target events, characterize mutations, and disentangle experiment-related features toward new biological hypotheses, providing project support to gene therapy project teams. Analyze human variations and how these variations may alter the genotoxic potential of our elements, onboarding relevant methods and datasets. Identify and acquire relevant public and third-party ‘omics data and perform integrative data analyses to generate insights that address strategic biological questions critical to Tessera’s core mission. Design and development of pipelines in a cloud environment with a standard software life cycle approach, releasing full documentation, and validation of the methods with statistical benchmarking. Operationalize data analysis aspects of relevant molecular assays to maximize the design, build, test cycle for platform and pipeline candidates. Structure and store data to enable data reuse, data mining, and machine learning, supporting data standardization and high-level data integration. Create compelling data visualizations and result presentations for internal and external dissemination.   Basic Qualifications: Ph.D./M.S. in Computational Biology, Bioinformatics, or related quantitative discipline. 8+ years of industry experience in discovery research. Proficient with experimental design, data processing, statistical analysis, and bioinformatics analysis/reporting of next-generation sequencing data. Experience analyzing gene therapy, gene editing, in vitro/vivo assay, genetics, genomics and cell biology data. Proficient interaction with experimental biologists to provide feedback on raw sequencing data quality. Strong grounding in biology or medicine. Strong data visualization skills and experience. Fluency in one or more programming languages with bioinformatics applications (R, Python). Track record of success working in a fast-paced, cross-functional, and rapidly growing organization. Outstanding written and verbal communication skills, ability to work with colleagues from diverse scientific backgrounds and cultures.   Preferred Qualifications: Experience with recent advances in gene therapy and development of gene editing platforms as therapeutics. Familiarity with short and long-read next-generation sequencing platforms (Illumina, PacBio, Nanopore). Proficiency in handling large-scale sequencing data in a cloud environment (AWS preferred). Proficiency in statistics and machine learning. Experience in virology or mobile genetic elements. More About Flagship Pioneering Flagship Pioneering has conceived of and created companies such as Moderna Therapeutics (NASDAQ: MRNA), Editas Medicine (NASDAQ: EDIT), Omega Therapeutics (NASDAQ: OMGA), Seres Therapeutics (NASDAQ: MCRB), and Indigo Agriculture. Since its launch in 2000, Flagship has applied its unique hypothesis-driven innovation process to originate and foster more than 100 scientific ventures. In 2021, Flagship Pioneering was ranked 12th globally on Fortune’s “Change the World” list, an annual ranking of companies that have made a positive social and environmental impact through activities that are part of their core business strategies. Flagship Pioneering and our ecosystem companies are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Recruitment & Staffing Agencies:  Flagship Pioneering and its affiliated Flagship Lab companies (collectively, “FSP”) do not accept unsolicited resumes from any source other than candidates.  The submission of unsolicited resumes by recruitment or staffing agencies to FSP or its employees is strictly prohibited unless contacted directly by Flagship Pioneering’s internal Talent Acquisition team.   Any resume submitted by an agency in the absence of a signed agreement will automatically become the property of FSP, and FSP will not owe any referral or other fees with respect thereto.    About Agoda  Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Overview: The Agoda Content department is currently looking for a curious and questioning self-starter and proactive analyst, who will help drive decision making with insights from content, marketing and partner performance data. You will get the opportunity to own analytical projects to direct our department’s focus, and prioritize our actions. By joining Agoda, you will become part of a truly international team, with leading experts of different backgrounds coming from 50+ countries around the world. This is a genuine opportunity to gain valuable experience in a challenging and cutting-edge tech environment. The ideal candidate would have a passion for high-converting content, great user-experience, data and analysis tools and methods. This position reports to the Associate Director of Content Operations, in Bangkok, Thailand.   Main responsibilities: Understand Content goals and KPIs and be able to align reports and insights based on them. Identify and investigate trends, anomalies and opportunities to improve Agoda’s Content strategy. Identify content opportunities that drive customer value, bookings and conversion Help build business cases around the opportunity and get buy-in from stakeholders Ensure appropriate data/tools/dashboards to measure execution and enable deeper analysis Track execution and report up in regular updates Work with product, data/BI team and IT to create data resources and build appropriate reporting Work with Content team leads to understand their business needs and identify opportunities in terms of team actions prioritization and focus. Use multiple data sources to report Content projects insights and impact; support Content tests and experiments. Encourage and train the Content team in best practice use of Agoda data, analysis techniques and interpretation. Coordinate with other Cross Functional departments like Analytics, Partner Services, and Product Owners Use Web-Analytics for Research and Analysis Requirements: Bachelor degree or higher 2+ years of relevant experience Experience / knowledge in statistics, SQL, Python/R, Tableau and advanced Excel – required Ability to demonstrate data manipulation using data warehouse and create meaningful insight and visualization Experience / knowledge in Vertica and / or Impala – advantage Experience in generating data and / or preparing experiments for product development – advantage Professional characteristics: Attentive to detail and committed to data integrity Keen and curious nature; able and willing to share your opinion Organized; able to manage multiple, competing priorities and deliver results under tight deadlines Able to communicate effectively; fluent in English – both spoken and written #STRA#ANLS#MRKT#3#LI-TR2 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz #linz #baku #minsk #brussels #antwerp #ghent #charleroi #liege #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra #lisbon #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester #liverpool #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics power bi Equal Opportunity Employer  At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.         Who We Are Verily is a subsidiary of Alphabet that is using a data-driven approach to change the way people manage their health and the way healthcare is delivered. Launched from Google X in 2015, Our purpose is to bring the promise of precision health to everyone, every day. We are focused on generating and activating data from a variety of sources, including clinical, social, behavioral and the real world, to arrive at the best solutions for a person based on a comprehensive view of the evidence. Our unique expertise and capabilities in technology, data science and healthcare enable the entire healthcare ecosystem to drive better health outcomes. Verily’s internship is a paid 13 week program for rising seniors, either undergraduate or graduate students, who are interested in working at the intersection of technology, data science and healthcare. The program is designed for Computer Science and Data Science students, and again this year we encourage students who have been historically underrepresented in this field to explore the program, which is a pathway towards full-time employment within Verily. This includes but is not limited to: women, Black/African-American, Latine/Hispanic, Native American, people with disabilities, veterans, and members of the LGBTQ+ community. Description Our Data Science group specializes in analyzing and building models to help make sense of large datasets resulting from bio-sensors, digital pathology, clinical informatics, molecular assays and patient surveys. We combine domain knowledge and programming expertise with statistical and machine learning knowledge to build scalable models and solutions that help power Verily’s various product areas. For this position, we are looking for interns with experience and interest in computational biology. As a Data Scientist intern working on Computational Biology, you will be joining a team making use of diverse ‘omics data to improve biomarker and target discovery in different disease settings. You will help develop and implement methods to analyze and derive insights from large, disease-focused datasets from the Immune Profiler platform. **Join us for a unique 13 week internship that will take place May 15th to August 11th 2023 OR June 19th to September 15th 2023.   Responsibilities Develop performant and reusable models and libraries from original architecture. Review literature related to the project area and integrate relevant domain knowledge. Analyze complex ‘omics data sets in combination with clinical and other data. Communicate technical results and methods to cross-functional teams. Qualifications Minimum Qualifications Currently enrolled as a full-time student in a PhD program in a quantitative discipline (e.g., Computational Biology, Bioinformatics, Statistical Genetics, Computer Science, or related) with an anticipated graduation date at or before the end of 2024.  Authorization to work in the United States. Expertise in statistical data analysis, modeling, machine learning, and exploratory data analysis. Programming experience in R.  Preferred Qualifications Experience working with clinical study data in any disease setting. Familiarity with software engineering practices and experience developing production software. Programming experience in SQL and/or bash.  Outstanding oral and written communication and teamwork.   The US base pay range for this intern position is $50.48-$61.06. Our pay ranges are determined by role, education level, experience, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire pay ranges for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific pay range for your preferred location during the hiring process.   Why Join Us Build What’s Vital. At Verily, you are a part of something bigger. We are a diverse team of builders innovating at the intersection of health and technology—united by a shared spirit of curiosity, resilience and determination to make better health possible for all. This builder mindset means your fingerprints will be on the work that shapes the future of health. Fulfilling our precision health purpose starts with the health of our Veeps (what we call our employees), which is why we offer flexibility, resources, and competitive benefits to support you in your whole-person well being. We believe diversity of thought drives innovation—we unite the brightest minds, and encourage all Veeps to bring their lived experience to work with them. If this sounds exciting to you, we would love to hear from you. You can find out more about our company culture on our LinkedIn Company Page and Verily Careers page. We are Kaizen Gaming Kaizen Gaming is the leading GameTech company in Greece and one of the fastest-growing in Europe, with the Stoiximan brand in Greece and Cyprus and Betano in Germany, Romania, Bulgaria, Czech Republic, Portugal, Brazil, Chile, Peru, Ecuador and Canada. Our aim is to leverage cutting-edge Technology in order to provide the optimum experience to those who trust us for their entertainment. The Role We’re looking for a Reporting Principal Engineer to join our Big Data reporting team, who will help teams devise elegant and performant solutions in response to real business problems, guide them in designing and implementing these solutions in code, as well as teach coding, testing, and performance analysis techniques, while also carrying out code reviews. Will frequently attend teams' scrum events (esp. refinements) and help teams' product owners shape a better understanding of the technical challenges involved. Production problems are usually escalated to Principal Engineer for triaging before landing in a team's backlog. Principal Engineers should also stay up to date on the latest technologies and drive their adoption.   The Team Our Big Data reporting team(s) consists of twelve members with diverse backgrounds and expertise in several fields including, but not limited to, Databricks/ Delta lake/ SQL Server/ Azure Data Warehouse/ SSRS/ SSIS.   Responsibilities Lead team enablement initiatives; Orchestrate the plan by motivating other team members and collaborating closely in achieving it; Break the efforts down and work closely by guiding the reporting engineers through gaps to lead them to sound technical solutions; Technical expertise and knowledge sharing. Present practices, innovations, and inventions inside and outside of the organization; Partner with management to find new potential talent; Mentor engineers to take them to the next level of their careers; Set up cross-organization engineering best practice standards and guidelines. Create a culture where the contribution patterns and quality are paramount. They partner closely with teams to implement them.   Requirements Must have: 8+ years of hands-on experience in writing complex, highly optimized SQL code for data manipulation and reporting; 5+ years of experience in ETL/ELT, Data Modeling, Data Warehouse Architecture and Reporting tools; Knowledge of Data Governance; Team player, analytical thinker and problem solver, with ability to self-organize; Fast learner - you will need to get up to speed on business, people and teams, infrastructure and the technologies used, as quickly as possible. Nice to have: A bachelor's degree in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering) or equivalent industry experience; Experience in the Microsoft BI stack (SQL Server, SSRS, SSAS); Experience with Azure Data platforms such as Synapse Analytics, Data Lake, Databricks;  Experience in programming languages preferable in Python or Scala; Exposure to CI/CD; Exposure to an Agile team-working environment.   Kaizen Gaming Perks 🕑 Work from home & remote working options. 🏃 A buddy will support you with your onboarding. 💸Competitive salary package and bonus scheme. 👩‍⚕️ Health and life insurance for you and your family. 💰 Monthly allowance for lunch & commuting expenses. 💻Nice rigs - 2.5K monitor, latest i7, tons of RAM, fast SSD. 📚 Pluralsight, unlimited access to Udemy & continuous training for all your learning and development needs. ⭐Clear career paths & a developmental 360° feedback framework. ✈️ Relocation package and "Brain Gain" relocation bonus for Greek expats. Recruitment Privacy Notice Regarding the data you share with us, you may find and read our recruitment privacy notice here.